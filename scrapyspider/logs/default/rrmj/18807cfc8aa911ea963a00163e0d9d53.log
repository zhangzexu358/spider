2020-04-30 14:09:19 [scrapy.utils.log] INFO: Scrapy 2.0.1 started (bot: spiderV1)
2020-04-30 14:09:19 [scrapy.utils.log] INFO: Versions: lxml 4.5.0.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 20.3.0, Python 3.7.1 (default, Mar 24 2020, 11:45:49) - [GCC 4.8.5 20150623 (Red Hat 4.8.5-39)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Linux-3.10.0-1062.18.1.el7.x86_64-x86_64-with-centos-7.7.1908-Core
2020-04-30 14:09:19 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
2020-04-30 14:09:19 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'spiderV1',
 'COOKIES_ENABLED': False,
 'DOWNLOAD_DELAY': 2,
 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter',
 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage',
 'LOG_FILE': 'logs/default/rrmj/18807cfc8aa911ea963a00163e0d9d53.log',
 'NEWSPIDER_MODULE': 'spiderV1.spiders',
 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler',
 'SPIDER_MODULES': ['spiderV1.spiders']}
2020-04-30 14:09:19 [scrapy.extensions.telnet] INFO: Telnet Password: 4cc67ea64efc5d3e
2020-04-30 14:09:19 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.memusage.MemoryUsage',
 'scrapy.extensions.logstats.LogStats']
2020-04-30 14:09:19 [rrmj] INFO: Reading start URLs from redis key 'rrmj:spider:strat_urls' (batch size: 16, encoding: utf-8
2020-04-30 14:09:19 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'spiderV1.middlewares.SeleniumMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'spiderV1.middlewares.ScrapytestDownloaderMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2020-04-30 14:09:19 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2020-04-30 14:09:19 [py.warnings] WARNING: /root/spider/scrapyspider/spiderV1/pipelines.py:80: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  temp = yaml.load(f.read())

2020-04-30 14:09:19 [scrapy.middleware] INFO: Enabled item pipelines:
['spiderV1.pipelines.SaveDataToFile']
2020-04-30 14:09:19 [scrapy.core.engine] INFO: Spider opened
2020-04-30 14:09:19 [rrmj] DEBUG: Resuming crawl (318 requests scheduled)
2020-04-30 14:09:19 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2020-04-30 14:09:19 [rrmj] INFO: Spider opened: rrmj
2020-04-30 14:09:19 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6025
2020-04-30 14:09:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/2373162/> (referer: https://www.douban.com/search?q=%E7%BB%BF%E5%8C%96%E4%B8%96%E7%95%8C)
2020-04-30 14:09:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/2373162/>
{'cover': 'http://img.rr.tv/album/20190906/o_1567767436458.png',
 'data_type': 'movie',
 'id': 'rrmj_15142',
 'intro': 'Four adventurers descend to the depths of the ocean when the cable '
          'on their underwater diving bell snaps. The rest of their '
          'expedition, believing them to be lost, abandons hope of finding '
          'them. Exiting the diving bell, the party finds themselves in a '
          'network of underwater caverns. They encounter a shipwreck survivor. '
          'He tells them he has been there for 14 years and that there i...',
 'is_new': False,
 'name': '绿化世界',
 'platforms': '',
 'publishdate': '2018-02-23',
 'rate': 0.0,
 'sectionid': 'rrmj_1005',
 'tags': ['科幻', '冒险'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/2373162/'}
2020-04-30 14:09:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%97%B6%E5%B0%9A%E5%A4%A7%E5%B8%9D%20> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:09:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/4843480/> (referer: https://www.douban.com/search?q=%E7%9B%91%E5%AE%88%E8%87%AA%E7%9B%97)
2020-04-30 14:09:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/4843480/>
{'cover': 'http://img.rr.tv/album/20180705/o_1530759256403.png',
 'data_type': 'movie',
 'id': 'rrmj_12601',
 'intro': '2008年，全球金融海啸，多国陷入金融危机，损失高达20万亿美元，数以百万计人加入失业大军，甚至丧失家园……本片通过详尽的资料搜集，追访全球金融业界猛人、政客、财经记者，披露金融大鳄的崛兴之路，公开业内和学界贪污腐败的政策背后的惊人真相。',
 'is_new': False,
 'name': '监守自盗',
 'platforms': '',
 'publishdate': '2010-10-08',
 'rate': 8.7,
 'sectionid': 'rrmj_1871',
 'tags': ['纪录片', '犯罪'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/4843480/'}
2020-04-30 14:09:22 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/4881630/> (referer: https://www.douban.com/search?q=%E7%82%AB%E8%BD%A6%E9%85%B7%E9%A9%BE)
2020-04-30 14:09:22 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/4881630/>: HTTP status code is not handled or not allowed
2020-04-30 14:09:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30291579/> (referer: https://www.douban.com/search?q=%E4%B8%8D%E6%9C%9F%E8%80%8C%E7%88%B1)
2020-04-30 14:09:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30291579/>
{'cover': 'http://img.rr.tv/album/20181011/o_1539244237423.jpg',
 'data_type': 'movie',
 'id': 'rrmj_12922',
 'intro': '该剧讲述在工程学院中，有八位性格迥异的男生，他们各怀不同的梦想，上演着不一样的人生。Ae（Perth-王俊勇饰）善良慷慨、不计回报，不畏权势；Pete（Saint-黄明明饰）善良，单纯，生活在象牙塔中涉世未深的懵懂少年，但勇于面对内心真实的自己；Tin（Mean-洪天逸饰）商业世家继承人，冷酷、自信。信奉人与人之间是利益关系，没有真情；Can（Plan-林乐杰饰）活泼厚脸皮、讲义气，路见不平拔刀相助，愿为朋友两肋插刀；Techno（Gun-陈智霆饰）学院足球队队长，温柔耐心，暖心的大哥哥；Kengkla（Mark-陈瑞书饰）聪明可爱、有点小腹黑。他们同在工程学院读书，虽然身份背景、性格爱好都不相同，但却不妨碍他们成为各自成长路上的小伙伴、好朋友，相互扶持、陪伴自己共同成长。',
 'is_new': False,
 'name': '不期而爱',
 'platforms': '',
 'publishdate': '2018-08-03',
 'rate': 8.6,
 'sectionid': 'rrmj_989',
 'tags': ['爱情', '同性'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30291579/'}
2020-04-30 14:09:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30372302/> (referer: https://www.douban.com/search?q=%E6%B7%B1%E8%93%9D%E4%B9%8B%E5%90%BB)
2020-04-30 14:09:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30372302/>
{'cover': 'http://img.rr.tv/cover/20191009/o_1570616516789.jpg',
 'data_type': 'movie',
 'id': 'rrmj_16099',
 'intro': '《深蓝之吻》是Kiss Me series的延伸，改编自泰国同名人气小说。故事中的Kao和Pete起初互相看不顺眼，后来却激发感情。 '
          '《深蓝》描述两人交往之后的恋爱日常，男男恋爱难以向家人坦白。Pete&Kao人气CP甜蜜回归，还有暖男店长Sun收服不良少年Mork的热血爱情浪漫插曲。',
 'is_new': False,
 'name': '深蓝之吻',
 'platforms': '',
 'publishdate': '2019-10-12',
 'rate': 8.6,
 'sectionid': 'rrmj_989',
 'tags': ['爱情', '同性'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30372302/'}
2020-04-30 14:09:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30486608/> (referer: https://www.douban.com/search?q=%E7%BC%98%E6%9D%A5%E8%AA%93%E4%BD%A0)
2020-04-30 14:09:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30486608/>
{'cover': 'http://img.rr.tv/cover/20200114/o_1578995688775.jpg',
 'data_type': 'movie',
 'id': 'rrmj_17018',
 'intro': 'Zon某天发现自己的妹妹Soul把他写进了耽美小说里，Zon发誓说这些情节绝对不会发生在自己的身上，然而最后认识了Saifah之后，两个人都是互相看对方不顺眼，但是自从一起参加音乐活动开始，从此命运让他们紧紧相连。Tutor曾经是个富二代少爷，突然有一天家里破产了，从少爷变成了穷小子，Fighter是个富二代，喜欢用金钱来解决问题，一开始两人也是相互不喜欢，可是随着时间的推移，两人慢慢相处之后逐渐爱上了对方。',
 'is_new': False,
 'name': '缘来誓你',
 'platforms': '',
 'publishdate': '2020-01-24',
 'rate': 8.0,
 'sectionid': 'rrmj_989',
 'tags': ['爱情', '同性'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30486608/'}
2020-04-30 14:09:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30488639/> (referer: https://www.douban.com/search?q=%E5%8F%8C%E5%AD%90%E5%81%B7%E5%BF%83)
2020-04-30 14:09:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30488639/>
{'cover': 'http://img.rr.tv/album/20190426/o_1556250588376.jpg',
 'data_type': 'movie',
 'id': 'rrmj_14673',
 'intro': '爱情来了第一部的主演Pak和Mild再次合体之作。                                                                            \u3000\u3000'
          'The Best '
          'Twins《双子偷心》这部剧是讲述一对双胞胎兄弟的故事。                                                                            \u3000\u3000'
          'Pond和Per是一对双胞胎兄弟，Per是弟弟喜欢女孩子，是个直男，Pond是喜欢男孩子的，Pond的男友是隔壁的邻居Bon老师。这对双胞胎的姐姐Pad反对Per和男生交往，不接受弟弟的性向，这让他们的家庭关系受到震动。                                                                            \u3000\u3000'
          '不仅如此，当Pond的前男友Tee回来时，让事情变得更复杂。Pond在现任男友，前男友和姐姐之间的关系让他感到崩溃。                                                                            \u3000\u3000'
          '在剧集中，哥哥Pond是大学教授，弟弟Per是电影编辑，虽然他们的姐姐Pad很反对弟弟是个gay，但是Pad内心是十分疼爱两个弟弟，Pad的职业是高中老师。                                                                            \u3000\u3000'
          'Mild扮演的Tee是Per的前男友，是一名大学生，究竟这对双胞胎兄弟将如何处理生活和情感上的这几层关系呢？一切答案让我们期待3月30...',
 'is_new': False,
 'name': '双子偷心',
 'platforms': '',
 'publishdate': '2019-03-30',
 'rate': 5.6,
 'sectionid': 'rrmj_989',
 'tags': ['爱情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30488639/'}
2020-04-30 14:09:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/33218295/> (referer: https://www.douban.com/search?q=%E7%88%B1%E6%83%85%E6%95%88%E5%BA%94)
2020-04-30 14:09:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/33218295/>
{'cover': 'http://img.rr.tv/cover/20190919/o_1568874061248.jpg',
 'data_type': 'movie',
 'id': 'rrmj_15913',
 'intro': '泰剧爱情效应是根据泰国网络小说《The '
          'Effect》改编而成。                                                                    \u3000\u3000'
          'Keng是这所学校里人见人爱花见花开的大帅哥，不仅学习厉害各方面都非常优秀。                                                                    \u3000\u3000'
          'Chin是一个不善于交谈的大一新生，经常最好的朋友Pramote待在一起。                                                                    \u3000\u3000'
          '突然有一天Chin不小心撞到了Keng，当他和他相遇之后，两人之间多次的相见让他们很快的有了好感，但是偶然的间他们相依相偎的照片被上传到网络之后，一瞬间都在讨论Chin和Keng的事情，网络的暴力让Chin无法承受，所以决定和Keng分手，但是Keng非常的喜欢Chin所有在情急之下Keng就把Chin给强奸了，他们的爱情看似非常的偶然，其实他们是双向暗恋哟，他们的爱情虽然坎坷备受网友的质疑，他们的爱情能否不顾世俗的眼光而成功走向胜利吗？这个8月敬请期待……',
 'is_new': False,
 'name': '爱情效应',
 'platforms': '',
 'publishdate': '2019-10-11',
 'rate': 8.0,
 'sectionid': 'rrmj_989',
 'tags': ['爱情', '同性'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/33218295/'}
2020-04-30 14:09:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/33418663/> (referer: https://www.douban.com/search?q=%E5%9B%A0%E4%B8%BA%E6%83%B3%E4%BD%A0)
2020-04-30 14:09:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/33418663/>
{'cover': 'http://img.rr.tv/album/20190429/o_1556510626519.jpg',
 'data_type': 'movie',
 'id': 'rrmj_14686',
 'intro': '我想我喜欢的始终是那份像夏天一样炙热的感情。至于白船他们作为演员不可能永远只被这两个角色困住，当我看到预告的时候先是激动万分，随即有一点失落，因为我很难从现在这个英俊帅气的船身上找到闹闹的青涩和烂漫。那个小平头200斤大腿和基友们弹吉他唱歌的音乐社社长，长大了更帅气也更成熟了。这可能是成长的过程是不可逆的，所以我想算了船会长大，闹闹又何尝不是呢，能够现在发糖让我们怀念一下初心，怀念一下曾经追剧的欢乐时光也没什么不好。而白白深情的杏仁眼真的还是那个学生会秘书长啊～',
 'is_new': False,
 'name': '因为想你',
 'platforms': '',
 'publishdate': '2019-04-17',
 'rate': 6.8,
 'sectionid': 'rrmj_989',
 'tags': ['剧情', '同性'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/33418663/'}
2020-04-30 14:09:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/34894678/> (referer: https://www.douban.com/search?q=%E6%98%8E%E6%97%A5%E5%AE%B6%E6%97%8F)
2020-04-30 14:09:39 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/34894678/>
{'cover': 'http://img.rr.tv/cover/20200107/o_1578385259299.jpg',
 'data_type': 'movie',
 'id': 'rrmj_16978',
 'intro': '小野寺理纱（宫崎葵饰）四年前在婚礼上遭遇新郎逃婚，现如今心情已经平复，一直跟父母生活在一起。其父亲俊作（松重丰饰）曾经是糕点生产公司的营业部部长，现因人事变动被调到了其他的部门，而该部门新上任的部长就是俊作曾经的下属兵头幸太郎（永山瑛太饰）。其母真知子（松坂庆子饰）是一个性格开朗的家庭主妇，经常去仓桥响子（一路真辉饰）开的插花班上课。仓桥响子的前夫村上洋一（六平直政饰）是俊作的发小兼前辈，他经营了一家小酒馆，俊作是他家的常客。                                                                            \u3000\u3000'
          '四年前父亲俊作为了想和女儿女婿住在一起建了一栋双户型的别墅，然而因为理纱被逃婚，现在就理纱、俊作以及真知子，这一家三口住在别墅里。某天理纱说自己被求婚了，要带个对象回来给俊作和真知子看看，谁知带回来的人竟然是兵头幸太郎。之前的下属，现如今成了自己的上司兼准女婿……                                                                            \u3000\u3000'
          '理纱和幸太郎的感情究竟会如何发展？理纱、幸太郎会和俊作及真知子...',
 'is_new': False,
 'name': '明日家族',
 'platforms': '',
 'publishdate': '2020-01-05',
 'rate': 8.1,
 'sectionid': 'rrmj_745',
 'tags': ['剧情', '家庭'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/34894678/'}
2020-04-30 14:09:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/34908103/> (referer: https://www.douban.com/search?q=%E8%B6%85%E8%83%BD%E8%AD%A6%E6%8E%A2)
2020-04-30 14:09:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/34908103/>
{'cover': 'http://img.rr.tv/cover/20200224/o_1582513500113.jpg',
 'data_type': 'movie',
 'id': 'rrmj_17222',
 'intro': '该剧改编自同名人气网漫，讲述失忆的超能力刑警“东柏”遇到连续杀人事件后发生的故事。                                                                    \u3000\u3000'
          '由电影《邻居》《石雕宅邸杀人案》的金辉导演、《恩珠的房间》苏在贤导演共同执导，2020年播出。',
 'is_new': False,
 'name': '超能警探',
 'platforms': '',
 'publishdate': '2020-03-11',
 'rate': 8.0,
 'sectionid': 'rrmj_745',
 'tags': ['悬疑', '犯罪', '奇幻'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/34908103/'}
2020-04-30 14:09:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/3184572/> (referer: https://www.douban.com/search?q=%E7%B4%A7%E6%80%A5%E6%95%91%E5%91%BD)
2020-04-30 14:09:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/3184572/>
{'cover': 'http://img.rr.tv/album/20180504/o_1525417199063.webp',
 'data_type': 'movie',
 'id': 'rrmj_12110',
 'intro': '拥有直升机紧急救援的大学附属医院迎来了一批实习医生。他们分别是蓝泽耕作（山下智久 饰）、白石惠（新垣结衣 饰）、绯山美帆子（户田绘里香 '
          '饰）和滕川一男（浅利阳介 '
          '饰）。直升机每天平均运送7到8个急救患者，能协助医生坐上直升飞机是对其应变能力和医术的证明，大家都跃跃欲试。                                                                    \u3000\u3000'
          '四人的性格各不相同。蓝泽最有能力但过于冷静；白石理论知识很强但缺乏魄力；绯山表现欲强但易冲动；滕川则相对平庸做事马虎。最初开始的紧急救援让大家手忙脚乱，看似拉风的直升机需要与之相应的能力与魄力。在一系列救援的过程中，他们直面死亡与无奈，也鉴证奇迹，体味人情。互为竞争对手的他们，谁能最终留下来？还是携手共进？',
 'is_new': False,
 'name': '紧急救命',
 'platforms': '',
 'publishdate': '2008-07-03',
 'rate': 8.2,
 'sectionid': 'rrmj_1646',
 'tags': ['剧情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/3184572/'}
2020-04-30 14:09:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/5907534/> (referer: https://www.douban.com/search?q=%E5%8D%96%E8%BA%AB%E7%94%B7%E5%AD%90)
2020-04-30 14:09:46 [scrapy.core.scraper] ERROR: Error processing {'cover': 'http://img.rr.tv/album/20190613/o_1560419542385.webp',
 'data_type': 'movie',
 'id': 'rrmj_15083',
 'intro': 'An intimate and unflinching look over 12 months at the hardscrabble '
          'lives of hustlers in downtown Montreal.',
 'is_new': False,
 'name': '卖身男子',
 'platforms': '',
 'publishdate': '',
 'rate': 7.3,
 'sectionid': 'rrmj_1416',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/5907534/'}
Traceback (most recent call last):
  File "/usr/python37/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/python37/lib/python3.7/site-packages/scrapy/utils/defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/root/spider/scrapyspider/spiderV1/pipelines.py", line 262, in process_item
    timeStruct = time.strptime(publishdate, '%Y-%m-%d')
  File "/usr/python37/lib/python3.7/_strptime.py", line 571, in _strptime_time
    tt = _strptime(data_string, format)[0]
  File "/usr/python37/lib/python3.7/_strptime.py", line 359, in _strptime
    (data_string, format))
ValueError: time data '' does not match format '%Y-%m-%d'
2020-04-30 14:09:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/10787752/> (referer: https://www.douban.com/search?q=%E4%BF%AF%E7%9E%B0%E5%BE%B7%E5%9B%BD)
2020-04-30 14:09:48 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/10787752/>
{'cover': 'http://img.rr.tv/album/20190906/o_1567768083406.png',
 'data_type': 'movie',
 'id': 'rrmj_15136',
 'intro': '俯瞰德国第一季分城市、乡村、河流三集不同地貌特征鸟瞰全景，在展示自然景致的同时，也涉及到很多当代科技和历史文化，是一部很不错的国家形象宣传片。',
 'is_new': False,
 'name': '俯瞰德国',
 'platforms': '',
 'publishdate': '2010-05-23',
 'rate': 9.2,
 'sectionid': 'rrmj_1005',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/10787752/'}
2020-04-30 14:09:50 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/27028198/> (referer: https://www.douban.com/search?q=%E7%9D%80%E8%A3%85%E5%AE%88%E5%88%99)
2020-04-30 14:09:50 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/27028198/>: HTTP status code is not handled or not allowed
2020-04-30 14:09:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27183365/> (referer: https://www.douban.com/search?q=%E6%80%AA%E5%A5%87%E8%83%8C%E5%90%8E)
2020-04-30 14:09:53 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/27183365/>
{'cover': 'http://img.rr.tv/album/20190509/o_1557389195531.png',
 'data_type': 'movie',
 'id': 'rrmj_14783',
 'intro': 'Netflix叫好叫座剧《怪奇物语 Stranger '
          'Things》第二季即将上线，而该媒体表示紧接主剧上线后，其访谈节目《Beyond Stranger '
          'Things》亦会同日上线。《怪奇背后》由编剧/制作人/演员Jim Rash主持，会有幕后故事﹑第二季分析及解答一些问题。',
 'is_new': False,
 'name': '怪奇背后',
 'platforms': '',
 'publishdate': '2017-10-27',
 'rate': 8.8,
 'sectionid': 'rrmj_1405',
 'tags': ['脱口秀'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/27183365/'}
2020-04-30 14:09:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27186532/> (referer: https://www.douban.com/search?q=%E5%A4%8D%E4%BB%87%E7%AC%94%E8%AE%B0)
2020-04-30 14:09:55 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/27186532/>
{'cover': 'http://img.rr.tv/album/20180530/o_1527670847400.jpg',
 'data_type': 'movie',
 'id': 'rrmj_12313',
 'intro': '讲述了一个爱管闲事,平凡的女高中生,通过某一天给自己的复仇笔记软件解决了自己冤屈的事情,明白了家人和朋友的珍贵,自我成长的故事。',
 'is_new': False,
 'name': '复仇笔记',
 'platforms': '',
 'publishdate': '2017-10-27',
 'rate': 8.0,
 'sectionid': 'rrmj_1244',
 'tags': ['剧情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/27186532/'}
2020-04-30 14:09:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27611421/> (referer: https://www.douban.com/search?q=%E6%BB%91%E6%9D%BF%E5%B0%91%E5%B9%B4)
2020-04-30 14:09:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/27611421/>
{'cover': 'http://img.rr.tv/album/20190717/o_1563347739090.jpg',
 'data_type': 'movie',
 'id': 'rrmj_15359',
 'intro': '导演刘冰将镜头对准了从小与自己一起玩滑板的好友们。年纪最大的Zack初为人父，新生儿的降临似乎让Zack一夜之间长大，但随之而来的生存压力与家庭矛盾也让他接近崩溃。Keira刚刚成年，初入社会的他充满迷茫，纪录片的拍摄给了他重新审视自己的过往与家庭，以及周遭一切的契机。刘冰也交出镜头，讲述了自己的故事，是什么让他选择了滑板？又是什么促使他拍摄了这部纪录片？',
 'is_new': False,
 'name': '滑板少年',
 'platforms': '',
 'publishdate': '2018-01-21',
 'rate': 8.7,
 'sectionid': 'rrmj_1657',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/27611421/'}
2020-04-30 14:09:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30127189/> (referer: https://www.douban.com/search?q=%E7%BE%8E%E9%A3%9F%E4%B8%8D%E7%BE%8E)
2020-04-30 14:09:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30127189/>
{'cover': 'http://img.rr.tv/album/20180704/o_1530666490901.jpg',
 'data_type': 'movie',
 'id': 'rrmj_12562',
 'intro': 'NetFlix原创纪录片，味道至上，绝不废话。明星大厨 David Chang '
          '带朋友们踏上令人口水直流的跨文化之旅，探寻世上最令人满意的美味佳肴。',
 'is_new': False,
 'name': '美食不美',
 'platforms': '',
 'publishdate': '2018-02-23',
 'rate': 8.8,
 'sectionid': 'rrmj_1883',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30127189/'}
2020-04-30 14:10:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30171321/> (referer: https://www.douban.com/search?q=%E7%BB%9D%E5%AF%B9%E8%BE%BE%E4%BB%A4)
2020-04-30 14:10:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30171321/>
{'cover': 'http://img.rr.tv/album/20190510/o_1557459792403.jpg',
 'data_type': 'movie',
 'id': 'rrmj_14628',
 'intro': '该剧是由日本人气漫画《绝对达令》改编，讲述了因受情伤变得心硬如铁的特殊化妆师多多，在大明星马王俊和恋爱用人偶英久之间纠缠不断的恋爱故事的奇幻浪漫喜剧。',
 'is_new': False,
 'name': '绝对达令',
 'platforms': '',
 'publishdate': '2019-05-15',
 'rate': 6.9,
 'sectionid': 'rrmj_1244',
 'tags': ['喜剧', '爱情', '科幻', '奇幻'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30171321/'}
2020-04-30 14:10:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30263943/> (referer: https://www.douban.com/search?q=%E6%97%A5%E6%9C%AC%E4%B9%8B%E8%80%BB)
2020-04-30 14:10:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30263943/>
{'cover': 'http://img.rr.tv/album/20180808/o_1533695713924.jpg',
 'data_type': 'movie',
 'id': 'rrmj_12934',
 'intro': '这部电影讲述了一位29岁的日本记者伊藤诗织的动人故事，她声称自己是在2015年的一次工作晚餐会上被时任东京广播公司华盛顿分社的社长、日本首相安倍晋三的传记作者山口敬之强奸。但山口先生强烈否认了这一说法。                                                                    \u3000\u3000'
          '尽管向警方报案，但警方要求伊藤用真人大小的娃娃重新模拟所谓的强奸案，该案件经过一年的调查后被撤销。当伊藤采取前所未有的决定公开她的指控并揭露她的身份时，她遭到了公开的羞辱和仇恨邮件。                                                                    \u3000\u3000'
          '这部影片在上映后的一年内，以独特的方式记录了伊藤。虽然全球MeToo运动激励全世界的女性大肆宣传他们对性侵犯的指控，但在日本的回应却很平静。伊藤没有被吓倒，她访问了认为她失败的机构，并见了其他害怕不敢说话的女性。这部电影将伊藤的故事与日本更广泛的社会背景交织在一起，直到2017年，强奸的最低刑期短于盗窃。',
 'is_new': False,
 'name': '日本之耻',
 'platforms': '',
 'publishdate': '2018-06-28',
 'rate': 9.1,
 'sectionid': 'rrmj_1903',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30263943/'}
2020-04-30 14:10:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30304086/> (referer: https://www.douban.com/search?q=%E8%A7%A6%E5%8F%8A%E7%9C%9F%E5%BF%83)
2020-04-30 14:10:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30304086/>
{'cover': 'http://img.rr.tv/album/20190111/o_1547175327204.jpg',
 'data_type': 'movie',
 'id': 'rrmj_13854',
 'intro': '该剧翻拍自同名网络小说，讲述巨星演员吴允书因突然爆发的和富三代之间的丑闻而一落千丈，为了出演著名编剧的电视剧，不惜伪装成以龟毛而出名的韩国顶尖律师权政录的秘书。',
 'is_new': False,
 'name': '触及真心',
 'platforms': '',
 'publishdate': '2019-02-06',
 'rate': 7.7,
 'sectionid': 'rrmj_1244',
 'tags': ['剧情', '喜剧', '爱情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30304086/'}
2020-04-30 14:10:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%A6%96%E6%80%AA%E4%BA%BA%E9%97%B4> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:10:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30327894/> (referer: https://www.douban.com/search?q=%E7%A6%81%E5%BF%8C%E5%A5%B3%E5%AD%A9)
2020-04-30 14:10:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30327894/>
{'cover': 'http://img.rr.tv/album/20190822/o_1566484306145.jpg',
 'data_type': 'movie',
 'id': 'rrmj_14094',
 'intro': '来自未名地方的新生 Nanno '
          '如伊甸园的毒蛇，放大人们的欲望，揭露心灵深处的黑暗。他是令人尊敬的老师，一场视频风波揭露了老师背后的肮脏行为，性侵、威胁，道貌岸然的样子由 '
          'Nanno 来放大！',
 'is_new': False,
 'name': '禁忌女孩',
 'platforms': '',
 'publishdate': '2018-08-08',
 'rate': 8.3,
 'sectionid': 'rrmj_1917',
 'tags': ['剧情', '惊悚', '犯罪'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30327894/'}
2020-04-30 14:10:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30332529/> (referer: https://www.douban.com/search?q=%E6%9C%AB%E4%BB%A3%E6%B2%99%E7%9A%87)
2020-04-30 14:10:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30332529/>
{'cover': 'http://img.rr.tv/album/20190703/o_1562145215465.png',
 'data_type': 'movie',
 'id': 'rrmj_15237',
 'intro': '社会动荡席卷20世纪初的俄罗斯。沙皇尼古拉斯二世抵制变革，从而引发了一场革命，结束了王朝。',
 'is_new': False,
 'name': '末代沙皇',
 'platforms': '',
 'publishdate': '2019-07-03',
 'rate': 8.0,
 'sectionid': 'rrmj_1425',
 'tags': ['剧情', '传记', '古装'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30332529/'}
2020-04-30 14:10:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30337518/> (referer: https://www.douban.com/search?q=%E9%87%8E%E7%94%9F%E4%B8%96%E7%95%8C)
2020-04-30 14:10:14 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30337518/>
{'cover': 'http://img.rr.tv/album/20190906/o_1567763988823.png',
 'data_type': 'movie',
 'id': 'rrmj_15135',
 'intro': '野生世界里，女人上赤星天堂，男人则变为原始野兽。为了解救人类，一个失控的女孩和一个流氓赏金猎人，浪迹野生世界，希冀找到神话庇护所，或拯救人类或毁灭人类……',
 'is_new': False,
 'name': '野生世界',
 'platforms': '',
 'publishdate': '2018-09-28',
 'rate': 7.0,
 'sectionid': 'rrmj_1005',
 'tags': ['科幻', '惊悚', '恐怖', '奇幻', '冒险'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30337518/'}
2020-04-30 14:10:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30382485/> (referer: https://www.douban.com/search?q=%E7%A5%9E%E6%8E%A2%E6%9E%97%E8%82%AF)
2020-04-30 14:10:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30382485/>
{'cover': 'http://img.rr.tv/cover/20200108/o_1578484800713.webp',
 'data_type': 'movie',
 'id': 'rrmj_16989',
 'intro': '小说改编剧《神探林肯 Lincoln Rhyme: Hunt for the Bone Collector》由原作作者Jeffery '
          'Deaver创作， VJ Boyd及Mark Bianculli负责剧本﹑Seth '
          'Gordon执导。《神探林肯》讲述天才法医犯罪学家Lincoln Rhyme因追捕连环杀手「Bone '
          'Collector」时受重伤，故此只好退休。但当凶手重出江湖后，他决定复出并与充满野心的警探Amelia '
          'Sachs组成拍档，合作追捕「Bone Collector」及其他危险罪犯。《格林 Grimm》主演Russell '
          'Hornsby将饰演主角Lincoln Rhyme﹑Arielle Kebbel饰演聪明﹑坚守立场的Amelia '
          'Sachs。                                                                            \u3000\u3000'
          'Michael Imperioli饰演纽约警探Rick Sellitto，Lincoln的...',
 'is_new': False,
 'name': '神探林肯',
 'platforms': '',
 'publishdate': '2020-01-10',
 'rate': 7.8,
 'sectionid': 'rrmj_745',
 'tags': ['剧情', '惊悚', '犯罪'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30382485/'}
2020-04-30 14:10:19 [scrapy.extensions.logstats] INFO: Crawled 28 pages (at 28 pages/min), scraped 23 items (at 23 items/min)
2020-04-30 14:10:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30384336/> (referer: https://www.douban.com/search?q=%E5%AF%BB%E7%88%B1%E6%B3%95%E6%9C%AF)
2020-04-30 14:10:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30384336/>
{'cover': 'http://img.rr.tv/album/20190513/o_1557730308192.png',
 'data_type': 'movie',
 'id': 'rrmj_14809',
 'intro': '该剧讲述对现实充满失望的女主请求神婆魔法相助，被送到了三年后的未来。三年后的她居然结婚有丈夫了！饰她的丈夫还喜欢扰乱她的身心！于是女主就千方百计想回到最初的人生，可却在遭遇各种磨难中不小心将心交给了男主! '
          '当时光之轮重启，女主回到现实世界，开始寻找未来的他之旅…',
 'is_new': False,
 'name': '寻爱法术',
 'platforms': '',
 'publishdate': '2019-05-12',
 'rate': 6.1,
 'sectionid': 'rrmj_1244',
 'tags': ['爱情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30384336/'}
2020-04-30 14:10:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30390700/> (referer: https://www.douban.com/search?q=%E7%BE%8E%E5%9B%BD%E5%B7%A5%E5%8E%82)
2020-04-30 14:10:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30390700/>
{'cover': 'http://img.rr.tv/album/20190910/o_1568105826908.jpg',
 'data_type': 'movie',
 'id': 'rrmj_15688',
 'intro': '《美国工厂》是一部 Netflix 原创纪录片，由 Higher Ground Productions 和 Participant '
          'Media 出品，荣获奥斯卡金像奖®提名并斩获艾美奖®的朱莉娅·赖克特和史蒂文·博格纳尔（《最后一辆车：通用王国的破产》《A Lion '
          'in the '
          'House》《正观“红色”》）打造。这部广受好评的电影深入研究了后工业时代的俄亥俄州，一位中国亿万富翁在当地一家废弃的通用汽车工厂中开设新工厂，并雇佣了 '
          '2000 名美国蓝领工人。随着高科技中国企业与美国工人阶级产生冲突，最初的希望和乐观遭受了挫折。',
 'is_new': False,
 'name': '美国工厂',
 'platforms': '',
 'publishdate': '2019-01-25',
 'rate': 8.4,
 'sectionid': 'rrmj_1425',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30390700/'}
2020-04-30 14:10:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30401122/> (referer: https://www.douban.com/search?q=%E8%87%B4%E5%91%BD%E5%A5%B3%E4%BA%BA)
2020-04-30 14:10:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30401122/>
{'cover': 'http://img.rr.tv/album/20190822/o_1566457500356.jpg',
 'data_type': 'movie',
 'id': 'rrmj_15622',
 'intro': '贝斯（金妮弗·古德温 Ginnifer Goodwin 饰）从小的梦想就是能够成为一名家庭主妇，如今她嫁给了罗伯特（山姆·贾格 Sam '
          'Jaeger '
          '饰）为妻，总算是实现了理想。没想到第三者的出现将她美好的生活幻影撕成了碎片。                                                                    \u3000\u3000'
          '社交名媛西蒙尼（刘玉玲 饰）嫁给了非常疼爱她的卡尔（杰克·达文波特 Jack Davenport '
          '饰），哪知道竟然在偶然之中发现卡尔竟然是一名同性恋者，在守住秘密和守住尊严之间，西蒙尼必须做出选择。                                                                    \u3000\u3000'
          '泰勒（柯尔比·豪威尔-巴普蒂斯特 Kirby Howell-Baptiste 饰）和埃里（瑞德·斯科特 Reid Scott '
          '饰）正在进行一场开放式婚姻，泰勒的情人杰德（亚历珊德拉·达达里奥 Alexandra Daddario '
          '饰）的出现让埃里开始觉得，在他们两个人里面再加一个人似乎也是个不错的主意。',
 'is_new': False,
 'name': '致命女人',
 'platforms': '',
 'publishdate': '2019-07-21',
 'rate': 9.4,
 'sectionid': 'rrmj_1912',
 'tags': ['剧情', '喜剧', '犯罪'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30401122/'}
2020-04-30 14:10:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30434771/> (referer: https://www.douban.com/search?q=%E5%8C%BB%E7%94%9F%E8%80%80%E6%B1%89)
2020-04-30 14:10:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30434771/>
{'cover': 'http://img.rr.tv/album/20190716/o_1563243019322.jpg',
 'data_type': 'movie',
 'id': 'rrmj_15300',
 'intro': '这是一部关于医生专门从事疼痛管理的医学剧，把医生寻找病人神秘疼痛的原因描绘成一场惊心动魄的追逐，几乎就像一名侦探在未解决的犯罪背后追捕犯罪者。',
 'is_new': False,
 'name': '医生耀汉',
 'platforms': '',
 'publishdate': '2019-07-19',
 'rate': 8.3,
 'sectionid': 'rrmj_1646',
 'tags': ['剧情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30434771/'}
2020-04-30 14:10:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30448601/> (referer: https://www.douban.com/search?q=%E5%BD%BC%E5%B2%B8%E4%B9%8B%E5%AB%81)
2020-04-30 14:10:28 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30448601/>
{'cover': 'http://img.rr.tv/cover/20200416/o_1587016193250.png',
 'data_type': 'movie',
 'id': 'rrmj_17514',
 'intro': 'Netflix中文新片《彼岸之嫁》(小说《鬼新娘》电影版)宣布开机的同时，也发布先导预告。主演吴慷仁(《白蚁：欲望谜网》《下一站，幸福》)、黄姵嘉(《宝米恰恰》)、林路迪(《海王》)亮相，浓浓年代感。改编自美籍华裔作家朱洋熹的同名小说，故事混合了冥婚等中国民俗和浪漫爱情、超自然元素。设定在1890年代，殖民地时期的马六甲，讲述一个体面的华人人家的女儿丽兰因为家道中落，被要求去当富人家林家的“鬼新娘”——嫁给这户人家已死去的儿子。她能衣食无忧，但嫁给死人这件事将跟随她的余生，想逃走更加困难。此后，丽兰被卷入阴间，发现了“夫家”的黑暗秘密，也发现了自己家族的往事。                                                                    \u3000\u3000'
          '马来西亚导演郭修篆(《光》)和何宇恒(《K女士》)执导。编剧团队来自好莱坞和台湾，领头的是《汉尼拔》《闪电侠》编剧之一Wu Kai '
          'Yu。上线日期尚未确定。',
 'is_new': False,
 'name': '彼岸之嫁',
 'platforms': '',
 'publishdate': '2020-01-23',
 'rate': 7.0,
 'sectionid': 'rrmj_1904',
 'tags': ['剧情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30448601/'}
2020-04-30 14:10:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30449306/> (referer: https://www.douban.com/search?q=%E5%AE%8C%E7%BE%8E%E4%B8%96%E7%95%8C)
2020-04-30 14:10:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30449306/>
{'cover': 'http://img.rr.tv/album/20190426/o_1556270118406.jpg',
 'data_type': 'movie',
 'id': 'rrmj_14487',
 'intro': '本作改编自同名漫画《完美世界》。                                                                    \u3000\u3000'
          '因为遭遇事故而下身残疾，只能依靠轮椅生活的主人公鮎川樹（松坂桃李），在同学会上和高中同学川奈つぐみ（山本美月）再会。在心动之后，两人却要直面双亲的反对、疾病与伤痛、生活上的障碍、以及残疾所带来的并发症等等问题。                                                                    \u3000\u3000'
          '「究竟什么是幸福？」两人会做出怎样的选择呢？',
 'is_new': False,
 'name': '完美世界',
 'platforms': '',
 'publishdate': '2019-04-16',
 'rate': 8.1,
 'sectionid': 'rrmj_1244',
 'tags': ['剧情', '爱情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30449306/'}
2020-04-30 14:10:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/32493816/> (referer: https://www.douban.com/search?q=%E4%BC%BC%E6%87%82%E9%9D%9E%E6%87%82)
2020-04-30 14:10:34 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/32493816/>
{'cover': 'http://img.rr.tv/album/20190311/o_1552284033334.jpg',
 'data_type': 'movie',
 'id': 'rrmj_14276',
 'intro': '剧情讲述拥有「能听到别人内心话」的特殊能力和漂亮外貌，但却是边缘人的学妹，遇见了「不知道为什么总是听不见他内心想法」的暖男学长（김강민饰）后，所发生的一系列浪漫日常和成长改变的故事。是一部青春甜蜜的网剧。',
 'is_new': False,
 'name': '似懂非懂',
 'platforms': '',
 'publishdate': '2019-03-12',
 'rate': 7.3,
 'sectionid': 'rrmj_1244',
 'tags': ['爱情', '奇幻'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/32493816/'}
2020-04-30 14:10:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/32579502/> (referer: https://www.douban.com/search?q=%E4%B8%89%E9%87%8D%E6%9A%A7%E6%98%A7)
2020-04-30 14:10:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/32579502/>
{'cover': 'http://img.rr.tv/album/20190329/o_1553841813342.jpg',
 'data_type': 'movie',
 'id': 'rrmj_14404',
 'intro': '网络电视剧《三倍的暧昧》是以校内三个长得帅的男主人公为中心，讲述了新学期开始的同时发生的一系列趣事。',
 'is_new': False,
 'name': '三重暧昧',
 'platforms': '',
 'publishdate': '2019-03-14',
 'rate': 6.7,
 'sectionid': 'rrmj_1244',
 'tags': ['剧情', '爱情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/32579502/'}
2020-04-30 14:10:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%B5%B7%E8%92%82%E5%92%8C%E7%88%B7%E7%88%B7> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:10:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/33425801/> (referer: https://www.douban.com/search?q=%E8%AF%B7%E8%9E%8D%E5%8C%96%E6%88%91)
2020-04-30 14:10:38 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/33425801/>
{'cover': 'http://img.rr.tv/album/20190828/o_1566983781685.jpg',
 'data_type': 'movie',
 'id': 'rrmj_15728',
 'intro': '该剧讲述了参与了24小时冷冻人类项目的男女，因为神秘的阴谋20年后才醒来时迎来的感人故事。池昌旭实验20年间作为冷冻人活着的异能局PD马东灿。',
 'is_new': False,
 'name': '请融化我',
 'platforms': '',
 'publishdate': '2019-09-28',
 'rate': 7.2,
 'sectionid': 'rrmj_1726',
 'tags': ['剧情', '爱情', '科幻'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/33425801/'}
2020-04-30 14:10:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/33446371/> (referer: https://www.douban.com/search?q=%E6%97%A0%E4%BA%BA%E7%9F%A5%E6%99%93)
2020-04-30 14:10:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%89%B6%E6%A1%91%E8%8A%B1%E5%A5%B3%E5%AD%A9> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:10:40 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/33446371/>
{'cover': 'http://img.rr.tv/cover/20200218/o_1581995496717.jpg',
 'data_type': 'movie',
 'id': 'rrmj_17185',
 'intro': '该剧讲述女主角因为连环杀人案痛失最爱的朋友，时隔19年她再次追踪连环杀人案，揭发巨大的恶的真实面貌的故事。                                                                    \u3000\u3000'
          '金瑞亨饰演重案组刑警车英真，她因年幼时没有守护最爱的朋友，怀揣罪恶感和愧疚，负重前行，立誓要揪出凶手。                                                                    \u3000\u3000'
          '柳德焕饰演新星中学科学教师李善宇一角。他对学生倾注了多少的感情，就受到了多 '
          '少的伤害，甚至更深。本意想要离开教团的他却在周围人的挽留和劝导下，来到了姐夫担任理事长的新星中学。在那里他遇到了内心多情温暖的孩子。',
 'is_new': False,
 'name': '无人知晓',
 'platforms': '',
 'publishdate': '2020-03-02',
 'rate': 9.0,
 'sectionid': 'rrmj_1726',
 'tags': ['剧情', '悬疑'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/33446371/'}
2020-04-30 14:10:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/33468614/> (referer: https://www.douban.com/search?q=%E9%87%91%E9%92%B1%E6%B8%B8%E6%88%8F)
2020-04-30 14:10:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/33468614/>
{'cover': 'http://img.rr.tv/cover/20200106/o_1578290075849.jpg',
 'data_type': 'movie',
 'id': 'rrmj_16968',
 'intro': '该剧讲述围绕着卖掉投入大量公共资金的廷仁银行（政府持股50%）而发生的纠葛的故事。将描写想把银行转手给国内其他单位的人们和想把银行卖给海外私募基金的人们之间的争斗。                                                                    \u3000\u3000'
          '由《付岩洞复仇者们》《春天来了，春天》金相浩导演执导，李英美编剧执笔，预计下半年播出。',
 'is_new': False,
 'name': '金钱游戏',
 'platforms': '',
 'publishdate': '2020-01-15',
 'rate': 8.5,
 'sectionid': 'rrmj_1871',
 'tags': ['剧情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/33468614/'}
2020-04-30 14:10:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%B8%AD%E5%AD%A6%E5%9C%A3%E6%97%A5%E8%AE%B0> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:10:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%AF%8C%E8%B1%AA%E8%BE%A9%E6%8A%A4%E4%BA%BA> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:10:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/11538029/> (referer: https://www.douban.com/search?q=%E6%9D%80%E6%88%AE%E6%BC%94%E7%BB%8E)
2020-04-30 14:10:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/11538029/>
{'cover': 'http://img.rr.tv/album/20180712/o_1531365787209.webp',
 'data_type': 'movie',
 'id': 'rrmj_12756',
 'intro': '1965年，印尼政府被军政府推翻，那些反对军事独裁的人都被认定为“共产党人”，并遭遇了血腥屠杀，一年之内，就有超过100万“共产党人”丧命，其中就包括农民还有一些当地的华人。本片的主角Anwar '
          'Congo和他的朋友们就参与了当年的屠杀活动，他如今是印尼最大的准军事组织Pemuda '
          'Pancasila的元老人物。Anwar和他的朋友接受导演的邀请，在镜头前重新演绎当年他们是如何处死那些“共产党人”的，他们通过拍摄电影的方式，重现了当年的场景，再次拿起了那些沾满鲜血的用来勒死人的铁丝。Anwar讲述了他的故事，其中就包含着他年轻时候对美国黑帮电影的喜爱，而他所属的准军事组织Pemuda '
          'Pancasila虽然是维护国家安全的力量，恰恰也被人视为印尼最大的黑帮......',
 'is_new': False,
 'name': '杀戮演绎',
 'platforms': '',
 'publishdate': '2012-08-31',
 'rate': 8.3,
 'sectionid': 'rrmj_1416',
 'tags': ['纪录片', '历史', '犯罪'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/11538029/'}
2020-04-30 14:10:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26317338/> (referer: https://www.douban.com/search?q=%E8%B6%85%E7%BA%A7%E4%B8%AD%E5%9B%BD)
2020-04-30 14:10:47 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26317338/>
{'cover': 'http://img.rr.tv/album/20180527/o_1527406286761.webp',
 'data_type': 'movie',
 'id': 'rrmj_12281',
 'intro': '韩国KBS电视台推出的这个纪录片共分七集，分别从人口、经济、外交军事、土地、文化、政治六个方面介绍中国发展现状。摄制组周游世界各国，以政府官员、研究学者、企业家及普通民众的视野，观察中国为世界带来的改变。也想让韩国更加了解自己周围的强大邻居及朋友。                                                                    \u3000\u3000'
          '人口：十三亿人的力量                                                                    \u3000\u3000'
          '在外国人眼中，中国这个“超级中国，庞大的人口规模，是一种优势，更是一种威胁。                                                                    \u3000\u3000'
          '经济：钱的力量                                                                    \u3000\u3000'
          '超级中国，外汇储备绝对的1位，购入世界的矿山、企业、机场、港口                                                                    \u3000\u3000'
          '外交军事：中国治世                                                                    \u3000\u3000'
          '急剧的军费扩张，与美国的竞争，中国走向顶尖国家的雄心                                                                    \u3000\u3000'
          '土地：                                                                    \u3000\u3000'
          '文化：                                                                    \u3000\u3000'
          '政治：',
 'is_new': False,
 'name': '超级中国',
 'platforms': '',
 'publishdate': '2015-01-15',
 'rate': 6.6,
 'sectionid': 'rrmj_1384',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26317338/'}
2020-04-30 14:10:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%A3%92%E7%90%83%E5%A4%A7%E8%81%94%E7%9B%9F> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:10:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%B8%96%E7%95%8C%E4%BD%B3%E8%82%B4%EF%BC%81> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:10:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26381767/> (referer: https://www.douban.com/search?q=%E5%90%8C%E5%BF%97%E5%AE%9D%E8%B4%9D)
2020-04-30 14:10:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26381767/>
{'cover': 'http://img.rr.tv/album/20190725/o_1564035764507.webp',
 'data_type': 'movie',
 'id': 'rrmj_15462',
 'intro': '本片描寫澳洲四個同志家庭孩子的故事—葛斯、艾寶尼、馬特和葛拉罕，他們的父母剛好都是同性戀。當他們正與青春期裡的諸多挑戰搏鬥時，外面的世界則正在對婚姻平權的議題進行抗爭；少見從小孩視角呈現在同志家庭成長的樣貌，關乎家庭、性別、性與親子關係衝突等議題。在台灣同志領養小孩議題爭議不斷之時，可謂為值得參考的影像紀錄。',
 'is_new': False,
 'name': '同志宝贝',
 'platforms': '',
 'publishdate': '2015-04-29',
 'rate': 8.7,
 'sectionid': 'rrmj_1431',
 'tags': ['纪录片', '同性'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26381767/'}
2020-04-30 14:10:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26679116/> (referer: https://www.douban.com/search?q=%E5%9C%A3%E6%B4%81%E5%9C%B0%E7%8B%B1)
2020-04-30 14:10:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26679116/>
{'cover': 'http://img.rr.tv/album/20190515/o_1557907790154.webp',
 'data_type': 'movie',
 'id': 'rrmj_14829',
 'intro': '在加州的一个邪教团体领导者惊人的真相被公之于众后，一名前成员讲述他在这个组织里从理想主义到觉醒的经过。',
 'is_new': False,
 'name': '圣洁地狱',
 'platforms': '',
 'publishdate': '2016-01-25',
 'rate': 7.6,
 'sectionid': 'rrmj_1416',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26679116/'}
2020-04-30 14:10:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%B8%AD%E5%9B%BD%E4%BA%BA%E6%9D%A5%E4%BA%86> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:10:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%BA%BA%E7%94%9F%E5%A6%82%E7%90%83%E5%9C%BA> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:10:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26857719/> (referer: https://www.douban.com/search?q=%E7%BA%BD%E7%BA%A6%E9%BC%A0%E6%82%A3)
2020-04-30 14:10:55 [scrapy.core.scraper] ERROR: Error processing {'cover': 'http://img.rr.tv/album/20190313/o_1552458497157.webp',
 'data_type': 'movie',
 'id': 'rrmj_14294',
 'intro': '深入探索老鼠令人咋舌的世界，见证它们在不同环境的强韧生存能力，如何在人类史上带来灾难。',
 'is_new': False,
 'name': '纽约鼠患',
 'platforms': '',
 'publishdate': '',
 'rate': 7.2,
 'sectionid': 'rrmj_1416',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26857719/'}
Traceback (most recent call last):
  File "/usr/python37/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/python37/lib/python3.7/site-packages/scrapy/utils/defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/root/spider/scrapyspider/spiderV1/pipelines.py", line 262, in process_item
    timeStruct = time.strptime(publishdate, '%Y-%m-%d')
  File "/usr/python37/lib/python3.7/_strptime.py", line 571, in _strptime_time
    tt = _strptime(data_string, format)[0]
  File "/usr/python37/lib/python3.7/_strptime.py", line 359, in _strptime
    (data_string, format))
ValueError: time data '' does not match format '%Y-%m-%d'
2020-04-30 14:10:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%8D%B0%E5%BA%A6%E7%9A%84%E5%A5%B3%E5%84%BF> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:10:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26928130/> (referer: https://www.douban.com/search?q=%E4%BC%8A%E5%8D%A1%E6%B4%9B%E6%96%AF)
2020-04-30 14:10:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26928130/>
{'cover': 'http://img.rr.tv/album/20190730/o_1564479690421.webp',
 'data_type': 'movie',
 'id': 'rrmj_15486',
 'intro': '一名美国单车运动员和一位俄罗斯专家在国际体坛引爆严重丑闻后，一场对用药行为的调查引发了全球追逐战。',
 'is_new': False,
 'name': '伊卡洛斯',
 'platforms': '',
 'publishdate': '2017-01-20',
 'rate': 8.4,
 'sectionid': 'rrmj_1657',
 'tags': ['纪录片', '运动'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26928130/'}
2020-04-30 14:10:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26929016/> (referer: https://www.douban.com/search?q=%E5%9D%9A%E5%BC%BA%E4%B9%8B%E5%B2%9B)
2020-04-30 14:10:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26929016/>
{'cover': 'http://img.rr.tv/cover/20200114/o_1578981943052.webp',
 'data_type': 'movie',
 'id': 'rrmj_17016',
 'intro': '《强岛》（Strong Island） 导演：扬斯·福特（Yance Ford） 入围2017年圣丹斯电影节纪录片单元',
 'is_new': False,
 'name': '坚强之岛',
 'platforms': '',
 'publishdate': '2017-01-15',
 'rate': 5.8,
 'sectionid': 'rrmj_1657',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26929016/'}
2020-04-30 14:11:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%92%96%E5%95%A1%E4%B8%8E%E9%A6%99%E8%8D%89> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:11:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27663751/> (referer: https://www.douban.com/search?q=%E7%88%B1%E7%9A%84%E7%9D%80%E9%99%86)
2020-04-30 14:11:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/27663751/>
{'cover': 'https://img.rr.tv/season/20180323/o_1521792317735.png',
 'data_type': 'movie',
 'id': 'rrmj_11881',
 'intro': '该剧将空少们的秘密基地为主题讲述几对不同关系男男、男女之间错综复杂的关系,在这场存在金钱利益,爱情阴谋的关系中,深藏攻与零,因爱有基,因爱放纵,谁愿一同登这爱的飞机,探险这段惊险有爱的旅程。',
 'is_new': False,
 'name': '爱的着陆',
 'platforms': '',
 'publishdate': '2018-01-01',
 'rate': 5.9,
 'sectionid': 'rrmj_989',
 'tags': ['喜剧', '同性'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/27663751/'}
2020-04-30 14:11:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%BE%B7%E9%B2%81%E7%BA%B3%E9%85%92%E5%BA%97> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:11:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30326966/> (referer: https://www.douban.com/search?q=%E5%A4%A7%E8%B1%A1%E5%A5%B3%E7%8E%8B)
2020-04-30 14:11:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30326966/>
{'cover': 'http://img.rr.tv/album/20191114/o_1573710799349.webp',
 'data_type': 'movie',
 'id': 'rrmj_16580',
 'intro': '雅典娜是一位母亲，当他们被迫离开他们的水坑时，她会尽她所能保护她的牧群。这一史诗般的旅程，由Chiwetel '
          'Ejiofor讲述，带领观众穿越非洲大草原，进入大象家庭的核心。一个关于爱，失去和回家的故事。',
 'is_new': False,
 'name': '大象女王',
 'platforms': '',
 'publishdate': '2018-09-08',
 'rate': 9.1,
 'sectionid': 'rrmj_1425',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30326966/'}
2020-04-30 14:11:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30391726/> (referer: https://www.douban.com/search?q=%E8%9C%82%E8%9C%9C%E4%B9%8B%E5%9C%B0)
2020-04-30 14:11:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%81%8B%E7%88%B1%E6%B2%99%E5%B0%98%E6%9A%B4> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:11:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30391726/>
{'cover': 'http://img.rr.tv/cover/20200115/o_1579067866996.webp',
 'data_type': 'movie',
 'id': 'rrmj_17019',
 'intro': '鲜黄衣袂点缀马其顿偏乡的荒芜，与悬崖上野生蜂蜜琼浆的金黄相辉映。喀迪丝是欧洲大地最后一位女采蜂人，与抱病半盲母亲相依为命，依附野蜂为生，坚守「取一半、留一半」黄金定律。游牧民族一家突然欺至，打破宁静生活的不止是七个孩子与一众牲畜的喧闹，还有疯狂掏尽蜂蜜的贪婪，以及破坏生态环境的肆无忌惮。历时三年静观人与蜂和谐共处的隐世生活，以自然曦光与幽微烛照辉映大地，美得教人肃然起敬。获辛丹斯电影节世界纪录片评审团大奖。',
 'is_new': False,
 'name': '蜂蜜之地',
 'platforms': '',
 'publishdate': '2019-01-28',
 'rate': 8.8,
 'sectionid': 'rrmj_1657',
 'tags': ['剧情', '纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30391726/'}
2020-04-30 14:11:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30419881/> (referer: https://www.douban.com/search?q=%E6%94%BE%E5%BC%83%E6%B1%82%E7%94%9F)
2020-04-30 14:11:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30419881/>
{'cover': 'http://img.rr.tv/cover/20190919/o_1568877096969.webp',
 'data_type': 'movie',
 'id': 'rrmj_15914',
 'intro': '瑞典的数百名难民儿童面临被驱逐出境的危险，他们饱受放弃求生综合征的折磨，开始逃避现实并陷入一种昏迷般的状态，仿佛被冻结了数月甚至数年。《放弃求生》让观众了解这些患儿父母的痛苦，以及他们如何努力照顾生病的孩子。',
 'is_new': False,
 'name': '放弃求生',
 'platforms': '',
 'publishdate': '2019-01-26',
 'rate': 6.4,
 'sectionid': 'rrmj_1657',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30419881/'}
2020-04-30 14:11:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%88%91%E4%BB%AC%E4%B8%80%E5%AE%B6%E4%BA%BA> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:11:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30433802/> (referer: https://www.douban.com/search?q=%E6%9C%88%E4%BA%8B%E9%9D%A9%E5%91%BD)
2020-04-30 14:11:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%88%91%E4%BB%AC%E7%9A%84%E6%98%9F%E7%90%83> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:11:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30433802/>
{'cover': 'http://img.rr.tv/album/20190305/o_1551772242522.webp',
 'data_type': 'movie',
 'id': 'rrmj_14223',
 'intro': '第91届奥斯卡金像奖(2019)最佳纪录短片。这是一部关于月经和卫生巾的纪录片。讲述的是印度德里的一群妇女，为自己以及所有女性获得卫生巾的权利而抗争，而加利福尼亚州的一群高中女生们，给予了她们支持。',
 'is_new': False,
 'name': '月事革命',
 'platforms': '',
 'publishdate': '2018-04-05',
 'rate': 7.5,
 'sectionid': 'rrmj_1657',
 'tags': ['纪录片', '短片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30433802/'}
2020-04-30 14:11:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%94%BE%E7%BE%8A%E7%9A%84%E6%98%9F%E6%98%9F> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:11:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/2042437/> (referer: https://www.douban.com/search?q=%E6%97%B6%E5%B0%9A%E5%A4%A7%E5%B8%9D%20)
2020-04-30 14:11:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/2042437/>
{'cover': 'http://img.rr.tv/album/20190705/o_1562310680417.webp',
 'data_type': 'movie',
 'id': 'rrmj_15267',
 'intro': '这部由法国青年导演鲁道夫·马可尼执导，耗费十年光阴构思，两年贴身拍摄的时尚纪录片《时尚大帝》，以看似随性不拘的叙述手法和诗意化的影像风格，带您走进“时尚界的凯撒大帝”卡尔·拉格菲尔德，不为人知的隐密生活与内心世界。                                                                    \u3000\u3000'
          '这位大名鼎鼎的时尚界之神，第一次首肯这样近距离纪录他的生活，也是第一次如此立体地呈现在世人面前。在影片中，拉格菲尔德畅谈着他对时尚的看法，对文学、电影以及绘画等艺术元素的见解。甚至导演还捕捉到了这位饱受争议的大师背后，鲜为人知的内心独白。面对镜头，拉格菲尔德娓娓道来他如谜般的性向和自爆幼年遭男女轮番性侵事件，让观众零距离的接近这位时尚大帝。',
 'is_new': False,
 'name': '时尚大帝 ',
 'platforms': '',
 'publishdate': '2007-10-10',
 'rate': 7.3,
 'sectionid': 'rrmj_1399',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/2042437/'}
2020-04-30 14:11:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%96%B0%E5%88%9B%E6%96%B0%E5%A4%A9%E5%9C%B0> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:11:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/34966397/> (referer: https://www.douban.com/search?q=%E5%A6%96%E6%80%AA%E4%BA%BA%E9%97%B4)
2020-04-30 14:11:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/34966397/>
{'cover': 'http://img.rr.tv/seasonCover/20200422/o_1587539930542.jpg',
 'data_type': 'movie',
 'id': 'rrmj_17545',
 'intro': '公视《妖怪人间》带有奇幻色彩，将台湾各地乡野奇谈中的妖怪、鬼神等做连结，打造出人、妖共处的奇异世界，透过写实拍摄和大量视觉效果来呈现人类与妖怪之间的冲突。',
 'is_new': False,
 'name': '妖怪人间',
 'platforms': '',
 'publishdate': '2020-04-04',
 'rate': 6.0,
 'sectionid': 'rrmj_1904',
 'tags': ['剧情', '科幻', '悬疑'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/34966397/'}
2020-04-30 14:11:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%B5%B7%E8%B1%9A%E6%B9%BE%E6%81%8B%E4%BA%BA> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:11:19 [scrapy.extensions.logstats] INFO: Crawled 70 pages (at 42 pages/min), scraped 47 items (at 24 items/min)
2020-04-30 14:11:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%B7%B1%E8%93%9D%E4%B8%8E%E6%9C%88%E5%85%89> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:11:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%8B%90%E7%8B%B8%E6%96%B0%E5%A8%98%E6%98%9F> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:11:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%8E%8B%E5%AD%90%E5%8F%98%E9%9D%92%E8%9B%99> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:11:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%9C%9F%E7%88%B1%E8%B6%81%E7%8E%B0%E5%9C%A8> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:11:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%87%AA%E5%B7%B1%E5%8A%A8%E6%89%8B%E5%81%9A> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:11:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E9%BB%91%E8%89%B2%E6%AD%A2%E8%A1%80%E9%92%B3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:11:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E9%BB%91%E7%B3%96%E7%8E%9B%E5%A5%87%E6%9C%B5> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:11:30 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/684662/> (referer: https://www.douban.com/search?q=%E5%AF%8C%E8%B1%AA%E8%BE%A9%E6%8A%A4%E4%BA%BA)
2020-04-30 14:11:30 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/684662/>: HTTP status code is not handled or not allowed
2020-04-30 14:11:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/1788940/> (referer: https://www.douban.com/search?q=%E6%89%B6%E6%A1%91%E8%8A%B1%E5%A5%B3%E5%AD%A9)
2020-04-30 14:11:34 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/1788940/>
{'cover': 'http://img.rr.tv/cover/20191107/o_1573108342159.webp',
 'data_type': 'movie',
 'id': 'rrmj_16532',
 'intro': '1965年福岛县的煤矿小镇磐城，如今正面临着时代变革所带来的巨大冲击。石油能源逐渐成为主流，而煤资源则渐渐退出历史舞台。世代靠挖煤为生的磐城百姓开始感到生活的艰辛，镇上的煤矿相继关闭，失业不断增加。为了使小镇重新焕发活力，一个兴建“夏威夷娱乐中心”的计划旋即出炉。                                                                    \u3000\u3000'
          '世代 居住于此的女高中生纪美子（苍井优 '
          '饰）得知娱乐中心招聘草裙舞演员的消息后，和好友一同前来应聘。然而暴露的服装却吓退了很多保守纯朴的女孩，最终只有只有纪美子、早苗、初子和小百合四人留下。在来自东京的舞蹈老师平山圆香（松雪泰子 '
          '饰）的指导下，这几个没有任何基础的女孩顶住各方压力，为早日成为优秀的草裙舞女郎而刻苦学习……',
 'is_new': False,
 'name': '扶桑花女孩',
 'platforms': '',
 'publishdate': '2006-09-26',
 'rate': 8.1,
 'sectionid': 'rrmj_1729',
 'tags': ['剧情', '喜剧'],
 'type': 'movie',
 'url': 'https://movie.douban.com/subject/1788940/'}
2020-04-30 14:11:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%B8%AD%E5%9B%BD%E7%9A%84%E9%87%8D%E7%94%9F> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:11:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%BA%92%E8%81%94%E7%BD%91%E4%B9%8B%E5%AD%90> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:11:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/25958717/> (referer: https://www.douban.com/search?q=%E6%B5%B7%E8%92%82%E5%92%8C%E7%88%B7%E7%88%B7)
2020-04-30 14:11:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/25958717/>
{'cover': 'http://img.rr.tv/album/20191016/o_1571207462779.jpg',
 'data_type': 'movie',
 'id': 'rrmj_16178',
 'intro': '孤儿海蒂（阿努克·斯特芬 饰）被姨母迪蒂（安娜·希恩斯 饰）送上了阿尔卑斯山，与远离小镇独居于高山的祖父（布鲁诺·甘茨 '
          '饰）一同生活。活泼的海蒂在这里如鱼得水，不仅收获了羊倌彼得（奎林·阿格里皮 '
          '饰）的友情和孤僻祖父的亲情，还与山下彼得的家人打成一片。一天，海蒂同彼得在山上放羊，姨母突然出现，连哄带骗将海蒂卖到法兰克福的泽塞曼家。从此，目不识A的海蒂成为了小姐克拉拉（伊莎贝尔·奥特曼 '
          '饰）的伴读。克拉拉幼年丧母，大病一场再不能站立，只能被困在豪宅中与轮椅相伴。父亲（马克西姆·梅米特 '
          '饰）常年在外很少回家，寂寞的克拉拉把海蒂当成了救命稻草。海蒂能适应泽塞曼家的新生活吗？远在天边的祖父和彼得还能再见吗？克拉拉的腿还有好起来的希望吗？',
 'is_new': False,
 'name': '海蒂和爷爷',
 'platforms': '',
 'publishdate': '2019-05-16',
 'rate': 9.2,
 'sectionid': 'rrmj_1729',
 'tags': ['剧情', '家庭', '冒险'],
 'type': 'movie',
 'url': 'https://movie.douban.com/subject/25958717/'}
2020-04-30 14:11:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%8F%98%E6%80%A7%E5%88%87%E5%B0%94%E8%A5%BF> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:11:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/25853071/> (referer: https://www.douban.com/search?q=%E5%A4%8D%E4%BB%87%E7%AC%AC%E4%B8%80%E5%AD%A3)
2020-04-30 14:11:40 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/25853071/>
{'cover': 'http://img.rr.tv/album/20180820/o_1534746758243.jpg',
 'data_type': 'movie',
 'id': 'rrmj_179',
 'intro': '某大学文学史专业的学生张庆熟读古典名著，但他用现代观念剖析古代文学史的论文命题不被叶教授所认可。为了让叶教授成为自己的研究生导师，张庆决定通过写小说的方式，进一步阐述自己想要表达的观点。                                                                    \u3000\u3000'
          '在他的小说中，身世神秘的少年——范闲，自小跟随奶奶生活在海边小城澹州，随着一位老师的突然造访，他看似平静的生活开始直面重重的危机与考验。在神秘老师和一位蒙眼守护者的指点下，范闲熟识药性药理，修炼霸道真气并精进武艺，而后接连化解了诸多危局。因对身世之谜的好奇，范闲离开澹州，前赴京都。                                                                    \u3000\u3000'
          '在京都，范闲凭借过人的智谋与勇武成为年轻一代的佼佼者，他先以诗文冠绝京都，而后出使邻国，营救人质，整合谍报网，查处震动朝野的走私案……这个过程中，范闲饱尝人间冷暖并坚守对正义、良善的坚持，历经家族、江湖、庙堂的种种考验与锤炼，书写了光彩的人生传奇。',
 'is_new': False,
 'name': '复仇第一季',
 'platforms': '',
 'publishdate': '2019-11-26',
 'rate': 8.0,
 'sectionid': 'rrmj_1912',
 'tags': ['剧情', '古装'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/25853071/'}
2020-04-30 14:11:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%90%8C%E5%BF%97%E6%88%90%E9%95%BF%E8%AE%B0> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:11:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%A4%A9%E5%A0%82%E5%A4%A7%E5%A1%9E%E8%BD%A6> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:11:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%A9%9A%E5%A7%BB%E5%B9%B3%E6%9D%83%E8%B7%AF> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:11:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%96%B0%E4%B8%9D%E7%BB%B8%E4%B9%8B%E8%B7%AF> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:11:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%B0%91%E4%B8%BB%E7%9A%84%E8%BE%B9%E7%BC%98> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:11:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/2157176/> (referer: https://www.douban.com/search?q=%E6%94%BE%E7%BE%8A%E7%9A%84%E6%98%9F%E6%98%9F)
2020-04-30 14:11:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/2157176/>
{'cover': 'http://img.rr.tv/cover/20200414/o_1586835734514.jpg',
 'data_type': 'movie',
 'id': 'rrmj_17488',
 'intro': '替爱人顶罪刚被假释出狱的女诈欺犯夏之星（刘荷娜 饰）发现爱人竟与别的女子结婚。而E-shine集团二公子仲天骐（林志颖 '
          '饰）的旧情人要和哥哥仲天骏(立威廉 饰) 结婚。两人因天骐母亲的遗物Queen '
          'Mary相遇了，来到简朴温馨的明日乡。两个被爱情抛弃的人放下身分的隔阂，用心去相处。阿星喜欢设计珠宝，却只能靠仿冒饰品维生。天骐为圆她的梦想，参加了赌命赛车，却在一次败北当中被黑道老大废了右手，身负重伤。阿星不拖累了天骐，忍痛接受了仲父的支票离开天骐。天骏不忍拆散两人，开车要带阿星回来却半路车祸身亡。天骐自此封锁情感，性情骤变，抱着对阿星的仇恨，加倍工作，变成冷血无情的商人。                                                                            \u3000\u3000'
          '五年后，因争取代言，天骐与阿星再度相逢，再也不能信任彼此的怨偶，却因为当初定情的一条手链“仲夏夜之星”，仍然被紧紧地牵系在一起，再度爱上彼此的两人，却只能用谎言不断包装自己的真心....',
 'is_new': False,
 'name': '放羊的星星',
 'platforms': '',
 'publishdate': '2007-03-11',
 'rate': 7.7,
 'sectionid': 'rrmj_1904',
 'tags': ['爱情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/2157176/'}
2020-04-30 14:11:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/2303292/> (referer: https://www.douban.com/search?q=%E6%B5%B7%E8%B1%9A%E6%B9%BE%E6%81%8B%E4%BA%BA)
2020-04-30 14:11:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/2303292/>
{'cover': 'http://img.rr.tv/cover/20200415/o_1586937658504.jpg',
 'data_type': 'movie',
 'id': 'rrmj_17503',
 'intro': '小瓶盖因母亲因交通意外离世被送到泰瑞莎之家。同院的小泽亚一直守护着她直到被SET董事长徐若谷接走，临走前约好回来接她，但等他再次回来时小瓶盖己离开。多年后，学成回国的徐泽亚(许绍洋 '
          '饰) 已经成了SET电视公司的总经理，而他人生继续下去只剩下与“小瓶盖”的约定。在寻找小瓶盖的过程中他在海豚湾邂逅了易天边(张韶涵 '
          '饰) '
          '，天边坚强乐观的个性吸引着他，两人间似乎产生了情愫。                                                                    \u3000\u3000'
          '金牌制作人钟晓刚(霍建华 饰) '
          '要做一张《漫步云端》的专辑，一直在寻找理想的声音。酷爱音乐的天边有一把动人的嗓子，梦想成为歌星，经过层层筛选取得SET的歌唱比赛表格，最终成为《漫步云端》的演唱者。                                                                    \u3000\u3000'
          '而SET董事长徐若谷似乎也隐藏着另一个众人所不知道的秘密，泽亚是否能追寻已久的真相呢？他能否找到当年的小瓶盖呢？',
 'is_new': False,
 'name': '海豚湾恋人',
 'platforms': '',
 'publishdate': '2003-05-18',
 'rate': 7.1,
 'sectionid': 'rrmj_1904',
 'tags': ['剧情', '爱情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/2303292/'}
2020-04-30 14:11:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%A7%91%E6%AF%94%E7%9A%84%E7%BC%AA%E6%96%AF> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:11:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%BB%88%E5%AE%88%E9%98%BF%E5%8B%92%E6%B3%A2> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:11:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/2381010/> (referer: https://www.douban.com/search?q=%E6%96%B0%E5%88%9B%E6%96%B0%E5%A4%A9%E5%9C%B0)
2020-04-30 14:11:57 [scrapy.core.scraper] ERROR: Error processing {'cover': 'http://img.rr.tv/album/20190906/o_1567764477584.png',
 'data_type': 'movie',
 'id': 'rrmj_15139',
 'intro': '沈乐文（杨恭如 饰）和男友乔力行（张智霖 '
          '饰）相恋七年，彼此之间感情十分深厚。对于他们两人来说，彼此早已经成为了未来生活图景的一部分。沈乐文虽然在高级西餐厅担任餐厅经理的职务，却一直怀揣着在香港开一间茶餐厅的梦想。终于，梦想实现的那一天近在眼前，两人带上他们所有的积蓄启程了，去投奔哪里的朋友包家龙（邓健泓 '
          '饰）。                                                                    \u3000\u3000'
          '然而，让沈乐文和乔力行没有想到的是，包家龙不仅卷走了他们全部的钱，还失去了踪迹音信全无。程琳（范冰冰 '
          '饰）是包家龙的女友，无奈之下，她只得一边收留走投无路的这对情侣，一边寻找男友的下落。',
 'is_new': False,
 'name': '新创新天地',
 'platforms': '',
 'publishdate': '',
 'rate': 7.8,
 'sectionid': 'rrmj_1005',
 'tags': ['剧情', '爱情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/2381010/'}
Traceback (most recent call last):
  File "/usr/python37/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/python37/lib/python3.7/site-packages/scrapy/utils/defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/root/spider/scrapyspider/spiderV1/pipelines.py", line 262, in process_item
    timeStruct = time.strptime(publishdate, '%Y-%m-%d')
  File "/usr/python37/lib/python3.7/_strptime.py", line 571, in _strptime_time
    tt = _strptime(data_string, format)[0]
  File "/usr/python37/lib/python3.7/_strptime.py", line 359, in _strptime
    (data_string, format))
ValueError: time data '' does not match format '%Y-%m-%d'
2020-04-30 14:11:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%BE%8E%E5%88%A9%E5%9D%9A%E5%A5%B3%E5%A3%AB> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:11:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/3105276/> (referer: https://www.douban.com/search?q=%E9%BB%91%E7%B3%96%E7%8E%9B%E5%A5%87%E6%9C%B5)
2020-04-30 14:11:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/3105276/>
{'cover': 'http://img.rr.tv/cover/20200414/o_1586842745380.jpg',
 'data_type': 'movie',
 'id': 'rrmj_17489',
 'intro': '敖犬（庄濠全 饰）、王子（邱胜翊 饰）、小煜（杨奇煜 饰）、小杰（廖俊杰 饰）、威廉和阿纬（刘俊纬 '
          '饰）各自生活在不同家庭，他们都以为自己是独生子。这天，他们父亲的秘书把六人招集到律师所，告诉他们其实是同父异母的兄弟，要他们和睦相处一年，如履行合约将得到100亿元的财产。原先六兄弟并不认识，这突如其来的消息令他们无法适应，小煜立即选择离开，但合约规定，六人中如有一人不履行合约，合约将宣布无效，其余五人在律师的鼓动下极力劝阻小煜。众人签约后被安排在一所房子中居住，他们的管家是一个父亲早年收养的女孩丫头（詹子晴 '
          '饰）。一边履行着合约中各种苛刻的规定一边磕磕绊绊的相处，六兄弟就这样生活在了一起。',
 'is_new': False,
 'name': '黑糖玛奇朵',
 'platforms': '',
 'publishdate': '2007-07-15',
 'rate': 6.9,
 'sectionid': 'rrmj_1904',
 'tags': ['剧情', '喜剧', '家庭'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/3105276/'}
2020-04-30 14:12:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E9%98%BF%E5%A7%86%E6%96%AF%E7%89%B9%E6%9C%97> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:12:01 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/3463536/> (referer: https://www.douban.com/search?q=%E4%B8%96%E7%95%8C%E4%BD%B3%E8%82%B4%EF%BC%81)
2020-04-30 14:12:01 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/3463536/>: HTTP status code is not handled or not allowed
2020-04-30 14:12:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=Nicki%20Minaj%3A%20My%20Time%20Again> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:12:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/5201828/> (referer: https://www.douban.com/search?q=%E4%B8%AD%E5%9B%BD%E4%BA%BA%E6%9D%A5%E4%BA%86)
2020-04-30 14:12:05 [scrapy.core.scraper] ERROR: Error processing {'cover': 'http://img.rr.tv/album/20190524/o_1558678812389.png',
 'data_type': 'movie',
 'id': 'rrmj_14892',
 'intro': '',
 'is_new': False,
 'name': '中国人来了',
 'platforms': '',
 'publishdate': '',
 'rate': 7.5,
 'sectionid': 'rrmj_1384',
 'tags': ['喜剧'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/5201828/'}
Traceback (most recent call last):
  File "/usr/python37/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/python37/lib/python3.7/site-packages/scrapy/utils/defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/root/spider/scrapyspider/spiderV1/pipelines.py", line 262, in process_item
    timeStruct = time.strptime(publishdate, '%Y-%m-%d')
  File "/usr/python37/lib/python3.7/_strptime.py", line 571, in _strptime_time
    tt = _strptime(data_string, format)[0]
  File "/usr/python37/lib/python3.7/_strptime.py", line 359, in _strptime
    (data_string, format))
ValueError: time data '' does not match format '%Y-%m-%d'
2020-04-30 14:12:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%B8%BB%E5%8E%A8%E7%9A%84%E9%A4%90%E6%A1%8C> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:12:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/5944276/> (referer: https://www.douban.com/search?q=%E8%87%AA%E5%B7%B1%E5%8A%A8%E6%89%8B%E5%81%9A)
2020-04-30 14:12:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/5944276/>
{'cover': 'http://img.rr.tv/album/20190906/o_1567767857019.png',
 'data_type': 'movie',
 'id': 'rrmj_15137',
 'intro': 'The Rough Trade story begins more than thirty years ago on 20th '
          'February 1976. Britain was in the grip of an IRA bombing campaign; '
          'a future prime minister was beginning to make her mark on middle '
          'England, where punk was yet to run amok; and a young Cambridge '
          'graduate called Geoff Travis opened a new shop at 202 Kensington '
          'Park Road, just off Ladbroke Grove in West London. The R...',
 'is_new': False,
 'name': '自己动手做',
 'platforms': '',
 'publishdate': '2018-02-23',
 'rate': 7.5,
 'sectionid': 'rrmj_1005',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/5944276/'}
2020-04-30 14:12:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%BF%83%E9%87%8C%E7%9A%84%E5%A3%B0%E9%9F%B32> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:12:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30267281/> (referer: https://www.douban.com/search?q=%E4%B8%AD%E5%AD%A6%E5%9C%A3%E6%97%A5%E8%AE%B0)
2020-04-30 14:12:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30267281/>
{'cover': 'http://img.rr.tv/album/20180917/o_1537172500361.jpg',
 'data_type': 'movie',
 'id': 'rrmj_13159',
 'intro': '主人公・25岁的末永圣是一名乡村中学的语文老师，她和恋人已经有了婚约，目前两人处于异地恋爱的状态。但第一次担任班主任的她却对比她小11岁的美少年黑岩晶动了心。',
 'is_new': False,
 'name': '中学圣日记',
 'platforms': '',
 'publishdate': '2018-10-09',
 'rate': 7.8,
 'sectionid': 'rrmj_747',
 'tags': ['剧情', '爱情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30267281/'}
2020-04-30 14:12:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%8E%8B%E5%9B%BD%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:12:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/34660401/> (referer: https://www.douban.com/search?q=%E6%A3%92%E7%90%83%E5%A4%A7%E8%81%94%E7%9B%9F)
2020-04-30 14:12:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/34660401/>
{'cover': 'http://img.rr.tv/cover/20191205/o_1575524962307.jpg',
 'data_type': 'movie',
 'id': 'rrmj_16770',
 'intro': '该剧是讲述排名倒数第一、球迷的眼泪都流干了的棒球队的新上任的团长，准备不平凡的赛季的冬季物语。 '
          '这是一部讲述棒球队准备赛季的电视剧，每集都会分别解决球队遇到的问题，将以球队实力逐渐见长为设定。虽然以职棒为题材，但将讲述并不华丽的赛场背后的故事。                                                                    \u3000\u3000'
          '南宫珉将在剧中饰演职棒D '
          'reams新任团长白承洙，他被称为很能干的人，经他带领的球队都经过脱胎换骨的过程取得珍贵的优胜，但他接手的球队的母公司都是没人气的业界的穷公司，拿得冠军后球队都被解散了。他收到了出任万年处于倒数排名的职棒球队Dreams的新团长的邀约。                                                                    \u3000\u3000'
          '由《奇怪的搭档》《命运与愤怒》郑东允PD执导，李新华编剧执笔。',
 'is_new': False,
 'name': '棒球大联盟',
 'platforms': '',
 'publishdate': '2019-12-13',
 'rate': 9.4,
 'sectionid': 'rrmj_745',
 'tags': ['剧情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/34660401/'}
2020-04-30 14:12:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/4230999/> (referer: https://www.douban.com/search?q=%E6%96%B0%E4%B8%9D%E7%BB%B8%E4%B9%8B%E8%B7%AF)
2020-04-30 14:12:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/4230999/>
{'cover': 'http://img.rr.tv/album/20191010/o_1570688381910.webp',
 'data_type': 'movie',
 'id': 'rrmj_16110',
 'intro': '第一集 '
          '楼兰四千年的睡梦                                                                            \u3000\u3000'
          '第二集 '
          '吐鲁番_炙热的大画廊                                                                            \u3000\u3000'
          '第三集 '
          '草原之路铁马疾风                                                                            \u3000\u3000'
          '第四集 '
          '塔克拉玛干_西域的蒙娜丽莎                                                                            \u3000\u3000'
          '第五集 '
          '天山南路_青金石的光辉                                                                            \u3000\u3000'
          '第六集 '
          '敦煌_魂消石窟                                                                            \u3000\u3000'
          '第七集 '
          '青海_天空之旅                                                                            \u3000\u3000'
          '第八集 '
          '哈拉浩特_消失在沙漠中的西夏                                                                            \u3000\u3000'
          '第九集 '
          '喀什_千年的小巷流淌着诗歌                                                                            \u3000\u3000'
          '第十集 '
          '西安_不朽之都                                                                            \u3000\u3000'
          '.                                                                            \u3000\u3000'
          '＂丝绸之路＂在地理上只是跨越亚欧大陆的一条通道，它对于世界文化的意义却远非如此。                                                                            \u3000\u3000'
          '它的东西两端，分别是东西方文明的源头，就像织造丝绸的经纬线一般，它将中国、埃及、印度和希腊、美索不达米亚编织在一起，成为一个永远不枯竭的想像的源泉———在通讯和交通都不发达的古代，对于丝路两端的民族来说，它就意味着通往彼岸的舟楫，意味着陌生而奇异的世界本身。                                                                            \u3000\u3000'
          '1980年，NHK向中国中央电视台发出探索丝绸之路的邀请，NHK因而成为第一家进入中国西部腹地进行纪录片拍摄的境外媒体...',
 'is_new': False,
 'name': '新丝绸之路',
 'platforms': '',
 'publishdate': '2005-01-01',
 'rate': 9.2,
 'sectionid': 'rrmj_1384',
 'tags': ['纪录片', '历史'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/4230999/'}
2020-04-30 14:12:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%BE%9E%E8%80%BB%20%E7%AC%AC%E4%B8%89%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:12:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%A1%80%E6%97%8F%20%E7%AC%AC%E4%BA%8C%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:12:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/20279476/> (referer: https://www.douban.com/search?q=%E7%9C%9F%E7%88%B1%E8%B6%81%E7%8E%B0%E5%9C%A8)
2020-04-30 14:12:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/20279476/>
{'cover': 'http://img.rr.tv/cover/20200416/o_1587007805175.jpg',
 'data_type': 'movie',
 'id': 'rrmj_17513',
 'intro': '奕茹（陈庭妮 '
          '饰）一心扑在事业之上，因此而忽略了个人的感情生活，某日，她意外地被医生告知患上了不治之症，只剩下半年的寿命，精彩的人生还未真正开始，便已经即将走向终结。震惊和绝望之中，奕茹踏上了前往异国的旅途。                                                                    \u3000\u3000'
          '途中，奕茹结识了名为蓝仕德（胡宇崴 '
          '饰）的男子，然而，这却并非两人的第一次见面。原来，早在大学时期，蓝仕德便被奕茹的善良和坚强所吸引，这次重逢让这份纯洁美好的感情迅速升温，没过多久，两人便坠入了爱河。尽管得知了奕茹的病情，但蓝仕德却并没有退缩，在海边，两人举行了一场浪漫至极的婚礼，然而在此之后，奕茹不辞而别。',
 'is_new': False,
 'name': '真爱趁现在',
 'platforms': '',
 'publishdate': '2012-10-31',
 'rate': 7.2,
 'sectionid': 'rrmj_1904',
 'tags': ['爱情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/20279476/'}
2020-04-30 14:12:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26336727/> (referer: https://www.douban.com/search?q=%E5%8D%B0%E5%BA%A6%E7%9A%84%E5%A5%B3%E5%84%BF)
2020-04-30 14:12:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26336727/>
{'cover': 'http://img.rr.tv/album/20190313/o_1552463383962.jpg',
 'data_type': 'movie',
 'id': 'rrmj_14300',
 'intro': '此纪录片围绕2012年12月震惊世界的德里公交车轮奸案，23岁的Jyoti '
          'Singh在车上遭轮奸和殴打最终因此死亡，四名成年被告被判死刑，纪录片采访了其中一位强奸犯Mukesh '
          'Singh、他的律师和受害者的父母。',
 'is_new': False,
 'name': '印度的女儿',
 'platforms': '',
 'publishdate': '2015-03-04',
 'rate': 8.9,
 'sectionid': 'rrmj_1903',
 'tags': ['纪录片', '犯罪'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26336727/'}
2020-04-30 14:12:19 [scrapy.extensions.logstats] INFO: Crawled 111 pages (at 41 pages/min), scraped 59 items (at 12 items/min)
2020-04-30 14:12:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=IT%E7%8B%82%E4%BA%BA%E8%AF%B4%E6%98%8E%E4%B9%A6> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:12:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26785285/> (referer: https://www.douban.com/search?q=%E6%81%8B%E7%88%B1%E6%B2%99%E5%B0%98%E6%9A%B4)
2020-04-30 14:12:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26785285/>
{'cover': 'http://img.rr.tv/cover/20200415/o_1586937268978.jpg',
 'data_type': 'movie',
 'id': 'rrmj_17502',
 'intro': '爸爸妈妈不知道从什么时候不再沟通倾听了，他们只要一讲话就会开始吵架，妈妈对于爸爸总是在外面装好人心怀不满，在外笑容满面替中庭那些菲佣推轮椅按电梯提购物袋，一回家就只会颐指气使臭着一张脸。可想而知两人已经很久没有性生活，但其实妈妈不知道爸爸为了不举的问题暗地烦恼许久。                                                                    \u3000\u3000'
          '三个孩子也有各自的苦恼，大哥亦得打肿脸充胖子筹钱给女友娇娇去欧洲玩，搞得自己没钱吃饭，为了多赚钱他答应帮同事解决被太妹仙人跳的纠纷；二妹亦珊从小就宣称自己是爱情绝缘体，却为了帮好友被劈腿男欺负，跟监跟到汽车旅馆去；三弟亦谦为自己不断勃起的问题痛苦，青春期对女体的绮丽想象让他气喘发作紧急送医。                                                                    \u3000\u3000'
          '表面看似完美幸福的一家人，却没发现一场风暴即将来袭……',
 'is_new': False,
 'name': '恋爱沙尘暴',
 'platforms': '',
 'publishdate': '2016-08-19',
 'rate': 8.4,
 'sectionid': 'rrmj_1904',
 'tags': ['剧情', '爱情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26785285/'}
2020-04-30 14:12:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%BA%BF%E4%B8%87%20%E7%AC%AC%E5%9B%9B%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:12:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27157794/> (referer: https://www.douban.com/search?q=%E6%B7%B1%E8%93%9D%E4%B8%8E%E6%9C%88%E5%85%89)
2020-04-30 14:12:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/27157794/>
{'cover': 'http://img.rr.tv/cover/20200415/o_1586936936746.png',
 'data_type': 'movie',
 'id': 'rrmj_17501',
 'intro': '我们在城市中寻找着，渴望被爱、渴望拥抱、渴望着有人可以相伴。只不过这世上，总有无法去爱的人、更有无法放手不去爱的人，月光洒下，他和他的相遇开始，他和他的爱情滋长。                                                                    \u3000\u3000'
          '《深蓝与月光》是由《着魔》导演Adiamond '
          'Lee执导，陈彦名、黄庭轩、王庭匀、林柏叡、詹雅涵等主演的同性题材的耽美剧。本剧还讲述的是四位男主角对爱的徬徨与辩证，在亲情和爱情之间游移的生命故事及强力描述台湾同性恋婚姻合法后的爱情。',
 'is_new': False,
 'name': '深蓝与月光',
 'platforms': '',
 'publishdate': '2017-11-21',
 'rate': 7.0,
 'sectionid': 'rrmj_1904',
 'tags': ['爱情', '同性'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/27157794/'}
2020-04-30 14:12:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%B1%89%E5%A8%9C%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:12:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/28509671/> (referer: https://www.douban.com/search?q=%E7%8B%90%E7%8B%B8%E6%96%B0%E5%A8%98%E6%98%9F)
2020-04-30 14:12:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/28509671/>
{'cover': 'http://img.rr.tv/album/20181107/o_1541584027152.jpg',
 'data_type': 'movie',
 'id': 'rrmj_13156',
 'intro': '《狐狸新娘星》（剧本：姜银庆，导演：申宇哲）讲述了带着创伤与缺憾，在仁川机场相遇的李修延和韩夏天，与路过仁川机场的人们发生相遇冲撞的故事。是一部令人感动的人情浪漫成长剧。                                                                            \u3000\u3000'
          '李帝勋饰演从KAIST毕业后，凭借不寻常的阅历和托业满分进入仁川机场的李修延，他以只以6个月适应这里的生活为目标来到仁川机场，是与周围人都保持着适当距离的神秘人物。                                                                            \u3000\u3000'
          '蔡秀彬饰演带着梦想来到仁川机场的韩夏天，虽然每日都看着飞机起降，但本人却从未乘坐过飞机。经过三次终于被仁川机场录取，但在发生意外事故后背负着“人类炸弹”的角色，被派遣到了最为繁忙的旅客服务小组。                                                                            \u3000\u3000'
          '李东健将饰演具有柔韧亲和领导力的资深运营企划组长徐仁宇，他是善于为人处世的高手，比任何人都更快进阶的仁川机场年轻掌权人士之一。                                                                            \u3000\u3000'
          '金智秀担任仁川机场旅客服务部门旅客服务组长杨舒君，是能在危机面前也堂堂正正站在顾客面前的热血女狂人...',
 'is_new': False,
 'name': '狐狸新娘星',
 'platforms': '',
 'publishdate': '2018-10-01',
 'rate': 6.6,
 'sectionid': 'rrmj_1726',
 'tags': ['剧情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/28509671/'}
2020-04-30 14:12:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%8E%8B%E5%9B%BD%20%E7%AC%AC%E4%BA%8C%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:12:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30135594/> (referer: https://www.douban.com/search?q=%E9%BB%91%E8%89%B2%E6%AD%A2%E8%A1%80%E9%92%B3)
2020-04-30 14:12:28 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30135594/>
{'cover': 'http://img.rr.tv/album/20180404/o_1522832297426.png',
 'data_type': 'movie',
 'id': 'rrmj_11961',
 'intro': '偏处地方的东城大学医学部附属医院，凭借佐伯清刚（内野圣阳 '
          '饰）出神入化般的“佐伯式”心脏二瓣膜修复手术而举国闻名，佐伯教授仪式般的黑色止血钳更为他增添了几许神话色彩。与之形成对立关系的，则是综合实力远在东城大之上的帝华大学医院部附属医院，该院的西崎启介教授（市川猿之助 '
          '饰）与佐伯教授围绕着日本综合外科学会会长的宝座展开了激烈的角逐。为此，西崎派出得意门生高阶权太（小泉孝太郎 '
          '饰）潜入敌营，试图通过最新的医疗器械撼动佐伯的地位。然而，佐伯麾下还有一个令所有医生头疼的人物。此人名叫渡海征司郎（二宫和也 '
          '饰），他凭借高超的外科技巧拯救了一条条濒危的生命，但是毒舌外加阴暗的性格让他成为可怕的恶魔医生。怀着不可告人的目的，渡海卷入了佐伯和西崎的纷争之中……                                                                    \u3000\u3000'
          '本片根据海堂尊的同名原作改编。',
 'is_new': False,
 'name': '黑色止血钳',
 'platforms': '',
 'publishdate': '2018-04-22',
 'rate': 8.6,
 'sectionid': 'rrmj_1646',
 'tags': ['剧情', '悬疑'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30135594/'}
2020-04-30 14:12:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%A1%80%E7%96%AB%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:12:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30183785/> (referer: https://www.douban.com/search?q=%E6%88%91%E6%98%AF%E5%A4%A7%E5%93%A5%E5%A4%A7)
2020-04-30 14:12:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30183785/>
{'cover': 'http://img.rr.tv/album/20181204/o_1543890113475.jpg',
 'data_type': 'movie',
 'id': 'rrmj_13123',
 'intro': '故事发生在20世纪80年代，中学生三桥贵志（贺来贤人 饰）和伊藤真司（伊藤健太郎 '
          '饰）转学来到新的学校，为了看起来凶恶一点，他们不约而同改换了不良少年的打扮。刚刚入学，两人意外打倒十人，一战成名。此后他们结识了女校的戏精大姐大早川京子（桥本环奈 '
          '饰）、男校的大嗓门傻老大今井（太贺 饰）、今井的小跟班谷川（矢本悠马 饰）以及本校的功夫纪律委员赤坂理子（清野菜名 '
          '饰）。在与黑道分子和其他学校不良少年的抗争过程中，少男少女的友情不断加深，而爆笑沙雕的故事也接二连三的发生。三桥与伊藤的确度过了一段难忘的青春岁月……                                                                    \u3000\u3000'
          '本片根据同名漫画改编。',
 'is_new': False,
 'name': '我是大哥大',
 'platforms': '',
 'publishdate': '2018-10-14',
 'rate': 9.4,
 'sectionid': 'rrmj_1917',
 'tags': ['剧情', '喜剧'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30183785/'}
2020-04-30 14:12:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30246343/> (referer: https://www.douban.com/search?q=%E7%8E%8B%E5%AD%90%E5%8F%98%E9%9D%92%E8%9B%99)
2020-04-30 14:12:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30246343/>
{'cover': 'http://img.rr.tv/cover/20200414/o_1586849166686.png',
 'data_type': 'movie',
 'id': 'rrmj_17492',
 'intro': '平凡可爱的荔枝少女叶芊语，偶遇误入渔村的落魄霸总单俊皓，开启一段梦幻又甜蜜的恋爱童话。',
 'is_new': False,
 'name': '王子变青蛙',
 'platforms': '',
 'publishdate': '2020-03-23',
 'rate': 7.7,
 'sectionid': 'rrmj_1917',
 'tags': ['爱情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30246343/'}
2020-04-30 14:12:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E9%BB%91%E9%92%B1%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:12:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%B7%9F%E9%B2%A8%E9%B1%BC%E6%8E%A5%E5%90%BB> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:12:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30374707/> (referer: https://www.douban.com/search?q=%E6%88%91%E4%BB%AC%E7%9A%84%E6%98%9F%E7%90%83)
2020-04-30 14:12:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30374707/>
{'cover': 'http://img.rr.tv/album/20190411/o_1554979145826.png',
 'data_type': 'movie',
 'id': 'rrmj_14480',
 'intro': '由大卫·艾登堡负责解说                                                                    \u3000\u3000'
          '这部八部分的剧集将探索自然世界的独特又宝贵的奇迹，由屡获奖项的剧集《地球脉动》的创剧人倾情打造。通过与世界自然基金会合作，《我们的星球》采用了令人惊艳的摄影和技术，并以前所未有的拍摄方式探寻了地球上尚存的野生区域和那里的动物居民。这档耗时 '
          '4 年的大制作节目在遍布全球各个大洲的 50 个国家/地区进行过拍摄，600 多名工作人员共计花费超过 3500 '
          '个拍摄日，从偏远的北极荒野和神秘的深海到广袤的非洲地貌和南美多样化的热带雨林，全面关注全世界生境多样性的广度。',
 'is_new': False,
 'name': '我们的星球',
 'platforms': '',
 'publishdate': '2019-04-05',
 'rate': 9.8,
 'sectionid': 'rrmj_1425',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30374707/'}
2020-04-30 14:12:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%90%8C%E8%A1%8C%20%E7%AC%AC%E4%BA%8C%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:12:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30433323/> (referer: https://www.douban.com/search?q=%E5%BE%B7%E9%B2%81%E7%BA%B3%E9%85%92%E5%BA%97)
2020-04-30 14:12:38 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30433323/>
{'cover': 'http://img.rr.tv/album/20190702/o_1562031959379.jpg',
 'data_type': 'movie',
 'id': 'rrmj_15101',
 'intro': '据悉演员IU、吕珍九确定接演tvN新剧《月之酒店》，该剧因是韩剧洪氏姐妹的新剧而备受瞩目，讲述精英酒店经理人因一场命中注定的事件而与美如皎月却性格孤僻的老板一同经营月之酒店的故事，IU李知恩将在剧中饰演张满月，因犯下重罪而在漫长岁月里被束缚于月之酒店，在酒店里打发着无聊琐碎的时光，外表高傲美丽，性格却异常孤僻，贪心善变又会耍心机；吕珍九将饰演精英酒店经理人具灿成一角，性格中有着强迫症、洁癖以及偏执的完美主义者，虽然看似理智又冷静，但其实内心也有着脆弱的一面，对自己要求严苛，打造了自己完美的工作履历，坐上了跨国酒店集团最年轻的二掌门的位置，却因意想不到的原因来到了月之酒店，接待鬼客。',
 'is_new': False,
 'name': '德鲁纳酒店',
 'platforms': '',
 'publishdate': '2019-07-13',
 'rate': 8.0,
 'sectionid': 'rrmj_1917',
 'tags': ['剧情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30433323/'}
2020-04-30 14:12:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30443773/> (referer: https://www.douban.com/search?q=%E6%88%91%E4%BB%AC%E4%B8%80%E5%AE%B6%E4%BA%BA)
2020-04-30 14:12:40 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30443773/>
{'cover': 'http://img.rr.tv/album/20190705/o_1562310177683.jpg',
 'data_type': 'movie',
 'id': 'rrmj_15264',
 'intro': '一位留学后移民美国的中国同志，他和他的同性伴侣在美国通过代孕生子创造了一个彻底的现代家庭。但现在他的难题是如何向他那非常传统的中国父母和亲戚介绍自己的伴侣和孩子...…',
 'is_new': False,
 'name': '我们一家人',
 'platforms': '',
 'publishdate': '2019-05-03',
 'rate': 8.1,
 'sectionid': 'rrmj_1431',
 'tags': ['纪录片', '短片', '同性'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30443773/'}
2020-04-30 14:12:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/33459786/> (referer: https://www.douban.com/search?q=%E5%92%96%E5%95%A1%E4%B8%8E%E9%A6%99%E8%8D%89)
2020-04-30 14:12:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/33459786/>
{'cover': 'http://img.rr.tv/album/20190726/o_1564107831799.jpg',
 'data_type': 'movie',
 'id': 'rrmj_15224',
 'intro': '超受欢迎的女大学生白城里沙(福原遥饰)一直被周围的人当作可望而不可及的存在,但其实她完全没有过恋爱经验.                                                                    \u3000\u3000'
          '里沙一直梦想着能有一场很甜很甜的恋爱,一天,正饱受搭讪困扰的里沙面前出现了一个叫深见宏斗(樱田通饰)的男人,他西装革履,成熟稳重,巧妙地帮里沙解决了麻烦.为表达感谢,里沙要和深见一起吃饭……',
 'is_new': False,
 'name': '咖啡与香草',
 'platforms': '',
 'publishdate': '2019-07-04',
 'rate': 6.1,
 'sectionid': 'rrmj_1917',
 'tags': ['剧情', '爱情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/33459786/'}
2020-04-30 14:12:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/34851294/> (referer: https://www.douban.com/search?q=%E5%A4%AB%E5%A6%BB%E7%9A%84%E4%B8%96%E7%95%8C)
2020-04-30 14:12:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/34851294/>
{'cover': 'http://img.rr.tv/cover/20200312/o_1583994488192.jpg',
 'data_type': 'movie',
 'id': 'rrmj_17315',
 'intro': '该剧是讲述原以为是相爱着的夫妻的缘分因为背叛而终结，并被卷入复仇的旋涡的故事。将描写想毁掉对方的憎恨成为一种爱的形式，拼死勒住彼此的脖子的激烈的爱情。                                                                    \u3000\u3000'
          '由《Misty》毛完日导演执导，《玉氏南政基》朱贤编剧执笔，接档《梨泰院Class》播出。',
 'is_new': False,
 'name': '夫妻的世界',
 'platforms': '',
 'publishdate': '2020-03-27',
 'rate': 8.3,
 'sectionid': 'rrmj_1912',
 'tags': ['剧情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/34851294/'}
2020-04-30 14:12:47 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/6017331/> (referer: https://www.douban.com/search?q=%E5%A4%8D%E4%BB%87%20%E7%AC%AC%E4%BA%8C%E5%AD%A3)
2020-04-30 14:12:47 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/6017331/>: HTTP status code is not handled or not allowed
2020-04-30 14:12:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/25785114/> (referer: https://www.douban.com/search?q=%E4%BA%92%E8%81%94%E7%BD%91%E4%B9%8B%E5%AD%90)
2020-04-30 14:12:51 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/25785114/>
{'cover': 'http://img.rr.tv/album/20190705/o_1562309385093.webp',
 'data_type': 'movie',
 'id': 'rrmj_15260',
 'intro': '本片《互联网之子》讲的是编程天才和信息活动家 亚伦·斯沃茨 '
          '的故事。                                                                    \u3000\u3000'
          '从参与基础互联网协议RSS到联合创办Reddit，斯沃茨的足迹遍及整个互联网。                                                                    \u3000\u3000'
          '但斯沃茨在社会公正和政治组织方面的开创性工作，以及对信息存取的雄心壮志，                                                                    \u3000\u3000'
          '使他陷入了一场两年之久的法律噩梦。                                                                        '
          '亚伦的故事也触动了对他如雷贯耳的网络社区之外的人们。',
 'is_new': False,
 'name': '互联网之子',
 'platforms': '',
 'publishdate': '2014-01-20',
 'rate': 9.1,
 'sectionid': 'rrmj_1399',
 'tags': ['纪录片', '传记'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/25785114/'}
2020-04-30 14:12:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26334993/> (referer: https://www.douban.com/search?q=%E7%A7%91%E6%AF%94%E7%9A%84%E7%BC%AA%E6%96%AF)
2020-04-30 14:12:53 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26334993/>
{'cover': 'http://img.rr.tv/cover/20200127/o_1580104243561.webp',
 'data_type': 'movie',
 'id': 'rrmj_17085',
 'intro': '这部长篇记录片背标邦威记录科比的生活，灵感及遇到的挑战，也为他下一季重回NBA赛季奠定了基础。这部片子还会聚焦在科比在其职业生涯内所取得的成功及面临的挑战，让大家看到另一面的篮球明星。科比在片中也会谈到自己对于运动生涯结束后的规划，尽管没有给出详细的例子，但是Showt '
          'ime节目表示科比的“个人成长经历”也会着重被讲述。                                                                    \u3000\u3000'
          '“《科比·布莱恩特的缪斯》将提供给观众一个全面的职业运动员，一个已经超越了自身职业并成为了一个标志性人物的运动员”。美国娱乐时间电视台执行副总裁埃斯皮诺萨表示，“我们很高兴，科比给了我们这个前所未有的访问，这将让我们的观众见证一次NBA的最伟大球员之一生命中这样一个充满挑战的时期”。                                                                    \u3000\u3000'
          '科比·布莱恩特，18次进入NBA全明星赛，五次进入NBA总冠军赛，因为左膝受伤而缺席了2013-14赛季。',
 'is_new': False,
 'name': '科比的缪斯',
 'platforms': '',
 'publishdate': '2015-02-21',
 'rate': 9.1,
 'sectionid': 'rrmj_1399',
 'tags': ['纪录片', '传记', '运动'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26334993/'}
2020-04-30 14:12:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26911443/> (referer: https://www.douban.com/search?q=%E6%B0%91%E4%B8%BB%E7%9A%84%E8%BE%B9%E7%BC%98)
2020-04-30 14:12:55 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26911443/>
{'cover': 'http://img.rr.tv/cover/20190910/o_1568102479088.webp',
 'data_type': 'movie',
 'id': 'rrmj_15808',
 'intro': '巴西曾一度因军事独裁而陷于瘫痪。在1985年，巴西建立了民主基础。在2002年，巴西选举出了一位非常受欢迎的政治颠覆者：钢铁工人转为活动家路易斯·伊纳西奥·卢拉·达·席尔瓦(Luiz '
          'Inácio Lula da '
          'Silva)。在他的领导下，2000万巴西人摆脱了贫困，他的国家在国际上声名鹊起。2010年，“卢拉”将总统指挥棒传给了他的继任者，一个名叫迪尔玛·罗塞夫(Dilma '
          'Rousseff)的凶猛的女游击队队员。                                                                            \u3000\u3000'
          '但是，在他们阳光灿烂的遗产背后，民粹主义愤怒和机构腐败的喧嚣蔓延到主流，其中大部分受到一位党派法官的怂恿，这位法官给新闻媒体提供了耸人听闻的、有严重缺陷的腐败报道，这些报道针对的是卢拉(Lula)、迪尔玛(Dilma)，以及其他拒绝讨好有权势的政治家和特别利益集团的人。                                                                            \u3000\u3000'
          '通过非常密切的接触，《民主的边缘》紧跟着巴西四面楚歌的领导人，他...',
 'is_new': False,
 'name': '民主的边缘',
 'platforms': '',
 'publishdate': '2019-01-24',
 'rate': 8.0,
 'sectionid': 'rrmj_1657',
 'tags': ['纪录片', '历史'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26911443/'}
2020-04-30 14:12:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26928137/> (referer: https://www.douban.com/search?q=%E7%BB%88%E5%AE%88%E9%98%BF%E5%8B%92%E6%B3%A2)
2020-04-30 14:12:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26928137/>
{'cover': 'http://img.rr.tv/album/20190306/o_1551858674387.webp',
 'data_type': 'movie',
 'id': 'rrmj_14239',
 'intro': 'After five years of war in Syria, Aleppos remaining residents '
          'prepare themselves for a siege. Khalid, Subhi and Mahmoud, founding '
          'members of The White Helmets, have remained in the city to help '
          'their fellow citizens-and experience daily life, death, struggle '
          'and triumph in a city under '
          'fire.                                                                            \u3000\u3000'
          '《阿勒波的最后一个人》（Last Men in Aleppo） 导演：菲拉斯·法耶德（Feras '
          'Fayyad）、斯蒂恩·约翰内森（Steen Johannessen） 丹...',
 'is_new': False,
 'name': '终守阿勒波',
 'platforms': '',
 'publishdate': '2017-01-23',
 'rate': 5.9,
 'sectionid': 'rrmj_1657',
 'tags': ['纪录片', '战争'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26928137/'}
2020-04-30 14:13:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26988678/> (referer: https://www.douban.com/search?q=%E5%A9%9A%E5%A7%BB%E5%B9%B3%E6%9D%83%E8%B7%AF)
2020-04-30 14:13:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26988678/>
{'cover': 'http://img.rr.tv/album/20190925/o_1569390050271.webp',
 'data_type': 'movie',
 'id': 'rrmj_15967',
 'intro': 'This is the epic, untold story of how same-sex marriage became law '
          'of the land. Documenting one of the greatest civil rights stories '
          'of our time, THE FREEDOM TO MARRY is a nail-biting, '
          'behind-the-scenes story that traces the marriage equality movements '
          'historic progress, and reveals the masterminds of the movement as '
          'they lead the fight to win same sex marriage throughout the ...',
 'is_new': False,
 'name': '婚姻平权路',
 'platforms': '',
 'publishdate': '2017-03-03',
 'rate': 8.9,
 'sectionid': 'rrmj_1431',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26988678/'}
2020-04-30 14:13:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27032268/> (referer: https://www.douban.com/search?q=%E5%90%8C%E5%BF%97%E6%88%90%E9%95%BF%E8%AE%B0)
2020-04-30 14:13:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/27032268/>
{'cover': 'http://img.rr.tv/album/20190620/o_1561018641303.webp',
 'data_type': 'movie',
 'id': 'rrmj_15159',
 'intro': '该纪录片主人翁是Years & Years乐队的主唱兼键盘手：Olly '
          'Alexander，该片以其个人经历为线索，讲述了他读书时期，因遭受校园霸凌导致抑郁症，由此引出性少数人群在成长过程中，为何更易遭受心理问题的困扰，且心理疾病的患病率要高于普通人群。',
 'is_new': False,
 'name': '同志成长记',
 'platforms': '',
 'publishdate': '2017-07-18',
 'rate': 7.5,
 'sectionid': 'rrmj_1431',
 'tags': ['紀錄片 Documentary'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/27032268/'}
2020-04-30 14:13:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%8D%9A%E6%96%AF%20%E7%AC%AC%E5%85%AD%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:13:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27203609/> (referer: https://www.douban.com/search?q=%E5%8F%98%E6%80%A7%E5%88%87%E5%B0%94%E8%A5%BF)
2020-04-30 14:13:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%92%B2%E5%85%AC%E8%8B%B1%E7%9A%84%E7%81%B0%E5%B0%98> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:13:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/27203609/>
{'cover': 'http://img.rr.tv/album/20190904/o_1567576385932.webp',
 'data_type': 'movie',
 'id': 'rrmj_15767',
 'intro': '布拉德利·爱德华·曼宁，美国陆军上等兵。他利用职务之便，非法下载了二十五万份美国政府的机密资料，转交给维基解密。他在网络上向另一位黑客Adrian '
          'Lamo夸耀此事，遭举发。                                                                    \u3000\u3000'
          '2013年，曼宁被判在军事监狱服刑35年。被判刑后，她宣布自己要变为女性，并改名切尔西·曼宁。2016年，曼宁在狱中接受变性手术。2017年1月，美国前总统奥巴马在卸任前为她减刑，同年5月曼宁获释。2019年3月，曼宁再次被捕。2019年4月22日，美国联邦法院驳回了曼宁的保释上诉，她将继续坐牢。',
 'is_new': False,
 'name': '变性切尔西',
 'platforms': '',
 'publishdate': '2019-05-24',
 'rate': 7.6,
 'sectionid': 'rrmj_1431',
 'tags': ['同性', '传记'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/27203609/'}
2020-04-30 14:13:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27605447/> (referer: https://www.douban.com/search?q=%E5%A4%A9%E5%A0%82%E5%A4%A7%E5%A1%9E%E8%BD%A6)
2020-04-30 14:13:08 [scrapy.core.scraper] ERROR: Error processing {'cover': 'http://img.rr.tv/album/20190313/o_1552458087226.webp',
 'data_type': 'movie',
 'id': 'rrmj_14292',
 'intro': '明迪·阿尔珀是一位56岁的艺术家，在洛杉矶的一家顶级画廊中担任代理。严重的焦虑、精神错乱和严重的抑郁症使她被送进精神病院接受电击治疗，在10年的时间里没有说话的能力。她的高度自我意识使她能够产生毕生的作品，以强有力的心理精确表达她的情感状态。通过采访、重新设计、为她心爱的精神病医生制作一个八英尺半高的纸制半身像，以及检查她小时候的画作，我们了解到她是如何从黑暗和孤独中走出来，走向包括爱、信任和支持在内的生活。',
 'is_new': False,
 'name': '天堂大塞车',
 'platforms': '',
 'publishdate': '',
 'rate': 8.0,
 'sectionid': 'rrmj_1657',
 'tags': ['纪录片', '短片', '传记'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/27605447/'}
Traceback (most recent call last):
  File "/usr/python37/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/python37/lib/python3.7/site-packages/scrapy/utils/defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/root/spider/scrapyspider/spiderV1/pipelines.py", line 262, in process_item
    timeStruct = time.strptime(publishdate, '%Y-%m-%d')
  File "/usr/python37/lib/python3.7/_strptime.py", line 571, in _strptime_time
    tt = _strptime(data_string, format)[0]
  File "/usr/python37/lib/python3.7/_strptime.py", line 359, in _strptime
    (data_string, format))
ValueError: time data '' does not match format '%Y-%m-%d'
2020-04-30 14:13:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/33461071/> (referer: https://www.douban.com/search?q=%E9%98%BF%E5%A7%86%E6%96%AF%E7%89%B9%E6%9C%97)
2020-04-30 14:13:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/33461071/>
{'cover': 'http://img.rr.tv/album/20190814/o_1565765051543.webp',
 'data_type': 'movie',
 'id': 'rrmj_15596',
 'intro': '2019年阿姆斯特朗壮全长传记纪录片',
 'is_new': False,
 'name': '阿姆斯特朗',
 'platforms': '',
 'publishdate': '2019-07-12',
 'rate': 7.3,
 'sectionid': 'rrmj_1399',
 'tags': ['纪录片', '传记'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/33461071/'}
2020-04-30 14:13:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E9%BE%99%E7%8E%8B%E5%AD%90%E7%AC%AC%E4%BA%8C%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:13:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/34834426/> (referer: https://www.douban.com/search?q=%E4%B8%AD%E5%9B%BD%E7%9A%84%E9%87%8D%E7%94%9F)
2020-04-30 14:13:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/34834426/>
{'cover': 'http://img.rr.tv/album/20191015/o_1571121882616.webp',
 'data_type': 'movie',
 'id': 'rrmj_16164',
 'intro': '片中所用的影像素材并非全新，只是“先前从未公之于世”。这些素材由10多位苏联最杰出的纪录片大师在70年前实地拍摄而成。1949年，苏联派摄影师们前往百废待兴的中国，纪录新中国的诞生。这批资料的备注名便是《苏联摄影师眼中的中国》。它们在苏俄纪录片档案库里沉睡了半个多世纪，所幸全俄国家广播电视公司历史频道总编辑杰尼索夫从浩如烟海的胶片中发现了它们，并决意向人们展现：如今我们所熟悉的中国，在70年前曾经遭遇哪些困难，有着怎样的市井生活？',
 'is_new': False,
 'name': '中国的重生',
 'platforms': '',
 'publishdate': '2019-09-16',
 'rate': 9.3,
 'sectionid': 'rrmj_1425',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/34834426/'}
2020-04-30 14:13:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%B8%AD%E5%9B%BD%E8%80%81%E5%B8%88%E6%9D%A5%E4%BA%86> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:13:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/34907421/> (referer: https://www.douban.com/search?q=%E7%BE%8E%E5%88%A9%E5%9D%9A%E5%A5%B3%E5%A3%AB)
2020-04-30 14:13:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/34907421/>
{'cover': 'http://img.rr.tv/cover/20200202/o_1580633113752.webp',
 'data_type': 'movie',
 'id': 'rrmj_17107',
 'intro': '本片以不加修饰和感性的方式，记录了当代最标志性的艺人之一泰勒·斯威夫特在人生转折期的点滴。该片讲述泰勒如何在他人的期许之下找到自我。导演拉娜·威尔逊通过这部明亮而多角度的电影，展现了一名国际巨星如何接纳自己的多重身份：她不仅是词曲作者和表演者，还是一名能够用声音带来影响力的女性。',
 'is_new': False,
 'name': '美利坚女士',
 'platforms': '',
 'publishdate': '2020-01-23',
 'rate': 8.9,
 'sectionid': 'rrmj_1295',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/34907421/'}
2020-04-30 14:13:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%85%A8%E7%90%83%E7%8E%AF%E4%BF%9D%E5%88%9B%E6%84%8F> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:13:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26316022/> (referer: https://www.douban.com/search?q=Nicki%20Minaj%3A%20My%20Time%20Again)
2020-04-30 14:13:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26316022/>
{'cover': 'http://img.rr.tv/album/20190423/o_1556017210011.png',
 'data_type': 'movie',
 'id': 'rrmj_14645',
 'intro': '"Nicki Minaj: My Time AGAIN" showcases the superstar at her most '
          'raw and uninhibited as she prepares to release her most '
          'introspective album to date, "The Pinkprint."',
 'is_new': False,
 'name': 'Nicki Minaj: My Time Again',
 'platforms': '',
 'publishdate': '2015-01-18',
 'rate': 6.0,
 'sectionid': 'rrmj_1295',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26316022/'}
2020-04-30 14:13:19 [scrapy.extensions.logstats] INFO: Crawled 148 pages (at 37 pages/min), scraped 81 items (at 22 items/min)
2020-04-30 14:13:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%8F%8D%E6%AD%A3%E6%98%AF%E7%BA%AA%E5%BF%B5%E6%97%A5> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:13:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26358147/> (referer: https://www.douban.com/search?q=%E4%B8%BB%E5%8E%A8%E7%9A%84%E9%A4%90%E6%A1%8C)
2020-04-30 14:13:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26358147/>
{'cover': 'https://img.rr.tv/season/20180412/o_1523503434619.png',
 'data_type': 'movie',
 'id': 'rrmj_12008',
 'intro': 'Netflix美食纪录片.影片分别记录了来自意大利,美国,阿根廷,澳大利亚,瑞典的六大名厨的厨房生活.本片恢宏大气.是关于食物,信念,坚持与创造的故事,动人心魄',
 'is_new': False,
 'name': '主厨的餐桌',
 'platforms': '',
 'publishdate': '2015-04-26',
 'rate': 9.2,
 'sectionid': 'rrmj_1883',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26358147/'}
2020-04-30 14:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%A4%A7%E7%86%8A%E7%8C%AB%E7%9A%84%E7%94%9F%E6%B4%BB> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:13:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26435723/> (referer: https://www.douban.com/search?q=%E5%BF%83%E9%87%8C%E7%9A%84%E5%A3%B0%E9%9F%B32)
2020-04-30 14:13:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26435723/>
{'cover': 'http://img.rr.tv/album/20190617/o_1560736618065.jpg',
 'data_type': 'movie',
 'id': 'rrmj_15112',
 'intro': '《心里的声音》改编自赵石网络漫画，由河秉勋执导，李光洙、郑素敏、金大明等主演。乍看之下可能会觉得这只是一部以描绘日常生活为主题的作品，但其实里面的故事非常夸张和搞笑，绝对只会发生在漫画中。该剧先行在Naver '
          'cast播出十集、每集10分钟的先行版，之后在KBS 2TV电视台放送。',
 'is_new': False,
 'name': '心里的声音2',
 'platforms': '',
 'publishdate': '2016-11-07',
 'rate': 9.1,
 'sectionid': 'rrmj_1917',
 'tags': ['剧情', '喜剧'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26435723/'}
2020-04-30 14:13:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%AD%A4%E9%AB%98%E7%9A%84%E6%89%8B%E6%9C%AF%E5%88%80> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:13:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/25955694/> (referer: https://www.douban.com/search?q=%E8%A1%80%E6%97%8F%20%E7%AC%AC%E4%BA%8C%E5%AD%A3)
2020-04-30 14:13:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/25955694/>
{'cover': 'https://img.rr.tv/video/20151009/o_1444394929665.jpg',
 'data_type': 'movie',
 'id': 'rrmj_469',
 'intro': '美剧《血族》改编自吉尔莫·德尔·托罗和Chuck '
          'Hogan联合出版的同名小说。承接第一季剧情，在本季中，人类和吸血鬼之间的战争仍在继续， “血祖”The Master '
          '继续实施他的邪恶计划，而病毒已遍布全美，幸存者们不仅要对抗反派，还要继续寻找治疗病毒的方法。据悉，原著角色“昆兰”将登场，第一季血族突击队队长并非真正的昆兰。',
 'is_new': False,
 'name': '血族 第二季',
 'platforms': '',
 'publishdate': '2015-07-12',
 'rate': 7.2,
 'sectionid': 'rrmj_1917',
 'tags': ['剧情', '恐怖'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/25955694/'}
2020-04-30 14:13:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%AE%A1%E5%88%A4%E5%85%AB%E5%8F%B7%E6%8F%90%E6%A1%88> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:13:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26811832/> (referer: https://www.douban.com/search?q=%E7%BE%9E%E8%80%BB%20%E7%AC%AC%E4%B8%89%E5%AD%A3)
2020-04-30 14:13:28 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26811832/>
{'cover': 'http://img.rr.tv/album/20190430/o_1556622116373.jpg',
 'data_type': 'movie',
 'id': 'rrmj_12391',
 'intro': '在奥斯陆Hartvig Nissens上高中的一群年轻人的青春故事，每一季变换一个主角',
 'is_new': False,
 'name': '羞耻 第三季',
 'platforms': '',
 'publishdate': '2016-10-07',
 'rate': 9.6,
 'sectionid': 'rrmj_989',
 'tags': ['剧情', '爱情', '同性'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26811832/'}
2020-04-30 14:13:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26947951/> (referer: https://www.douban.com/search?q=%E7%8E%8B%E5%9B%BD%20%E7%AC%AC%E4%B8%80%E5%AD%A3)
2020-04-30 14:13:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26947951/>
{'cover': 'http://img.rr.tv/album/20181204/o_1543919351131.jpg',
 'data_type': 'movie',
 'id': 'rrmj_13702',
 'intro': '在一个充斥着贪腐和饥荒的王国中，关于国王死亡的神秘传闻沸沸扬扬，同时一场奇怪的瘟疫传播开来，感染者可获得不死之身并嗜食人肉。成为阴谋牺牲品的世子开始踏上揭露邪恶阴谋，拯救子民的征程。',
 'is_new': False,
 'name': '王国 第一季',
 'platforms': '',
 'publishdate': '2019-01-25',
 'rate': 8.5,
 'sectionid': 'rrmj_747',
 'tags': ['剧情', '动作', '惊悚'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26947951/'}
2020-04-30 14:13:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%B0%8F%E5%B0%8F%E5%B7%B4%E9%BB%8E%E5%8E%A8%E6%88%BF> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:13:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%B7%B1%E5%85%A5%E5%AE%8C%E6%95%B4%E6%8A%A5%E9%81%93> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:13:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/25800237/> (referer: https://www.douban.com/search?q=IT%E7%8B%82%E4%BA%BA%E8%AF%B4%E6%98%8E%E4%B9%A6)
2020-04-30 14:13:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/25800237/>
{'cover': 'http://img.rr.tv/album/20190723/o_1563864535837.png',
 'data_type': 'movie',
 'id': 'rrmj_15423',
 'intro': '《IT狂人》幕后纪录片。',
 'is_new': False,
 'name': 'IT狂人说明书',
 'platforms': '',
 'publishdate': '2013-12-24',
 'rate': 9.5,
 'sectionid': 'rrmj_1405',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/25800237/'}
2020-04-30 14:13:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26993119/> (referer: https://www.douban.com/search?q=%E6%B1%89%E5%A8%9C%20%E7%AC%AC%E4%B8%80%E5%AD%A3)
2020-04-30 14:13:34 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26993119/>
{'cover': 'http://img.rr.tv/album/20190204/o_1549254780111.webp',
 'data_type': 'movie',
 'id': 'rrmj_14084',
 'intro': '位于北极圈附近的冰原森林，生活着一对平凡却有着非凡身手的父女。父亲艾利克·海勒（乔尔·金纳曼 '
          '饰）曾是受雇于CIA的特工，在上世纪90年代活跃于东欧和中亚等地，具有丰富的经验。然而最终却因为某种原因，令他带着女儿汉娜隐居在这人类罕至的寒冷所在。经过十多年的艰苦磨练，汉娜（伊斯曼·葛雷德·迈尔斯 '
          '饰）终于成长为拥有广博知识和出色身手的战斗少女。                                                                    \u3000\u3000'
          '某天，自认已做好准备的汉娜按下了父亲那台信号发射器，不久美国方面便收到消息。艾利克当年的联系人玛丽莎（米瑞·伊诺丝 '
          '饰）声称这个消失多年的特工掌握非常敏感的秘密，于是在她的主持下，一场居心叵测的围捕旋即展开。汉娜也已柔弱的身躯投入了血腥的战斗之中……',
 'is_new': False,
 'name': '汉娜 第一季',
 'platforms': '',
 'publishdate': '2019-02-03',
 'rate': 7.5,
 'sectionid': 'rrmj_747',
 'tags': ['剧情', '动作', '悬疑'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26993119/'}
2020-04-30 14:13:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%8B%97%E7%9A%84%E7%A7%98%E5%AF%86%E7%94%9F%E6%B4%BB> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:13:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30206924/> (referer: https://www.douban.com/search?q=%E4%BA%BF%E4%B8%87%20%E7%AC%AC%E5%9B%9B%E5%AD%A3)
2020-04-30 14:13:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30206924/>
{'cover': 'http://img.rr.tv/album/20190318/o_1552876058087.jpg',
 'data_type': 'movie',
 'id': 'rrmj_14324',
 'intro': 'Showtime剧集《亿万》正式续订第4季。',
 'is_new': False,
 'name': '亿万 第四季',
 'platforms': '',
 'publishdate': '2019-03-17',
 'rate': 9.4,
 'sectionid': 'rrmj_1871',
 'tags': ['剧情', '犯罪'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30206924/'}
2020-04-30 14:13:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%A7%A3%E8%AF%B4%E4%B8%96%E7%95%8C%E7%BB%8F%E6%B5%8E> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:13:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30306401/> (referer: https://www.douban.com/search?q=%E7%8E%8B%E5%9B%BD%20%E7%AC%AC%E4%BA%8C%E5%AD%A3)
2020-04-30 14:13:39 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30306401/>
{'cover': 'http://img.rr.tv/cover/20200218/o_1581996865594.jpg',
 'data_type': 'movie',
 'id': 'rrmj_17187',
 'intro': '疫情爆发，人人自危。在世子李苍捍卫朝鲜王国之际，挡在他面前的不仅仅是染疫之人。',
 'is_new': False,
 'name': '王国 第二季',
 'platforms': '',
 'publishdate': '2020-03-13',
 'rate': 9.0,
 'sectionid': 'rrmj_1726',
 'tags': ['剧情', '动作', '惊悚'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30306401/'}
2020-04-30 14:13:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%B4%9E%E7%A9%B4%E9%87%8C%E7%9A%84%E5%8C%BB%E9%99%A2> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:13:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%98%9F%E7%96%AB%E6%B1%82%E7%94%9F%E6%8C%87%E5%8D%97> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:13:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26857109/> (referer: https://www.douban.com/search?q=%E5%90%8C%E8%A1%8C%20%E7%AC%AC%E4%BA%8C%E5%AD%A3)
2020-04-30 14:13:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26857109/>
{'cover': 'http://img.rr.tv/album/20190911/o_1568180345013.webp',
 'data_type': 'movie',
 'id': 'rrmj_15814',
 'intro': '在这部纪录片里，艾伦·佩姬和她的好友伊恩·丹尼尔继续与观众一起探索世界各地的LGBTQ文化。从乌克兰到印度，从法国再深入到美国南部，领略各地风情，倾听人们对生活的看法以及他们的故事。然而就在第二季节目播出前，奥兰多发生惨案，为这部纪录片增添了新的注脚。这让我们深刻领悟到 '
          '，平权不是最终目的，改变陈旧观念才是。然而任重且道远。',
 'is_new': False,
 'name': '同行 第二季',
 'platforms': '',
 'publishdate': '2016-08-24',
 'rate': 9.3,
 'sectionid': 'rrmj_1431',
 'tags': ['纪录片', '同性'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26857109/'}
2020-04-30 14:13:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%89%AF%E5%8C%BB%20%E7%AC%AC%E4%B8%89%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:13:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27664017/> (referer: https://www.douban.com/search?q=%E9%BB%91%E9%92%B1%20%E7%AC%AC%E4%B8%80%E5%AD%A3)
2020-04-30 14:13:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/27664017/>
{'cover': 'http://img.rr.tv/album/20190306/o_1551852995205.webp',
 'data_type': 'movie',
 'id': 'rrmj_14229',
 'intro': '从害人不浅的发薪日贷款到尾气排放测试作假的汽车，这部调查类剧集揭露了企业厚颜无耻的贪腐行径。',
 'is_new': False,
 'name': '黑钱 第一季',
 'platforms': '',
 'publishdate': '2018-01-26',
 'rate': 8.6,
 'sectionid': 'rrmj_1420',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/27664017/'}
2020-04-30 14:13:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%BC%9E%E5%AD%A6%E9%99%A2%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:13:46 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/756321120/> (referer: https://www.douban.com/search?q=%E8%A1%80%E7%96%AB%20%E7%AC%AC%E4%B8%80%E5%AD%A3)
2020-04-30 14:13:46 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/756321120/>: HTTP status code is not handled or not allowed
2020-04-30 14:13:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%85%BB%E8%82%B2%E8%80%85%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:13:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/34953546/> (referer: https://www.douban.com/search?q=%E8%B7%9F%E9%B2%A8%E9%B1%BC%E6%8E%A5%E5%90%BB)
2020-04-30 14:13:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/34953546/>
{'cover': 'http://img.rr.tv/seasonCover/20200424/o_1587699113456.jpg',
 'data_type': 'movie',
 'id': 'rrmj_17556',
 'intro': '身处职场食物链顶端的『鲨鱼女王』，却在爱情的海域里遇上天敌『虎鲸男』。当真心被无条件偷走、骄傲的尖牙被拔去，断鯺后的鲨鱼该如何重返荣耀？                                                                    \u3000\u3000'
          '受伤的鲨鱼和虎鲸，在深海的海沟里相遇。他们曾经是狩猎者和掠夺者，也曾经互相撕咬、攻击，如今为了生存，他们必须成为对方的鯺，一起游向远洋，将失去的一切，重新夺回。而这一次，杜艾纱告诉自己一定要守住真心，不能再让易飞洋有机可趁。然而爱情的海域里，总是危机四伏，谁都没有把握，到底谁才是这场爱情食物链里的最终赢家！',
 'is_new': False,
 'name': '跟鲨鱼接吻',
 'platforms': '',
 'publishdate': '2020-02-02',
 'rate': 8.0,
 'sectionid': 'rrmj_1904',
 'tags': ['爱情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/34953546/'}
2020-04-30 14:13:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%A5%B3%E6%9C%8B%E5%8F%8B%20%E7%AC%AC%E4%BA%8C%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:13:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/5969408/> (referer: https://www.douban.com/search?q=%E4%B8%91%E9%97%BB%20%E7%AC%AC%E4%B8%80%E5%AD%A3)
2020-04-30 14:13:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/5969408/>
{'cover': 'http://img.rr.tv/seasonCover/20200424/o_1587712722916.png',
 'data_type': 'movie',
 'id': 'rrmj_192',
 'intro': '该剧是《实习医生格蕾》、《私人诊所》和《人在异乡》创作者Shonda Rhimes多年来打造的第一部非医学剧，根据Judy '
          'Smith的真人真事改编。故事主要描述一名危机处理专家及其所领导的团队的工作与生活。                                                                            \u3000\u3000'
          '从媒体关系顾问到总统新闻顾问，Olivia Pope（Kerry '
          'Washington扮演）一辈子都在保护美国的秘密－－对她来说，维护美国精英阶层的形象、避免让各种丑闻曝光对这个国家来说是极其重要的事情。小布什的总统任期结束后，和布什关系密切的Olivia离开了白宫，创办了自己的公关公司，希望就此揭开人生的新篇章－－无论工作还是生活。可是她似乎无法完全摆脱过去－－无论是她还是她的精英团队，他们能够「修复」任何人的生活，但却对自己生活中出现的问题无能为力。                                                                            \u3000\u3000'
          '来自《迷失》的Henry Ian Cusick扮演男主人公Stephen，诉讼律师，为Ol...',
 'is_new': False,
 'name': '丑闻 第一季',
 'platforms': '',
 'publishdate': '2012-04-05',
 'rate': 7.5,
 'sectionid': 'rrmj_1912',
 'tags': ['剧情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/5969408/'}
2020-04-30 14:13:53 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/646388/> (referer: https://www.douban.com/search?q=%E9%BE%99%E7%8E%8B%E5%AD%90%E7%AC%AC%E4%BA%8C%E5%AD%A3)
2020-04-30 14:13:53 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/646388/>: HTTP status code is not handled or not allowed
2020-04-30 14:13:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%8C%8E%E9%AD%94%E4%BA%BA%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:13:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E9%BB%91%E6%AD%BB%E7%97%85%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:13:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/3011414/> (referer: https://www.douban.com/search?q=%E8%92%B2%E5%85%AC%E8%8B%B1%E7%9A%84%E7%81%B0%E5%B0%98)
2020-04-30 14:13:56 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/3011414/>
{'cover': 'http://img.rr.tv/album/20191019/o_1571464520231.webp',
 'data_type': 'movie',
 'id': 'rrmj_16263',
 'intro': '杰克（科尔·豪瑟 Cole Hauser 饰）和莫利（凯特·勒维宁 Kate Levering '
          '饰）是一对平凡的夫妻，他们和收养来的儿子乔伊（Maxwell Perry Cotton '
          '饰）过着平静而又安宁的生活。虽然乔伊并非亲生，但莫利和杰克早就将其视如己出。                                                                    \u3000\u3000'
          '一天，一通突如其来的电话让美好的生活化作了泡影。原来，乔伊的生父名叫瑞普（巴里·佩珀 Barry Pepper '
          '饰），刚刚出狱的他同妻子温蒂（米拉·索维诺 Mira Sorvino '
          '饰）做出了一个莽撞的决定，他们决定将乔伊从莫利和杰克的身边带走，去建立属于他们的新家庭。这一消息使夫妻二人陷入了极度恐慌，为了保护乔伊不被夺走，他们的脑海里开始酝酿出了一个计划。而在四个大人剑拔弩张之际，谁也没有想到去问一问作为当事人的乔伊心中的想法。',
 'is_new': False,
 'name': '蒲公英的灰尘',
 'platforms': '',
 'publishdate': '2010-09-24',
 'rate': 8.5,
 'sectionid': 'rrmj_1729',
 'tags': ['剧情', '家庭'],
 'type': 'movie',
 'url': 'https://movie.douban.com/subject/3011414/'}
2020-04-30 14:13:57 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/300715/> (referer: https://www.douban.com/search?q=%E5%85%A8%E7%90%83%E7%8E%AF%E4%BF%9D%E5%88%9B%E6%84%8F)
2020-04-30 14:13:57 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/300715/>: HTTP status code is not handled or not allowed
2020-04-30 14:13:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%B8%8B%E4%B8%80%E7%AB%99%EF%BC%8C%E5%B9%B8%E7%A6%8F> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:14:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%AE%88%E6%8A%A4%E8%80%85%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:14:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/34439111/> (referer: https://www.douban.com/search?q=%E5%8D%9A%E6%96%AF%20%E7%AC%AC%E5%85%AD%E5%AD%A3)
2020-04-30 14:14:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/34439111/>
{'cover': 'http://img.rr.tv/seasonCover/20200417/o_1587104101924.webp',
 'data_type': 'movie',
 'id': 'rrmj_17521',
 'intro': 'When domestic terrorists threaten the fate of Los Angeles, Harry '
          'Bosch must save the city in the highest stakes season to date. '
          'Watch all episodes April 17!',
 'is_new': False,
 'name': '博斯 第六季',
 'platforms': '',
 'publishdate': '2020-04-17',
 'rate': 8.9,
 'sectionid': 'rrmj_742',
 'tags': ['剧情', '悬疑'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/34439111/'}
2020-04-30 14:14:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%BA%B8%E9%92%9E%E5%B1%8B%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:14:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/1775654/> (referer: https://www.douban.com/search?q=%E8%A7%A3%E8%AF%B4%E4%B8%96%E7%95%8C%E7%BB%8F%E6%B5%8E)
2020-04-30 14:14:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/1775654/>
{'cover': 'http://img.rr.tv/album/20190906/o_1567767162335.png',
 'data_type': 'movie',
 'id': 'rrmj_15153',
 'intro': '“制高点”是普利策纪实文学奖得主丹尼尔.耶尔金教授的一部财经巨著，被西方媒体誉为我们这个时代经济制度的编年史，对包括中国在内的世界各国的经济改革都具有极高的指导意义。“制高点”通过对大量历史人物和历史事件的生动叙述为我们绘制了一幅从政府到市场演变过程的全景图。                                                                            \u3000\u3000'
          '20世纪80年代是全球改革的年代，在西方，撒切尔和里根以激进变革的方式结束了英美国家对市场严格管制，政府撤出了管理经济的制高点，从此，以竞争和开放的自由市场经济体制主导西方主流的经济学家的制高点。在东方，邓小平所推行的渐进式经济改革创造性把社会主义和市场经济的概念结合起来，探寻政府和市场的边界，平稳的在全球经济一体化的过程中，为中国造就了21世纪的经济奇迹。一个世纪，人们一直争论究竟哪种经济模式让人类真正受益是市场还是政府主导？目前 '
          '，许多力量正推动着从国家控制到市场控制的转变。然而，从根本上...',
 'is_new': False,
 'name': '解说世界经济',
 'platforms': '',
 'publishdate': '2004-04-05',
 'rate': 8.0,
 'sectionid': 'rrmj_1005',
 'tags': ['纪录片', '历史'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/1775654/'}
2020-04-30 14:14:05 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/1877623/> (referer: https://www.douban.com/search?q=%E6%B7%B1%E5%85%A5%E5%AE%8C%E6%95%B4%E6%8A%A5%E9%81%93)
2020-04-30 14:14:05 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/1877623/>: HTTP status code is not handled or not allowed
2020-04-30 14:14:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%BF%99%E6%A0%B7%E4%B8%8DOK%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:14:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%9B%9B%E5%A4%84%E6%95%A3%E8%90%BD%E7%9A%84%E7%A2%8E%E7%89%87> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:14:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/3003828/> (referer: https://www.douban.com/search?q=%E5%A4%A7%E7%86%8A%E7%8C%AB%E7%9A%84%E7%94%9F%E6%B4%BB)
2020-04-30 14:14:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/3003828/>
{'cover': 'http://img.rr.tv/album/20180707/o_1530940623259.png',
 'data_type': 'movie',
 'id': 'rrmj_12645',
 'intro': '这是一部以熊猫为主角联系中日两国的纪录片。毛茸茸胖鼓鼓的熊猫似乎过着无忧无虑的生活，他们除了大嚼竹子、滚来滚去，就是呼呼大睡。然而，熊猫是度过了严酷的冰川期、延续了八百万年的物种。这部追拍了熊猫一年多的纪录片将展现出鲜为人知的熊猫的生活。                                                                    \u3000\u3000'
          '影片的一个舞台是坐落在我国四川成都的熊猫繁育研究基地，在这里生活着八十多只熊猫。本片摄制组获得特许成了第一个进入产房拍摄熊猫育儿场面的外国团队。我们将能在片中看到熊猫宝宝一点点成长的历程。第二个舞台则是日本和歌山县的游乐园，这是世界上第一只自己哺育双胞胎儿子的熊猫妈妈美美的家。去年，美美的两个儿子四岁了，它们离开母亲和培育它们长大的饲养员们，乘坐飞机来到了成都的外婆家，重新开始新的生活……',
 'is_new': False,
 'name': '大熊猫的生活',
 'platforms': '',
 'publishdate': '2008-08-30',
 'rate': 8.5,
 'sectionid': 'rrmj_1384',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/3003828/'}
2020-04-30 14:14:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/7015730/> (referer: https://www.douban.com/search?q=%E7%98%9F%E7%96%AB%E6%B1%82%E7%94%9F%E6%8C%87%E5%8D%97)
2020-04-30 14:14:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/7015730/>
{'cover': 'http://img.rr.tv/album/20190822/o_1566454786433.webp',
 'data_type': 'movie',
 'id': 'rrmj_15663',
 'intro': '二十世纪80至90年代，艾滋如瘟疫般肆虐蔓延，夺走超过四千万人的生命。一群年轻勇敢的男女同性恋，他们用强大的信念和行动争取自己的权利。通过走上街头示威，冲击政府机构、渗透科学研究和参与临床实验，他们付出了自己的青春甚至生命，成功扭转了社会的价值认知，寻找到有效的药物和治疗方法，让新世代的艾滋患者免于被宣判死刑的命运。                                                                    \u3000\u3000'
          '本片几乎全部采用当年的历史影像剪辑而成，是导演戴维·弗朗斯的第一部电影作品。《瘟疫求生指南》获得2012年哥谭奖最佳纪录片，并入围第85届奥斯卡最佳纪录片单元。',
 'is_new': False,
 'name': '瘟疫求生指南',
 'platforms': '',
 'publishdate': '2012-01-22',
 'rate': 8.0,
 'sectionid': 'rrmj_1693',
 'tags': ['纪录片', '历史'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/7015730/'}
2020-04-30 14:14:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E9%A3%9E%E4%B8%8D%E8%B5%B7%E6%9D%A5%E7%9A%84%E7%AB%A5%E5%B9%B4> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:14:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%BD%90%E4%BC%8A%E7%9A%84%E8%AF%BB%E5%BF%83%E6%AD%8C%E5%8D%95> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:14:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/19972628/> (referer: https://www.douban.com/search?q=%E5%B0%8F%E5%B0%8F%E5%B7%B4%E9%BB%8E%E5%8E%A8%E6%88%BF)
2020-04-30 14:14:14 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/19972628/>
{'cover': 'http://img.rr.tv/album/20190509/o_1557388353191.png',
 'data_type': 'movie',
 'id': 'rrmj_14773',
 'intro': 'Croydon-born Rachel Khoo demonstrates her flair for the cuisine of '
          'Paris.                                                                            \u3000\u3000'
          '英籍美女厨师Rachel '
          'Khoo為了追求学厨的梦想，毅然放弃自己的时装公关事业，即使不諳法语，仍然坚持独自到法国，入读最有名的法国蓝带厨艺学院，并花三個月学习甜品，然后长居法国，租住一个小地方，开始她的「私房菜」，继续追寻她的煮食之梦。                                                                            \u3000\u3000'
          'Rachel擅长将个人的创意灵感混入传统菜式，为美食添上更多新鲜感。別以为小妮子像其他大厨一样，可以在宽敞的厨房內享受烹饪之乐，其实，她只有一个小小的厨房，在這个小天地，她精心炮制出一流的食物。Rachel深信，不一定只在米其林星级餐厅才可以尝到法国名菜，即使在这个只能容纳四位宾客的小小空间內，同样可以令她的支持者食指大动！                                                                            \u3000\u3000'
          '这位可人儿除了下厨之外，还会走到法国街上，搜...',
 'is_new': False,
 'name': '小小巴黎厨房',
 'platforms': '',
 'publishdate': '2012-03-19',
 'rate': 9.1,
 'sectionid': 'rrmj_1883',
 'tags': ['纪录片', '家庭'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/19972628/'}
2020-04-30 14:14:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/24695878/> (referer: https://www.douban.com/search?q=%E7%8B%97%E7%9A%84%E7%A7%98%E5%AF%86%E7%94%9F%E6%B4%BB)
2020-04-30 14:14:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/24695878/>
{'cover': 'http://img.rr.tv/album/20190626/o_1561537288069.jpg',
 'data_type': 'movie',
 'id': 'rrmj_15205',
 'intro': '聪明的史宾格，呆萌的拉布拉多，矫健的哈士奇，憨态可掬的哈巴狗，每只狗狗都能融化你的心。狗狗如何看待世界，又是如何看待我们？它们有什么不为人知的特殊能力？一切尽在《萌犬秘闻》。',
 'is_new': False,
 'name': '狗的秘密生活',
 'platforms': '',
 'publishdate': '2013-01-31',
 'rate': 9.1,
 'sectionid': 'rrmj_1425',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/24695878/'}
2020-04-30 14:14:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%88%9D%E6%9D%A5%E4%B9%8D%E5%88%B0%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:14:19 [scrapy.extensions.logstats] INFO: Crawled 196 pages (at 48 pages/min), scraped 101 items (at 20 items/min)
2020-04-30 14:14:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%9B%A0%E4%B8%BA%E7%88%B1%E6%83%85%E5%BE%88%E5%A4%8D%E6%9D%82> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:14:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/25785108/> (referer: https://www.douban.com/search?q=%E5%AE%A1%E5%88%A4%E5%85%AB%E5%8F%B7%E6%8F%90%E6%A1%88)
2020-04-30 14:14:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/25785108/>
{'cover': 'http://img.rr.tv/album/20190731/o_1564554764422.jpg',
 'data_type': 'movie',
 'id': 'rrmj_15499',
 'intro': '电影讲述08年美国大选期间，美国加州通过了一项极具争议的8号提案，8号提案将婚姻权界定为仅限于一男一女的婚姻，使加州同志群体丧失了4个月前刚刚获得的合法婚姻权。随后为了争取婚姻平等，两对最普通的加州同性伴侣与8号提案的支持者就8号提案是否违宪开始了一场法庭上的长期战役。影片用5年的时间拍摄，对于美国的司法体系制度和上诉最高法院这神秘的历程做了前所未有的深刻披露。',
 'is_new': False,
 'name': '审判八号提案',
 'platforms': '',
 'publishdate': '2014-01-18',
 'rate': 9.0,
 'sectionid': 'rrmj_1431',
 'tags': ['纪录片', '同性', '传记'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/25785108/'}
2020-04-30 14:14:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26741568/> (referer: https://www.douban.com/search?q=%E6%88%91%E7%9A%84%E6%81%90%E6%80%96%E5%A6%BB%E5%AD%90)
2020-04-30 14:14:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%B0%8F%E9%95%87%E6%BB%8B%E5%91%B3%E7%AC%AC%E4%B8%89%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:14:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26741568/>
{'cover': 'http://img.rr.tv/album/20180322/o_1521715597521.jpg',
 'data_type': 'movie',
 'id': 'rrmj_11849',
 'intro': '居住在某富人社区的望月夫妇过着令人欣羡的幸福生活。望月幸平（伊藤英明 饰）出身贫寒，不过他的妻子真理亚（木村佳乃 '
          '饰）家境优渥。真理亚的父母去世后留下了丰厚的遗产，利用这笔钱幸平经营了一家咖啡店。日常里幸平的衣食起居全由真理亚一人照顾，妻子体贴入微，甚至连望月老家的母亲和姐姐也都关爱有加。可就是这样一位近乎完美的妻子，却因无微不至的关怀而引来幸平越来越多的反感。他与咖啡店主厨北里杏男（相武纱季 '
          '饰）陷入不伦之恋，后者则怂恿他杀掉妻子。                                                                    \u3000\u3000'
          '就当计划准备实施当天，妻子疑似遭人绑架。对方索要两亿日元赎金，否则将杀掉真理亚。看似老天帮助了幸平，然而接下来的事实却让他惊恐万分……',
 'is_new': False,
 'name': '我的恐怖妻子',
 'platforms': '',
 'publishdate': '2016-04-19',
 'rate': 9.0,
 'sectionid': 'rrmj_1912',
 'tags': ['剧情', '悬疑'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26741568/'}
2020-04-30 14:14:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%9C%BA%E6%99%BA%E7%9A%84%E5%8C%BB%E7%94%9F%E7%94%9F%E6%B4%BB> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:14:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30212150/> (referer: https://www.douban.com/search?q=%E4%B8%AD%E5%9B%BD%E8%80%81%E5%B8%88%E6%9D%A5%E4%BA%86)
2020-04-30 14:14:25 [scrapy.core.scraper] ERROR: Error processing {'cover': 'http://img.rr.tv/album/20190509/o_1557388059616.jpg',
 'data_type': 'movie',
 'id': 'rrmj_14770',
 'intro': '《中国老师来了》中，摄制组邀请5名中国老师到英国，给50名英国初中生进行为期一个月的"中式教育"。纪录片中，除了这50名学生外，剩下的学生仍然由英国老师授课。一个月结束后，两组学生将分别进行数学、自然科学的考试，看哪种教学方法更有效，结果会在纪录片中公布。第一集58分钟的纪录片里，英国学生的全天作息安排和中国学校相同，中国老师带着英国学生做眼保健操、课间操、上晚自习。中国老师逼哭了英国的"熊孩子"，中国老师也被"熊孩子"们惹哭了。随着试验项目的推进，学生们展现出更多对学习时间和严格纪律的反抗。中国老师和英国学生间的冲突磨合，让这部纪录片热度持续走高。',
 'is_new': False,
 'name': '中国老师来了',
 'platforms': '',
 'publishdate': '',
 'rate': 7.7,
 'sectionid': 'rrmj_1384',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30212150/'}
Traceback (most recent call last):
  File "/usr/python37/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/python37/lib/python3.7/site-packages/scrapy/utils/defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/root/spider/scrapyspider/spiderV1/pipelines.py", line 262, in process_item
    timeStruct = time.strptime(publishdate, '%Y-%m-%d')
  File "/usr/python37/lib/python3.7/_strptime.py", line 571, in _strptime_time
    tt = _strptime(data_string, format)[0]
  File "/usr/python37/lib/python3.7/_strptime.py", line 359, in _strptime
    (data_string, format))
ValueError: time data '' does not match format '%Y-%m-%d'
2020-04-30 14:14:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%B8%85%E6%98%8E%E6%97%B6%E8%8A%82%E7%88%B1%E4%B8%8A%E6%88%91> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:14:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30279870/> (referer: https://www.douban.com/search?q=%E5%AD%A4%E9%AB%98%E7%9A%84%E6%89%8B%E6%9C%AF%E5%88%80)
2020-04-30 14:14:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30279870/>
{'cover': 'http://img.rr.tv/album/20181127/o_1543307970133.jpg',
 'data_type': 'movie',
 'id': 'rrmj_13651',
 'intro': '该剧根据作家、医师大钟稔彦创作的系列医疗小说改编，讲述了一位在医学界的历史中主刀了约6000例以上的手术、现在在淡路岛的诊所担任面向当地医疗的医生的故事。                                                                    \u3000\u3000'
          '器官移植仍视为禁忌的1980年代后半，曾在医疗先进国家美国钻研的外科医生当麻铁彦到地方的民营医院赴任。当麻在“地方应该有和大学医院一样水平的医疗”的信念下，挑战一切困难手术，挽救眼前的患者们生命。但是，日本首次的器官移植手术之前，权力绝对主义和旧习俗惯涂抹加固的医疗体制阻挡了去路。',
 'is_new': False,
 'name': '孤高的手术刀',
 'platforms': '',
 'publishdate': '2019-01-13',
 'rate': 7.9,
 'sectionid': 'rrmj_1646',
 'tags': ['剧情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30279870/'}
2020-04-30 14:14:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%BB%9D%E5%AF%B9%E9%9B%B6%E5%BA%A6%E7%AC%AC%E5%9B%9B%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:14:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/33457596/> (referer: https://www.douban.com/search?q=%E5%8F%8D%E6%AD%A3%E6%98%AF%E7%BA%AA%E5%BF%B5%E6%97%A5)
2020-04-30 14:14:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/33457596/>
{'cover': 'http://img.rr.tv/album/20190514/o_1557802398719.jpg',
 'data_type': 'movie',
 'id': 'rrmj_14818',
 'intro': '《总之是纪念日》是讲述两个男女不同视角，青春校园的暧昧和暗恋，三条不同的感情线，每对都非常真实和精彩。                                                                    \u3000\u3000'
          '女主是个乖乖女学霸，最近总觉得自己被某个奇怪的男生盯上了，走哪都能碰到不说，还老是闹出矛盾，很烦很烦；男主是个学渣！自信，也炒鸡自恋！感受到来自女主的目光，就执着地分析女主可能喜欢自己…',
 'is_new': False,
 'name': '反正是纪念日',
 'platforms': '',
 'publishdate': '2019-05-21',
 'rate': 8.4,
 'sectionid': 'rrmj_1244',
 'tags': ['喜剧', '爱情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/33457596/'}
2020-04-30 14:14:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%91%BD%E4%B8%AD%E6%B3%A8%E5%AE%9A%E6%88%91%E7%88%B1%E4%BD%A0> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:14:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/34796192/> (referer: https://www.douban.com/search?q=%E6%B4%9E%E7%A9%B4%E9%87%8C%E7%9A%84%E5%8C%BB%E9%99%A2)
2020-04-30 14:14:33 [scrapy.core.scraper] ERROR: Error processing {'cover': 'http://img.rr.tv/cover/20200211/o_1581418145111.webp',
 'data_type': 'movie',
 'id': 'rrmj_17146',
 'intro': '为了躲避目前对医院的空袭和造成许多受害者死亡的化学武器攻击，叙利亚的一些医务人员被迫建立隐藏的地下医院，以挽救病人的生命，避免医务人员和设备的损失。大马士革的Alghouta发生了几起化学武器袭击事件，那里的工作人员建立了一个地下避难所，名为“洞穴”。Amani博士和她的同事Alaa博士、护士Samaher以及其他18名妇女被选为医院的常务董事，医院共有80名员工。他们每天都面临死亡，因为他们试图拯救他们城镇的人民的生命，并隔离和加强医院以防止进一步的攻击。',
 'is_new': False,
 'name': '洞穴里的医院',
 'platforms': '',
 'publishdate': '',
 'rate': 7.1,
 'sectionid': 'rrmj_1657',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/34796192/'}
Traceback (most recent call last):
  File "/usr/python37/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/python37/lib/python3.7/site-packages/scrapy/utils/defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/root/spider/scrapyspider/spiderV1/pipelines.py", line 262, in process_item
    timeStruct = time.strptime(publishdate, '%Y-%m-%d')
  File "/usr/python37/lib/python3.7/_strptime.py", line 571, in _strptime_time
    tt = _strptime(data_string, format)[0]
  File "/usr/python37/lib/python3.7/_strptime.py", line 359, in _strptime
    (data_string, format))
ValueError: time data '' does not match format '%Y-%m-%d'
2020-04-30 14:14:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%96%9C%E6%AC%A2%E7%9A%84%E8%AF%9D%E8%AF%B7%E5%93%8D%E9%93%83> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:14:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/3262045/> (referer: https://www.douban.com/search?q=%E4%BC%9E%E5%AD%A6%E9%99%A2%20%E7%AC%AC%E4%B8%80%E5%AD%A3)
2020-04-30 14:14:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/3262045/>
{'cover': 'http://img.rr.tv/album/20190218/o_1550484862266.jpg',
 'data_type': 'movie',
 'id': 'rrmj_14124',
 'intro': '在 1989 '
          '年的同一天，四十三个婴儿莫名降生，而这些随机成为母亲的女性之前未有任何怀孕迹象，亦无任何关联。其中七个孩子由亿万富翁实业家雷金纳德·哈格里夫斯爵士收养，他创建了伞学院，并培养自己的“孩子”来拯救世界。但事情并未按计划进行。在他们的少年时代，这个家庭分裂了，团队也解散了。时至今日，六位幸存的成员已经三十几岁，他们因为哈格里夫斯去世的消息而重聚。卢瑟、迭戈、艾莉森、克劳斯、万尼亚和五号共同破解父亲神秘死亡的谜团。但由于个性和能力各异，这个关系疏远的家庭再一次濒临破裂，更不要说末日将至的威胁了。                                                                    \u3000\u3000'
          '《伞学院》改编自荣获艾斯纳奖的热门漫画和图画小说，该书由杰拉德·威（《My Chemical '
          'Romance》）创作编写、加布里埃尔·巴绘制，由 Dark Horse Comics 出版。',
 'is_new': False,
 'name': '伞学院 第一季',
 'platforms': '',
 'publishdate': '2019-02-15',
 'rate': 6.8,
 'sectionid': 'rrmj_747',
 'tags': ['动作', '犯罪', '奇幻'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/3262045/'}
2020-04-30 14:14:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%98%8E%E5%98%8E%EF%BC%9A%E4%BA%94%E5%B0%BA%E4%BA%8C%E5%AF%B8> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:14:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30163510/> (referer: https://www.douban.com/search?q=%E5%85%BB%E8%82%B2%E8%80%85%20%E7%AC%AC%E4%B8%80%E5%AD%A3)
2020-04-30 14:14:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%A4%84%E5%A5%B3%E6%83%85%E7%BC%98%E7%AC%AC%E4%BA%94%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:14:38 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30163510/>
{'cover': 'http://img.rr.tv/cover/20200219/o_1582097686037.jpg',
 'data_type': 'movie',
 'id': 'rrmj_17198',
 'intro': '《养育者》是一部由马丁·弗瑞曼 （Martin Freeman）和黛西·海格达（ Daisy '
          'Haggard）主演的一部育儿轻喜剧，探讨了每对父母都知道但却从未承认的悖论：你愿意为孩子而死，但很多时候你也想杀死他们。马丁饰演“保罗”，他是一个有爱心的父亲；黛西饰演“艾莉”，是保罗的工作搭档，经营一家录音棚，他们相爱并结了婚。                                                                    \u3000\u3000'
          '然而生活并不会一直顺风顺水，保罗和艾莉一心忙于全职工作，要照顾孩子，偿还贷款，照顾父母以及一系列的动荡事儿。当艾莉疏远的父亲迈克尔出现在家门口时，意味着这个家庭又多了一个“孩子”要养，保罗的父母愿意随时提供帮助，但是这对夫妻的养育方式却有所不同。',
 'is_new': False,
 'name': '养育者 第一季',
 'platforms': '',
 'publishdate': '2020-03-02',
 'rate': 8.4,
 'sectionid': 'rrmj_745',
 'tags': ['喜剧'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30163510/'}
2020-04-30 14:14:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30454230/> (referer: https://www.douban.com/search?q=%E8%89%AF%E5%8C%BB%20%E7%AC%AC%E4%B8%89%E5%AD%A3)
2020-04-30 14:14:40 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30454230/>
{'cover': 'http://img.rr.tv/cover/20190925/o_1569378665745.webp?imageslim',
 'data_type': 'movie',
 'id': 'rrmj_15965',
 'intro': '改编自朴才范执笔之同名韩国电视剧，由大卫·萧尔开发，在ABC播出的美国医学电视剧。本剧由ABC工作室与索尼影业电视共同制作，韩裔男星金大贤和身兼节目统筹的萧尔担任执行制作，并由佛莱迪·海默尔领衔主演兼任制作人。',
 'is_new': False,
 'name': '良医 第三季',
 'platforms': '',
 'publishdate': '2019-09-23',
 'rate': 9.3,
 'sectionid': 'rrmj_1646',
 'tags': ['剧情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30454230/'}
2020-04-30 14:14:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%B0%86%E6%81%8B%E7%88%B1%E8%BF%9B%E8%A1%8C%E5%88%B0%E5%BA%95> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:14:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26637615/> (referer: https://www.douban.com/search?q=%E7%8C%8E%E9%AD%94%E4%BA%BA%20%E7%AC%AC%E4%B8%80%E5%AD%A3)
2020-04-30 14:14:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%81%90%E6%80%96%E5%88%86%E5%AD%90%E7%9A%84%E5%AD%A9%E5%AD%90> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:14:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26637615/>
{'cover': 'http://img.rr.tv/cover/20191202/o_1575273547504.webp',
 'data_type': 'movie',
 'id': 'rrmj_16737',
 'intro': '《猎魔人》改编自畅销的奇幻小说系列，讲述了一个关于命运和家庭的史诗故事。利维亚的杰洛特是一名独居的猎魔人，他努力在这个人类比野兽更邪恶的世界上寻得自己的一席之地。但命运将他推向一名强大的女术士和一位身上暗藏着危险秘密的年轻公主，他们三人必须学会共同在日益动荡的大陆中前行。',
 'is_new': False,
 'name': '猎魔人 第一季',
 'platforms': '',
 'publishdate': '2019-12-20',
 'rate': 8.0,
 'sectionid': 'rrmj_745',
 'tags': ['剧情', '动作', '奇幻', '冒险'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26637615/'}
2020-04-30 14:14:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27123733/> (referer: https://www.douban.com/search?q=%E9%BB%91%E6%AD%BB%E7%97%85%20%E7%AC%AC%E4%B8%80%E5%AD%A3)
2020-04-30 14:14:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/27123733/>
{'cover': 'http://img.rr.tv/album/20181107/o_1541562432342.jpg',
 'data_type': 'movie',
 'id': 'rrmj_13492',
 'intro': '十六世纪下半叶，塞维利亚是西方世界的大城市，是欧洲通往美洲的门户。这座城市的富饶，依靠的是国际贸易和金银财富，同时也归功于共同生活与此的海内外人口：基督徒、皈依基督教的犹太人、受过洗礼的摩尔人、奴隶、获得自由的奴隶、流浪汉、盗贼、妓女、贵族、平民。同时，不平等、饥荒和传染病构成了这座城市的阴暗面。                                                                            \u3000\u3000'
          '在一次黑死病的爆发中，塞维利亚社会中的几名杰出成员被杀。马特奥，一位被宗教法庭审判的罪犯，必须解决这一系列的凶案，才能得到宗教法庭的赦免，从而拯救自己的生命。这是一场孤掷一注的调查，面对的是一个极为复杂与矛盾的环境。在那里，公众压抑和私人享乐并存；神秘主义和混乱无序随处可见；修道院纪律涣散，妓院却法规森严；监狱俨然变为藏身之所，医院则成为葬身之地；背叛与忠诚交织涌动。                                                                            \u3000\u3000'
          '2019年11月已确定将推出第二季。                                                                            \u3000\u3000'
          '奖项：2017年圣塞巴斯蒂安电影节：官方选择 非竞...',
 'is_new': False,
 'name': '黑死病 第一季',
 'platforms': '',
 'publishdate': '2018-01-12',
 'rate': 8.6,
 'sectionid': 'rrmj_1693',
 'tags': ['惊悚'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/27123733/'}
2020-04-30 14:14:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%8A%A2%E6%95%91%E5%88%87%E5%B0%94%E8%AF%BA%E8%B4%9D%E5%88%A9> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:14:47 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/759603009/> (referer: https://www.douban.com/search?q=%E5%A5%B3%E6%9C%8B%E5%8F%8B%20%E7%AC%AC%E4%BA%8C%E5%AD%A3)
2020-04-30 14:14:47 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/759603009/>: HTTP status code is not handled or not allowed
2020-04-30 14:14:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%98%AF%E7%9C%9F%E7%88%B1%E8%BF%98%E6%98%AF%E5%B8%8C%E6%9C%9B> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:14:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%B5%AA%E6%BC%AB%E5%8C%BB%E7%94%9F%E9%87%91%E5%B8%88%E5%82%85> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:14:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/4059238/> (referer: https://www.douban.com/search?q=%E4%B8%8B%E4%B8%80%E7%AB%99%EF%BC%8C%E5%B9%B8%E7%A6%8F)
2020-04-30 14:14:51 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/4059238/>
{'cover': 'http://img.rr.tv/seasonCover/20200419/o_1587265351499.png',
 'data_type': 'movie',
 'id': 'rrmj_17529',
 'intro': '梁慕橙（安以轩 '
          '饰）本生于富贵之家，自幼练习钢琴，但因一场车祸，其父身亡，家道中落，小阿姨带她改嫁小店主，寄人篱下，艰辛度日。长大后，一次偶然的机会，梁慕橙结识了圣德中学校董的儿子任光晞（吴建豪 '
          '饰），并卷入了他与女友的分手事件。后来，小阿姨带着梁慕橙在圣德中学开了一家饭堂，这让她得以与该校学生相识，并成为瞩目焦点。任光晞自幼父母离异，因此性格乖张，对待感情如同儿戏，并与同党夸下海口，要一天之内搞定梁慕橙。然而，就在大功告成之际，对方急中生智的表现，却让他改变了初衷。后梁慕橙在圣德堂误弹钢琴，被任光晞抓住了把柄，两人共度一晚，却被其养父暗自发现，大做文章。此后，两人约定在圣德堂弹琴，但是养父却走漏风声，引发了校园震荡，从此两人的感情发展经历了曲折而浪漫的过程……',
 'is_new': False,
 'name': '下一站，幸福',
 'platforms': '',
 'publishdate': '2009-10-04',
 'rate': 8.2,
 'sectionid': 'rrmj_1904',
 'tags': ['剧情', '爱情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/4059238/'}
2020-04-30 14:14:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%88%B1%E5%B0%94%E5%85%B0%E4%BA%BA%EF%BC%9A%E5%AF%B9%E8%AF%9D> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:14:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27185036/> (referer: https://www.douban.com/search?q=%E7%BA%B8%E9%92%9E%E5%B1%8B%20%E7%AC%AC%E4%B8%80%E5%AD%A3)
2020-04-30 14:14:53 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/27185036/>
{'cover': 'https://img.rr.tv/season/20180410/o_1523340277244.png',
 'data_type': 'movie',
 'id': 'rrmj_11999',
 'intro': '八名窃贼将自己与人质反锁在西班牙皇家造币厂内，他们背后的犯罪首脑则妄图操纵警察实现自己的计划。',
 'is_new': False,
 'name': '纸钞屋 第一季',
 'platforms': '',
 'publishdate': '2017-05-02',
 'rate': 8.7,
 'sectionid': 'rrmj_1871',
 'tags': ['剧情', '动作', '悬疑'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/27185036/'}
2020-04-30 14:14:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%89%B9%E6%9C%97%E6%99%AE%E7%9A%84%E7%BE%8E%E5%9B%BD%E6%A2%A6> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:14:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30238667/> (referer: https://www.douban.com/search?q=%E5%AE%88%E6%8A%A4%E8%80%85%20%E7%AC%AC%E4%B8%80%E5%AD%A3)
2020-04-30 14:14:56 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30238667/>
{'cover': 'https://img.rr.tv/season/20170906/o_1504695967804.png',
 'data_type': 'movie',
 'id': 'rrmj_10521',
 'intro': '他的任务就要展开。《伊斯坦堡的守护者》Netflix独家上线。 '
          '哈坎跟英雄完全沾不上边。当他发现自己与古代的神秘教团有著深刻渊源，并被授予保护伊斯坦堡的任务，他原先的现代生活就此产生天翻地覆的转变。他的家乡被神秘玄妙的不死力量威胁，而保护家园的责任全在他身上。对于这个任务，他不但没有心理准备，更心生抗拒，哈坎可以顺利完成守护伊斯坦堡的使命吗？',
 'is_new': False,
 'name': '守护者 第一季',
 'platforms': '',
 'publishdate': '2018-12-14',
 'rate': 9.0,
 'sectionid': 'rrmj_1903',
 'tags': ['动作', '科幻'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30238667/'}
2020-04-30 14:14:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%9C%9F%E5%A5%BD%E5%95%8A%EF%BC%81%E5%85%89%E6%BA%90%E6%B0%8F> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:14:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/2266464/> (referer: https://www.douban.com/search?q=%E5%9B%9B%E5%A4%84%E6%95%A3%E8%90%BD%E7%9A%84%E7%A2%8E%E7%89%87)
2020-04-30 14:14:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/2266464/>
{'cover': 'http://img.rr.tv/album/20191019/o_1571469457738.jpg',
 'data_type': 'movie',
 'id': 'rrmj_16269',
 'intro': '本片获2007罗马电影节最佳男演员奖。一个犹太孤儿亲眼目睹了家人被纳粹杀害，而他本人则被一位希腊考古学家解救并收养。之后，他便跟随着养父先后在不同的国家生活。小孤儿逐渐长大并拥有了正常的生活，而养父的事业也逐渐发展。但是有一天，当孤儿无意中打开养父的记事本时，却发现了养父生活中不为人知的一些事……',
 'is_new': False,
 'name': '四处散落的碎片',
 'platforms': '',
 'publishdate': '2007-09-06',
 'rate': 7.8,
 'sectionid': 'rrmj_1729',
 'tags': ['剧情'],
 'type': 'movie',
 'url': 'https://movie.douban.com/subject/2266464/'}
2020-04-30 14:15:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%A1%97%E5%A4%B4%E7%BE%8E%E9%A3%9F%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:15:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/10539856/> (referer: https://www.douban.com/search?q=%E6%B1%89%E5%B0%BC%E6%8B%94%20%E7%AC%AC%E4%B8%80%E5%AD%A3)
2020-04-30 14:15:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/10539856/>
{'cover': 'http://img.rr.tv/seasonCover/20200426/o_1587869823434.png',
 'data_type': 'movie',
 'id': 'rrmj_262',
 'intro': '本剧根据著名畅销小说《红龙》（Red '
          'Dragon）和同名电影改编。                                                                    \u3000\u3000'
          'Will Graham（休·丹西 Hugh Dancy '
          '饰）是FBI的特别调查顾问，也是一名犯罪分析师。Will有一种特别的能力：可以在犯罪现场根据线索还原犯罪经过。他正在调查一起凶残的连环杀人案，凶手非常狡猾，每次作案留下的线索都很少。为了破案，Will向著名的心理医生Hannibal '
          'Lecter（麦德斯·米科尔森 Mads Mikkelsen '
          '饰）寻求帮助。在案件调查的过程中，这位学术精湛又极具个人品味的Hannibal都对Will有所启发，让他感觉离揭开凶手的真正身份又近了一步。但在亲手击毙罪犯之后Will陷入了自责和幻境中，不得不再次向Hannibal寻求帮助。渐渐，Will越发依赖这位受人尊重和爱戴的医生。但是，故事似乎才刚刚开始......',
 'is_new': False,
 'name': '汉尼拔 第一季',
 'platforms': '',
 'publishdate': '2013-04-04',
 'rate': 8.1,
 'sectionid': 'rrmj_1917',
 'tags': ['悬疑', '惊悚', '犯罪'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/10539856/'}
2020-04-30 14:15:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E9%BB%84%E9%98%BF%E4%B8%BD%EF%BC%9A%E9%93%81%E5%A8%98%E5%AD%90> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:15:04 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/735104639/> (referer: https://www.douban.com/search?q=%E8%BF%99%E6%A0%B7%E4%B8%8DOK%20%E7%AC%AC%E4%B8%80%E5%AD%A3)
2020-04-30 14:15:04 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/735104639/>: HTTP status code is not handled or not allowed
2020-04-30 14:15:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%86%8D%E8%A7%81%EF%BC%8C%E6%88%91%E7%9A%84%E6%96%B0%E9%83%8E> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:15:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%9D%82%E6%9C%AC%E9%BE%99%E4%B8%80%EF%BC%9A%E7%BB%88%E6%9B%B2> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:15:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%88%91%E4%B8%8D%E6%98%AF%E4%BD%A0%E7%9A%84%E9%BB%91%E9%AC%BC> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:15:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%89%AC%E5%AD%90%E6%B1%9F%E4%B8%AD%E7%9A%84%E5%A4%A7%E9%B3%84> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:15:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%98%AF%E7%9C%9F%E7%88%B1%E8%BF%98%E6%98%AF%E5%9B%B0%E6%83%91> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:15:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%B5%81%E6%B5%AA%E6%B1%89%E4%B8%8E%E7%8B%AC%E8%A3%81%E8%80%85> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:15:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%BF%80%E9%9C%87%E7%89%B9%E6%9C%97%E6%99%AE%E6%97%B6%E4%BB%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:15:19 [scrapy.extensions.logstats] INFO: Crawled 240 pages (at 44 pages/min), scraped 115 items (at 14 items/min)
2020-04-30 14:15:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%BD%97%E9%A9%AC%EF%BC%9A%E5%B9%95%E5%90%8E%E7%BA%AA%E5%AE%9E> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:15:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E9%BB%91%E5%B0%94%E9%83%A1%E7%9A%84%E6%97%A5%E4%B8%8E%E5%A4%9C> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:15:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/25845397/> (referer: https://www.douban.com/search?q=%E9%A3%9E%E4%B8%8D%E8%B5%B7%E6%9D%A5%E7%9A%84%E7%AB%A5%E5%B9%B4)
2020-04-30 14:15:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/25845397/>
{'cover': 'http://img.rr.tv/album/20191106/o_1573023009197.webp',
 'data_type': 'movie',
 'id': 'rrmj_16508',
 'intro': '11岁的查拉自小与其吸毒的母亲相依为命。他以训练战犬为生。这种谋生手段使得他变得很暴戾。这点在他的校园生活中便有所体现。卡米拉是他很敬畏，很爱慕的6年级的老师。有一天，这位老师病了，以致于几个月都不能来学校上课。而新来老师不能理解查拉的行为，并送他去了劳教所。等卡米拉老师回来后，她极力反对新老师和同学们的这种做法。于是，卡米拉和查拉的感情开始持续升温，但这段日益亲密的关系却为他们对他们留在学校产生了威胁。 '
          '该片荣获2014年纽约哈瓦那第15届电影节最佳影片奖。',
 'is_new': False,
 'name': '飞不起来的童年',
 'platforms': '',
 'publishdate': '2015-04-18',
 'rate': 8.4,
 'sectionid': 'rrmj_1729',
 'tags': ['剧情'],
 'type': 'movie',
 'url': 'https://movie.douban.com/subject/25845397/'}
2020-04-30 14:15:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%8D%B1%E6%9C%BA%E8%BE%B9%E7%BC%98%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:15:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=Shawn%20Mendes%E5%85%A8%E6%96%B0%E7%BA%AA%E5%BD%95%E7%89%87> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:15:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%B5%AA%E6%BC%AB%E5%8C%BB%E7%94%9F%E9%87%91%E5%B8%88%E5%82%852> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:15:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%85%88%E8%A7%81%E4%B9%8B%E6%98%8E%20%E7%AC%AC%E4%BA%8C%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:15:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%90%8D%E6%A0%A1%E9%A3%8E%E6%9A%B4%20%E7%AC%AC%E4%B8%89%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:15:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%91%BD%E8%BF%90%E8%88%AA%E7%8F%AD%20%E7%AC%AC%E4%BA%8C%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:15:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%9B%9B%E5%A4%84%E7%BA%A6%E4%BC%9A%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:15:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%82%B2%E6%83%A8%E4%B8%96%E7%95%8C%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:15:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/2989755/> (referer: https://www.douban.com/search?q=%E5%91%BD%E4%B8%AD%E6%B3%A8%E5%AE%9A%E6%88%91%E7%88%B1%E4%BD%A0)
2020-04-30 14:15:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/2989755/>
{'cover': 'http://img.rr.tv/cover/20200415/o_1586939399527.png',
 'data_type': 'movie',
 'id': 'rrmj_17504',
 'intro': '“便利贴女孩”陈欣怡（陈乔恩 '
          '饰）为了挽回新任男友古驰，请男友登上了浪漫豪华游轮。不料阴差阳错进错房间，糊里糊涂的和被下催情药的富少纪存希（阮经天 '
          '饰）发生关系。莫名其秒失去了第一次，被另结新欢的男友嘲笑，而且负债20万。决望之时在甲板巧遇纪存希，纪存希带她在游轮的赌场里大出风头，并且狠狠教训了花心的古驰，之后二人又在众人的见证经历了一次浪漫的订婚仪式。游轮到达终点，灰姑娘陈欣怡又回到了现实生活中。一个月之后陈欣怡发现自己怀孕了，怀了那个叫纪存希的男人的孩子，仿佛就像是命中注定，“便利贴女孩”和“优质王子”因为这个孩子又一次相遇……                                                                    \u3000\u3000'
          '本剧在台湾单集平均收视率达10.91，成为台湾电视史上收视率最高的偶像剧，并且获得2008年“第四十三届金钟奖”节目行销奖、戏剧类节目奖。',
 'is_new': False,
 'name': '命中注定我爱你',
 'platforms': '',
 'publishdate': '2008-03-16',
 'rate': 7.6,
 'sectionid': 'rrmj_1904',
 'tags': ['喜剧', '爱情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/2989755/'}
2020-04-30 14:15:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%98%8E%E6%97%A5%E4%BC%A0%E5%A5%87%20%E7%AC%AC%E4%BA%94%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:15:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/3057368/> (referer: https://www.douban.com/search?q=%E6%8A%A2%E6%95%91%E5%88%87%E5%B0%94%E8%AF%BA%E8%B4%9D%E5%88%A9)
2020-04-30 14:15:45 [scrapy.core.scraper] ERROR: Error processing {'cover': 'http://img.rr.tv/album/20180704/o_1530691692633.png',
 'data_type': 'movie',
 'id': 'rrmj_12584',
 'intro': '1986年4月26日凌晨的1点23分，随着前苏联乌克兰地区传来的一声爆炸，彩色的火焰冲上千米高空，切尔诺贝利核电站发生了爆炸，这也是人类和平使用核能以来最大的一次惨剧。事故造成31人当场死亡，爆炸后的核能严重泄漏导致上万居民送命或致病，至今仍有被放射线影响而导致畸形的胎 '
          '儿出生。当日抢险的消防士兵更是用生命和健康为代价避免了核电站的二次爆炸。但令人震惊的是，前苏联政府选择了将事故消息打压保密，而全然不顾此时的辐射尘已经随着大气外泄到了东欧地区甚至北欧的斯堪的纳维亚半岛地区……                                                                    \u3000\u3000'
          '纪录片借用当时摄影师拍摄的照片以及档案影片，重映了当年在切尔诺贝利事故现场紧张进行的大作战，每个抢救阶段一一再现。',
 'is_new': False,
 'name': '抢救切尔诺贝利',
 'platforms': '',
 'publishdate': '',
 'rate': 9.2,
 'sectionid': 'rrmj_1425',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/3057368/'}
Traceback (most recent call last):
  File "/usr/python37/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/python37/lib/python3.7/site-packages/scrapy/utils/defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/root/spider/scrapyspider/spiderV1/pipelines.py", line 262, in process_item
    timeStruct = time.strptime(publishdate, '%Y-%m-%d')
  File "/usr/python37/lib/python3.7/_strptime.py", line 571, in _strptime_time
    tt = _strptime(data_string, format)[0]
  File "/usr/python37/lib/python3.7/_strptime.py", line 359, in _strptime
    (data_string, format))
ValueError: time data '' does not match format '%Y-%m-%d'
2020-04-30 14:15:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/25885410/> (referer: https://www.douban.com/search?q=%E5%88%9D%E6%9D%A5%E4%B9%8D%E5%88%B0%E7%AC%AC%E4%B8%80%E5%AD%A3)
2020-04-30 14:15:47 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/25885410/>
{'cover': 'https://img.rr.tv/video/20151103/o_1446547143096.jpg',
 'data_type': 'movie',
 'id': 'rrmj_556',
 'intro': '这部单镜头情景喜剧根据华裔美国厨师黄颐铭（Eddie '
          'Huang）的回忆录《初来乍到》改编，主要描述上世纪九十年代一个台湾家庭来到奥兰多定居的故事。黄颐铭的父母都是台湾移民，他从小就热爱美国的一切，尤其是嘻哈乐。他的父亲尚能很好地融入当地社会，但母亲却时常为白人文化感到困惑。他的父亲经营着一家全美国式的牛排餐厅连锁企业，和全家人一起憧憬着「美国梦」。与此同时，他们还要竭力保持自己的民族文化特性，确保家庭的完整。剧名「fresh '
          'off the boat」是一个俗语，通常泛指新一代去美国追求「美国梦」的移民。',
 'is_new': False,
 'name': '初来乍到第一季',
 'platforms': '',
 'publishdate': '2015-02-04',
 'rate': 8.4,
 'sectionid': 'rrmj_1726',
 'tags': ['喜剧'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/25885410/'}
2020-04-30 14:15:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%8B%8D%E7%A9%B9%E6%B5%A9%E7%80%9A%20%E7%AC%AC%E5%9B%9B%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:15:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%B1%AA%E6%96%AF%E5%8C%BB%E7%94%9F%20%E7%AC%AC%E5%85%AB%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:15:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30214032/> (referer: https://www.douban.com/search?q=%E7%BB%9D%E5%AF%B9%E9%9B%B6%E5%BA%A6%E7%AC%AC%E5%9B%9B%E5%AD%A3)
2020-04-30 14:15:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30214032/>
{'cover': 'http://img.rr.tv/cover/20200107/o_1578364468430.jpg',
 'data_type': 'movie',
 'id': 'rrmj_16975',
 'intro': '混杂于群众之中，以人类的肉为食。拥有人类的形态，却与人类不同的存在……“喰种”。                                                                    \u3000\u3000'
          '在对“喰种”进行驱逐、研究的“CCG”，曾经率领“Quinx”小组的喰种搜查官“佐佐木琲世”。他正是行踪不明的眼罩喰种“金木研”。                                                                    \u3000\u3000'
          '另一方面，在成立了新体制的“CCG”，以旧多二福为中心，不安定的行动终于表面化……                                                                    \u3000\u3000'
          '与“金木研”有关的故事，终于迈向最终章——。',
 'is_new': False,
 'name': '绝对零度第四季',
 'platforms': '',
 'publishdate': '2018-10-09',
 'rate': 7.5,
 'sectionid': 'rrmj_742',
 'tags': ['动作', '动画', '惊悚'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30214032/'}
2020-04-30 14:15:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%BD%AE%E5%9B%9E%E6%B4%BE%E5%AF%B9%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:15:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30317841/> (referer: https://www.douban.com/search?q=%E5%9B%A0%E4%B8%BA%E7%88%B1%E6%83%85%E5%BE%88%E5%A4%8D%E6%9D%82)
2020-04-30 14:15:53 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30317841/>
{'cover': 'http://img.rr.tv/album/20181102/o_1541142532781.jpg',
 'data_type': 'movie',
 'id': 'rrmj_13475',
 'intro': '现在的社会有着许多的复杂的感情关系。在现代人的道德观念里，爱情应该是一对一的，二加一的爱情在别人眼里都是不道德的，是花心的。也有些人在爱情里保持着开放性的关系，认为爱与性是分开的。有些人在结婚后发现对彼此的爱情变味了，找不到当初相爱的感觉。还有些人在恋爱期间只想要单纯的恋爱，不想发生关系。但无论如何人生都是自己的选择，没有人有权利站在最道德的最高点指责别人的生活。',
 'is_new': False,
 'name': '因为爱情很复杂',
 'platforms': '',
 'publishdate': '2018-08-02',
 'rate': 7.2,
 'sectionid': 'rrmj_989',
 'tags': ['剧情', '爱情', '同性'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30317841/'}
2020-04-30 14:15:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E9%A3%8E%E9%AA%9A%E5%BE%8B%E5%B8%88%20%E7%AC%AC%E4%BA%94%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:15:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30345008/> (referer: https://www.douban.com/search?q=%E4%BD%90%E4%BC%8A%E7%9A%84%E8%AF%BB%E5%BF%83%E6%AD%8C%E5%8D%95)
2020-04-30 14:15:55 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30345008/>
{'cover': 'http://img.rr.tv/cover/20191227/o_1577432709688.jpg',
 'data_type': 'movie',
 'id': 'rrmj_16909',
 'intro': '由Austin Winsberg执笔﹑Richard Shepard执导的NBC音乐剧《佐伊的读心歌单 Zoey’s '
          'Extraordinary Playlist》获正式预订，此剧被形容为《偷听女人心 What Women Want》及《爱乐之城 La '
          'La Land》 '
          '的融合体，剧中讲述聪明但不擅社交﹑典型A型人的快30岁女主Zoey，她某天突然获得以歌曲﹑音乐剧方式听到旁人内心想法的能力，于是她决定以此能力了解及帮助身边的人。曾在ABC喜剧《郊区故事 '
          'Suburgatory》主演的Jane '
          'Levy饰演女主Zoey。                                                                            \u3000\u3000'
          'Skylar Astin饰演女主同事兼好友Max﹑Alex Newell饰演Mo，女主的随和邻居﹑John Clarence '
          'Stewart饰演女主工作的科技公司销售助理Simon。Mary Steenburgen饰演女主母亲Mag...',
 'is_new': False,
 'name': '佐伊的读心歌单',
 'platforms': '',
 'publishdate': '2020-01-07',
 'rate': 8.0,
 'sectionid': 'rrmj_745',
 'tags': ['喜剧', '音乐'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30345008/'}
2020-04-30 14:15:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E9%BB%91%E8%89%B2%E7%AB%A5%E8%AF%9D%20%E7%AC%AC%E4%BA%8C%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:15:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30372311/> (referer: https://www.douban.com/search?q=%E6%B8%85%E6%98%8E%E6%97%B6%E8%8A%82%E7%88%B1%E4%B8%8A%E6%88%91)
2020-04-30 14:15:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30372311/>
{'cover': 'http://img.rr.tv/album/20190426/o_1556250256759.jpg',
 'data_type': 'movie',
 'id': 'rrmj_14672',
 'intro': 'Mez是没有亲人的鬼魂，连自己名字都已经忘记的鬼，没有任何一个亲人记得他，直到Than出现在Mez面前。Mez来到了城市，成为了Than的鬼室友。Mez究竟是谁？生前发生过什么？一切还都是未知。',
 'is_new': False,
 'name': '清明时节爱上我',
 'platforms': '',
 'publishdate': '2019-02-28',
 'rate': 8.6,
 'sectionid': 'rrmj_989',
 'tags': ['剧情', '爱情', '同性', '奇幻'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30372311/'}
2020-04-30 14:15:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E9%BB%91%E9%92%B1%E8%83%9C%E5%9C%B0%20%E7%AC%AC%E4%B8%89%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:16:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/33464863/> (referer: https://www.douban.com/search?q=%E6%9C%BA%E6%99%BA%E7%9A%84%E5%8C%BB%E7%94%9F%E7%94%9F%E6%B4%BB)
2020-04-30 14:16:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/33464863/>
{'cover': 'http://img.rr.tv/cover/20200219/o_1582099519827.jpg',
 'data_type': 'movie',
 'id': 'rrmj_17199',
 'intro': '此剧以医院急诊室为背景，讲述医生、护士和患者之间，围绕着生命进行拼死奋斗的温馨故事。',
 'is_new': False,
 'name': '机智的医生生活',
 'platforms': '',
 'publishdate': '2020-03-12',
 'rate': 9.6,
 'sectionid': 'rrmj_745',
 'tags': ['剧情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/33464863/'}
2020-04-30 14:16:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%82%B2%E9%AA%A8%E8%B4%A4%E5%A6%BB%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:16:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/34456079/> (referer: https://www.douban.com/search?q=%E5%B0%8F%E9%95%87%E6%BB%8B%E5%91%B3%E7%AC%AC%E4%B8%89%E5%AD%A3)
2020-04-30 14:16:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/34456079/>
{'cover': 'http://img.rr.tv/album/20190329/o_1553842368509.jpg',
 'data_type': 'movie',
 'id': 'rrmj_14435',
 'intro': '罗天大醮之后，王也被武当除名回到了家中，却因为身怀“八奇技-风后奇门”遭人觊觎，家人遭人监视。王也万般无奈，在好友诸葛青的建议下向“哪都通”公司的求助，张楚岚携冯宝宝前来破案。张楚岚如何一展身手帮王也抓出幕后黑手？诸葛青和王也等人又将有怎样精彩的表现？觊觎“八奇技”的人究竟是谁？《一人之下-入世篇》即将揭晓！',
 'is_new': False,
 'name': '小镇滋味第三季',
 'platforms': '',
 'publishdate': '2020-04-24',
 'rate': 8.9,
 'sectionid': 'rrmj_747',
 'tags': ['动画'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/34456079/'}
2020-04-30 14:16:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%82%B2%E9%AA%A8%E8%B4%A4%E5%A6%BB%20%E7%AC%AC%E4%BA%8C%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:16:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/2287724/> (referer: https://www.douban.com/search?q=%E6%B5%81%E6%B5%AA%E6%B1%89%E4%B8%8E%E7%8B%AC%E8%A3%81%E8%80%85)
2020-04-30 14:16:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/2287724/>
{'cover': 'http://img.rr.tv/album/20190526/o_1558851281219.webp',
 'data_type': 'movie',
 'id': 'rrmj_14918',
 'intro': '',
 'is_new': False,
 'name': '流浪汉与独裁者',
 'platforms': '',
 'publishdate': '2002-02-14',
 'rate': 9.0,
 'sectionid': 'rrmj_1405',
 'tags': ['纪录片', '传记', '历史', '战争'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/2287724/'}
2020-04-30 14:16:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%9B%BD%E5%9C%9F%E5%AE%89%E5%85%A8%20%E7%AC%AC%E5%85%AB%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:16:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/2338071/> (referer: https://www.douban.com/search?q=%E5%8D%B1%E6%9C%BA%E8%BE%B9%E7%BC%98%20%E7%AC%AC%E4%B8%80%E5%AD%A3)
2020-04-30 14:16:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/2338071/>
{'cover': 'http://img.rr.tv/cover/20200305/o_1583376551269.jpg',
 'data_type': 'movie',
 'id': 'rrmj_97',
 'intro': '一架从汉堡飞往波士顿航班安全着陆，飞机上的机组成员和乘客却全部死亡。这起离奇案件揭开了一连串奇异、危险事件的序幕。                                                                    \u3000\u3000'
          'FBI女探员奥莉维亚•德纳姆（Anna Torv 安娜•特弗 饰）精明干练，她刚刚和同事约翰•斯科特（Mark Valley '
          '马克•维利 '
          '饰）确立恋爱关系，然而却在某次调查中痛失爱人。奥莉维亚随后被招入专门负责离奇案件的“边缘档案部门”。在此之后，各种匪夷所思事件接连发生，种种迹象表明，这一切似乎与被世人称为“当代爱因斯坦”的沃尔特•贝肖普博士（John '
          'Noble 饰）以及资力雄厚、背景神秘的巨力公司有关。随着调查的深入，事件背后的黑幕和秘密逐渐显露出来……',
 'is_new': False,
 'name': '危机边缘 第一季',
 'platforms': '',
 'publishdate': '2008-09-23',
 'rate': 8.6,
 'sectionid': 'rrmj_1726',
 'tags': ['剧情', '科幻', '悬疑', '惊悚', '恐怖'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/2338071/'}
2020-04-30 14:16:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%9B%BC%E8%BE%BE%E6%B4%9B%E4%BA%BA%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:16:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/3077668/> (referer: https://www.douban.com/search?q=%E9%BB%91%E5%B0%94%E9%83%A1%E7%9A%84%E6%97%A5%E4%B8%8E%E5%A4%9C)
2020-04-30 14:16:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/3077668/>
{'cover': 'http://img.rr.tv/cover/20200115/o_1579068007114.webp',
 'data_type': 'movie',
 'id': 'rrmj_17020',
 'intro': '天水围位于香港新界元朗区，原是一条小围村，1980年代末被港英政府发展成为以住宅为主的新市镇，但今天它的30万居民多为底层劳工（其中有诸多新移民及大陆新娘）。由于天水围发生过多起震惊港媒的伦常惨案，该地被视作“悲情市镇”，可是其中多数居民平日其实过着与其他港人并无差异的生活，相依为命的贵（鲍起静）与张家安（梁进龙）母子便是如此。                                                                            \u3000\u3000'
          '年纪轻轻便守寡的贵14岁出来做工，先后供两个弟弟念完大学，如今他们做成富贵人，她依旧是超市女工一名，但是她并不觉上天待她刻薄，每日生活都很乐观。张家安是乖乖仔，会考完毕没找暑期工做的他多数时候会呆在家里睡觉或看电视，外出见朋友、参加活动的时间非常有限。母子一起坐下吃晚饭聊天时，说的也是该买哪家报纸一类再平常不过的话。                                                                            \u3000\u3000'
          '与他们住在同一栋楼里的阿婆梁欢（陈丽云）是新搬来的住户，她每日过着郁郁寡欢、斤斤计较的孤独生活。凭着曾在市区...',
 'is_new': False,
 'name': '黑尔郡的日与夜',
 'platforms': '',
 'publishdate': '2008-07-17',
 'rate': 6.3,
 'sectionid': 'rrmj_1657',
 'tags': ['剧情', '家庭'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/3077668/'}
2020-04-30 14:16:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%88%B1%E7%8A%AC%E6%83%85%E6%B7%B1%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:16:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26836806/> (referer: https://www.douban.com/search?q=%E6%B5%AA%E6%BC%AB%E5%8C%BB%E7%94%9F%E9%87%91%E5%B8%88%E5%82%85)
2020-04-30 14:16:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26836806/>
{'cover': 'http://img.rr.tv/album/20180906/o_1536225595028.png',
 'data_type': 'movie',
 'id': 'rrmj_11094',
 'intro': '《浪漫医生金实福》讲述了想要赢任何人的男医生姜东柱和想要从别人那里获得认可的女医生尹书真的爱情故事而展开。本是毫无联系的两人在遇见了怪才医生金实福之后，领悟到真正的人生价值和爱情的人性爱情……',
 'is_new': False,
 'name': '浪漫医生金师傅',
 'platforms': '',
 'publishdate': '2016-11-07',
 'rate': 8.3,
 'sectionid': 'rrmj_1646',
 'tags': ['剧情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26836806/'}
2020-04-30 14:16:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%9B%91%E6%9F%A5%E5%BD%B9%20%E9%87%8E%E5%B4%8E%E4%BF%AE%E5%B9%B3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:16:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26955950/> (referer: https://www.douban.com/search?q=%E5%96%9C%E6%AC%A2%E7%9A%84%E8%AF%9D%E8%AF%B7%E5%93%8D%E9%93%83)
2020-04-30 14:16:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26955950/>
{'cover': 'http://img.rr.tv/album/20190808/o_1565233029504.jpg',
 'data_type': 'movie',
 'id': 'rrmj_15479',
 'intro': '改编自同名漫画《恋爱铃》，描述一位软体开发工程师打造出一套应用程式，能在使用者周遭有人对他们滋生浪漫情愫时给予提醒。',
 'is_new': False,
 'name': '喜欢的话请响铃',
 'platforms': '',
 'publishdate': '2019-08-22',
 'rate': 8.0,
 'sectionid': 'rrmj_1244',
 'tags': ['爱情', '科幻'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26955950/'}
2020-04-30 14:16:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%BA%A6%E4%BC%9A%E7%94%B7%E5%A5%B3%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:16:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27032345/> (referer: https://www.douban.com/search?q=%E6%98%AF%E7%9C%9F%E7%88%B1%E8%BF%98%E6%98%AF%E5%B8%8C%E6%9C%9B)
2020-04-30 14:16:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/27032345/>
{'cover': 'https://img.rr.tv/season/20170522/o_1495461934602.png',
 'data_type': 'movie',
 'id': 'rrmj_4862',
 'intro': '靓模Kate（Paula Taylor饰演）在一次拍摄活动中结识了高级成衣店长兼服装设计师Cee（Woonsen '
          'Virithipa饰演），在得知Kate与前男友分手之后，Cee对Kate展开了姬情满满的情感攻势。在互相了解中，Kate也对Cee产生了超友谊的情感，与Cee成为了一对恋人。但是Kate一直梦想着有一个孩子。机缘巧合，Kate认识了David，产生了借种生子的想法。如愿怀孕后，David却向Kate求婚。最终Kate会做出怎样的选择呢？',
 'is_new': False,
 'name': '是真爱还是希望',
 'platforms': '',
 'publishdate': '2018-02-23',
 'rate': 5.2,
 'sectionid': 'rrmj_989',
 'tags': ['爱情', '同性'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/27032345/'}
2020-04-30 14:16:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%BE%8E%E5%A6%99%E4%B9%8B%E7%89%A9%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:16:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%B8%80%E5%96%84%E4%B9%8B%E5%B7%AE%20%E7%AC%AC%E4%BA%8C%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:16:19 [scrapy.extensions.logstats] INFO: Crawled 282 pages (at 42 pages/min), scraped 130 items (at 15 items/min)
2020-04-30 14:16:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27174539/> (referer: https://www.douban.com/search?q=%E9%BB%84%E9%98%BF%E4%B8%BD%EF%BC%9A%E9%93%81%E5%A8%98%E5%AD%90)
2020-04-30 14:16:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/27174539/>
{'cover': 'http://img.rr.tv/album/20190530/o_1559202541428.jpg',
 'data_type': 'movie',
 'id': 'rrmj_14962',
 'intro': '挺着大肚子的老司机段子手黄阿丽(Ali Wong)又来了，她将推出与Netflix合作的第二档原创单口特别喜剧节目《Ali Wong: '
          'Hard Knock '
          'Wife》，今年5月13日母亲节上线，新节目的宣传视频中，她依然挺着孕肚，这次她要讲有了孩子的挑战，母乳喂养、平衡事业家庭等，“所有女性都该有3年带薪产假”。',
 'is_new': False,
 'name': '黄阿丽：铁娘子',
 'platforms': '',
 'publishdate': '2018-05-13',
 'rate': 8.2,
 'sectionid': 'rrmj_1421',
 'tags': ['喜剧', '脱口秀'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/27174539/'}
2020-04-30 14:16:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%82%B2%E9%AA%A8%E4%B9%8B%E6%88%98%20%E7%AC%AC%E5%9B%9B%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:16:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27194924/> (referer: https://www.douban.com/search?q=%E7%89%B9%E6%9C%97%E6%99%AE%E7%9A%84%E7%BE%8E%E5%9B%BD%E6%A2%A6)
2020-04-30 14:16:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/27194924/>
{'cover': 'http://img.rr.tv/album/20190910/o_1568105917550.jpg',
 'data_type': 'movie',
 'id': 'rrmj_14769',
 'intro': '朋友、同事和评论家们揭示了唐纳德·特朗普背后的真实美国故事，讲述了这名鲁莽的商人排除万难当选美国总统的历程。',
 'is_new': False,
 'name': '特朗普的美国梦',
 'platforms': '',
 'publishdate': '2017-11-09',
 'rate': 8.3,
 'sectionid': 'rrmj_1420',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/27194924/'}
2020-04-30 14:16:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27120369/> (referer: https://www.douban.com/search?q=%E5%98%8E%E5%98%8E%EF%BC%9A%E4%BA%94%E5%B0%BA%E4%BA%8C%E5%AF%B8)
2020-04-30 14:16:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/27120369/>
{'cover': 'http://img.rr.tv/album/20190910/o_1568106589025.jpg',
 'data_type': 'movie',
 'id': 'rrmj_14231',
 'intro': '这部电影纪录片主要纪录Gaga第五张专辑Joanne制作和发行的过程，以及她为超级碗中场表演的准备，窥探了这位万众瞩目的明星镜头之外的一面。',
 'is_new': False,
 'name': '嘎嘎：五尺二寸',
 'platforms': '',
 'publishdate': '2017-09-22',
 'rate': 8.9,
 'sectionid': 'rrmj_1295',
 'tags': ['纪录片', '音乐', '传记'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/27120369/'}
2020-04-30 14:16:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%9D%80%E6%AD%BB%E4%BC%8A%E8%8A%99%20%E7%AC%AC%E4%B8%89%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:16:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27621575/> (referer: https://www.douban.com/search?q=%E6%81%90%E6%80%96%E5%88%86%E5%AD%90%E7%9A%84%E5%AD%A9%E5%AD%90)
2020-04-30 14:16:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/27621575/>
{'cover': 'http://img.rr.tv/album/20190722/o_1563795152545.jpg',
 'data_type': 'movie',
 'id': 'rrmj_15420',
 'intro': '塔拉勒·德克回到了他的家乡，在那里他获得了一个激进的伊斯兰家庭的信任，并分享他们的日常生活长达两年多。他的照相机提供了一种极为罕见的洞察，了解在伊斯兰哈里发长大意味着什么。',
 'is_new': False,
 'name': '恐怖分子的孩子',
 'platforms': '',
 'publishdate': '2017-11-15',
 'rate': 8.6,
 'sectionid': 'rrmj_1657',
 'tags': ['纪录片', '战争'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/27621575/'}
2020-04-30 14:16:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%B5%B4%E8%A1%80%E9%BB%91%E5%B8%AE%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:16:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/33425318/> (referer: https://www.douban.com/search?q=%E5%A4%84%E5%A5%B3%E6%83%85%E7%BC%98%E7%AC%AC%E4%BA%94%E5%AD%A3)
2020-04-30 14:16:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/33425318/>
{'cover': 'http://img.rr.tv/album/20190402/o_1554184262140.jpg',
 'data_type': 'movie',
 'id': 'rrmj_14456',
 'intro': '浙江卫视推出的大型原创室内竞技真人秀节目，每期围绕一个主题，邀请两支王牌团队，由两队固定队长各带领多名热门IP嘉宾进行PK对战，通过才艺比拼、游戏竞技，决出王牌中的王牌。',
 'is_new': False,
 'name': '处女情缘第五季',
 'platforms': '',
 'publishdate': '2020-02-21',
 'rate': 8.2,
 'sectionid': 'rrmj_1244',
 'tags': ['真人秀'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/33425318/'}
2020-04-30 14:16:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%BE%8E%E9%A3%9F%E4%B8%8D%E7%BE%8E%20%E7%AC%AC%E4%BA%8C%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:16:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/34440009/> (referer: https://www.douban.com/search?q=%E8%A1%97%E5%A4%B4%E7%BE%8E%E9%A3%9F%E7%AC%AC%E4%B8%80%E5%AD%A3)
2020-04-30 14:16:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/34440009/>
{'cover': 'http://img.rr.tv/album/20190424/o_1556105376166.jpg',
 'data_type': 'movie',
 'id': 'rrmj_14665',
 'intro': '第2季《Street Food '
          'Fighter》定于韩国时间9月22日晚10时40分首播，土耳其是白种元最喜爱的旅行地，也是新婚旅行地点，白种元表示：“去土耳其新婚旅行时，不舍得时间去观光地，而是去了美食店。现在看来，妻子也是该生气。”',
 'is_new': False,
 'name': '街头美食第一季',
 'platforms': '',
 'publishdate': '2019-09-22',
 'rate': 7.6,
 'sectionid': 'rrmj_1883',
 'tags': ['真人秀'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/34440009/'}
2020-04-30 14:16:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%A5%BF%E9%83%A8%E4%B8%96%E7%95%8C%20%E7%AC%AC%E4%B8%89%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:16:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/34805659/> (referer: https://www.douban.com/search?q=%E5%B0%86%E6%81%8B%E7%88%B1%E8%BF%9B%E8%A1%8C%E5%88%B0%E5%BA%95)
2020-04-30 14:16:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/34805659/>
{'cover': 'http://img.rr.tv/cover/20191224/o_1577177776676.jpg',
 'data_type': 'movie',
 'id': 'rrmj_16879',
 'intro': '佐仓七濑（上白石萌音饰）因偶然发生的事情与命中注定的医生相遇，并坠入爱河。5年后成为护士的她如愿以偿与医生重逢，憧憬的医生天堂浬（佐藤健饰）却与想象中的人完全不同，是名被人称为“魔王”的毒舌超抖S医生。',
 'is_new': False,
 'name': '将恋爱进行到底',
 'platforms': '',
 'publishdate': '2020-01-14',
 'rate': 8.0,
 'sectionid': 'rrmj_1917',
 'tags': ['剧情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/34805659/'}
2020-04-30 14:16:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/34909138/> (referer: https://www.douban.com/search?q=%E7%88%B1%E5%B0%94%E5%85%B0%E4%BA%BA%EF%BC%9A%E5%AF%B9%E8%AF%9D)
2020-04-30 14:16:34 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/34909138/>
{'cover': 'http://img.rr.tv/cover/20191211/o_1576049874236.png',
 'data_type': 'movie',
 'id': 'rrmj_16822',
 'intro': '快跟随导演马丁·斯科塞斯，与明星罗伯特·德尼罗、阿尔·帕西诺和乔·佩西一起，对《爱尔兰人》进行一次近距离、有趣的深入了解。',
 'is_new': False,
 'name': '爱尔兰人：对话',
 'platforms': '',
 'publishdate': '2019-11-27',
 'rate': 8.9,
 'sectionid': 'rrmj_1405',
 'tags': ['纪录片', '短片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/34909138/'}
2020-04-30 14:16:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%BF%A1%E4%BB%B0%E8%B4%BE%E6%96%AF%E6%B1%80%C2%B7%E6%AF%94%E4%BC%AF> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:16:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/34937763/> (referer: https://www.douban.com/search?q=%E7%9C%9F%E5%A5%BD%E5%95%8A%EF%BC%81%E5%85%89%E6%BA%90%E6%B0%8F)
2020-04-30 14:16:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/34937763/>
{'cover': 'http://img.rr.tv/cover/20200409/o_1586425266594.jpg',
 'data_type': 'movie',
 'id': 'rrmj_17459',
 'intro': '本剧改编自同名漫画，讲述了《源氏物语》中的平安贵族光源氏偶然穿越到世界观完全不同的现代，降临在单身女白领藤原沙织的家中，并开始了跨越千年寄居生活的喜剧故事。',
 'is_new': False,
 'name': '真好啊！光源氏',
 'platforms': '',
 'publishdate': '2020-04-04',
 'rate': 7.7,
 'sectionid': 'rrmj_1726',
 'tags': ['剧情', '喜剧'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/34937763/'}
2020-04-30 14:16:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%88%90%E4%B8%BA%E6%B2%83%E4%BC%A6%C2%B7%E5%B7%B4%E8%8F%B2%E7%89%B9> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:16:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/19975889/> (referer: https://www.douban.com/search?q=%E6%89%AC%E5%AD%90%E6%B1%9F%E4%B8%AD%E7%9A%84%E5%A4%A7%E9%B3%84)
2020-04-30 14:16:39 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/19975889/>
{'cover': 'http://img.rr.tv/album/20190306/o_1551856579089.webp',
 'data_type': 'movie',
 'id': 'rrmj_14237',
 'intro': 'Crocodile in the Yangtze follows China’s first Internet '
          'entrepreneur and former English teacher, Jack Ma, as he battles US '
          'giant eBay on the way to building Chinas first global Internet '
          'company, Alibaba Group. An independent memoir written, directed and '
          'produced by an American who worked in Ma’s comany for eight years, '
          'Crocodile in the Yangtze captures the emotional ups and do...',
 'is_new': False,
 'name': '扬子江中的大鳄',
 'platforms': '',
 'publishdate': '2018-02-23',
 'rate': 8.8,
 'sectionid': 'rrmj_1399',
 'tags': ['纪录片', '传记'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/19975889/'}
2020-04-30 14:16:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/22559478/> (referer: https://www.douban.com/search?q=%E5%86%8D%E8%A7%81%EF%BC%8C%E6%88%91%E7%9A%84%E6%96%B0%E9%83%8E)
2020-04-30 14:16:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/22559478/>
{'cover': 'http://img.rr.tv/album/20190705/o_1562307926136.webp',
 'data_type': 'movie',
 'id': 'rrmj_15254',
 'intro': '《再见，我的新郎》记录了同志青年肖恩·彼特尼·克罗恩 （Shane Bitney Crone） 和汤姆·布莱德格鲁（Tom '
          'Bridegroom）感人的爱情故事。他们刻骨铭心的相爱，曾经考虑结婚育子、组建家庭，然而所有可能性随着汤姆在2011年5月7日由屋顶意外坠落而化为乌有。肖恩不能去医院见汤姆最后的一眼，他无权处置汤姆的遗物，他甚至被禁止出席汤姆的葬礼，一切只因为他不是汤姆的“家人”，他们的关系得不到法律认可。                                                                    \u3000\u3000'
          '2012年汤姆去世一周年时，肖恩将他的不幸故事做成视频上传到YouTube网站，结果在世界各地引起极大反响，从而最终促成这部《再见，我的新郎》的诞生。《再见，我的新郎》获纽约翠贝卡电影节观众票选最佳纪录片奖。',
 'is_new': False,
 'name': '再见，我的新郎',
 'platforms': '',
 'publishdate': '2013-04-23',
 'rate': 8.9,
 'sectionid': 'rrmj_1431',
 'tags': ['纪录片', '同性'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/22559478/'}
2020-04-30 14:16:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26861970/> (referer: https://www.douban.com/search?q=%E6%88%91%E4%B8%8D%E6%98%AF%E4%BD%A0%E7%9A%84%E9%BB%91%E9%AC%BC)
2020-04-30 14:16:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26861970/>
{'cover': 'http://img.rr.tv/cover/20200115/o_1579070784893.webp',
 'data_type': 'movie',
 'id': 'rrmj_17021',
 'intro': '由塞缪尔·杰克逊献声、刻划美国黑人民权运动血泪史的《我不是你的黑鬼》，自推出后便崭露锋芒，不仅横扫数座国际影展最佳纪录片、观众票选奖，更强势入围奥斯卡最佳纪录长片，荣获BBC严选2017十大必看佳片，高踞美国各大传媒年度推荐最佳影片。                                                                    \u3000\u3000'
          '本片改编自美国黑人作家詹姆斯·鲍德温未完遗作《记得这屋子》。作品忆及1960年代黑人民权运动过程和他的挚友—麦格艾佛斯、麦尔坎X和金恩博士三大精神领袖接连遭到暗杀的事件。这部作品尚未完成，詹姆斯·鲍德温就因胃癌逝世，遗下的手稿来到海地导演哈乌·佩克手中，成就了这部见证美国黑人民权运动最重要的光影篇章！',
 'is_new': False,
 'name': '我不是你的黑鬼',
 'platforms': '',
 'publishdate': '2016-09-10',
 'rate': 7.7,
 'sectionid': 'rrmj_1657',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26861970/'}
2020-04-30 14:16:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26984189/> (referer: https://www.douban.com/search?q=%E5%9D%82%E6%9C%AC%E9%BE%99%E4%B8%80%EF%BC%9A%E7%BB%88%E6%9B%B2)
2020-04-30 14:16:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26984189/>
{'cover': 'http://img.rr.tv/album/20190313/o_1552457767271.webp',
 'data_type': 'movie',
 'id': 'rrmj_14291',
 'intro': '这部关于日本顶级作曲家坂本龙一的纪录片，主要按照2012年到2017年的时间顺序，剪辑了坂本龙一30年前参与《末代皇帝》等电影以及40年前作为YMO乐队成员活动的宝贵片段。Coda在音乐术语中是，Coda是一个乐章最后的段落里强调终止效果的乐段。正如有着匠人精神的坂本龙一，愿将每部作品都当做生命中的最后一部进行创作。',
 'is_new': False,
 'name': '坂本龙一：终曲',
 'platforms': '',
 'publishdate': '2019-12-16',
 'rate': 8.9,
 'sectionid': 'rrmj_1399',
 'tags': ['纪录片', '音乐'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26984189/'}
2020-04-30 14:16:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27053249/> (referer: https://www.douban.com/search?q=%E6%98%AF%E7%9C%9F%E7%88%B1%E8%BF%98%E6%98%AF%E5%9B%B0%E6%83%91)
2020-04-30 14:16:48 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/27053249/>
{'cover': 'https://img.rr.tv/season/20180906/o_1536245020911.png',
 'data_type': 'movie',
 'id': 'rrmj_13113',
 'intro': 'มาถึงละครเรื่องใหม่ที่สร้างมาจากเค้าโครงเรื่องจริงจากรายการวิทยุสุดดังอย่าง '
          '“Club Friday The Series 8 รักแท้มีจริงหรือไม่มีจริง” '
          'กันแล้วนะครับโดย Club Friday The Series 8 '
          'รักแท้มีจริงหรือไม่มีจริง” ประจำค่ำคืนวันเสาร์ที่ 3 มิถุนายน 2560 '
          'นี้นำเสนอให้ได้รับชมกันในตอนรักแท้หรือแค่สับสนเป็นตอนที่ '
          '1                                                                            \u3000\u3000'
          'สำหรับเรื่องราว '
          'ไฮไลทืและเนื้อหาของละครในตอนแรกนี้นั้นเริ่มต้นที่เม้ง '
          '(นำแสดงโดยโทนี...',
 'is_new': False,
 'name': '是真爱还是困惑',
 'platforms': '',
 'publishdate': '2017-06-03',
 'rate': 8.3,
 'sectionid': 'rrmj_989',
 'tags': ['爱情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/27053249/'}
2020-04-30 14:16:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27069830/> (referer: https://www.douban.com/search?q=%E6%BF%80%E9%9C%87%E7%89%B9%E6%9C%97%E6%99%AE%E6%97%B6%E4%BB%A3)
2020-04-30 14:16:51 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/27069830/>
{'cover': 'http://img.rr.tv/album/20190904/o_1567576744806.webp',
 'data_type': 'movie',
 'id': 'rrmj_15769',
 'intro': '美国特朗普总统所主张的“本国第一主义”影响至隔海相望的欧洲，世界的权力分配愈来愈无法得到平衡。4月-5月法国进行的总统选举中，提议“排斥移民”以及“伊斯兰威胁论”的极右政党——国民战线，党首勒庞在舆论调查中占据得票率第一。反对EU无国界化，支持脱离欧盟的呼声越发高涨。另一方面，今年秋季德国将进行首相选举。在此同时，对接收100万难民的默克尔首相的批判也愈加强烈，排外的右派政党也乘机起势。然而，但由于德国历史上发动的大屠杀，很多市民都支持接纳难民，在德国各地爆发了示威群众的冲突。欧洲为避免重蹈战争悲剧的覆辙，推进一体化，决心成为守护自由宽容精神的“最后的堡垒”。“特朗普风”仍在各国扩散，作为欧盟的中枢的德法两国将何去何从。从投票处的市民中寻求答案吧。',
 'is_new': False,
 'name': '激震特朗普时代',
 'platforms': '',
 'publishdate': '2017-04-22',
 'rate': 7.0,
 'sectionid': 'rrmj_1420',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/27069830/'}
2020-04-30 14:16:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/34966347/> (referer: https://www.douban.com/search?q=%E7%BD%97%E9%A9%AC%EF%BC%9A%E5%B9%95%E5%90%8E%E7%BA%AA%E5%AE%9E)
2020-04-30 14:16:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/34966347/>
{'cover': 'http://img.rr.tv/cover/20200221/o_1582262311376.webp',
 'data_type': 'movie',
 'id': 'rrmj_17216',
 'intro': '令人震撼的片段，引人共鸣的细节，前所未有的拍摄流程。让我们一窥这部创新巨作的幕后纪实。',
 'is_new': False,
 'name': '罗马：幕后纪实',
 'platforms': '',
 'publishdate': '2020-02-11',
 'rate': 8.5,
 'sectionid': 'rrmj_1405',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/34966347/'}
2020-04-30 14:16:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/6781992/> (referer: https://www.douban.com/search?q=%E8%B1%AA%E6%96%AF%E5%8C%BB%E7%94%9F%20%E7%AC%AC%E5%85%AB%E5%AD%A3)
2020-04-30 14:16:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/6781992/>
{'cover': 'https://img.rr.tv/video/20151202/o_1449047177111.jpg',
 'data_type': 'movie',
 'id': 'rrmj_683',
 'intro': '继将好兄弟Wilson的爱车开进旧情人Cuddy的客厅后，备受伤害的House终于在等待假释的看守所内找到了新的刺激。当然，编剧没有忘记为House安插新的小朋友进行调教：这次被House征服的是具有一副混血面孔的美丽女医生Adams。                                                                            \u3000\u3000'
          'House在新剧集里再次展现了惊人的天赋。过人的观察力、大胆的推理、剑走偏锋的行事风格和神乎其技的查体功底一览无遗。曾在Hopkins训练过的高材生Adams医生态度也从开始的倨傲转向惊奇，并最终成为House式行动的追随者。                                                                            \u3000\u3000'
          '本集的病例依旧稀有。与往常不同，House这次并没有充沛的医疗资源可加利用，诊断完全依靠最原始的手段。一名年轻男子在狱中相继出现了关节痛、发热、皮疹等症状，Adams起初认为是淋病，但House以更有说服力的红斑狼疮推翻了Adams。不过患者的表现远不止这么简单，该男子被烟草熏黄的手指和接下来...',
 'is_new': False,
 'name': '豪斯医生 第八季',
 'platforms': '',
 'publishdate': '2011-10-03',
 'rate': 9.5,
 'sectionid': 'rrmj_1646',
 'tags': ['剧情', '悬疑'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/6781992/'}
2020-04-30 14:17:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/34839400/> (referer: https://www.douban.com/search?q=%E6%B5%AA%E6%BC%AB%E5%8C%BB%E7%94%9F%E9%87%91%E5%B8%88%E5%82%852)
2020-04-30 14:17:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/34839400/>
{'cover': 'http://img.rr.tv/cover/20191231/o_1577772165288.jpg',
 'data_type': 'movie',
 'id': 'rrmj_16929',
 'intro': '该剧以位于地方城市的石垣医院为背景，讲述怪胎天才医生金师傅和热情高涨的年轻医生们之间的故事。由第一季的刘仁植导演、姜银庆编剧再次合作。',
 'is_new': False,
 'name': '浪漫医生金师傅2',
 'platforms': '',
 'publishdate': '2020-01-06',
 'rate': 8.4,
 'sectionid': 'rrmj_1646',
 'tags': ['剧情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/34839400/'}
2020-04-30 14:17:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/3754368/> (referer: https://www.douban.com/search?q=%E5%82%B2%E9%AA%A8%E8%B4%A4%E5%A6%BB%20%E7%AC%AC%E4%B8%80%E5%AD%A3)
2020-04-30 14:17:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/3754368/>
{'cover': 'https://img.rr.tv/video/20160329/o_1459237662171.jpg',
 'data_type': 'movie',
 'id': 'rrmj_1475',
 'intro': '政客Peter（克里斯·诺斯 Chris Noth 饰）因性丑闻和政治丑闻被捕入狱后，妻子Alicia （朱丽安娜· 玛格丽丝 '
          'Julianna Margulies '
          '饰）只能结束“家庭主妇”的生活，独支撑家庭的重任。Alicia重拾自己婚前的职业－－辩护律师。作为芝加哥一所知名法律公司的初级合伙人，Alicia受到了老朋友Will（乔西·查尔斯 '
          'Josh Charles '
          '饰）的欢迎。Will是她读法律学校时的同学，也是公司的冠名合伙人。他想看看时隔十三年之后，这位昔日叱咤风云的女强人在法庭上会有什么样的表现。Alicia还有幸受到公司顶级诉讼律师Diane '
          'Lockhart（克里斯汀·芭伦斯基 Christine Baranski '
          '饰）的大力提携和指导，这多少让她受宠若惊，心存感激。但她很快发现这些“指导”是有条件的，Diane并不像她看起来那么“热...',
 'is_new': False,
 'name': '傲骨贤妻 第一季',
 'platforms': '',
 'publishdate': '2009-09-22',
 'rate': 8.9,
 'sectionid': 'rrmj_1912',
 'tags': ['剧情', '悬疑', '犯罪'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/3754368/'}
2020-04-30 14:17:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/5028366/> (referer: https://www.douban.com/search?q=%E5%82%B2%E9%AA%A8%E8%B4%A4%E5%A6%BB%20%E7%AC%AC%E4%BA%8C%E5%AD%A3)
2020-04-30 14:17:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/5028366/>
{'cover': 'https://img.rr.tv/video/20160329/o_1459238364201.jpg',
 'data_type': 'movie',
 'id': 'rrmj_1476',
 'intro': '在今年艾美奖上，JuliannaMargulies到手的「最佳情节剧女主角奖」被半路杀出的KyraSedgwick抢走，真是令人始料未及。不过，JuliannaMargulies自称并不看重荣誉。在上季结尾，Peter高调重返政坛，而Alicia在最后关头接到了Will打来的「求爱」电话。与此同时，新公司的命运令人担忧－－与另一家公司合并后，Will和Alicia的前途很可能大受冲击。吝啬的CBS在描述新季首集时只用了一句话：与Will的感情和与Peter的婚姻让Alicia左右为难，Alicia必须做一个决断。',
 'is_new': False,
 'name': '傲骨贤妻 第二季',
 'platforms': '',
 'publishdate': '2010-09-28',
 'rate': 9.2,
 'sectionid': 'rrmj_1912',
 'tags': ['剧情', '悬疑', '犯罪'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/5028366/'}
2020-04-30 14:17:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%BE%BE%E4%BC%A6%C2%B7%E5%B8%83%E6%9C%97%EF%BC%9A%E5%B0%B1%E8%8C%83> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:17:05 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/5037640/> (referer: https://www.douban.com/search?q=%E7%BA%A6%E4%BC%9A%E7%94%B7%E5%A5%B3%20%E7%AC%AC%E4%B8%80%E5%AD%A3)
2020-04-30 14:17:05 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/5037640/>: HTTP status code is not handled or not allowed
2020-04-30 14:17:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%B4%AB%E6%B0%91%E7%AA%9F%E7%9A%84%E7%99%BE%E4%B8%87%E5%AF%8C%E7%BF%81> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:17:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26971159/> (referer: https://www.douban.com/search?q=%E5%85%88%E8%A7%81%E4%B9%8B%E6%98%8E%20%E7%AC%AC%E4%BA%8C%E5%AD%A3)
2020-04-30 14:17:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26971159/>
{'cover': 'http://img.rr.tv/album/20190319/o_1552996545497.jpg',
 'data_type': 'movie',
 'id': 'rrmj_14345',
 'intro': '布里特·马灵主演，本季平行宇宙来了：马灵饰演的Prairie '
          'Johnson被Hap(詹森·艾萨克饰)俘获后，作为一名俄罗斯女继承人，试图穿越一个新的维度。                                                                    \u3000\u3000'
          '新角色Karim Washington(金斯利·本-阿迪尔)是一个私人侦探，致力于寻找失踪的少女Michelle '
          'Vu(克洛伊·莱文饰)，他最终和OA组队一起寻找少女，他们还将调查诺布山一所与几名青少年失踪有关的房子。',
 'is_new': False,
 'name': '先见之明 第二季',
 'platforms': '',
 'publishdate': '2019-03-22',
 'rate': 8.7,
 'sectionid': 'rrmj_747',
 'tags': ['剧情', '悬疑', '奇幻'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26971159/'}
2020-04-30 14:17:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30234319/> (referer: https://www.douban.com/search?q=%E8%8B%8D%E7%A9%B9%E6%B5%A9%E7%80%9A%20%E7%AC%AC%E5%9B%9B%E5%AD%A3)
2020-04-30 14:17:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30234319/>
{'cover': 'http://img.rr.tv/cover/20191209/o_1575871180719.jpg',
 'data_type': 'movie',
 'id': 'rrmj_16816',
 'intro': '本季将揭开全新篇章，“如今是改变和挑战、希望和恐惧、知识和无知并存的时代。”罗西南特的船员们接到任务：探索星环之门外的新世界。',
 'is_new': False,
 'name': '苍穹浩瀚 第四季',
 'platforms': '',
 'publishdate': '2019-12-13',
 'rate': 8.0,
 'sectionid': 'rrmj_742',
 'tags': ['剧情', '科幻'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30234319/'}
2020-04-30 14:17:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30285826/> (referer: https://www.douban.com/search?q=%E9%A3%8E%E9%AA%9A%E5%BE%8B%E5%B8%88%20%E7%AC%AC%E4%BA%94%E5%AD%A3)
2020-04-30 14:17:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30285826/>
{'cover': 'http://img.rr.tv/cover/20200219/o_1582097169075.jpg',
 'data_type': 'movie',
 'id': 'rrmj_17197',
 'intro': '“你的正义不迟到！”——索尔·古德曼，法律事务代理人，(505) '
          '842-5662                                                                    \u3000\u3000'
          '吉米·麦吉尔最终做出改变一切的决定——化身“索尔·古德曼”执业走江湖，而这也将很快为其朋友圈中的每一个人带来意想不到的深远影响。',
 'is_new': False,
 'name': '风骚律师 第五季',
 'platforms': '',
 'publishdate': '2020-02-23',
 'rate': 9.8,
 'sectionid': 'rrmj_742',
 'tags': ['剧情', '犯罪'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30285826/'}
2020-04-30 14:17:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30347315/> (referer: https://www.douban.com/search?q=%E9%BB%91%E9%92%B1%E8%83%9C%E5%9C%B0%20%E7%AC%AC%E4%B8%89%E5%AD%A3)
2020-04-30 14:17:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30347315/>
{'cover': 'http://img.rr.tv/cover/20200313/o_1584091505940.jpg',
 'data_type': 'movie',
 'id': 'rrmj_17321',
 'intro': '《黑钱胜地》第 3 '
          '季：六个月过去了，赌场已经开张营业了，但是马蒂和温蒂还在为掌控家族命运而战。马蒂宣扬维持现状。温蒂与海伦和毒枭奥马·纳瓦洛结盟，并计划乘势进行扩张。但当温蒂的弟弟本来到镇上时，每个人的生活都陷入了混乱。                                                                    \u3000\u3000'
          '新一季的主演包括艾美奖得主杰森·贝特曼、艾美奖得主劳拉·琳妮、艾美奖得主朱莉娅·加纳、荣获艾美奖提名的珍妮·麦克蒂尔、汤姆·派福瑞、索菲娅·胡布利茨、斯凯勒·加特纳、查理·塔汉、丽莎·埃默里和杰西卡·弗朗西斯·杜克斯。这部来自 '
          'MRC Television '
          '的剧集由比尔·迪比克和马克·威廉姆斯打造，并且他们还与杰森·贝特曼、克里斯·芒迪和约翰·施班共同担任监制。',
 'is_new': False,
 'name': '黑钱胜地 第三季',
 'platforms': '',
 'publishdate': '2020-03-27',
 'rate': 9.0,
 'sectionid': 'rrmj_742',
 'tags': ['剧情', '惊悚', '犯罪'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30347315/'}
2020-04-30 14:17:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30405990/> (referer: https://www.douban.com/search?q=%E9%BB%91%E8%89%B2%E7%AB%A5%E8%AF%9D%20%E7%AC%AC%E4%BA%8C%E5%AD%A3)
2020-04-30 14:17:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30405990/>
{'cover': 'http://img.rr.tv/cover/20191114/o_1573714596313.jpg',
 'data_type': 'movie',
 'id': 'rrmj_16587',
 'intro': 'CBS网络平台剧集#黑色童话##Tell Me a '
          'Story#第二季确定为公主主题，目前已经确定会有《美女与野兽》里的贝儿、睡美人和灰姑娘！                                                                    \u3000\u3000'
          '该剧每季一个不同的故事，将经典童话进行融合，形成新的黑暗故事。另外，第一季里的Paul Wesley将会回归。',
 'is_new': False,
 'name': '黑色童话 第二季',
 'platforms': '',
 'publishdate': '2019-12-05',
 'rate': 8.0,
 'sectionid': 'rrmj_742',
 'tags': ['惊悚'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30405990/'}
2020-04-30 14:17:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30414812/> (referer: https://www.douban.com/search?q=%E8%BD%AE%E5%9B%9E%E6%B4%BE%E5%AF%B9%20%E7%AC%AC%E4%B8%80%E5%AD%A3)
2020-04-30 14:17:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30414812/>
{'cover': 'http://img.rr.tv/album/20190121/o_1548062265515.jpg',
 'data_type': 'movie',
 'id': 'rrmj_14024',
 'intro': '《轮回派对》讲述了年轻女子纳蒂亚（娜塔莎·雷昂饰演）的故事。她将在纽约以受邀嘉宾的身份参加一场似乎永远无法逃离的夜晚派对。                                                                            \u3000\u3000'
          '《轮回派对》由娜塔莎·雷昂、艾米·波勒和莱丝利·海德兰德共同担任联合创剧人和监制，海德兰德和雷昂共同担任整季的编剧。其他演员包括格里塔·李（《韩国城》）、尤尔·瓦斯克斯（《菲利普船长》）、托尼奖得主伊丽莎白·阿什利（《瞒天过海：美人计》）和查理·班尼特（《芝加哥烈焰》）。荣获金球奖并获奥斯卡金像奖提名的科洛·塞维尼（《丽兹》）、美国演员工会奖得主达丝莎·坡兰科（《劲爆女子监狱》、布兰登·萨克斯顿（《三块广告牌》）、瑞贝卡·亨德森（《伊朗式分手》）、杰里米·洛厄尔·博布（《尼克病院》）及瑞提什·拉詹（《编织记忆》）也将客串演出。                                                                            \u3000\u3000'
          '该剧集由 Universal Television、波勒的 Paper Kite Production...',
 'is_new': False,
 'name': '轮回派对 第一季',
 'platforms': '',
 'publishdate': '2019-02-01',
 'rate': 7.9,
 'sectionid': 'rrmj_747',
 'tags': ['喜剧'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30414812/'}
2020-04-30 14:17:19 [scrapy.extensions.logstats] INFO: Crawled 318 pages (at 36 pages/min), scraped 156 items (at 26 items/min)
2020-04-30 14:17:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30450388/> (referer: https://www.douban.com/search?q=%E6%98%8E%E6%97%A5%E4%BC%A0%E5%A5%87%20%E7%AC%AC%E4%BA%94%E5%AD%A3)
2020-04-30 14:17:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30450388/>
{'cover': 'http://img.rr.tv/cover/20200117/o_1579229455076.jpg',
 'data_type': 'movie',
 'id': 'rrmj_17027',
 'intro': 'CW台一口气宣布续订旗下10部美剧，刚刚庆祝播出300集的《邪恶力量》续订第15季，收视稳定的超级英雄系列剧集《绿箭侠》（第八季）、《黑霹雳》（第三季）、《明日传奇》（第五季）、《闪电侠》（第六季）、《女超人》（第五季）毫无悬念获得了新一季的续订。',
 'is_new': False,
 'name': '明日传奇 第五季',
 'platforms': '',
 'publishdate': '2020-01-21',
 'rate': 7.5,
 'sectionid': 'rrmj_742',
 'tags': ['剧情', '动作', '科幻', '冒险'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30450388/'}
2020-04-30 14:17:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30454863/> (referer: https://www.douban.com/search?q=%E5%9B%9B%E5%A4%84%E7%BA%A6%E4%BC%9A%20%E7%AC%AC%E4%B8%80%E5%AD%A3)
2020-04-30 14:17:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30454863/>
{'cover': 'http://img.rr.tv/album/20190225/o_1551061552175.jpg',
 'data_type': 'movie',
 'id': 'rrmj_14170',
 'intro': '每集中，一位单身人士将参加五次相亲，过程中不乏调情、尬聊和真情相对的时刻。那么，谁会收获第二次约会？Netflix '
          '推出首部原创相亲节目，以真诚、引人入胜的视角，展示真实的相亲世界。',
 'is_new': False,
 'name': '四处约会 第一季',
 'platforms': '',
 'publishdate': '2019-02-14',
 'rate': 7.9,
 'sectionid': 'rrmj_747',
 'tags': ['爱情', '真人秀'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30454863/'}
2020-04-30 14:17:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/33413087/> (referer: https://www.douban.com/search?q=%E5%91%BD%E8%BF%90%E8%88%AA%E7%8F%AD%20%E7%AC%AC%E4%BA%8C%E5%AD%A3)
2020-04-30 14:17:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/33413087/>
{'cover': 'http://img.rr.tv/cover/20191227/o_1577432385366.jpg',
 'data_type': 'movie',
 'id': 'rrmj_16908',
 'intro': 'NBC悬疑剧《#命运航班# Manifest》获续订第二季，目前未知新季集数，不过据报会是较短的一季。',
 'is_new': False,
 'name': '命运航班 第二季',
 'platforms': '',
 'publishdate': '2020-01-06',
 'rate': 8.3,
 'sectionid': 'rrmj_742',
 'tags': ['剧情', '科幻', '悬疑'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/33413087/'}
2020-04-30 14:17:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/34809510/> (referer: https://www.douban.com/search?q=%E5%90%8D%E6%A0%A1%E9%A3%8E%E6%9A%B4%20%E7%AC%AC%E4%B8%89%E5%AD%A3)
2020-04-30 14:17:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/34809510/>
{'cover': 'http://img.rr.tv/cover/20200309/o_1583722284288.jpg',
 'data_type': 'movie',
 'id': 'rrmj_17300',
 'intro': 'Las Encinas '
          '是西班牙最优秀、门槛最高的学校，也是精英阶层子女就读的去处。在地震震毁一所平民学校后，地方议会决定将学生们分至本地各校中，三个工薪家庭的孩子因此来到这所贵族学校。一无所有的穷孩子遇上应有尽有的富二代，激烈的冲突爆发，最终竟酿成谋杀。那么，罪魁祸首到底是谁呢？',
 'is_new': False,
 'name': '名校风暴 第三季',
 'platforms': '',
 'publishdate': '2020-03-13',
 'rate': 8.0,
 'sectionid': 'rrmj_742',
 'tags': ['剧情', '惊悚', '犯罪'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/34809510/'}
2020-04-30 14:17:30 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/758848471/> (referer: https://www.douban.com/search?q=Shawn%20Mendes%E5%85%A8%E6%96%B0%E7%BA%AA%E5%BD%95%E7%89%87)
2020-04-30 14:17:30 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/758848471/>: HTTP status code is not handled or not allowed
2020-04-30 14:17:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26854276/> (referer: https://www.douban.com/search?q=%E5%9B%BD%E5%9C%9F%E5%AE%89%E5%85%A8%20%E7%AC%AC%E5%85%AB%E5%AD%A3)
2020-04-30 14:17:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26854276/>
{'cover': 'http://img.rr.tv/cover/20200120/o_1579500248233.jpeg',
 'data_type': 'movie',
 'id': 'rrmj_17062',
 'intro': '《国土安全》最终季，捱过七个多月俄罗斯残酷监禁的卡丽·马瑟森日渐康复，但其相关记忆仍旧支离破碎，这对索尔·贝伦森而言是个问题。作为美国新晋总统拉尔夫·华纳的国家安全顾问，他受派前往阿富汗与塔利班展开和谈，然而喀布尔当地充斥着各路军阀、雇佣兵、狂热分子和间谍——这让索尔不得不向轻车熟路的卡丽寻求协助，并不顾医生意见恳请她陪自己最后一次深入虎穴。',
 'is_new': False,
 'name': '国土安全 第八季',
 'platforms': '',
 'publishdate': '2020-02-09',
 'rate': 9.6,
 'sectionid': 'rrmj_742',
 'tags': ['剧情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26854276/'}
2020-04-30 14:17:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%B8%80%E7%9D%81%E7%9C%BC%EF%BC%8C%E4%B8%89%E5%90%8D%E7%94%B7%E5%8F%8B> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:17:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27166458/> (referer: https://www.douban.com/search?q=%E7%9B%91%E6%9F%A5%E5%BD%B9%20%E9%87%8E%E5%B4%8E%E4%BF%AE%E5%B9%B3)
2020-04-30 14:17:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/27166458/>
{'cover': 'http://img.rr.tv/album/20180207/o_1517992969799.jpg',
 'data_type': 'movie',
 'id': 'rrmj_11729',
 'intro': '大空银行是一家大银行，区域分行长野崎修平（织田裕二）被银行提拔到监査的位置，将来有机会进入高层。而他现在的工作，就是找出银行内各种不正当行为。他所面对的是，银行行长京极雅彦（古谷一行），京极的得力助手 '
          '武田真吾（岸谷五朗），以及具有野心的菁英银行员 立川祥子（松嶋菜菜子）。面对银行内的巨大黑暗，野崎修平能否坚持他的正义？',
 'is_new': False,
 'name': '监查役 野崎修平',
 'platforms': '',
 'publishdate': '2018-01-14',
 'rate': 6.7,
 'sectionid': 'rrmj_1871',
 'tags': ['剧情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/27166458/'}
2020-04-30 14:17:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%B8%AD%E5%9B%BD%EF%BC%9A%E6%91%87%E6%99%83%E7%9A%84%E5%B7%A8%E4%BA%BA> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:17:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30344167/> (referer: https://www.douban.com/search?q=%E6%9B%BC%E8%BE%BE%E6%B4%9B%E4%BA%BA%20%E7%AC%AC%E4%B8%80%E5%AD%A3)
2020-04-30 14:17:38 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30344167/>
{'cover': 'http://img.rr.tv/album/20191105/o_1572936344162.jpg',
 'data_type': 'movie',
 'id': 'rrmj_16476',
 'intro': '继詹戈与波巴·费特后，另一段曼达洛武士传奇即将徐徐展开。                                                                    \u3000\u3000'
          '彼时帝国陷落、军团未起，远在新共和国疆域之外，一名孤胆枪手浪迹星涯。',
 'is_new': False,
 'name': '曼达洛人 第一季',
 'platforms': '',
 'publishdate': '2019-11-12',
 'rate': 9.3,
 'sectionid': 'rrmj_1917',
 'tags': ['科幻', '奇幻'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30344167/'}
2020-04-30 14:17:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%9B%BD%E7%8E%8B%EF%BC%9A%E6%B0%B8%E8%BF%9C%E7%9A%84%E5%90%9B%E4%B8%BB> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:17:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30365359/> (referer: https://www.douban.com/search?q=%E7%88%B1%E7%8A%AC%E6%83%85%E6%B7%B1%20%E7%AC%AC%E4%B8%80%E5%AD%A3)
2020-04-30 14:17:40 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30365359/>
{'cover': 'http://img.rr.tv/album/20181119/o_1542595345165.jpg',
 'data_type': 'movie',
 'id': 'rrmj_13565',
 'intro': '这是一部感人、触动人心的纪实系列纪录片，颂扬人类与四条腿挚友之间深层次的情感联系。该剧集跟踪拍摄了来自全球各地（包括叙利亚、日本、哥斯达黎加、意大利和美国）的六个不可思议的故事，每个故事都证明了一个暖心的真理：狗对主人的爱是无条件的。本剧由备受赞誉的导演执导，他们分别为：荣获奥斯卡金像奖提名的艾米·博格（《驱魔警探》）、荣获奥斯卡金像奖的罗杰·罗斯·威廉姆斯（《生活，动画》、《普鲁登斯的音乐》）、荣获奥斯卡金像奖提名的海迪·埃温（《基督营》、《选择自由》）、荣获艾美奖的理查德·哈金（《纽约灾星》）以及奥斯卡金像奖得主 '
          'T.J.·马丁和丹尼尔·林赛（《不可击败》）。《爱犬情深》带领我们踏上一段鼓舞人心的旅程，探索非凡、甚至堪称神奇的品质是怎样让这些动物在所有人心中占据特殊位置。                                                                            \u3000\u3000'
          '《爱犬情深》是一部 Netflix 原创纪录片系列，由格伦·齐珀与荣获奥斯...',
 'is_new': False,
 'name': '爱犬情深 第一季',
 'platforms': '',
 'publishdate': '2018-11-16',
 'rate': 9.0,
 'sectionid': 'rrmj_1425',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30365359/'}
2020-04-30 14:17:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%98%A8%E6%99%9A%E8%BF%87%E5%BE%97%E5%BE%88%E6%84%89%E5%BF%AB%E5%90%A7> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:17:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30395072/> (referer: https://www.douban.com/search?q=%E5%85%AC%E5%85%B3%E5%8D%B1%E6%9C%BA%20%E7%AC%AC%E4%B8%80%E5%AD%A3)
2020-04-30 14:17:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30395072/>
{'cover': 'http://img.rr.tv/album/20190220/o_1550652680454.jpg',
 'data_type': 'movie',
 'id': 'rrmj_14151',
 'intro': '安娜·帕奎因主演新剧《公关危机》(Flack)发布首款预告，第一视角有点意思。设定在竞争激烈的名人公关世界里，美国危机公关策略师罗宾居住在伦敦，是这一行业的专家，她的工作节奏很快，为行为不端的知名人士提供咨询，但一涉及到自身生活，罗宾就会成为一个自我破坏者。                                                                    \u3000\u3000'
          '该剧由Oliver '
          'Lansley(《名厨怀特》)打造，帕奎因和丈夫史蒂芬·莫耶担任执行制作人，彼得·卡坦纽(《光猪六壮士》《烦恼的牧师》)执导，索菲·奥克妮多(《卢旺达饭店》)、马克·沃伦(《兄弟连》《神秘博士》)、瑞贝卡·本森(《权力的游戏》)等参演，第一季共6集，明年2月21日在Pop '
          'TV播出。',
 'is_new': False,
 'name': '公关危机 第一季',
 'platforms': '',
 'publishdate': '2019-02-21',
 'rate': 8.5,
 'sectionid': 'rrmj_1912',
 'tags': ['喜剧'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30395072/'}
2020-04-30 14:17:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/34782742/> (referer: https://www.douban.com/search?q=%E5%85%AC%E5%85%B3%E5%8D%B1%E6%9C%BA%20%E7%AC%AC%E4%BA%8C%E5%AD%A3)
2020-04-30 14:17:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/34782742/>
{'cover': 'http://img.rr.tv/cover/20200304/o_1583289250962.jpg',
 'data_type': 'movie',
 'id': 'rrmj_17279',
 'intro': '安娜·帕奎因主演的新剧#公关##Flack#获得第二季续订。                                                                    \u3000\u3000'
          '来自《迷失》和《天堂执法者》的金大贤、来自《浴血黑帮》等剧的山姆·尼尔将加盟第二季。                                                                    \u3000\u3000'
          '同时安娜的丈夫，来自《真爱如血》的Stephen Moyer还将作为导演执导两集。',
 'is_new': False,
 'name': '公关危机 第二季',
 'platforms': '',
 'publishdate': '2020-03-13',
 'rate': 8.7,
 'sectionid': 'rrmj_1912',
 'tags': ['喜剧'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/34782742/'}
2020-04-30 14:17:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%BE%8E%E5%9B%BD%E5%95%86%E4%B8%9A%E5%A4%A7%E4%BA%A8%E4%BC%A0%E5%A5%87> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:17:46 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/747343888/> (referer: https://www.douban.com/search?q=%E6%82%B2%E6%83%A8%E4%B8%96%E7%95%8C%20%E7%AC%AC%E4%B8%80%E5%AD%A3)
2020-04-30 14:17:46 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/747343888/>: HTTP status code is not handled or not allowed
2020-04-30 14:17:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%B9%94%E6%B2%BB%E5%85%8B%E9%B2%81%E5%B0%BC%E7%9A%84%E6%9B%BF%E5%A3%B0> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:17:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/11577091/> (referer: https://www.douban.com/search?q=%E6%B5%B4%E8%A1%80%E9%BB%91%E5%B8%AE%20%E7%AC%AC%E4%B8%80%E5%AD%A3)
2020-04-30 14:17:48 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/11577091/>
{'cover': 'https://img.rr.tv/season/20160602/o_1464838841160.jpg',
 'data_type': 'movie',
 'id': 'rrmj_1711',
 'intro': '《浴血黑帮》讲述了战后伯明翰地区传奇黑帮家族Peaky '
          'Blinders的故事。时间要追溯到1919年，家族成员有一大嗜好，就是将剃刀刀片缝进他们帽子的帽檐之间，这也是“剃刀党”的名称由来。斯里安·墨菲将饰演一名残酷的黑帮份子Tommy '
          'Shelby '
          '，是家族兄弟的领袖，嗜血无情。在那个时代，退伍军人、革命者和罪犯，都在社会底层挣扎生存。而当贝尔法斯特的警方负责人开始介入时，Tommy和他的黑帮势力制造出的恐怖统治开始了倾斜。',
 'is_new': False,
 'name': '浴血黑帮 第一季',
 'platforms': '',
 'publishdate': '2013-09-13',
 'rate': 8.8,
 'sectionid': 'rrmj_1726',
 'tags': ['剧情', '犯罪'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/11577091/'}
2020-04-30 14:17:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%BA%BA%E4%BD%93%E5%99%A8%E5%AE%98%E4%BA%A4%E6%98%93%E5%AE%9E%E5%BD%95> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:17:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%A5%B3%E5%A4%A7%E6%B3%95%E5%AE%98%E9%87%91%E6%96%AF%E4%BC%AF%E6%A0%BC> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:17:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/25953429/> (referer: https://www.douban.com/search?q=%E5%A4%A7%E5%B0%8F%E8%B0%8E%E8%A8%80%20%E7%AC%AC%E4%B8%80%E5%AD%A3)
2020-04-30 14:17:51 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/25953429/>
{'cover': 'https://img.rr.tv/season/20171214/o_1513230546156.jpg',
 'data_type': 'movie',
 'id': 'rrmj_4732',
 'intro': '该剧根据同名畅销书改编，主要讲述三个年轻母亲看似完美的生活因卷入一宗谋杀案而被搅得天翻地覆，剧本则将由著名的David E. '
          'Kelley创作。',
 'is_new': False,
 'name': '大小谎言 第一季',
 'platforms': '',
 'publishdate': '2017-02-19',
 'rate': 8.0,
 'sectionid': 'rrmj_1912',
 'tags': ['剧情', '悬疑', '犯罪'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/25953429/'}
2020-04-30 14:17:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27078003/> (referer: https://www.douban.com/search?q=%E4%B8%80%E5%96%84%E4%B9%8B%E5%B7%AE%20%E7%AC%AC%E4%BA%8C%E5%AD%A3)
2020-04-30 14:17:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/27078003/>
{'cover': 'https://img.rr.tv/season/20171011/o_1507703460985.jpg',
 'data_type': 'movie',
 'id': 'rrmj_10629',
 'intro': '回归后,Letty修补了与Javier之间的关系,也和母亲Estelle和解。Letty、Javier和儿子Jacob将走向全新生活,尝试做”正常”人。Letty和Javier终于拿回Jacob的抚养权,他们决定在一处海滨小镇安定下来,但还是干回过去的勾当。在一次行动中 '
          'Javier失手了,他成了被人追杀的目标,进而牵连一家人。他们越是想过正常生活,麻烦便不断登上门来,这些麻烦比联邦调查局更加危险……',
 'is_new': False,
 'name': '一善之差 第二季',
 'platforms': '',
 'publishdate': '2017-10-15',
 'rate': 8.4,
 'sectionid': 'rrmj_747',
 'tags': ['剧情', '爱情', '悬疑', '犯罪'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/27078003/'}
2020-04-30 14:17:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%BD%92%E5%AE%B6%EF%BC%9A%E7%A2%A7%E6%98%82%E4%B8%9D%E4%BD%9C%E5%93%81> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:17:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30190634/> (referer: https://www.douban.com/search?q=%E9%BA%BB%E6%9C%A8%E4%B8%8D%E4%BB%81%20%E7%AC%AC%E4%B8%80%E5%AD%A3)
2020-04-30 14:17:56 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30190634/>
{'cover': 'http://img.rr.tv/album/20190504/o_1556969372335.webp',
 'data_type': 'movie',
 'id': 'rrmj_14700',
 'intro': '詹姆斯·麦斯登、艾德·阿斯纳(《飞屋环游记》《圣诞精灵》)加盟Netflix新剧《Dead to '
          'Me》，琳达·卡德里尼、克里斯蒂娜·艾伯盖特(《老友记》《坏妈妈》)参演。丽兹·费尔德曼(《破产姐妹》《幸福大家庭》)编写剧本，威尔·法瑞尔和亚当·麦凯的制片公司联合CBS '
          'TV制作。                                                                    \u3000\u3000'
          '该剧共10集，被描述为喜剧版的《大小谎言》，聚焦寡妇珍(艾伯盖特)和无拘无束、拥有惊人秘密的朱迪(卡德里尼)之间的一段强大的友谊。                                                                    \u3000\u3000'
          '麦斯登饰演朱迪的爱慕对象，看起来很自信也很有逻辑，但其实是一个有着复杂过去的脆弱男人，被朱迪宽阔的胸怀和自由的精神所吸引。阿斯纳饰演的Abe住在朱迪工作的一个生活机构里，他比大多数人都机智敏捷，和朱迪关系甜蜜，经常依靠对方度过生活的波折。',
 'is_new': False,
 'name': '麻木不仁 第一季',
 'platforms': '',
 'publishdate': '2019-05-03',
 'rate': 7.8,
 'sectionid': 'rrmj_1912',
 'tags': ['喜剧'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30190634/'}
2020-04-30 14:17:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%89%B9%E6%9C%97%E6%99%AE%E7%9A%84%E7%99%BD%E5%AE%AB%E4%B9%8B%E8%B7%AF> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:17:57 [scrapy_redis.dupefilter] DEBUG: Filtered duplicate request <GET https://movie.douban.com/subject/27194924/> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2020-04-30 14:18:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30206389/> (referer: https://www.douban.com/search?q=%E8%A5%BF%E9%83%A8%E4%B8%96%E7%95%8C%20%E7%AC%AC%E4%B8%89%E5%AD%A3)
2020-04-30 14:18:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30206389/>
{'cover': 'http://img.rr.tv/cover/20200225/o_1582625696547.webp',
 'data_type': 'movie',
 'id': 'rrmj_17249',
 'intro': '2016年由乔纳森·诺兰与丽莎·乔伊夫妻档联合开发的剧集，故事改编自作家迈克尔·克莱顿的同名科幻电影，围绕着一个未来主题乐园展开，乐园里有很多机器人，可以帮助人们实现自己的白日梦。然而一直运转良好的机器人中途突然出了问题，局势逐渐失去控制。',
 'is_new': False,
 'name': '西部世界 第三季',
 'platforms': '',
 'publishdate': '2020-03-15',
 'rate': 9.2,
 'sectionid': 'rrmj_1726',
 'tags': ['剧情', '科幻', '悬疑', '西部'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30206389/'}
2020-04-30 14:18:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%9C%9F%E5%AE%9E%E7%9A%84%E5%BE%B7%E9%9B%B7%E5%B0%94%E4%B8%80%E5%AE%B6> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:18:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/32509356/> (referer: https://www.douban.com/search?q=%E6%9D%80%E6%AD%BB%E4%BC%8A%E8%8A%99%20%E7%AC%AC%E4%B8%89%E5%AD%A3)
2020-04-30 14:18:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/32509356/>
{'cover': 'http://img.rr.tv/cover/20200407/o_1586236294563.webp',
 'data_type': 'movie',
 'id': 'rrmj_17441',
 'intro': '本剧围绕一位军情5处的安全员和一位善变的杀手之间展开。前者聪明却不满足于办公司的无聊工作，而自己也有着成为一名间谍的幻想；后者则是一位靠暴力工作来维持自己奢侈生活的杀手。',
 'is_new': False,
 'name': '杀死伊芙 第三季',
 'platforms': '',
 'publishdate': '2020-04-12',
 'rate': 9.1,
 'sectionid': 'rrmj_1726',
 'tags': ['剧情', '惊悚'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/32509356/'}
2020-04-30 14:18:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%87%B4%E6%9B%BE%E7%BB%8F%E7%BE%8E%E5%A5%BD%E7%9A%84%E6%88%91%E4%BB%AC> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:18:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/33399935/> (referer: https://www.douban.com/search?q=%E7%BE%8E%E9%A3%9F%E4%B8%8D%E7%BE%8E%20%E7%AC%AC%E4%BA%8C%E5%AD%A3)
2020-04-30 14:18:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/33399935/>
{'cover': 'http://img.rr.tv/cover/20200316/o_1584339611393.webp',
 'data_type': 'movie',
 'id': 'rrmj_17333',
 'intro': '风味层出，绝不瞎扯。明星主厨张锡镐带朋友们展开令人垂涎的跨文化猎食之旅，寻觅全世界最令人满足的佳肴。',
 'is_new': False,
 'name': '美食不美 第二季',
 'platforms': '',
 'publishdate': '2020-03-06',
 'rate': 8.7,
 'sectionid': 'rrmj_1883',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/33399935/'}
2020-04-30 14:18:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%A5%9E%E7%A7%98%E5%8D%9A%E5%A3%AB%20%E7%AC%AC%E5%8D%81%E4%BA%8C%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:18:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/33423261/> (referer: https://www.douban.com/search?q=%E5%82%B2%E9%AA%A8%E4%B9%8B%E6%88%98%20%E7%AC%AC%E5%9B%9B%E5%AD%A3)
2020-04-30 14:18:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/33423261/>
{'cover': 'http://img.rr.tv/cover/20200402/o_1585819050151.webp',
 'data_type': 'movie',
 'id': 'rrmj_17410',
 'intro': '雷迪克、博斯曼和洛克哈特律师事务所在接连失去最大客户“真香（chumhum）”搜索引擎、创始合伙人性侵丑闻东窗事发后，不得不接受跨国巨头STR劳瑞律师事务所收购成为其附属子公司，转眼间所有决定都逃不过顶头巨头事后批评问责。尽管STR劳瑞初看好似善主一枚，戴安·洛克哈特和同事却因丧失独立自主纷纷恼火不已。',
 'is_new': False,
 'name': '傲骨之战 第四季',
 'platforms': '',
 'publishdate': '2020-04-09',
 'rate': 9.3,
 'sectionid': 'rrmj_1726',
 'tags': ['剧情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/33423261/'}
2020-04-30 14:18:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%B8%80%E5%A4%9C%E6%A1%83%E8%8A%B1%E8%BF%90%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:18:08 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/758586382/> (referer: https://www.douban.com/search?q=%E7%BE%8E%E5%A6%99%E4%B9%8B%E7%89%A9%20%E7%AC%AC%E4%B8%80%E5%AD%A3)
2020-04-30 14:18:08 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/758586382/>: HTTP status code is not handled or not allowed
2020-04-30 14:18:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%B8%BB%E5%8E%A8%E7%9A%84%E9%A4%90%E6%A1%8C%20%E7%AC%AC%E5%85%AD%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:18:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/2209573/> (referer: https://www.douban.com/search?q=%E8%B4%AB%E6%B0%91%E7%AA%9F%E7%9A%84%E7%99%BE%E4%B8%87%E5%AF%8C%E7%BF%81)
2020-04-30 14:18:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/2209573/>
{'cover': 'http://img.rr.tv/album/20191018/o_1571385722045.jpg',
 'data_type': 'movie',
 'id': 'rrmj_16237',
 'intro': '2006年，印度孟买。                                                                    \u3000\u3000'
          '印度青年杰玛•马利克（戴夫•帕特尔饰）还差一个问题就能赢得2千万卢比。他是怎么做到的？A：他作弊；B：他幸运；C：他是天才；D：一切命中注定。                                                                    \u3000\u3000'
          '这是《谁想成为百万富翁》电视猜谜节目的人生版。杰玛•马利克在已经赢得1千万卢比的情况下被警方以欺诈罪逮捕，严刑拷问下杰玛说出他获得1千万卢比的真相——他确实知道答案，但他只知道这些！                                                                    \u3000\u3000'
          '出身贫民窟的杰玛年幼就生活艰苦，他与哥哥沙里姆、少女拉媞卡(芙蕾达•平托饰)三人却一起经历了几十年印度的变迁。之前每一个问题，都好像是杰玛的记忆碎片，牵动他关于亲情、爱情与人生的回忆。                                                                    \u3000\u3000'
          '而现在，杰玛一方面要洗清自己的犯罪嫌疑，一方面要拯救与拉媞卡的爱。在金钱与爱之前，杰玛能够沉着冷静，选择出正确的答案吗？',
 'is_new': False,
 'name': '贫民窟的百万富翁',
 'platforms': '',
 'publishdate': '2009-03-26',
 'rate': 8.6,
 'sectionid': 'rrmj_1729',
 'tags': ['剧情', '爱情'],
 'type': 'movie',
 'url': 'https://movie.douban.com/subject/2209573/'}
2020-04-30 14:18:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%B8%BB%E5%8E%A8%E7%9A%84%E9%A4%90%E6%A1%8C%20%E7%AC%AC%E5%9B%9B%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:18:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/25750691/> (referer: https://www.douban.com/search?q=%E4%BF%A1%E4%BB%B0%E8%B4%BE%E6%96%AF%E6%B1%80%C2%B7%E6%AF%94%E4%BC%AF)
2020-04-30 14:18:14 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/25750691/>
{'cover': 'http://img.rr.tv/album/20190423/o_1556017861882.jpg',
 'data_type': 'movie',
 'id': 'rrmj_14647',
 'intro': '头条的背后,众多的聚光灯…是贾斯汀的真实故事。了解贾斯汀·比伯的 '
          '只有少数幸运的——诚实、有趣并且完全迷人——通过不可思议的表演和独家采访明星本人。这是一个引人注目的纪录片,后台显示贾斯汀的真实故事:他的见解进化作为一个艺术家,他最重要的关系,是什么样子来的年龄在聚光灯下。它还包括惊险从未演唱会的实况,前所未有的幕后从经理-布劳恩,访问和特殊表象的斯特拉特福和许多更多。',
 'is_new': False,
 'name': '信仰贾斯汀·比伯',
 'platforms': '',
 'publishdate': '2013-12-25',
 'rate': 7.4,
 'sectionid': 'rrmj_1295',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/25750691/'}
2020-04-30 14:18:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%BD%A0%E5%A5%BD%20%E5%86%8D%E8%A7%81%EF%BC%8C%E5%A6%88%E5%A6%88%EF%BC%81> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:18:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26966609/> (referer: https://www.douban.com/search?q=%E6%88%90%E4%B8%BA%E6%B2%83%E4%BC%A6%C2%B7%E5%B7%B4%E8%8F%B2%E7%89%B9)
2020-04-30 14:18:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26966609/>
{'cover': 'http://img.rr.tv/album/20190509/o_1557389132621.jpg',
 'data_type': 'movie',
 'id': 'rrmj_14782',
 'intro': '身价净值超过600亿美元，沃伦•巴菲特是真正的独一无二的亿万富翁。这位传奇般的投资者仍旧住在他位于奥马哈的小房子里。今年86岁的他，每天都开车去到办公室管理世界第五大上市公司伯克希尔•哈撒韦公司。但比起他低调的生活方式，更令人惊讶的是他的道德情操。他庄重和正直的人格魅力让他累积了巨额财富，并在一次史上最大型的慈善活动中，捐出了所有财产。《成为沃伦•巴菲特》这部影片讲述了一个来自内布拉斯加洲的小男孩成为世界上最受人尊敬的男人之一的成长史，以及引导他的幕后贵人。影片为独家拍摄，包含沃伦•巴菲特从未曝光过的家庭影像，沃伦•巴菲特将带领大家思考，当金钱不再有意义时，什么才是最重要的？                                                                            \u3000\u3000'
          'With a net worth of over $60,000,000,000, Warren Buffett is truly a '
          'one-of-a-kind billio...',
 'is_new': False,
 'name': '成为沃伦·巴菲特',
 'platforms': '',
 'publishdate': '2017-01-30',
 'rate': 8.6,
 'sectionid': 'rrmj_1871',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26966609/'}
2020-04-30 14:18:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%8F%A4%E6%88%98%E5%9C%BA%E4%BC%A0%E5%A5%87%20%E7%AC%AC%E4%BA%94%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:18:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26717969/> (referer: https://www.douban.com/search?q=%E8%BE%BE%E4%BC%A6%C2%B7%E5%B8%83%E6%9C%97%EF%BC%9A%E5%B0%B1%E8%8C%83)
2020-04-30 14:18:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%81%B6%E9%AD%94%E5%9C%A8%E4%BA%BA%E9%97%B4%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:18:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26717969/>
{'cover': 'http://img.rr.tv/album/20190712/o_1562915930184.webp',
 'data_type': 'movie',
 'id': 'rrmj_15338',
 'intro': '该特别节目由来自英国的心理魔术师达伦·布朗（Derren '
          'Brown）倾力打造，旨在探索一个人在被挑衅的情况会不会走上极端最终夺人性命。                                                                    \u3000\u3000'
          '节目中，在毫不知情的情况下，一位普通人被置于一个令人紧张不安的预先设定的情境之中。同他打交道的其实都是演员，而这位普通人最后将不得不被迫做出是否该将一位百万富翁从高处推下致死的决定。                                                                    \u3000\u3000'
          '据悉，该特别节目将从心理角度解读人性服从和社会责任。面对权威，我们的本能其实是毫不妥协的服从。在极端情况下，一位有道德意识的普通人都会犯下最可怕的行径，而一切仅仅因为他们被别人告知怎么去做。',
 'is_new': False,
 'name': '达伦·布朗：就范',
 'platforms': '',
 'publishdate': '2016-01-12',
 'rate': 7.9,
 'sectionid': 'rrmj_1416',
 'tags': ['纪录片', '真人秀'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26717969/'}
2020-04-30 14:18:19 [scrapy.extensions.logstats] INFO: Crawled 362 pages (at 44 pages/min), scraped 178 items (at 22 items/min)
2020-04-30 14:18:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%8D%8D%E5%8D%AB%E9%9B%85%E5%90%84%E5%B8%83%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:18:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/3793783/> (referer: https://www.douban.com/search?q=%E4%B9%94%E6%B2%BB%E5%85%8B%E9%B2%81%E5%B0%BC%E7%9A%84%E6%9B%BF%E5%A3%B0)
2020-04-30 14:18:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/3793783/>
{'cover': 'http://img.rr.tv/album/20190410/o_1554879286498.webp',
 'data_type': 'movie',
 'id': 'rrmj_14515',
 'intro': '深邃浩瀚的外层空间，蔚蓝的地球与深不见底、漆黑一片的宇宙形成鲜明对比。一台隶属美国的空间站，数名宇航人员正进行太空漫步，对所属卫星做着例行检查。初上太空的瑞安·斯通博士（桑德拉·布洛克 '
          'Sandra Bullock 饰）在经验丰富的宇航员麦特·科沃斯基（乔治·克鲁尼 George Clooney '
          '饰）的协助下，有条不紊地检查每一个部件。此次是科沃斯基退休前的最后一次飞行，他幽默风趣地活跃着团队的氛围。就在此时，休士顿总部传来骇人消息，不久前行将废弃俄罗斯卫星被导弹击毁，碎片以超过子弹的速度在地球轨道上散开，并意外击中其他卫星，引起连锁反应制造了新的碎片。                                                                    \u3000\u3000'
          '瑞安一行遭到碎片重创，有的同伴不幸身亡，而她和科沃斯基失去控制坠入宇宙深处。幸存的二人不得不彼此信赖，拼尽全力朝向故土前进……',
 'is_new': False,
 'name': '乔治克鲁尼的替声',
 'platforms': '',
 'publishdate': '2013-11-19',
 'rate': 6.0,
 'sectionid': 'rrmj_1405',
 'tags': ['科幻', '惊悚', '灾难'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/3793783/'}
2020-04-30 14:18:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%8A%AF%E7%BD%AA%E5%BF%83%E7%90%86%20%E7%AC%AC%E5%8D%81%E4%BA%94%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:18:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/20277091/> (referer: https://www.douban.com/search?q=%E7%BE%8E%E5%9B%BD%E5%95%86%E4%B8%9A%E5%A4%A7%E4%BA%A8%E4%BC%A0%E5%A5%87)
2020-04-30 14:18:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/20277091/>
{'cover': 'https://img.rr.tv/video/20160411/o_1460387515425.jpg',
 'data_type': 'movie',
 'id': 'rrmj_1544',
 'intro': 'History '
          'Channel巨制，CCTV引进版改名为《美国商业大亨传奇》。                                                                    \u3000\u3000'
          '美利坚合众国不是被发现的，而是被建设的。洛克菲勒、范德比尔特、卡内基、阿斯特、福特和摩根，就是这些人建设了它，而且他们的名字与美国梦想同义。在工业时代的顶峰时期，这些人为一个现代国家创立了一个大胆的想象力，并改造了我们时代的最了不起的工业：石油、铁轨、港铁、船舶、汽车和金融。他们都是从贫困中挣扎起来的。当他们选举总统、设定经济政策并影响他们时代的每一重大事件的时候，他们的道路交叉反复，从内战到经济大萧条。这部系列片还勾勒出数百万美国工人从宾夕法尼亚州炼钢厂到底特律的组装线，是他们把这些梦想变成事实。',
 'is_new': False,
 'name': '美国商业大亨传奇',
 'platforms': '',
 'publishdate': '2012-02-08',
 'rate': 9.2,
 'sectionid': 'rrmj_1420',
 'tags': ['纪录片', '传记', '历史'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/20277091/'}
2020-04-30 14:18:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30353357/> (referer: https://www.douban.com/search?q=%E4%B8%AD%E5%9B%BD%EF%BC%9A%E6%91%87%E6%99%83%E7%9A%84%E5%B7%A8%E4%BA%BA)
2020-04-30 14:18:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30353357/>
{'cover': 'http://img.rr.tv/album/20190621/o_1561103013773.png',
 'data_type': 'movie',
 'id': 'rrmj_15185',
 'intro': '为了赢得真正的胜利，调查军团决定执行夺回玛利亚之墙的作战。作战内容是利用艾伦的硬质化能力将位于玛利亚之墙希干希纳区城墙上的破洞封住。而且还要查明沉睡在艾伦老家地下室的「真相」。但是，「野兽巨人」等巨人就在那里等着他们！',
 'is_new': False,
 'name': '中国：摇晃的巨人',
 'platforms': '',
 'publishdate': '2019-04-28',
 'rate': 6.9,
 'sectionid': 'rrmj_1384',
 'tags': ['剧情', '动作', '科幻', '动画'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30353357/'}
2020-04-30 14:18:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%B4%AA%E5%98%B4%E6%84%8F%E5%A4%A7%E5%88%A9%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:18:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30371813/> (referer: https://www.douban.com/search?q=%E6%98%A8%E6%99%9A%E8%BF%87%E5%BE%97%E5%BE%88%E6%84%89%E5%BF%AB%E5%90%A7)
2020-04-30 14:18:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30371813/>
{'cover': 'http://img.rr.tv/album/20190102/o_1546416335300.jpg',
 'data_type': 'movie',
 'id': 'rrmj_13900',
 'intro': '女星本田翼与演员冈山天音双主演MBS/TBS深夜日剧《昨晚过得很愉快吧》剧集改编自金田一莲十郎的同名漫画，两人在剧中住合租屋一起玩游戏。                                                                    \u3000\u3000'
          '原著漫画讲述一对因网络游戏《勇者斗恶龙X》相识的男女的故事。冈山天音在剧中饰演宅男五月拓海，在游戏中玩女性角色，邀请游戏中的小伙伴吾郎合租房子，却不知现实中五郎的玩家是可爱女生冈元美弥子，于是两人就开始了奇妙的同居生活。',
 'is_new': False,
 'name': '昨晚过得很愉快吧',
 'platforms': '',
 'publishdate': '2019-01-07',
 'rate': 7.0,
 'sectionid': 'rrmj_1244',
 'tags': ['喜剧', '爱情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30371813/'}
2020-04-30 14:18:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E9%BB%91%E6%9A%97%E7%B3%BB%E6%B8%B8%E5%AE%A2%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:18:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/33437305/> (referer: https://www.douban.com/search?q=%E5%9B%BD%E7%8E%8B%EF%BC%9A%E6%B0%B8%E8%BF%9C%E7%9A%84%E5%90%9B%E4%B8%BB)
2020-04-30 14:18:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/33437305/>
{'cover': 'http://img.rr.tv/cover/20200415/o_1586946667833.jpg',
 'data_type': 'movie',
 'id': 'rrmj_17392',
 'intro': '该剧以"平行世界"为背景，上帝把恶魔释放到了人间，恶魔打开了平行世界的大门。如果另一个世界有比"我"生活得更好的"我"，你会跟他改变你的生活吗？面对恶魔抛出的这些问题，欲关上平行世界之门的理科型大韩帝国皇帝李坤，和为了守护爱情的文科型韩国刑警郑泰乙，通过跨世界互助演绎出时而激动、时而酸涩，层次不同的罗曼史。',
 'is_new': False,
 'name': '国王：永远的君主',
 'platforms': '',
 'publishdate': '2020-04-17',
 'rate': 8.5,
 'sectionid': 'rrmj_1726',
 'tags': ['剧情', '奇幻'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/33437305/'}
2020-04-30 14:18:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E9%BB%91%E8%89%B2%E6%98%9F%E6%9C%9F%E4%B8%80%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:18:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/34481152/> (referer: https://www.douban.com/search?q=%E4%B8%80%E7%9D%81%E7%9C%BC%EF%BC%8C%E4%B8%89%E5%90%8D%E7%94%B7%E5%8F%8B)
2020-04-30 14:18:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/34481152/>
{'cover': 'http://img.rr.tv/album/20190707/o_1562468504263.jpg',
 'data_type': 'movie',
 'id': 'rrmj_15278',
 'intro': '和三倍的暧昧的三个男生的设定挺像的（傲娇男，青梅竹马男，汪汪男）',
 'is_new': False,
 'name': '一睁眼，三名男友',
 'platforms': '',
 'publishdate': '2019-07-03',
 'rate': 6.7,
 'sectionid': 'rrmj_1244',
 'tags': ['爱情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/34481152/'}
2020-04-30 14:18:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E9%BB%91%E8%89%B2%E6%98%9F%E6%9C%9F%E4%B8%80%20%E7%AC%AC%E4%BA%8C%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:18:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/24871614/> (referer: https://www.douban.com/search?q=%E4%BA%BA%E4%BD%93%E5%99%A8%E5%AE%98%E4%BA%A4%E6%98%93%E5%AE%9E%E5%BD%95)
2020-04-30 14:18:34 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/24871614/>
{'cover': 'http://img.rr.tv/cover/20191014/o_1571048848688.webp',
 'data_type': 'movie',
 'id': 'rrmj_16152',
 'intro': '影片中既有器官贩卖经纪人、没有职业道德的医生的讲述，也展现了那些为了尽快拿到钱而愿意出卖器官的贫穷的男男女女，以及在遵守法律与生命中艰难选择的绝望病人的生活',
 'is_new': False,
 'name': '人体器官交易实录',
 'platforms': '',
 'publishdate': '2018-02-23',
 'rate': 8.1,
 'sectionid': 'rrmj_1416',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/24871614/'}
2020-04-30 14:18:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%95%A6%E5%95%A6%E9%98%9F%E5%A5%B3%E7%8E%8B%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:18:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27008416/> (referer: https://www.douban.com/search?q=%E8%87%B4%E6%9B%BE%E7%BB%8F%E7%BE%8E%E5%A5%BD%E7%9A%84%E6%88%91%E4%BB%AC)
2020-04-30 14:18:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/27008416/>
{'cover': 'http://img.rr.tv/album/20190611/o_1560223257523.jpeg',
 'data_type': 'movie',
 'id': 'rrmj_14864',
 'intro': '改编自赵乾乾同名畅销小说，主要讲述了陈小希与江辰19年间共同成长，从青梅竹马到错失后的再次牵手的爱情故事。腹黑傲娇的天才医生，蠢萌逗比的元气少女，全剧气质俏皮幽默，通过展现陈小希倒追江辰一路上啼笑皆非的日常，记录了青春时光里最美好的心动时刻，将专属17岁少男少女之间的青涩感情呈现出来，带领观众重返好时光。',
 'is_new': False,
 'name': '致曾经美好的我们',
 'platforms': '',
 'publishdate': '2017-11-09',
 'rate': 6.0,
 'sectionid': 'rrmj_1244',
 'tags': ['剧情', '爱情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/27008416/'}
2020-04-30 14:18:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27615467/> (referer: https://www.douban.com/search?q=%E5%A5%B3%E5%A4%A7%E6%B3%95%E5%AE%98%E9%87%91%E6%96%AF%E4%BC%AF%E6%A0%BC)
2020-04-30 14:18:38 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/27615467/>
{'cover': 'http://img.rr.tv/album/20190705/o_1562310182079.webp',
 'data_type': 'movie',
 'id': 'rrmj_15265',
 'intro': '鲁斯·巴德·金斯伯格是美国联邦最高法院的第二位女性法官、第一位犹太裔女性法官，哥伦比亚法学院历史上第一位获得终身教职（tenure）的女性，最高法院的自由派法官之一。影片讲述了美国联邦最高法院有史以来第二位女性大法官鲁斯·巴德·金斯伯格的生平事迹。',
 'is_new': False,
 'name': '女大法官金斯伯格',
 'platforms': '',
 'publishdate': '2018-01-21',
 'rate': 9.1,
 'sectionid': 'rrmj_1657',
 'tags': ['纪录片', '传记'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/27615467/'}
2020-04-30 14:18:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%94%9F%E6%AD%BB%E4%B8%8E%E8%BD%AE%E5%9B%9E%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:18:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/33400747/> (referer: https://www.douban.com/search?q=%E5%BD%92%E5%AE%B6%EF%BC%9A%E7%A2%A7%E6%98%82%E4%B8%9D%E4%BD%9C%E5%93%81)
2020-04-30 14:18:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/33400747/>
{'cover': 'http://img.rr.tv/album/20190420/o_1555739608966.webp',
 'data_type': 'movie',
 'id': 'rrmj_14613',
 'intro': '《Homecoming》带我们近距离感受碧昂斯在 2018 '
          '年科切拉音乐节上的精彩演出，这场演出致敬了美国历史上的黑人学院和大学。《Homecoming》穿插了一些真情洋溢的镜头和采访，详细讲述了她的愿景背后的准备工作和强烈的意图，记录了从创意构思到文化运动的感人历程。                                                                    \u3000\u3000'
          '该影片不提供预映版。',
 'is_new': False,
 'name': '归家：碧昂丝作品',
 'platforms': '',
 'publishdate': '2019-04-17',
 'rate': 9.1,
 'sectionid': 'rrmj_1295',
 'tags': ['纪录片', '音乐'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/33400747/'}
2020-04-30 14:18:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%B4%AA%E5%98%B4%E6%84%8F%E5%A4%A7%E5%88%A9%20%E7%AC%AC%E4%BA%8C%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:18:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/33459902/> (referer: https://www.douban.com/search?q=%E7%9C%9F%E5%AE%9E%E7%9A%84%E5%BE%B7%E9%9B%B7%E5%B0%94%E4%B8%80%E5%AE%B6)
2020-04-30 14:18:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/33459902/>
{'cover': 'http://img.rr.tv/album/20190807/o_1565158693709.webp',
 'data_type': 'movie',
 'id': 'rrmj_15550',
 'intro': 'What The Durrells Did Next is the definitive true story behind one '
          'of the best-loved families in TV '
          'drama.                                                                            \u3000\u3000                                                                            \u3000\u3000'
          'Fronted by Keeley Hawes, leading lady of ITV’s hugely popular '
          'series The Durrells, this documentary reveals the adventures of '
          'this eccentric family once they left '
          'Corfu.                                                                            \u3000\u3000                                                                            \u3000\u3000'
          'Lifting the lid on every family secret, heartbreak and triumph, '
          'it’s an outlandish story of African e...',
 'is_new': False,
 'name': '真实的德雷尔一家',
 'platforms': '',
 'publishdate': '2019-05-19',
 'rate': 9.2,
 'sectionid': 'rrmj_1405',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/33459902/'}
2020-04-30 14:18:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30377045/> (referer: https://www.douban.com/search?q=%E7%A5%9E%E7%A7%98%E5%8D%9A%E5%A3%AB%20%E7%AC%AC%E5%8D%81%E4%BA%8C%E5%AD%A3)
2020-04-30 14:18:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30377045/>
{'cover': 'http://img.rr.tv/cover/20191219/o_1576742052672.jpg',
 'data_type': 'movie',
 'id': 'rrmj_16863',
 'intro': '“神秘博士”暂时不会换人，第13任博士的演员朱迪·惠特克将回归《神秘博士》第12季，继续主演，《好莱坞报道者》独家报道了消息。                                                                    \u3000\u3000'
          '此前有猜测称这个第一位扮演神秘博士的女演员下季将不会回归，换人接替。而惠特克对THR表示：“我迫不及待要回去再次开工啦，这是个很棒的角色，迄今为止也都是很棒的旅程，我还未准备好交棒。”                                                                    \u3000\u3000'
          '第11季完结在即，也将有新年特别集，第12季预计明年早期开拍。',
 'is_new': False,
 'name': '神秘博士 第十二季',
 'platforms': '',
 'publishdate': '2020-01-01',
 'rate': 7.8,
 'sectionid': 'rrmj_742',
 'tags': ['剧情', '科幻', '悬疑', '家庭', '冒险'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30377045/'}
2020-04-30 14:18:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%B7%AF%E6%98%93%C2%B7C%C2%B7K%EF%BC%9A%E8%80%81%E6%8B%9B%E7%AC%91%E4%BA%86> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:18:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/10742835/> (referer: https://www.douban.com/search?q=%E8%B4%AA%E5%98%B4%E6%84%8F%E5%A4%A7%E5%88%A9%20%E7%AC%AC%E4%B8%80%E5%AD%A3)
2020-04-30 14:18:47 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/10742835/>
{'cover': 'http://img.rr.tv/album/20190509/o_1557388616883.png',
 'data_type': 'movie',
 'id': 'rrmj_14775',
 'intro': '两位意大利国宝级厨艺大师安东尼奥·卡路奇欧和詹纳罗·康塔多，回到阔别50年的祖国意大利，走遍意大利各个大区，回忆童年的味道，寻找融合的美味。第二季共四集，在第二季的旅途中，两位意大利名厨带领观众，在具有深厚底蕴的意大利美食中，提味意大利南方的童年回忆，意大利人的"扮靓"，意大利北方人的“求生之道”和意大利人的“男子汉气概”',
 'is_new': False,
 'name': '贪嘴意大利 第一季',
 'platforms': '',
 'publishdate': '2018-02-23',
 'rate': 9.2,
 'sectionid': 'rrmj_1883',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/10742835/'}
2020-04-30 14:18:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%B4%BE%E6%96%AF%E6%B1%80%C2%B7%E6%AF%94%E4%BC%AF%EF%BC%9A%E5%AD%A3%E8%8A%82> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:18:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26258117/> (referer: https://www.douban.com/search?q=%E6%8D%8D%E5%8D%AB%E9%9B%85%E5%90%84%E5%B8%83%20%E7%AC%AC%E4%B8%80%E5%AD%A3)
2020-04-30 14:18:47 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26258117/>
{'cover': 'http://img.rr.tv/cover/20200413/o_1586743480285.webp',
 'data_type': 'movie',
 'id': 'rrmj_17476',
 'intro': '重启的《鬼玩人》系列将以电视剧集的形式回归，剧情上承接《鬼玩人》的第二部和第三部。                                                                    \u3000\u3000'
          '剧集将在美国时间万圣节10月31日首播，首季为10集，主角由旧版电影主角布鲁斯·坎贝尔（Bruce '
          'Campbell）饰演，讲述在男主角艾什·威廉姆斯（Ash '
          'Williams）对抗恶魔大军30年后，当他们又再一次重临人间时，恶魔们要挟消灭所有的人类，于是艾什成了人类最后的希望。艾什又得再一次拿起他的电锯，然而岁月不留人，这次他得找帮手了。',
 'is_new': False,
 'name': '捍卫雅各布 第一季',
 'platforms': '',
 'publishdate': '2015-10-31',
 'rate': 9.0,
 'sectionid': 'rrmj_745',
 'tags': ['喜剧', '动作', '恐怖'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26258117/'}
2020-04-30 14:18:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%A8%98%E5%A8%98%E8%85%94%E7%9A%84%E6%97%A5%E8%AE%B0%E7%AC%AC%E4%BA%8C%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:18:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26743594/> (referer: https://www.douban.com/search?q=%E4%B8%BB%E5%8E%A8%E7%9A%84%E9%A4%90%E6%A1%8C%20%E7%AC%AC%E5%9B%9B%E5%AD%A3)
2020-04-30 14:18:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26743594/>
{'cover': 'http://img.rr.tv/album/20180703/o_1530607367344.jpg',
 'data_type': 'movie',
 'id': 'rrmj_12560',
 'intro': '《主厨的餐桌：甜点篇》将聚集世界上最优秀的烘焙师们。',
 'is_new': False,
 'name': '主厨的餐桌 第四季',
 'platforms': '',
 'publishdate': '2018-04-13',
 'rate': 8.7,
 'sectionid': 'rrmj_1883',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26743594/'}
2020-04-30 14:18:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27135496/> (referer: https://www.douban.com/search?q=%E9%BB%91%E8%89%B2%E6%98%9F%E6%9C%9F%E4%B8%80%20%E7%AC%AC%E4%B8%80%E5%AD%A3)
2020-04-30 14:18:53 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/27135496/>
{'cover': 'http://img.rr.tv/album/20181231/o_1546233733871.jpg',
 'data_type': 'movie',
 'id': 'rrmj_13885',
 'intro': '这是钱德尔自《谎言堂》后回归主演Showtime剧集，讲述1987年10月19日，华尔街遭遇史上最剧烈的股市暴跌，一队外来人士摧毁了华尔街那由蓝血贵族长期把握的财政体系。钱德尔饰演自学成才的股市大佬，兰内斯饰演股票交易神童，豪尔饰演一名操盘手主管。《嫁给我》编剧搭档David '
          'Caspe和Jordan Cahan写剧本并担任主创，明年1月开播。',
 'is_new': False,
 'name': '黑色星期一 第一季',
 'platforms': '',
 'publishdate': '2019-01-20',
 'rate': 8.9,
 'sectionid': 'rrmj_1871',
 'tags': ['喜剧', '犯罪'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/27135496/'}
2020-04-30 14:18:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%97%A0%E6%B3%95%E6%88%90%E4%B8%BA%E9%87%8E%E5%85%BD%E7%9A%84%E6%88%91%E4%BB%AC> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:18:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%B8%BB%E5%8E%A8%E7%9A%84%E9%A4%90%E6%A1%8C%EF%BC%9A%E6%B3%95%E5%9B%BD%E7%AF%87> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:18:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27135938/> (referer: https://www.douban.com/search?q=%E6%81%B6%E9%AD%94%E5%9C%A8%E4%BA%BA%E9%97%B4%20%E7%AC%AC%E4%B8%80%E5%AD%A3)
2020-04-30 14:18:55 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/27135938/>
{'cover': 'http://img.rr.tv/album/20180615/o_1529042394958.jpg',
 'data_type': 'movie',
 'id': 'rrmj_12434',
 'intro': 'From the devil himself to a vengeful ghost from Japanese urban '
          'legend, True Monsters seeks to find some truth behind infamous '
          'monsters in myth and legend.',
 'is_new': False,
 'name': '恶魔在人间 第一季',
 'platforms': '',
 'publishdate': '2015-10-09',
 'rate': 8.0,
 'sectionid': 'rrmj_1416',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/27135938/'}
2020-04-30 14:18:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30218542/> (referer: https://www.douban.com/search?q=%E5%8F%A4%E6%88%98%E5%9C%BA%E4%BC%A0%E5%A5%87%20%E7%AC%AC%E4%BA%94%E5%AD%A3)
2020-04-30 14:18:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%8A%AB%E5%A4%B4%E5%A3%AB%E5%A6%82%E4%BD%95%E6%94%B9%E5%8F%98%E4%B8%96%E7%95%8C> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:18:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30218542/>
{'cover': 'http://img.rr.tv/cover/20200211/o_1581400998329.webp',
 'data_type': 'movie',
 'id': 'rrmj_17140',
 'intro': 'Starz剧集《古战场传奇》还在拍摄第4季，如今就正式宣布一连续订第5、6两季，毕竟收视率很好。新续订的两季各有12集，预计2019和2020年播出，依次会基于原作小说《异乡人》系列中的《血十字》和《雪尘的呼吸》。而且这两季后，小说还有两本没拍完，现在作者Diana '
          'Gabaldon还在写一本新的，所以第6季很可能也不是该剧终点。',
 'is_new': False,
 'name': '古战场传奇 第五季',
 'platforms': '',
 'publishdate': '2020-02-16',
 'rate': 7.6,
 'sectionid': 'rrmj_742',
 'tags': ['剧情', '爱情', '奇幻'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30218542/'}
2020-04-30 14:19:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%BE%8E%E5%88%A9%E5%9D%9A%EF%BC%9A%E6%88%91%E4%BB%AC%E7%9A%84%E6%95%85%E4%BA%8B> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:19:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30280526/> (referer: https://www.douban.com/search?q=%E9%BB%91%E6%9A%97%E7%B3%BB%E6%B8%B8%E5%AE%A2%20%E7%AC%AC%E4%B8%80%E5%AD%A3)
2020-04-30 14:19:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30280526/>
{'cover': 'http://img.rr.tv/album/20190910/o_1568105868962.jpg',
 'data_type': 'movie',
 'id': 'rrmj_15603',
 'intro': 'From a nuclear lake to a haunted forest, New Zealand filmmaker and '
          'journalist David Farrier (Tickled) visits unusual -- and often '
          'macabre -- tourism spots around the world.',
 'is_new': False,
 'name': '黑暗系游客 第一季',
 'platforms': '',
 'publishdate': '2018-07-20',
 'rate': 7.7,
 'sectionid': 'rrmj_1416',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30280526/'}
2020-04-30 14:19:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%9B%BD%E5%AE%9D%E9%93%B6%E8%A1%8C%EF%BC%9A%E5%B0%8F%E5%8F%AF%E5%85%A5%E7%8B%B1> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:19:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30373143/> (referer: https://www.douban.com/search?q=%E4%B8%80%E5%A4%9C%E6%A1%83%E8%8A%B1%E8%BF%90%20%E7%AC%AC%E4%B8%80%E5%AD%A3)
2020-04-30 14:19:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30373143/>
{'cover': 'http://img.rr.tv/album/20181128/o_1543390320519.jpg',
 'data_type': 'movie',
 'id': 'rrmj_13667',
 'intro': '这部八集浪漫喜剧剧集以当代巴黎为背景，讲述了一群朋友声援他们始终单身的女性朋友埃尔莎，而埃尔莎却搞不清为什么自己无法得到爱神的眷顾。他们为了帮助埃尔莎重拾自信误入歧途，雇佣了一位男妓来重振埃尔莎在约会、感情和寻找爱情方面的信心。',
 'is_new': False,
 'name': '一夜桃花运 第一季',
 'platforms': '',
 'publishdate': '2018-12-07',
 'rate': 7.5,
 'sectionid': 'rrmj_1244',
 'tags': ['喜剧', '爱情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30373143/'}
2020-04-30 14:19:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%BD%93%E5%93%88%E5%88%A9%E7%A6%BB%E5%88%AB%E9%9C%8D%E6%A0%BC%E6%B2%83%E8%8C%A8> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:19:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30428027/> (referer: https://www.douban.com/search?q=%E7%8A%AF%E7%BD%AA%E5%BF%83%E7%90%86%20%E7%AC%AC%E5%8D%81%E4%BA%94%E5%AD%A3)
2020-04-30 14:19:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30428027/>
{'cover': 'http://img.rr.tv/cover/20200110/o_1578623174709.webp',
 'data_type': 'movie',
 'id': 'rrmj_16994',
 'intro': 'CBS正式宣布续订「犯罪心理」第15季，并确定这部将是该剧系列的最终季！！',
 'is_new': False,
 'name': '犯罪心理 第十五季',
 'platforms': '',
 'publishdate': '2020-01-08',
 'rate': 8.3,
 'sectionid': 'rrmj_742',
 'tags': ['剧情', '悬疑', '犯罪'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30428027/'}
2020-04-30 14:19:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30459044/> (referer: https://www.douban.com/search?q=%E4%B8%BB%E5%8E%A8%E7%9A%84%E9%A4%90%E6%A1%8C%20%E7%AC%AC%E5%85%AD%E5%AD%A3)
2020-04-30 14:19:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30459044/>
{'cover': 'http://img.rr.tv/album/20190228/o_1551340493515.jpg',
 'data_type': 'movie',
 'id': 'rrmj_14201',
 'intro': 'Netflix美食纪录片.影片分别记录了来自意大利,美国,阿根廷,澳大利亚,瑞典的六大名厨的厨房生活.本片恢宏大气.是关于食物,信念,坚持与创造的故事,动人心魄。',
 'is_new': False,
 'name': '主厨的餐桌 第六季',
 'platforms': '',
 'publishdate': '2019-02-22',
 'rate': 8.5,
 'sectionid': 'rrmj_1883',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30459044/'}
2020-04-30 14:19:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%9D%8E%E5%B0%8F%E9%BE%99%EF%BC%9A%E5%8B%87%E5%A3%AB%E7%9A%84%E6%97%85%E7%A8%8B> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:19:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%9E%84%E5%BB%BA%E3%80%8A%E7%96%AF%E7%8B%82%E5%8A%A8%E7%89%A9%E5%9F%8E%E3%80%8B> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:19:10 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/7589912/> (referer: https://www.douban.com/search?q=%E7%94%9F%E6%AD%BB%E4%B8%8E%E8%BD%AE%E5%9B%9E%20%E7%AC%AC%E4%B8%80%E5%AD%A3)
2020-04-30 14:19:10 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/7589912/>: HTTP status code is not handled or not allowed
2020-04-30 14:19:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%9A%87%E5%90%8E%E4%B9%90%E9%98%9F%EF%BC%9A%E6%BC%94%E5%87%BA%E5%B2%81%E6%9C%88> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:19:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/34434487/> (referer: https://www.douban.com/search?q=%E9%BB%91%E8%89%B2%E6%98%9F%E6%9C%9F%E4%B8%80%20%E7%AC%AC%E4%BA%8C%E5%AD%A3)
2020-04-30 14:19:14 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/34434487/>
{'cover': 'http://img.rr.tv/cover/20200316/o_1584344692191.jpg',
 'data_type': 'movie',
 'id': 'rrmj_17331',
 'intro': '1987年10月19日“黑色星期一”，触发道指有史以来最大单日跌幅后，唐和布莱尔掌控狙阻者集团（The Jammer '
          'Group），却发现老板这位子不好坐——尤其是还要时刻提防与联邦调查局线人基斯一同跑路的前老板莫。                                                                    \u3000\u3000'
          '谁会因股灾坐牢？谁会因谋杀入狱？谁又会因敲莫竹杠变身阶下囚？',
 'is_new': False,
 'name': '黑色星期一 第二季',
 'platforms': '',
 'publishdate': '2020-03-15',
 'rate': 8.5,
 'sectionid': 'rrmj_1871',
 'tags': ['喜剧'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/34434487/'}
2020-04-30 14:19:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%B4%A9%E5%8D%96%E3%80%8C%E7%88%B1%E3%80%8D%E7%9A%84%E7%94%B7%E5%AD%90%E4%BB%AC> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:19:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/34858567/> (referer: https://www.douban.com/search?q=%E4%BD%A0%E5%A5%BD%20%E5%86%8D%E8%A7%81%EF%BC%8C%E5%A6%88%E5%A6%88%EF%BC%81)
2020-04-30 14:19:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/34858567/>
{'cover': 'http://img.rr.tv/cover/20200205/o_1580861766846.jpg',
 'data_type': 'movie',
 'id': 'rrmj_17112',
 'intro': '该剧讲述世界上最暖心的离别故事。描写妈妈鬼神（女主）为了变成人类在49天里的真实转世计划，和妈妈鬼神经历了生离死别的痛苦并展开新的人生的丈夫（男主），以及回到两人的孩子（童演）描绘的上天和被留在人间的人们的故事。                                                                    \u3000\u3000'
          '金泰熙将在剧中饰演车宥利，她性格乐天随和热心，她主攻玻璃工艺，经营着一个小作坊，婚后在坐月子的时候也没有放弃工作。去世的那天也是在去工作的途中遇到了交通事故。                                                                    \u3000\u3000'
          '由《Go Back夫妇》权慧珠编剧执笔，预计接档《爱的迫降》播出。',
 'is_new': False,
 'name': '你好 再见，妈妈！',
 'platforms': '',
 'publishdate': '2020-02-22',
 'rate': 8.2,
 'sectionid': 'rrmj_1726',
 'tags': ['剧情', '奇幻'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/34858567/'}
2020-04-30 14:19:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%88%91%E7%9A%84%E5%A4%A9%E6%89%8D%E5%A5%B3%E5%8F%8B%20%E7%BA%AA%E5%BD%95%E7%89%87> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:19:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/24843509/> (referer: https://www.douban.com/search?q=%E8%B4%AA%E5%98%B4%E6%84%8F%E5%A4%A7%E5%88%A9%20%E7%AC%AC%E4%BA%8C%E5%AD%A3)
2020-04-30 14:19:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/24843509/>
{'cover': 'http://img.rr.tv/album/20190509/o_1557388729493.webp',
 'data_type': 'movie',
 'id': 'rrmj_14777',
 'intro': '两位意大利国宝级厨艺大师安东尼奥·卡路奇欧和詹纳罗·康塔多，回到阔别50年的祖国意大利，走遍意大利各个大区，回忆童年的味道，寻找融合的美味。第二季共四集，在第二季的旅途中，两位意大利名厨带领观众，在具有深厚底蕴的意大利美食中，提味意大利南方的童年回忆，意大利人的"扮靓"，意大利北方人的“求生之道”和意大利人的“男子汉气概”。',
 'is_new': False,
 'name': '贪嘴意大利 第二季',
 'platforms': '',
 'publishdate': '2012-04-19',
 'rate': 9.4,
 'sectionid': 'rrmj_1883',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/24843509/'}
2020-04-30 14:19:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%95%A6%E7%85%8C%E8%8E%AB%E9%AB%98%E7%AA%9F%20%E7%BE%8E%E7%9A%84%E5%85%A8%E8%B2%8C> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:19:19 [scrapy.extensions.logstats] INFO: Crawled 412 pages (at 50 pages/min), scraped 203 items (at 25 items/min)
2020-04-30 14:19:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/34935803/> (referer: https://www.douban.com/search?q=%E5%95%A6%E5%95%A6%E9%98%9F%E5%A5%B3%E7%8E%8B%20%E7%AC%AC%E4%B8%80%E5%AD%A3)
2020-04-30 14:19:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/34935803/>
{'cover': 'http://img.rr.tv/cover/20200108/o_1578474419057.webp',
 'data_type': 'movie',
 'id': 'rrmj_16987',
 'intro': '纪录片追踪记录了劲旅纳瓦罗学院啦啦队在争夺梦寐以求的全国冠军的道路上所遭遇的起起伏伏。',
 'is_new': False,
 'name': '啦啦队女王 第一季',
 'platforms': '',
 'publishdate': '2020-01-08',
 'rate': 8.9,
 'sectionid': 'rrmj_1425',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/34935803/'}
2020-04-30 14:19:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%89%B9%E6%96%AF%E6%8B%89%EF%BC%9A%E9%97%AA%E7%94%B5%E7%9A%84%E4%B8%BB%E4%BA%BA%20> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:19:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26388908/> (referer: https://www.douban.com/search?q=%E7%A6%8F%E6%96%AF%E7%89%B9%E5%8C%BB%E7%94%9F%20%E7%AC%AC%E4%B8%80%E5%AD%A3)
2020-04-30 14:19:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26388908/>
{'cover': 'https://img.rr.tv/season/20170906/o_1504688692345.png',
 'data_type': 'movie',
 'id': 'rrmj_10518',
 'intro': '在别人眼中，Foster医生有着令人羡慕的一切，工作受人尊敬，家庭幸福和睦，夫妻恩爱甜蜜，孩子乖巧听话。其实她自己也一直这样认为，直到有一天，一支唇膏，一根金发的出现，让她开始怀疑眼前的一切。为了查清楚丈夫是否真的出轨，她甚至利用病人帮她跟踪丈夫，结果却发现事情的真相，完全在她的预料之外。',
 'is_new': False,
 'name': '福斯特医生 第一季',
 'platforms': '',
 'publishdate': '2015-09-09',
 'rate': 8.8,
 'sectionid': 'rrmj_1912',
 'tags': ['剧情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26388908/'}
2020-04-30 14:19:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%80%A5%E8%AF%8A%E5%AE%A4%E7%9A%84%E6%95%85%E4%BA%8B%20%E7%AC%AC%E4%BA%8C%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:19:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26657443/> (referer: https://www.douban.com/search?q=%E7%A6%8F%E6%96%AF%E7%89%B9%E5%8C%BB%E7%94%9F%20%E7%AC%AC%E4%BA%8C%E5%AD%A3)
2020-04-30 14:19:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26657443/>
{'cover': 'https://img.rr.tv/season/20170906/o_1504688803434.png',
 'data_type': 'movie',
 'id': 'rrmj_10519',
 'intro': '自离婚之后，福斯特医生和儿子汤姆一度过着平静又有些沉闷的生活，—直至前夫西蒙的请柬飘然而至，他和女友凯特已经结婚，并准备重新搬回嘉玛所住的街区，福斯特医生和儿子已经平静安稳的生活再次掀起波澜。',
 'is_new': False,
 'name': '福斯特医生 第二季',
 'platforms': '',
 'publishdate': '2017-09-05',
 'rate': 7.1,
 'sectionid': 'rrmj_1912',
 'tags': ['剧情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26657443/'}
2020-04-30 14:19:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%BA%9A%E5%BD%93%C2%B7%E6%A1%91%E5%BE%B7%E5%8B%92%EF%BC%9A100%25%E6%96%B0%E9%B2%9C> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:19:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/34947590/> (referer: https://www.douban.com/search?q=%E6%9D%A5%E5%8B%BE%E5%BC%95%E6%88%91%E7%94%B7%E5%8F%8B%E5%90%A7%EF%BC%81)
2020-04-30 14:19:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/34947590/>
{'cover': 'http://img.rr.tv/seasonCover/20200423/o_1587625475663.jpg',
 'data_type': 'movie',
 'id': 'rrmj_17550',
 'intro': '由插画家盖彼亲自改编原创作品并自编自导全新网漫风格网路剧，为都会男女解开爱情困惑，更有渣男与闺蜜之间不能说的那些㊙',
 'is_new': False,
 'name': '来勾引我男友吧！',
 'platforms': '',
 'publishdate': '2020-01-02',
 'rate': 8.0,
 'sectionid': 'rrmj_1912',
 'tags': ['爱情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/34947590/'}
2020-04-30 14:19:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/5170652/> (referer: https://www.douban.com/search?q=%E8%B7%AF%E6%98%93%C2%B7C%C2%B7K%EF%BC%9A%E8%80%81%E6%8B%9B%E7%AC%91%E4%BA%86)
2020-04-30 14:19:32 [scrapy.core.scraper] ERROR: Error processing {'cover': 'http://img.rr.tv/album/20190530/o_1559203355351.webp',
 'data_type': 'movie',
 'id': 'rrmj_14964',
 'intro': 'Comedian Louis C.K. gleefully transcends the boundaries of good '
          'taste in a stand-up comedy special in which no topic is sacred – '
          'including his own children. Whether ranting about impatience in '
          'contemporary society, his ballooning physique, or the trials of '
          'fatherhood, C.K. has a curious talent for keeping an audience in '
          'stitches even – or especially – as they’re recoiling in ab...',
 'is_new': False,
 'name': '路易·C·K：老招笑了',
 'platforms': '',
 'publishdate': '',
 'rate': 8.6,
 'sectionid': 'rrmj_1421',
 'tags': ['喜剧'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/5170652/'}
Traceback (most recent call last):
  File "/usr/python37/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/python37/lib/python3.7/site-packages/scrapy/utils/defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/root/spider/scrapyspider/spiderV1/pipelines.py", line 262, in process_item
    timeStruct = time.strptime(publishdate, '%Y-%m-%d')
  File "/usr/python37/lib/python3.7/_strptime.py", line 571, in _strptime_time
    tt = _strptime(data_string, format)[0]
  File "/usr/python37/lib/python3.7/_strptime.py", line 359, in _strptime
    (data_string, format))
ValueError: time data '' does not match format '%Y-%m-%d'
2020-04-30 14:19:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%87%AF%E6%96%87%C2%B7%E5%93%88%E7%89%B9%EF%BC%9A%E4%B8%8D%E8%B4%9F%E8%B4%A3%E4%BB%BB> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:19:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%97%BA%E8%BE%BE%C2%B7%E5%A1%9E%E5%85%8B%E4%B8%9D%EF%BC%9A%E4%B8%8D%E6%AD%A3%E5%B8%B8> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:19:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%BA%A6%E7%BF%B0%C2%B7%E5%88%97%E4%BE%AC%E7%9A%84%E7%90%86%E6%83%B3%E4%B8%96%E7%95%8C> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:19:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/34938117/> (referer: https://www.douban.com/search?q=%E8%B4%BE%E6%96%AF%E6%B1%80%C2%B7%E6%AF%94%E4%BC%AF%EF%BC%9A%E5%AD%A3%E8%8A%82)
2020-04-30 14:19:34 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/34938117/>
{'cover': 'http://img.rr.tv/cover/20200215/o_1581748060393.webp',
 'data_type': 'movie',
 'id': 'rrmj_17171',
 'intro': '贾斯汀·比伯10集纪录剧集《贾斯汀·比伯：季节》(Justin Bieber: '
          'Seasons，暂译)发布海报。该剧将展示比伯创作新歌的幕后、第五张专辑的创作动机、取消《Purpose》巡演的后续，剧集还将展现比伯的私人生活，包括与海莉·比伯婚礼的独家花絮。该剧将于1月27日登陆YouTube。',
 'is_new': False,
 'name': '贾斯汀·比伯：季节',
 'platforms': '',
 'publishdate': '2020-01-27',
 'rate': 8.6,
 'sectionid': 'rrmj_1295',
 'tags': ['纪录片', '音乐'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/34938117/'}
2020-04-30 14:19:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/4822098/> (referer: https://www.douban.com/search?q=%E7%BE%8E%E5%88%A9%E5%9D%9A%EF%BC%9A%E6%88%91%E4%BB%AC%E7%9A%84%E6%95%85%E4%BA%8B)
2020-04-30 14:19:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/4822098/>
{'cover': 'http://img.rr.tv/album/20180701/o_1530423465494.jpg',
 'data_type': 'movie',
 'id': 'rrmj_12545',
 'intro': '美国：我们的故事 01 反抗者 \u3000\u3000美国：我们的故事 02 革命 \u3000\u3000美国：我们的故事 03 '
          '西进 \u3000\u3000美国：我们的故事 04 分裂 \u3000\u3000美国：我们的故事 05 '
          '内战 \u3000\u3000美国：我们的故事 06 腹地 \u3000\u3000美国：我们的故事 07 '
          '城市 \u3000\u3000美国：我们的故事 08 繁荣 \u3000\u3000美国：我们的故事 09 '
          '萧条 \u3000\u3000美国：我们的故事 10 二战 \u3000\u3000美国：我们的故事 11 '
          '超级大国 \u3000\u3000美国：我们的故事 12 黄金时代',
 'is_new': False,
 'name': '美利坚：我们的故事',
 'platforms': '',
 'publishdate': '2010-04-25',
 'rate': 8.9,
 'sectionid': 'rrmj_1420',
 'tags': ['纪录片', '历史'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/4822098/'}
2020-04-30 14:19:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%BA%BA%E4%BD%93%E5%A5%A5%E5%A6%99%E4%B9%8B%E7%BB%86%E8%83%9E%E7%9A%84%E6%9A%97%E6%88%98> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:19:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26877424/> (referer: https://www.douban.com/search?q=%E5%A8%98%E5%A8%98%E8%85%94%E7%9A%84%E6%97%A5%E8%AE%B0%E7%AC%AC%E4%BA%8C%E5%AD%A3)
2020-04-30 14:19:40 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26877424/>
{'cover': 'http://img.rr.tv/album/20181231/o_1546266728190.png',
 'data_type': 'movie',
 'id': 'rrmj_13886',
 'intro': '',
 'is_new': False,
 'name': '娘娘腔的日记第二季',
 'platforms': '',
 'publishdate': '2017-02-11',
 'rate': 8.6,
 'sectionid': 'rrmj_989',
 'tags': ['剧情', '喜剧'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26877424/'}
2020-04-30 14:19:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%8D%95%E5%90%91%E4%B9%90%E9%98%9F%EF%BC%9A%E8%BF%99%E5%B0%B1%E6%98%AF%E6%88%91%E4%BB%AC> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:19:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30290917/> (referer: https://www.douban.com/search?q=%E6%97%A0%E6%B3%95%E6%88%90%E4%B8%BA%E9%87%8E%E5%85%BD%E7%9A%84%E6%88%91%E4%BB%AC)
2020-04-30 14:19:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30290917/>
{'cover': 'http://img.rr.tv/album/20181022/o_1540192622839.jpg',
 'data_type': 'movie',
 'id': 'rrmj_13089',
 'intro': '新垣结衣饰演30岁的OL深海晶，笑容满满，工作完美，是被大家喜欢的理想女性，但她其实只是为了周围人的眼光而努力和忍耐，对工作和恋爱都感到烦恼而疲惫。                                                                    \u3000\u3000'
          '松田龙平饰演的33岁精英会计师根元恒星，擅长处世，很受欢迎，但内心不相信任何人，冷眼旁观一切。                                                                    \u3000\u3000'
          '故事讲述了两个内心包裹着坚硬铠甲的人相遇后展开的恋爱喜剧。                                                                    \u3000\u3000'
          '“如果可以像野兽一样自由生活就好了。”',
 'is_new': False,
 'name': '无法成为野兽的我们',
 'platforms': '',
 'publishdate': '2018-10-10',
 'rate': 8.1,
 'sectionid': 'rrmj_747',
 'tags': ['爱情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30290917/'}
2020-04-30 14:19:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%88%91%E7%9A%84%E5%BB%BA%E7%AD%91%E5%B8%88%EF%BC%9A%E5%AF%BB%E7%88%B6%E4%B9%8B%E6%97%85> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:19:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/1305710/> (referer: https://www.douban.com/search?q=%E6%9D%8E%E5%B0%8F%E9%BE%99%EF%BC%9A%E5%8B%87%E5%A3%AB%E7%9A%84%E6%97%85%E7%A8%8B)
2020-04-30 14:19:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/1305710/>
{'cover': 'http://img.rr.tv/album/20190417/o_1555483819840.webp',
 'data_type': 'movie',
 'id': 'rrmj_14589',
 'intro': '李小龙的遗作《死亡游戏》于一九七八年公映，当中只有约十一分钟的片断有他亲自拍摄。一九九四年一次偶然的机会下，约翰。力图先生与李小龙遗孀李莲达女士在李氏爱达荷州的故居中，发现李小龙筹拍《死亡游戏》的武术设计手稿及剧本等，其中部分片段，并没有在公映的《死亡游戏》中出现。这个发现激发他致力寻找有关片段的决心。力图先生是唯一一位 '
          '获授权使用李小龙的文字手稿 '
          '、照片、及其其他影像资料的人。他于同年飞抵香港，与嘉禾高层商量寻找这些片段的在事宜。在李莲达女士和功夫片研究者龙比意先生的协助下，他终于从嘉禾片仓中找到《死亡游戏》弃片。之后他根据李小龙原来的剧本剪接成《死亡游戏之旅 '
          '》这部长九十分钟的记录片，当中包括约二十五分钟李小龙原为《死亡游戏》所拍，而从未曝光的珍贵片段。',
 'is_new': False,
 'name': '李小龙：勇士的旅程',
 'platforms': '',
 'publishdate': '2000-10-22',
 'rate': 9.1,
 'sectionid': 'rrmj_1399',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/1305710/'}
2020-04-30 14:19:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%8F%AD%E7%A7%98%EF%BC%9A%E9%87%91%E5%AD%97%E5%A1%94%E9%BB%91%E6%9A%97%E4%B9%8B%E8%B0%9C> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:19:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/6778688/> (referer: https://www.douban.com/search?q=%E7%9A%87%E5%90%8E%E4%B9%90%E9%98%9F%EF%BC%9A%E6%BC%94%E5%87%BA%E5%B2%81%E6%9C%88)
2020-04-30 14:19:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%89%B9%E6%9C%97%E6%99%AE%E5%92%8C%E5%B8%8C%E6%8B%89%E9%87%8C%E7%9A%84%E6%95%85%E4%BA%8B> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:19:48 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/6778688/>
{'cover': 'http://img.rr.tv/album/20190424/o_1556091795090.webp',
 'data_type': 'movie',
 'id': 'rrmj_14663',
 'intro': '',
 'is_new': False,
 'name': '皇后乐队：演出岁月',
 'platforms': '',
 'publishdate': '1991-08-11',
 'rate': 9.5,
 'sectionid': 'rrmj_1295',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/6778688/'}
2020-04-30 14:19:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%AF%9A%E9%82%80%E8%BE%A3%E5%A6%B9%EF%BC%9A%E7%BD%91%E7%BB%9C%E6%80%A7%E4%B8%8E%E7%88%B1> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:19:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/7053733/> (referer: https://www.douban.com/search?q=%E5%BD%93%E5%93%88%E5%88%A9%E7%A6%BB%E5%88%AB%E9%9C%8D%E6%A0%BC%E6%B2%83%E8%8C%A8)
2020-04-30 14:19:51 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/7053733/>
{'cover': 'http://img.rr.tv/album/20191010/o_1570688172889.webp',
 'data_type': 'movie',
 'id': 'rrmj_16109',
 'intro': '十年，八部电影，哈利波特陪伴我们走过了一段重要的时光，这一部纪录片是收录在《哈利·波特与死亡圣器（下）》蓝光版里的特辑，揭秘你所不知道的台前幕后。',
 'is_new': False,
 'name': '当哈利离别霍格沃茨',
 'platforms': '',
 'publishdate': '2018-02-23',
 'rate': 9.3,
 'sectionid': 'rrmj_1405',
 'tags': ['剧情', '纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/7053733/'}
2020-04-30 14:19:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E9%B2%8D%E5%8B%83%C2%B7%E6%8B%89%E6%89%8E%EF%BC%9A51%E5%8C%BA%E5%92%8C%E9%A3%9E%E7%A2%9F> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:19:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26743593/> (referer: https://www.douban.com/search?q=%E4%B8%BB%E5%8E%A8%E7%9A%84%E9%A4%90%E6%A1%8C%EF%BC%9A%E6%B3%95%E5%9B%BD%E7%AF%87)
2020-04-30 14:19:53 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26743593/>
{'cover': 'http://img.rr.tv/album/20180703/o_1530607686810.jpg',
 'data_type': 'movie',
 'id': 'rrmj_12561',
 'intro': 'Disponible depuis ce vendredi 2 septembre sur Netflix, Chef’s '
          'Table: France nous emmène dans les cuisines étoilées de quatre '
          'chefs français, à la rencontre d’hommes et de femmes qui '
          'réinventent la sacro-sainte gastronomie '
          'hexagonale.                                                                            \u3000\u3000'
          'L’innovation, sans renier la tradition. C’est tout le défi que se '
          'sont lancés Alain Passard de L’Arpege, Michel Troisgros de la '
          'Maison Troisgros, ...',
 'is_new': False,
 'name': '主厨的餐桌：法国篇',
 'platforms': '',
 'publishdate': '2016-09-02',
 'rate': 9.0,
 'sectionid': 'rrmj_1883',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26743593/'}
2020-04-30 14:19:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%B8%80%E7%BA%A7%E6%96%B9%E7%A8%8B%E5%BC%8F%EF%BC%9A%E7%96%BE%E9%80%9F%E4%BA%89%E8%83%9C> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:19:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30136766/> (referer: https://www.douban.com/search?q=%E6%8A%AB%E5%A4%B4%E5%A3%AB%E5%A6%82%E4%BD%95%E6%94%B9%E5%8F%98%E4%B8%96%E7%95%8C)
2020-04-30 14:19:55 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30136766/>
{'cover': 'http://img.rr.tv/album/20190424/o_1556088134886.jpg',
 'data_type': 'movie',
 'id': 'rrmj_14661',
 'intro': '回顾披头士（甲壳虫乐队）如何从直率聪颖的利物浦工人阶级男孩，成为史上无二的超级音乐团、青年革命的领军者；从商业化的巨大成功，当权者的加冕，转入非主流文化的探索，前卫音乐形式的实验，迷幻药与反战立场的触角，逐渐深化且複杂化的灵性追寻，使他们不仅象徵了六零年代的文化现象，更拓展塑造了世界的未来样貌。',
 'is_new': False,
 'name': '披头士如何改变世界',
 'platforms': '',
 'publishdate': '2017-10-23',
 'rate': 6.0,
 'sectionid': 'rrmj_1295',
 'tags': ['纪录片', '音乐', '历史'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30136766/'}
2020-04-30 14:19:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%9B%9E%E5%BF%86%E5%BD%95%EF%BC%9A%E5%BC%82%E5%BD%A2%E8%B5%B7%E6%BA%90%E6%95%85%E4%BA%8B> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:19:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/25662329/> (referer: https://www.douban.com/search?q=%E6%9E%84%E5%BB%BA%E3%80%8A%E7%96%AF%E7%8B%82%E5%8A%A8%E7%89%A9%E5%9F%8E%E3%80%8B)
2020-04-30 14:19:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/25662329/>
{'cover': 'http://img.rr.tv/album/20190524/o_1558684940022.webp',
 'data_type': 'movie',
 'id': 'rrmj_14904',
 'intro': '故事发生在一个所有哺乳类动物和谐共存的美好世界中，兔子朱迪（金妮弗·古德温 Ginnifer Goodwin '
          '配音）从小就梦想着能够成为一名惩恶扬善的刑警，凭借着智慧和努力，朱迪成功的从警校中毕业进入了疯狂动物城警察局，殊不知这里是大型肉食类动物的领地，作为第一只，也是唯一的小型食草类动物，朱迪会遇到怎样的故事呢？                                                                    \u3000\u3000'
          '近日里，城中接连发生动物失踪案件，就在全部警员都致力于调查案件真相之时，朱迪却被局长（伊德瑞斯·艾尔巴 Idris Elba '
          '配音）发配成为了一名无足轻重的交警。某日，正在执勤的兔子遇见了名为尼克（杰森·贝特曼 Jason Bateman '
          '配音）的狐狸，两人不打不相识，之后又误打误撞的接受了寻找失踪的水獭先生的任务，如果不能在两天之内找到水獭先生，朱迪就必须自愿离开警局。朱迪找到了尼克，两人联手揭露了一个隐藏在疯狂动物城之中的惊天秘密。',
 'is_new': False,
 'name': '构建《疯狂动物城》',
 'platforms': '',
 'publishdate': '2016-03-04',
 'rate': 8.8,
 'sectionid': 'rrmj_1405',
 'tags': ['喜剧', '动画', '冒险'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/25662329/'}
2020-04-30 14:20:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%9C%B0%E5%B9%B3%E7%BA%BF%E7%B3%BB%E5%88%97%EF%BC%9A%E8%B7%A8%E6%80%A7%E5%88%AB%E8%80%85> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:20:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26857694/> (referer: https://www.douban.com/search?q=%E5%9B%BD%E5%AE%9D%E9%93%B6%E8%A1%8C%EF%BC%9A%E5%B0%8F%E5%8F%AF%E5%85%A5%E7%8B%B1)
2020-04-30 14:20:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26857694/>
{'cover': 'http://img.rr.tv/cover/20200114/o_1578981632031.webp',
 'data_type': 'movie',
 'id': 'rrmj_17015',
 'intro': '纽约唐人街一家社区银行2015年被联邦检察官起诉，成为2008年美国金融危机后唯一一家被起诉的银行。这个故事拍成了一部纪录片。2008年美国金融危机有个关键词叫“大不能倒” '
          '(Too Big to Fail)，指的是因滥发房屋次级贷款导致危机的美国大金融机构太大而不能倒 '
          '闭。实际上危机过后没有一家大金融机构或个人对那次危机承担法律责任。                                                                            \u3000\u3000'
          '一部最近公映的由独立制片人制作的纪录片，记录了金融危机后联邦政府起诉的唯一一家银行——由华人移民创办的纽约唐人街社区银行——国宝银行，以及它的创办人孙启诚和他家人赢得官司的过程。相对于“大不能倒”，记录片取名“小须入狱” '
          '(Small Enough to '
          'Jail)。                                                                            \u3000\u3000'
          '2012年5月31日，总部在纽约唐人街的国宝银行连同两名贷款主管，被纽约曼哈顿地区检察官办公室起诉，罪名从伪造商业记录、民用贷款欺诈、严重盗窃、串谋等...',
 'is_new': False,
 'name': '国宝银行：小可入狱',
 'platforms': '',
 'publishdate': '2016-09-11',
 'rate': 8.5,
 'sectionid': 'rrmj_1657',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26857694/'}
2020-04-30 14:20:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%B0%B8%E4%B8%8D%E5%85%A5%E7%9D%A1%EF%BC%9A%E7%8C%9B%E9%AC%BC%E8%A1%97%E4%BC%A0%E5%A5%87> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:20:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/34794682/> (referer: https://www.douban.com/search?q=%E8%B4%A9%E5%8D%96%E3%80%8C%E7%88%B1%E3%80%8D%E7%9A%84%E7%94%B7%E5%AD%90%E4%BB%AC)
2020-04-30 14:20:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/34794682/>
{'cover': 'http://img.rr.tv/album/20190822/o_1566454549955.webp',
 'data_type': 'movie',
 'id': 'rrmj_15661',
 'intro': '舞台は、新宿・歌舞伎町にあるニュータイプのホストクラブ。ホストのイメージを覆すカジュアルな服装、会話重視の接客を目当てに、ＯＬや看護師、主婦たちが押し寄せる。「女の“承認欲求”を満たすサービスを提供するプロになれ」そんな言葉が飛びかうこのクラブで、「ネオ・ホスト」を目指して日々修行する若者たちに密着。「愛」を売る男と「愛」を買いに来る女のラブゲームから、今を生きる若者たちの“愛のかたち”を探る。                                                                    \u3000\u3000'
          '位于新宿歌舞伎町的新型牛郎俱乐部，推翻公关印象的休闲的服装，以会话重视的接待客人为目标，OL和护士，主妇们蜂拥而来。“成为提供满足女人‘认可欲望’的服务的专业人士”在这样的语言飞来飞去的俱乐部，以“新东道主”为目标每天修行的年轻人们紧贴在一起。从贩卖“爱”的男人和来买“爱”的女人的爱情游戏中，探寻活在当下的年轻人的“爱的形态”。',
 'is_new': False,
 'name': '贩卖「爱」的男子们',
 'platforms': '',
 'publishdate': '2019-04-08',
 'rate': 7.3,
 'sectionid': 'rrmj_1416',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/34794682/'}
2020-04-30 14:20:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%BF%9D%E7%BD%97%E6%95%99%E4%BD%A0%E5%81%9A%E9%9D%A2%E5%8C%85%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:20:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/3839227/> (referer: https://www.douban.com/search?q=%E7%89%B9%E6%96%AF%E6%8B%89%EF%BC%9A%E9%97%AA%E7%94%B5%E7%9A%84%E4%B8%BB%E4%BA%BA%20)
2020-04-30 14:20:07 [scrapy.core.scraper] ERROR: Error processing {'cover': 'https://img.rr.tv/video/20160318/o_1458270041976.jpg',
 'data_type': 'movie',
 'id': 'rrmj_1339',
 'intro': 'Nikola '
          'Tesla是塞尔维亚裔美国科学家，电气工程师和发明家，他的研究为现代电气和通信系统奠定了基础。尽管他的成绩卓着，但是世人对他还是知之甚少，，他拥有700项专利并且这一切来自于令人钦佩的各方面的造诣，包括交流电系统、无线电、特斯拉感应线圈变压器，无线传输，和荧光灯。1856年7月10日，Tesla在克罗埃西亚的Smiljan '
          '出生。（有的记载认为是7月9日或者是7月9或10日）他的父亲是一个传统的牧师和作家同时也是一位诗人；他的母亲是一个发明工具的家庭主妇，打蛋器就是她发明的，这些发明的收入用来补充日常的开销。还是一个在校生的时候，Tesla就能够快速的进行复杂计算，以致于他时常被指责是在作弊。为了进入奥地利格拉茨的技术大学和布拉格大学他受过工程师培训。自从1884年他们移民到美国之后，Tesla和Thomas '
          'Edison一起工作。然而...',
 'is_new': False,
 'name': '特斯拉：闪电的主人 ',
 'platforms': '',
 'publishdate': '',
 'rate': 9.0,
 'sectionid': 'rrmj_1399',
 'tags': ['纪录片', '传记', '历史'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/3839227/'}
Traceback (most recent call last):
  File "/usr/python37/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/python37/lib/python3.7/site-packages/scrapy/utils/defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/root/spider/scrapyspider/spiderV1/pipelines.py", line 262, in process_item
    timeStruct = time.strptime(publishdate, '%Y-%m-%d')
  File "/usr/python37/lib/python3.7/_strptime.py", line 571, in _strptime_time
    tt = _strptime(data_string, format)[0]
  File "/usr/python37/lib/python3.7/_strptime.py", line 359, in _strptime
    (data_string, format))
ValueError: time data '' does not match format '%Y-%m-%d'
2020-04-30 14:20:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%AE%9E%E4%B9%A0%E5%8C%BB%E7%94%9F%E6%A0%BC%E8%95%BE%20%E7%AC%AC%E5%8D%81%E5%85%AD%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:20:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30479900/> (referer: https://www.douban.com/search?q=%E6%88%91%E7%9A%84%E5%A4%A9%E6%89%8D%E5%A5%B3%E5%8F%8B%20%E7%BA%AA%E5%BD%95%E7%89%87)
2020-04-30 14:20:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E9%BB%91%E6%9A%97%E7%89%A9%E8%B4%A8%E4%B8%89%E9%83%A8%E6%9B%B2%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:20:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30479900/>
{'cover': 'http://img.rr.tv/cover/20200324/o_1585015507267.jpg',
 'data_type': 'movie',
 'id': 'rrmj_17335',
 'intro': '《我的天才女友》衍生幕后纪录片，提供了详实的独家拍摄花絮，以及剧版完整的诞生流程。',
 'is_new': False,
 'name': '我的天才女友 纪录片',
 'platforms': '',
 'publishdate': '2018-12-06',
 'rate': 8.8,
 'sectionid': 'rrmj_1405',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30479900/'}
2020-04-30 14:20:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26642149/> (referer: https://www.douban.com/search?q=%E6%80%A5%E8%AF%8A%E5%AE%A4%E7%9A%84%E6%95%85%E4%BA%8B%20%E7%AC%AC%E4%BA%8C%E5%AD%A3)
2020-04-30 14:20:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26642149/>
{'cover': 'http://img.rr.tv/cover/20200303/o_1583214219571.webp',
 'data_type': 'movie',
 'id': 'rrmj_17271',
 'intro': '最好的编剧写不出最真实的急诊室故事，                                                                    \u3000\u3000'
          '这里每天都上演着无数悲欢离合；                                                                    \u3000\u3000'
          '我们用九十八个摄像头全天候记录，                                                                    \u3000\u3000'
          '只为向您呈现最动人震撼的生命魅力。                                                                    \u3000\u3000'
          '10月22日 21：20 '
          '东方卫视                                                                    \u3000\u3000'
          '《急诊室故事》第二季 感动回归！',
 'is_new': False,
 'name': '急诊室的故事 第二季',
 'platforms': '',
 'publishdate': '2015-10-22',
 'rate': 9.2,
 'sectionid': 'rrmj_1646',
 'tags': ['真人秀'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26642149/'}
2020-04-30 14:20:13 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/756341493/> (referer: https://www.douban.com/search?q=%E6%95%A6%E7%85%8C%E8%8E%AB%E9%AB%98%E7%AA%9F%20%E7%BE%8E%E7%9A%84%E5%85%A8%E8%B2%8C)
2020-04-30 14:20:13 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/756341493/>: HTTP status code is not handled or not allowed
2020-04-30 14:20:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%87%AF%E7%91%9F%E7%90%B3%C2%B7%E8%B5%96%E6%81%A9%EF%BC%9A%E8%80%80%E7%9C%BC%E5%A6%82%E5%88%9D> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:20:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30337031/> (referer: https://www.douban.com/search?q=%E4%BA%9A%E5%BD%93%C2%B7%E6%A1%91%E5%BE%B7%E5%8B%92%EF%BC%9A100%25%E6%96%B0%E9%B2%9C)
2020-04-30 14:20:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30337031/>
{'cover': 'http://img.rr.tv/album/20190530/o_1559203568151.png',
 'data_type': 'movie',
 'id': 'rrmj_14966',
 'intro': '亚当·桑德勒带着他的喜剧重新回归，从喜剧俱乐部到音乐厅，再到地铁站....',
 'is_new': False,
 'name': '亚当·桑德勒：100%新鲜',
 'platforms': '',
 'publishdate': '2018-10-23',
 'rate': 8.2,
 'sectionid': 'rrmj_1421',
 'tags': ['喜剧'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30337031/'}
2020-04-30 14:20:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%B3%B0%E5%8B%92%C2%B7%E6%96%AF%E5%A8%81%E5%A4%AB%E7%89%B9%E6%97%A0%E7%95%8F%E4%B9%8B%E6%97%85> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:20:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/1441479/> (referer: https://www.douban.com/search?q=%E7%BA%A6%E7%BF%B0%C2%B7%E5%88%97%E4%BE%AC%E7%9A%84%E7%90%86%E6%83%B3%E4%B8%96%E7%95%8C)
2020-04-30 14:20:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/1441479/>
{'cover': 'http://img.rr.tv/album/20190424/o_1556087826089.webp',
 'data_type': 'movie',
 'id': 'rrmj_14660',
 'intro': '本部描写摇滚史上最伟大音乐家之一约翰·温斯顿·列侬的纪录片《约翰列侬的理想世界》，以超过240小时的电影及录影片段，及穿插其中的36首经典名曲，讲述着这位摇滚乐坛有史以来最富传奇色彩的灵魂人物。                                                                    \u3000\u3000'
          '影片收录了多段未被公开的私人视频片段，扑捉记录下列侬这位在音乐世界中狂放不羁才华横溢的天才，在生活中的多重侧面。这些精彩珍贵的视频镜头在36首传唱度极高的经典歌曲中，道出了列侬这位乐坛巨匠背后鲜为人知的故事。',
 'is_new': False,
 'name': '约翰·列侬的理想世界',
 'platforms': '',
 'publishdate': '1988-10-07',
 'rate': 9.0,
 'sectionid': 'rrmj_1295',
 'tags': ['纪录片', '音乐', '传记'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/1441479/'}
2020-04-30 14:20:19 [scrapy.extensions.logstats] INFO: Crawled 457 pages (at 45 pages/min), scraped 223 items (at 20 items/min)
2020-04-30 14:20:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%90%89%E5%A7%86%C2%B7%E5%8A%A0%E8%8F%B2%E6%A0%B9%EF%BC%9A%E5%AE%87%E5%AE%99%E5%85%88%E7%94%9F> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:20:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30488016/> (referer: https://www.douban.com/search?q=%E5%87%AF%E6%96%87%C2%B7%E5%93%88%E7%89%B9%EF%BC%9A%E4%B8%8D%E8%B4%9F%E8%B4%A3%E4%BB%BB)
2020-04-30 14:20:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30488016/>
{'cover': 'http://img.rr.tv/album/20190530/o_1559202016629.jpg',
 'data_type': 'movie',
 'id': 'rrmj_14960',
 'intro': 'Netflix定档了凯文·哈特全新喜剧特辑——《凯文·哈特：不负责任》，将于4月2日下午3点首播。在这部全新的喜剧特辑中，凯文·哈特将自己的短处转变为绝佳笑料，和观众从婚姻中所犯的错误，一路谈到亚斯本的惊险刺激经历。这个喜剧特辑录制的是之前在伦敦O2剧院的表演，现场吸引1.5万人观众。',
 'is_new': False,
 'name': '凯文·哈特：不负责任',
 'platforms': '',
 'publishdate': '2019-04-02',
 'rate': 8.0,
 'sectionid': 'rrmj_1421',
 'tags': ['喜剧'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30488016/'}
2020-04-30 14:20:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%93%88%E5%88%A9%C2%B7%E6%B3%A2%E7%89%B9%EF%BC%9A%E4%B8%80%E6%AE%B5%E9%AD%94%E6%B3%95%E5%8F%B2> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:20:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E9%98%BF%E9%87%8C%C2%B7%E6%B2%99%E8%8F%B2%E5%B0%94%EF%BC%9A%E5%8F%8C%E9%87%8D%E5%90%A6%E5%AE%9A> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:20:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/33426016/> (referer: https://www.douban.com/search?q=%E6%97%BA%E8%BE%BE%C2%B7%E5%A1%9E%E5%85%8B%E4%B8%9D%EF%BC%9A%E4%B8%8D%E6%AD%A3%E5%B8%B8)
2020-04-30 14:20:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/33426016/>
{'cover': 'http://img.rr.tv/album/20190606/o_1559811739445.png',
 'data_type': 'movie',
 'id': 'rrmj_15026',
 'intro': '女演员旺达·塞克丝曾荣获艾美奖提名并有 30 年的喜剧经验，她在自己的第一部 Netflix '
          '喜剧特辑《旺达·塞克丝：不正常》中对时事现状发表了机智诙谐而令人捧腹的评论。这部时长 1 '
          '小时的特辑讲述了这位喜剧人对目前政治和文化氛围的看法，她只能用“不正常”来形容！',
 'is_new': False,
 'name': '旺达·塞克丝：不正常',
 'platforms': '',
 'publishdate': '2019-05-21',
 'rate': 7.6,
 'sectionid': 'rrmj_1421',
 'tags': ['喜剧'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/33426016/'}
2020-04-30 14:20:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/1418954/> (referer: https://www.douban.com/search?q=%E6%88%91%E7%9A%84%E5%BB%BA%E7%AD%91%E5%B8%88%EF%BC%9A%E5%AF%BB%E7%88%B6%E4%B9%8B%E6%97%85)
2020-04-30 14:20:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/1418954/>
{'cover': 'http://img.rr.tv/album/20180708/o_1531040477919.jpg',
 'data_type': 'movie',
 'id': 'rrmj_12672',
 'intro': '本部纪录片讲述美国费城著名建筑师路易斯·I·康因，这位曾设计过众多著名建筑的伟大建筑师生前有关事业和家庭的故事。这是一部有关爱与艺术的影片，也是一部讲述背叛和原谅的故事。从宾夕法尼亚火车站的地下走廊到人潮汹涌的孟加拉首都达卡的国家议会大厦，在这些美轮美奂的不朽作品中，我们似乎看到了这位20世纪下半叶被很多建筑历史学家公认的最具影响力的天才惊人的创造力。然而在生活中，路易斯却是一个既神秘又矛盾的丈夫、父亲。路易斯有着三段不同的家庭生活，执导本片的导演纳撒尼尔·康恩正是路易斯的其中一个儿子。                                                                    \u3000\u3000'
          '由美国导演纳撒尼尔·康恩执导的人物传记纪录片《我的建筑师》，荣获2004年第76届奥斯卡金像奖最佳纪录长片提名等多项纪录片大奖。',
 'is_new': False,
 'name': '我的建筑师：寻父之旅',
 'platforms': '',
 'publishdate': '2004-02-17',
 'rate': 8.7,
 'sectionid': 'rrmj_1399',
 'tags': ['纪录片', '传记'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/1418954/'}
2020-04-30 14:20:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E9%A9%AC%E9%BE%99%C2%B7%E9%9F%A6%E6%81%A9%E6%96%AF%EF%BC%9A%E5%8D%8A%E9%86%92%E4%B8%8D%E9%86%92> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:20:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%9F%B3%E5%8E%9F%E9%87%8C%E7%BE%8E%E7%9A%84%E5%B8%8C%E8%85%8A%E6%9C%AC%E8%89%B2%E6%97%85%E8%A1%8C> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:20:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/20388191/> (referer: https://www.douban.com/search?q=%E5%8D%95%E5%90%91%E4%B9%90%E9%98%9F%EF%BC%9A%E8%BF%99%E5%B0%B1%E6%98%AF%E6%88%91%E4%BB%AC)
2020-04-30 14:20:28 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/20388191/>
{'cover': 'http://img.rr.tv/album/20190424/o_1556085542977.jpg',
 'data_type': 'movie',
 'id': 'rrmj_14656',
 'intro': '继贾斯汀-比伯、凯蒂-佩瑞之后，英国当红偶像团体“单向乐队”(One '
          'Direction)也将拥有自己的3D音乐会纪录片，索尼公司今天宣布这部名为《单向乐队》(One '
          'Direction)的3D纪录电影将于2013年8月30日上映，索尼旗下三星影业(TriStar Pictures)将负责发行。',
 'is_new': False,
 'name': '单向乐队：这就是我们',
 'platforms': '',
 'publishdate': '2013-08-20',
 'rate': 6.0,
 'sectionid': 'rrmj_1295',
 'tags': ['纪录片', '音乐'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/20388191/'}
2020-04-30 14:20:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%BB%8E%E6%9A%97%E5%88%B0%E6%98%8E%EF%BC%9A%E7%94%B5%E8%A7%86%E4%B8%8E%E5%BD%A9%E8%99%B9%E5%8F%B2> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:20:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/20515275/> (referer: https://www.douban.com/search?q=%E4%BA%BA%E4%BD%93%E5%A5%A5%E5%A6%99%E4%B9%8B%E7%BB%86%E8%83%9E%E7%9A%84%E6%9A%97%E6%88%98)
2020-04-30 14:20:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/20515275/>
{'cover': 'http://img.rr.tv/album/20190804/o_1564901324413.png',
 'data_type': 'movie',
 'id': 'rrmj_15527',
 'intro': '每时每刻，你的身体中正进行着一场大战。这场起源于几十亿年前的战斗现今仍然在我们每个的体内发生。这是关于病毒入侵的故事——细胞的生死之战。                                                                    \u3000\u3000'
          '这部影片从细胞的内部世界揭示了人体细胞系统的精细机制：从狂热的、扮演着针对进出细胞的每个物体的安全防御系统的细胞膜、贯穿细胞的输送物质颗粒的细胞架、以及保持整个细胞世界运转的线粒体，到保存着DNA的细胞核和成千上万种各自拥有不同的蛋白质的合成。而病毒正是旨在劫持这套系统以为其所用：制造更多的病毒。',
 'is_new': False,
 'name': '人体奥妙之细胞的暗战',
 'platforms': '',
 'publishdate': '2012-10-21',
 'rate': 9.3,
 'sectionid': 'rrmj_1693',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/20515275/'}
2020-04-30 14:20:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26909404/> (referer: https://www.douban.com/search?q=%E7%89%B9%E6%9C%97%E6%99%AE%E5%92%8C%E5%B8%8C%E6%8B%89%E9%87%8C%E7%9A%84%E6%95%85%E4%BA%8B)
2020-04-30 14:20:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26909404/>
{'cover': 'http://img.rr.tv/album/20190509/o_1557392658347.png',
 'data_type': 'movie',
 'id': 'rrmj_14795',
 'intro': '香港地区凤凰视野制作的记录美国大选中两位候选人——希拉里·罗德姆·克林顿、唐纳德·特朗普的精彩表现的纪录片。',
 'is_new': False,
 'name': '特朗普和希拉里的故事',
 'platforms': '',
 'publishdate': '2016-09-12',
 'rate': 6.0,
 'sectionid': 'rrmj_1420',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26909404/'}
2020-04-30 14:20:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%88%B1%E5%9B%A0%E6%96%AF%E5%9D%A6%E9%9A%BE%E8%A7%A3%E7%9A%84%E9%87%8F%E5%AD%90%E4%B9%8B%E8%B0%9C> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:20:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/4038207/> (referer: https://www.douban.com/search?q=%E6%B0%B8%E4%B8%8D%E5%85%A5%E7%9D%A1%EF%BC%9A%E7%8C%9B%E9%AC%BC%E8%A1%97%E4%BC%A0%E5%A5%87)
2020-04-30 14:20:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/4038207/>
{'cover': 'http://img.rr.tv/album/20190509/o_1557389585349.webp',
 'data_type': 'movie',
 'id': 'rrmj_14785',
 'intro': '本片是专门为影史最卖座恐怖电影系列制作的纪录片,本片将揭秘鬼王-弗兰迪的更多精彩幕后。                                                                            \u3000\u3000'
          'Explore the origins of everyones favorite hideously charred '
          'boogeyman, discover the secrets of the horror franchise that keeps '
          'coming back, and find out just what an impact Wes Cravens creation '
          'has had on the world of pop culture in this documentary narrated by '
          'original Nightmare on Elm Street star Heather Langencamp. In-depth '
          '...',
 'is_new': False,
 'name': '永不入睡：猛鬼街传奇',
 'platforms': '',
 'publishdate': '2018-02-23',
 'rate': 7.9,
 'sectionid': 'rrmj_1405',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/4038207/'}
2020-04-30 14:20:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%89%B9%E6%9C%97%E6%99%AE%E5%AE%B6%E6%97%8F%E4%BB%8E%E7%A7%BB%E6%B0%91%E5%88%B0%E6%80%BB%E7%BB%9F> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:20:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27029032/> (referer: https://www.douban.com/search?q=%E8%AF%9A%E9%82%80%E8%BE%A3%E5%A6%B9%EF%BC%9A%E7%BD%91%E7%BB%9C%E6%80%A7%E4%B8%8E%E7%88%B1)
2020-04-30 14:20:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/27029032/>
{'cover': 'http://img.rr.tv/album/20180709/o_1531113634546.jpg',
 'data_type': 'movie',
 'id': 'rrmj_12674',
 'intro': 'Porn has gone mainstream; the question is, can we handle it? This '
          'exploration of the intersection of sex and technology is told '
          'through the stories of the people whose lives are defined by the '
          'current explosion of internet porn-whether theyre creating it, '
          'consuming it, or both.',
 'is_new': False,
 'name': '诚邀辣妹：网络性与爱',
 'platforms': '',
 'publishdate': '2017-04-21',
 'rate': 7.9,
 'sectionid': 'rrmj_1416',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/27029032/'}
2020-04-30 14:20:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E9%92%B1%E4%BF%A1%E4%BC%8A%EF%BC%9A%E4%BA%9A%E6%B4%B2%E7%AC%91%E6%98%9F%E9%97%B9%E7%BE%8E%E5%9B%BD> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:20:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30326519/> (referer: https://www.douban.com/search?q=%E6%8F%AD%E7%A7%98%EF%BC%9A%E9%87%91%E5%AD%97%E5%A1%94%E9%BB%91%E6%9A%97%E4%B9%8B%E8%B0%9C)
2020-04-30 14:20:39 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30326519/>
{'cover': 'http://img.rr.tv/album/20190711/o_1562823862376.jpg',
 'data_type': 'movie',
 'id': 'rrmj_15302',
 'intro': '埃及吉萨大金字塔曾在几千年间都是世界最高的建筑，无论是在结构和工程上都无可匹敌，虽然其宝藏早已被盗，但它本身就是古埃及最辉煌的遗产，本片揭秘古埃及人如何建造吉萨大金字塔。',
 'is_new': False,
 'name': '揭秘：金字塔黑暗之谜',
 'platforms': '',
 'publishdate': '2016-07-12',
 'rate': 7.5,
 'sectionid': 'rrmj_1416',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30326519/'}
2020-04-30 14:20:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E9%98%BF%E5%87%A1%E8%BE%BE%EF%BC%9A%E5%88%9B%E5%BB%BA%E6%BD%98%E5%A4%9A%E6%8B%89%E4%B8%96%E7%95%8C> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:20:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27160622/> (referer: https://www.douban.com/search?q=%E5%9C%B0%E5%B9%B3%E7%BA%BF%E7%B3%BB%E5%88%97%EF%BC%9A%E8%B7%A8%E6%80%A7%E5%88%AB%E8%80%85)
2020-04-30 14:20:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/27160622/>
{'cover': 'http://img.rr.tv/album/20191015/o_1571121616274.webp',
 'data_type': 'movie',
 'id': 'rrmj_16162',
 'intro': '探索变性的真正意义，通过那些亲身经历过的人，探索跨性别者所经历的生理以及心理变化。',
 'is_new': False,
 'name': '地平线系列：跨性别者',
 'platforms': '',
 'publishdate': '2017-09-26',
 'rate': 8.4,
 'sectionid': 'rrmj_1431',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/27160622/'}
2020-04-30 14:20:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30391774/> (referer: https://www.douban.com/search?q=%E5%9B%9E%E5%BF%86%E5%BD%95%EF%BC%9A%E5%BC%82%E5%BD%A2%E8%B5%B7%E6%BA%90%E6%95%85%E4%BA%8B)
2020-04-30 14:20:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30391774/>
{'cover': 'http://img.rr.tv/cover/20200218/o_1582024057033.webp',
 'data_type': 'movie',
 'id': 'rrmj_17194',
 'intro': '2019年是经典科幻片《异形》上映40周年纪念。亚历山大·欧·菲利普倾心力作解密异形的源起。从最原始的构思和草图，以及丹·欧班农原初的29页剧本说起，探索佐杜洛夫斯基、寄生学、希腊与埃及神话、地下漫画的诸多影响。影片有着丰富的内容、深刻的探讨，是一场科幻电影迷不可错过的盛宴。',
 'is_new': False,
 'name': '回忆录：异形起源故事',
 'platforms': '',
 'publishdate': '2019-01-24',
 'rate': 7.8,
 'sectionid': 'rrmj_1405',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30391774/'}
2020-04-30 14:20:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%90%8E%E8%A1%97%E7%94%B7%E5%AD%A9%EF%BC%9A%E4%BA%8C%E5%8D%81%E5%B9%B4%E5%85%A8%E8%AE%B0%E5%BD%95> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:20:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30404237/> (referer: https://www.douban.com/search?q=%E9%B2%8D%E5%8B%83%C2%B7%E6%8B%89%E6%89%8E%EF%BC%9A51%E5%8C%BA%E5%92%8C%E9%A3%9E%E7%A2%9F)
2020-04-30 14:20:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30404237/>
{'cover': 'http://img.rr.tv/album/20190817/o_1566024003609.webp',
 'data_type': 'movie',
 'id': 'rrmj_15631',
 'intro': 'In 1989, physicist Bob Lazar broke the story of Area 51 and the US '
          'governments work on alien spacecrafts. He blew the whistle, shocked '
          'the world, then went silent - until now.',
 'is_new': False,
 'name': '鲍勃·拉扎：51区和飞碟',
 'platforms': '',
 'publishdate': '2018-12-08',
 'rate': 6.1,
 'sectionid': 'rrmj_1416',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30404237/'}
2020-04-30 14:20:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%88%B1%EF%BC%8C%E6%AD%BB%E4%BA%A1%E5%92%8C%E6%9C%BA%E5%99%A8%E4%BA%BA%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:20:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%88%91%E4%BB%AC%E5%9C%A8%E6%AE%A1%E4%BB%AA%E9%A6%86%E5%B7%A5%E4%BD%9C%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:20:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30465634/> (referer: https://www.douban.com/search?q=%E4%B8%80%E7%BA%A7%E6%96%B9%E7%A8%8B%E5%BC%8F%EF%BC%9A%E7%96%BE%E9%80%9F%E4%BA%89%E8%83%9C)
2020-04-30 14:20:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30465634/>
{'cover': 'http://img.rr.tv/album/20190313/o_1552464404122.webp',
 'data_type': 'movie',
 'id': 'rrmj_14301',
 'intro': '每一个竞争激烈的赛季，不论赛道内外，一级方程式赛车选手、领队主管还有车队老板都过着赛车般分秒必争的快节奏生活。 '
          '剧集不光展现瞬息万变的赛道竞速，记录可能发生的车祸和意外——「比赛就像是一次次心脏病发作」——也将跟随车手了解他们在大赛前后的艰苦训练，讲述他们与家人和车队之间的故事。',
 'is_new': False,
 'name': '一级方程式：疾速争胜',
 'platforms': '',
 'publishdate': '2019-03-08',
 'rate': 9.5,
 'sectionid': 'rrmj_1425',
 'tags': ['纪录片', '运动'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30465634/'}
2020-04-30 14:20:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%9D%BE%E5%9D%82%E6%A1%83%E6%9D%8E%20%E9%81%A5%E8%BF%9C%E7%9A%84%E4%B8%9D%E8%B7%AF%E4%B9%8B%E6%97%85> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:20:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/24695923/> (referer: https://www.douban.com/search?q=%E4%BF%9D%E7%BD%97%E6%95%99%E4%BD%A0%E5%81%9A%E9%9D%A2%E5%8C%85%20%E7%AC%AC%E4%B8%80%E5%AD%A3)
2020-04-30 14:20:51 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/24695923/>
{'cover': 'https://img.rr.tv/video/20160323/o_1458716675811.jpg',
 'data_type': 'movie',
 'id': 'rrmj_1418',
 'intro': '最美味的面包是哪里的面包？当然是自家烤箱里的！                                                                    \u3000\u3000'
          '面包烘焙专家保罗·霍利伍德，将手把手地教你烘焙新鲜酥脆又营养健康的面包。                                                                    \u3000\u3000'
          '并向你展示：面包不止是主食，还能做成美味佳肴.                                                                    \u3000\u3000'
          'Paul Hollywood presents a series in which he reveals the secrets of '
          'breads from all over the world and shows how a loaf can be '
          'transformed into delicious dishes for breakfast, lunch and dinner.',
 'is_new': False,
 'name': '保罗教你做面包 第一季',
 'platforms': '',
 'publishdate': '2013-03-18',
 'rate': 9.0,
 'sectionid': 'rrmj_1883',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/24695923/'}
2020-04-30 14:20:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%B8%B9%E5%B0%BC%E5%B0%94%C2%B7%E6%96%AF%E6%B4%9B%E6%96%AF%EF%BC%9A%E7%8E%B0%E5%9C%BA%E8%A1%A8%E6%BC%94> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:20:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26657521/> (referer: https://www.douban.com/search?q=%E9%BB%91%E6%9A%97%E7%89%A9%E8%B4%A8%E4%B8%89%E9%83%A8%E6%9B%B2%20%E7%AC%AC%E4%B8%80%E5%AD%A3)
2020-04-30 14:20:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26657521/>
{'cover': 'http://img.rr.tv/album/20191104/o_1572847103532.webp',
 'data_type': 'movie',
 'id': 'rrmj_16472',
 'intro': '故事发生在不同于现实的异世界中。在这个世界中，所有的人类均拥有被称为守护精灵的动物同伴，这些动物是人类灵魂的具象体现。女主角莱拉·贝拉奎亚成长于英国牛津的约旦学院。在她前往伦敦寻找失踪的朋友罗杰的过程中，莱拉发现一系列儿童失踪事件与神秘物质尘埃有所关联。随着故事展开，她还发现了涉及到阿斯瑞尔勋爵和玛莉莎·库尔特的危险秘密。',
 'is_new': False,
 'name': '黑暗物质三部曲 第一季',
 'platforms': '',
 'publishdate': '2019-11-03',
 'rate': 9.1,
 'sectionid': 'rrmj_1917',
 'tags': ['奇幻', '冒险'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26657521/'}
2020-04-30 14:20:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%87%AF%E8%92%82%C2%B7%E6%B4%BE%E7%91%9E%EF%BC%9A%E4%BD%A0%E4%BC%9A%E8%A7%81%E8%AF%81%E6%88%91%E5%90%97> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:20:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/28087153/> (referer: https://www.douban.com/search?q=%E5%AE%9E%E4%B9%A0%E5%8C%BB%E7%94%9F%E6%A0%BC%E8%95%BE%20%E7%AC%AC%E5%8D%81%E5%85%AD%E5%AD%A3)
2020-04-30 14:20:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/28087153/>
{'cover': 'http://img.rr.tv/album/20190927/o_1569555141018.webp',
 'data_type': 'movie',
 'id': 'rrmj_16001',
 'intro': 'ABC宣布续订《实习医生格蕾》第16季、第17季。',
 'is_new': False,
 'name': '实习医生格蕾 第十六季',
 'platforms': '',
 'publishdate': '2019-09-26',
 'rate': 8.7,
 'sectionid': 'rrmj_1646',
 'tags': ['剧情', '爱情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/28087153/'}
2020-04-30 14:20:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%8F%B2%E8%92%82%E5%A4%AB%C2%B7%E4%B9%94%E5%B8%83%E6%96%AF%EF%BC%9A%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%94%9F> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:20:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/5341979/> (referer: https://www.douban.com/search?q=%E6%B3%B0%E5%8B%92%C2%B7%E6%96%AF%E5%A8%81%E5%A4%AB%E7%89%B9%E6%97%A0%E7%95%8F%E4%B9%8B%E6%97%85)
2020-04-30 14:20:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/5341979/>
{'cover': 'http://img.rr.tv/album/20190426/o_1556276761102.jpg',
 'data_type': 'movie',
 'id': 'rrmj_14641',
 'intro': '本系列剧集讲述泰勒·斯威夫特的童年记事和她如果成为超级巨星以及《Fearless》这张专辑发行中的一些故事。详细讲述泰勒· '
          '斯威夫特如何从纳什维尔开始她的事业，是什么帮助她克服了童年的不安全感，让她走向成功并得到真正的幸福.片中她将带着大家去看她的大量个人照片和家庭电影.',
 'is_new': False,
 'name': '泰勒·斯威夫特无畏之旅',
 'platforms': '',
 'publishdate': '2010-10-24',
 'rate': 8.9,
 'sectionid': 'rrmj_1295',
 'tags': ['纪录片', '音乐'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/5341979/'}
2020-04-30 14:21:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/34430315/> (referer: https://www.douban.com/search?q=%E5%87%AF%E7%91%9F%E7%90%B3%C2%B7%E8%B5%96%E6%81%A9%EF%BC%9A%E8%80%80%E7%9C%BC%E5%A6%82%E5%88%9D)
2020-04-30 14:21:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/34430315/>
{'cover': 'http://img.rr.tv/album/20190822/o_1566463217617.png',
 'data_type': 'movie',
 'id': 'rrmj_15667',
 'intro': '喜劇演員凱瑟琳·萊恩剛結束巡迴演出，上台分享她的犀利觀察，暢談校園霸凌、復仇之軀及扶養一個非常時髦的孩子',
 'is_new': False,
 'name': '凯瑟琳·赖恩：耀眼如初',
 'platforms': '',
 'publishdate': '2019-07-01',
 'rate': 7.7,
 'sectionid': 'rrmj_1421',
 'tags': ['喜剧'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/34430315/'}
2020-04-30 14:21:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%B1%89%E7%BA%B3%C2%B7%E7%9B%96%E8%8C%A8%E6%AF%94%E5%91%8A%E5%88%AB%E7%A7%80%EF%BC%9A%E5%A8%9C%E5%A8%9C> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:21:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%9C%88%E7%90%83%E4%B8%8A%E7%9A%84%E5%A4%96%E6%98%9F%E4%BA%BA%3A%20%E7%9C%9F%E7%9B%B8%E6%8A%AB%E9%9C%B2> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:21:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%87%AF%E6%96%87%C2%B7%E5%93%88%E7%89%B9%EF%BC%9A%E6%88%91%E5%8F%AA%E8%B4%9F%E8%B4%A3%E6%AC%A2%E4%B9%90> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:21:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/10583060/> (referer: https://www.douban.com/search?q=%E5%90%89%E5%A7%86%C2%B7%E5%8A%A0%E8%8F%B2%E6%A0%B9%EF%BC%9A%E5%AE%87%E5%AE%99%E5%85%88%E7%94%9F)
2020-04-30 14:21:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/10583060/>
{'cover': 'http://img.rr.tv/album/20190530/o_1559203887114.webp',
 'data_type': 'movie',
 'id': 'rrmj_14969',
 'intro': '谐星吉姆·加菲根在华盛顿特区直播开秀。从迪斯尼乐园聊到鲸鱼超重，一切都逃不过他的独特吐槽。',
 'is_new': False,
 'name': '吉姆·加菲根：宇宙先生',
 'platforms': '',
 'publishdate': '2012-04-11',
 'rate': 8.1,
 'sectionid': 'rrmj_1421',
 'tags': ['喜剧', '舞台艺术'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/10583060/'}
2020-04-30 14:21:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%B8%A9%E6%96%AF%E9%A1%BF%C2%B7%E4%B8%98%E5%90%89%E5%B0%94%EF%BC%9A%E4%B8%96%E7%BA%AA%E5%B7%A8%E4%BA%BA> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:21:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27089823/> (referer: https://www.douban.com/search?q=%E9%98%BF%E9%87%8C%C2%B7%E6%B2%99%E8%8F%B2%E5%B0%94%EF%BC%9A%E5%8F%8C%E9%87%8D%E5%90%A6%E5%AE%9A)
2020-04-30 14:21:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/27089823/>
{'cover': 'http://img.rr.tv/album/20190612/o_1560323302037.webp',
 'data_type': 'movie',
 'id': 'rrmj_15068',
 'intro': 'Ari Shaffir: Double Negative: '
          'Children                                                                    \u3000\u3000'
          'Ari Shaffir: Double Negative: Adulthood',
 'is_new': False,
 'name': '阿里·沙菲尔：双重否定',
 'platforms': '',
 'publishdate': '2017-07-18',
 'rate': 7.5,
 'sectionid': 'rrmj_1421',
 'tags': ['喜剧'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/27089823/'}
2020-04-30 14:21:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27135416/> (referer: https://www.douban.com/search?q=%E5%93%88%E5%88%A9%C2%B7%E6%B3%A2%E7%89%B9%EF%BC%9A%E4%B8%80%E6%AE%B5%E9%AD%94%E6%B3%95%E5%8F%B2)
2020-04-30 14:21:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/27135416/>
{'cover': 'http://img.rr.tv/album/20191015/o_1571121984486.webp',
 'data_type': 'movie',
 'id': 'rrmj_16165',
 'intro': '20年前，J·K·罗琳所著的《哈利·波特与魔法石》第一次在全球读者中引起轰动。为了纪念此书出版20周年，BBC制作了这部全新的纪录片，追寻了哈利波特心中真实的魔法世界。                                                                    \u3000\u3000'
          '这部好玩又惊险的纪录片中满是现实世界的神话、信仰和传说，也正是这些引燃了J·K·罗琳的想象力和创造力。J·K·罗琳在片中还来到大英图书馆《哈利波特：魔法的历史》展览，为我们展现魔法世界背后的真实故事，把现实生活和她脑海中的魔法世界做了对比。从怪异有趣的曼德拉草到伊丽莎白隐形术，从商代甲骨文上的神秘字符再到寻找现实中的魔法石，本片将带你开启神秘的魔法世界之旅。                                                                    \u3000\u3000'
          '《哈利波特》的演员们，大卫·休里斯、伊文娜·林奇、米瑞安·玛格莱斯和马克·威廉姆斯等将在片中献声朗读，而本书的插画师吉姆·凯伊也将在片中现身。                                                                    \u3000\u3000'
          '本片帮白由艾美达·斯丹顿担当。',
 'is_new': False,
 'name': '哈利·波特：一段魔法史',
 'platforms': '',
 'publishdate': '2017-12-25',
 'rate': 7.8,
 'sectionid': 'rrmj_1405',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/27135416/'}
2020-04-30 14:21:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%BE%8E%E5%9B%BD%E5%A4%A7%E5%B8%88%E7%B3%BB%E5%88%97%E4%B9%8B%E4%BC%8D%E8%BF%AA%C2%B7%E8%89%BE%E4%BC%A6> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:21:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30156987/> (referer: https://www.douban.com/search?q=%E9%A9%AC%E9%BE%99%C2%B7%E9%9F%A6%E6%81%A9%E6%96%AF%EF%BC%9A%E5%8D%8A%E9%86%92%E4%B8%8D%E9%86%92)
2020-04-30 14:21:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30156987/>
{'cover': 'http://img.rr.tv/album/20190606/o_1559811143960.webp',
 'data_type': 'movie',
 'id': 'rrmj_15022',
 'intro': '',
 'is_new': False,
 'name': '马龙·韦恩斯：半醒不醒',
 'platforms': '',
 'publishdate': '2018-02-27',
 'rate': 7.9,
 'sectionid': 'rrmj_1421',
 'tags': ['喜剧'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30156987/'}
2020-04-30 14:21:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%B5%B0%E8%BF%9B%E6%AF%94%E5%B0%94%EF%BC%9A%E8%A7%A3%E7%A0%81%E6%AF%94%E5%B0%94%C2%B7%E7%9B%96%E8%8C%A8> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:21:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%BC%82%E4%B9%A1%E4%BA%BA%EF%BC%9A%E4%B8%8A%E6%B5%B7%E7%9A%84%E8%8A%A5%E5%B7%9D%E9%BE%99%E4%B9%8B%E4%BB%8B> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:21:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30391258/> (referer: https://www.douban.com/search?q=%E7%9F%B3%E5%8E%9F%E9%87%8C%E7%BE%8E%E7%9A%84%E5%B8%8C%E8%85%8A%E6%9C%AC%E8%89%B2%E6%97%85%E8%A1%8C)
2020-04-30 14:21:14 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30391258/>
{'cover': 'http://img.rr.tv/cover/20200221/o_1582251350767.jpg',
 'data_type': 'movie',
 'id': 'rrmj_17213',
 'intro': '石原里美的旅途从毕尔巴鄂开始在西班牙拍摄了四天。她从调味料店买到帽子店，从甜品店吃到高级法餐店，中间还穿插着她对人生对事业的看法。节目将于1月3日在富士电视台和关西电视台播出。',
 'is_new': False,
 'name': '石原里美的希腊本色旅行',
 'platforms': '',
 'publishdate': '2019-01-03',
 'rate': 8.5,
 'sectionid': 'rrmj_745',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30391258/'}
2020-04-30 14:21:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/4311892/> (referer: https://www.douban.com/search?q=%E9%98%BF%E5%87%A1%E8%BE%BE%EF%BC%9A%E5%88%9B%E5%BB%BA%E6%BD%98%E5%A4%9A%E6%8B%89%E4%B8%96%E7%95%8C)
2020-04-30 14:21:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/4311892/>
{'cover': 'http://img.rr.tv/album/20180705/o_1530755408820.png',
 'data_type': 'movie',
 'id': 'rrmj_12593',
 'intro': '官方2010年1月19日发布的《阿凡达》最新幕后特辑，片长22分钟 分辨率：1280 x '
          '720                                                                    \u3000\u3000'
          '文件大小：1.1G                                                                    \u3000\u3000'
          '片中导演James Cameron以及众多演职员亲身解说了潘多拉世界的创建过程, '
          '从环境地貌取景、动植物、纳威语、演员训练、表情和动作捕捉、虚拟摄像机、3D Fution到音效配乐等等，非常详尽！',
 'is_new': False,
 'name': '阿凡达：创建潘多拉世界',
 'platforms': '',
 'publishdate': '2010-02-07',
 'rate': 8.6,
 'sectionid': 'rrmj_1405',
 'tags': ['纪录片', '短片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/4311892/'}
2020-04-30 14:21:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%9D%83%E5%8A%9B%E7%9A%84%E6%B8%B8%E6%88%8F%EF%BC%9A%E6%9C%80%E5%90%8E%E7%9A%84%E5%AE%88%E5%A4%9C%E4%BA%BA> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:21:19 [scrapy.extensions.logstats] INFO: Crawled 506 pages (at 49 pages/min), scraped 247 items (at 24 items/min)
2020-04-30 14:21:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26966301/> (referer: https://www.douban.com/search?q=%E7%89%B9%E6%9C%97%E6%99%AE%E5%AE%B6%E6%97%8F%E4%BB%8E%E7%A7%BB%E6%B0%91%E5%88%B0%E6%80%BB%E7%BB%9F)
2020-04-30 14:21:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26966301/>
{'cover': 'http://img.rr.tv/album/20190904/o_1567576583157.png',
 'data_type': 'movie',
 'id': 'rrmj_15768',
 'intro': 'Documentary telling the remarkable story of Donald Trumps family '
          'history, an extraordinary immigration success story. What can we '
          'learn about the next President of the United States from his '
          'background?',
 'is_new': False,
 'name': '特朗普家族从移民到总统',
 'platforms': '',
 'publishdate': '2017-01-17',
 'rate': 6.4,
 'sectionid': 'rrmj_1420',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26966301/'}
2020-04-30 14:21:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%BA%86%E4%B8%8D%E8%B5%B7%E7%9A%84%E9%BA%A6%E7%91%9F%E5%B0%94%E5%A4%AB%E4%BA%BA%20%E7%AC%AC%E4%B8%89%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:21:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30438239/> (referer: https://www.douban.com/search?q=%E7%88%B1%E5%9B%A0%E6%96%AF%E5%9D%A6%E9%9A%BE%E8%A7%A3%E7%9A%84%E9%87%8F%E5%AD%90%E4%B9%8B%E8%B0%9C)
2020-04-30 14:21:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30438239/>
{'cover': 'http://img.rr.tv/album/20190328/o_1553761442353.jpg',
 'data_type': 'movie',
 'id': 'rrmj_14417',
 'intro': 'Quantum entanglement is poised to revolutionize technology from '
          'networks to code breaking–but first we need to know it’s real. Join '
          'physicists as they capture light from across the universe in a bid '
          'to prove Einstein’s “spooky action at a distance.”',
 'is_new': False,
 'name': '爱因斯坦难解的量子之谜',
 'platforms': '',
 'publishdate': '2019-01-09',
 'rate': 6.0,
 'sectionid': 'rrmj_1399',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30438239/'}
2020-04-30 14:21:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%B2%A1%E6%9C%89%E7%9C%9F%E7%9B%B8%E7%9A%84%E5%86%85%E5%BF%83%E7%A7%98%E5%AF%86%20%E7%AC%AC%E4%BA%8C%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:21:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/34909282/> (referer: https://www.douban.com/search?q=%E9%92%B1%E4%BF%A1%E4%BC%8A%EF%BC%9A%E4%BA%9A%E6%B4%B2%E7%AC%91%E6%98%9F%E9%97%B9%E7%BE%8E%E5%9B%BD)
2020-04-30 14:21:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/34909282/>
{'cover': 'http://img.rr.tv/cover/20200218/o_1582006066656.png',
 'data_type': 'movie',
 'id': 'rrmj_17190',
 'intro': '喜剧演员、《每日秀》记者、《摘金奇缘》演员钱信伊推出自己的首个 Netflix '
          '喜剧特辑《亚洲笑星闹美国》。钱信伊出生于马来西亚，在曼彻斯特、新罕布什尔、新加坡和澳大利亚长大，他大谈特谈自己迄今为止在美国的旅程。从评估消费主义的影响，到亚裔美国总统的办事效率有多高，钱在《钱信伊：亚洲笑星闹美国》中分享了他认为使美国变得强大的真正原因。《钱信伊：亚洲笑星闹美国》将于 '
          '2019 年 12 月 17 日在 Netflix 面向全球上线。',
 'is_new': False,
 'name': '钱信伊：亚洲笑星闹美国',
 'platforms': '',
 'publishdate': '2019-12-17',
 'rate': 7.9,
 'sectionid': 'rrmj_1421',
 'tags': ['喜剧'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/34909282/'}
2020-04-30 14:21:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%B4%A7%E6%80%A5%E6%8A%A5%E5%91%8A%20%E6%96%B0%E5%9E%8B%E5%86%A0%E7%8A%B6%E7%97%85%E6%AF%92%E8%82%BA%E7%82%8E> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:21:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/34950039/> (referer: https://www.douban.com/search?q=%E4%BB%8E%E6%9A%97%E5%88%B0%E6%98%8E%EF%BC%9A%E7%94%B5%E8%A7%86%E4%B8%8E%E5%BD%A9%E8%99%B9%E5%8F%B2)
2020-04-30 14:21:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/34950039/>
{'cover': 'http://img.rr.tv/cover/20200214/o_1581672858915.jpg',
 'data_type': 'movie',
 'id': 'rrmj_17160',
 'intro': '该系列由电影制作人Ryan White和Jessica '
          'Hargrave创作，收录了五集，内容是“电视作为一种影响美国人良知的重要媒介的重要性，以及LGBTQ运动如何塑造了电视”。                                                                    \u3000\u3000'
          '长达一小时的剧集将探讨主题，包括对同性恋者的厌恶和恐惧，LGBTQ角色的演变以及在电视行业中的流行。                                                                    \u3000\u3000'
          '据说将档案影片与“运动的主要参与者”结合在一起，由Janet Mock、 Margaret Cho、Asia Kate Dillon、 '
          'Neil Patrick Harris、 Lena Waithe等人讲述。此外还将包括对Ellen DeGeneres、Oprah '
          'Winfrey、Anderson '
          'Cooper等人的采访。                                                                    \u3000\u3000'
          '《Visible: Out on Television》定于2020年2月14日在Apple TV +上首播。',
 'is_new': False,
 'name': '从暗到明：电视与彩虹史',
 'platforms': '',
 'publishdate': '2020-02-14',
 'rate': 8.0,
 'sectionid': 'rrmj_1431',
 'tags': ['纪录片', '传记'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/34950039/'}
2020-04-30 14:21:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/25978132/> (referer: https://www.douban.com/search?q=%E5%90%8E%E8%A1%97%E7%94%B7%E5%AD%A9%EF%BC%9A%E4%BA%8C%E5%8D%81%E5%B9%B4%E5%85%A8%E8%AE%B0%E5%BD%95)
2020-04-30 14:21:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/25978132/>
{'cover': 'http://img.rr.tv/album/20190424/o_1556087229585.webp',
 'data_type': 'movie',
 'id': 'rrmj_14658',
 'intro': 'A behind-the-scenes look at the popular boy band, Backstreet Boys.',
 'is_new': False,
 'name': '后街男孩：二十年全记录',
 'platforms': '',
 'publishdate': '2015-01-30',
 'rate': 9.2,
 'sectionid': 'rrmj_1295',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/25978132/'}
2020-04-30 14:21:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=3%E5%B9%B4A%E7%8F%AD%20%E4%BB%8E%E7%8E%B0%E5%9C%A8%E8%B5%B7%E5%A4%A7%E5%AE%B6%E9%83%BD%E6%98%AF%E4%BA%BA%E8%B4%A8> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:21:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30424374/> (referer: https://www.douban.com/search?q=%E7%88%B1%EF%BC%8C%E6%AD%BB%E4%BA%A1%E5%92%8C%E6%9C%BA%E5%99%A8%E4%BA%BA%20%E7%AC%AC%E4%B8%80%E5%AD%A3)
2020-04-30 14:21:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30424374/>
{'cover': 'http://img.rr.tv/album/20190315/o_1552644778023.jpg',
 'data_type': 'movie',
 'id': 'rrmj_14314',
 'intro': '这部名为《爱，死亡和机器人》的动画短片合集由18部分组成，每部分时长5-15分钟。这些短片涵盖多种类型，包括科幻、奇幻、恐怖和喜剧；这些短片也将包含多种形式，包括传统2D和3DCGI短片。                                                                            \u3000\u3000'
          '18部短片导演列表：                                                                            \u3000\u3000'
          '1.桑尼的优势 Dave '
          'Wilson                                                                            \u3000\u3000'
          '2.三个机器人 Víctor Maldonado&Alfredo '
          'Torres                                                                            \u3000\u3000'
          '3.证人 Alberto '
          'Mielgo                                                                            \u3000\u3000'
          '4.机动装甲 Franck '
          'Balson                                                                            \u3000\u3000'
          '5.噬魂者 Owen '
          'Sullivan                                                                            \u3000\u3000'
          '6.当酸奶统治世界 Victor Maldonado & Alfredo '
          'Torres                                                                            \u3000\u3000'
          '7.裂缝以外 Leon Berlue,Dominique Boidin,Remi Kozyra,Maxime '
          'Luere                                                                            \u3000\u3000'
          '8.祝有好的收获 Oliver '
          'Thomas                                                                            \u3000\u3000'
          '9.垃圾场 Javier Recio Gracia...',
 'is_new': False,
 'name': '爱，死亡和机器人 第一季',
 'platforms': '',
 'publishdate': '2019-03-15',
 'rate': 9.1,
 'sectionid': 'rrmj_747',
 'tags': ['喜剧', '科幻', '动画', '恐怖', '奇幻'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30424374/'}
2020-04-30 14:21:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%9F%83%E8%8E%B1%E6%89%8E%C2%B7%E6%96%BD%E8%8E%B1%E8%BE%9B%E6%A0%BC%EF%BC%9A%E7%A1%AE%E8%AE%A4%E5%87%BB%E6%9D%80> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:21:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26794215/> (referer: https://www.douban.com/search?q=%E6%88%91%E4%BB%AC%E5%9C%A8%E6%AE%A1%E4%BB%AA%E9%A6%86%E5%B7%A5%E4%BD%9C%20%E7%AC%AC%E4%B8%80%E5%AD%A3)
2020-04-30 14:21:34 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26794215/>
{'cover': 'http://img.rr.tv/album/20190417/o_1555480782521.webp',
 'data_type': 'movie',
 'id': 'rrmj_14580',
 'intro': '讲述一群不同的人，他们其中一些人的共同点就是「同一天生日」，他们的生活故事以有趣的方式交叉在一起。                                                                            \u3000\u3000'
          'Mandy Moore扮演Rebecca, Jack可爱的妻子也是最好的朋友。搬到匹兹堡后生了三胞胎。Milo '
          'Ventimiglia饰演Jack。                                                                            \u3000\u3000'
          'Justin Har tley 扮演Kevin, '
          '一个英俊且当红的电视演员，有着异常无趣没有终期的单身生活。                                                                            \u3000\u3000'
          'Sterling '
          'Brown扮演Randall,衣着光鲜亮丽在纽约工作的顾家生意人。与老婆Beth                                                                            \u3000\u3000'
          '合作无间地养育着两个女儿。                                                                            \u3000\u3000'
          'Susan Kelechi Watson '
          '扮演Beth，Randall老婆                                                                            \u3000\u3000'
          'Ron Cephas Jones 扮演William, '
          'Randall的生父。在Randall一出生的时候就遗弃了他。                                                                            \u3000\u3000'
          'Chrissy Metz 扮演Kate, 跟很多女人一样烦恼着饮食和身材. ...',
 'is_new': False,
 'name': '我们在殡仪馆工作 第一季',
 'platforms': '',
 'publishdate': '2016-09-20',
 'rate': 7.1,
 'sectionid': 'rrmj_1416',
 'tags': ['剧情', '家庭'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26794215/'}
2020-04-30 14:21:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%A4%A7%E5%8D%AB%C2%B7%E9%B2%8D%E4%BC%8A%EF%BC%9A%E6%94%B9%E5%8F%98%E4%B8%96%E7%95%8C%E7%9A%84%E7%94%B7%E4%BA%BA> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:21:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27064214/> (referer: https://www.douban.com/search?q=%E6%9D%BE%E5%9D%82%E6%A1%83%E6%9D%8E%20%E9%81%A5%E8%BF%9C%E7%9A%84%E4%B8%9D%E8%B7%AF%E4%B9%8B%E6%97%85)
2020-04-30 14:21:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/27064214/>
{'cover': 'http://img.rr.tv/album/20190807/o_1565159684989.webp',
 'data_type': 'movie',
 'id': 'rrmj_15558',
 'intro': '東西世界を結ぶシルクロード。悠久の時が刻まれた険しい山々と茫漠たる砂浜、そして、オアシス都市の緑に、わずかな休息を見出す。そんな古の旅人の息吹を感じながら、西域の絶景と「史記」の英雄・張騫の足跡を松坂桃李が辿る。                                                                    \u3000\u3000'
          '最初に向かったのは西安。中国の歴代王朝の都として栄え、シルクロードを往った全ての人がこの街を目指し、再び旅立った。物語の始まりに相応しい悠久の古都。西安から李広そして張騫が歩んだであろう、道なき道を行く。そして、李広の生地またその墓所が残る天水へ。そこから、シルクロードの要衝として栄えた風光明媚な蘭州を経てタクラマカン砂漠へ！シルクロードが結ぶ東西の融合を実感しながら、過酷な道のりを行く。',
 'is_new': False,
 'name': '松坂桃李 遥远的丝路之旅',
 'platforms': '',
 'publishdate': '2017-06-04',
 'rate': 8.5,
 'sectionid': 'rrmj_1384',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/27064214/'}
2020-04-30 14:21:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/25850443/> (referer: https://www.douban.com/search?q=%E5%8F%B2%E8%92%82%E5%A4%AB%C2%B7%E4%B9%94%E5%B8%83%E6%96%AF%EF%BC%9A%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%94%9F)
2020-04-30 14:21:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/25850443/>
{'cover': 'http://img.rr.tv/album/20190723/o_1563866726131.jpg',
 'data_type': 'movie',
 'id': 'rrmj_15429',
 'intro': '影片将取材于沃特·艾萨克森撰写的乔布斯生前唯一授权的传记，本片将不同于传统传记电影，由三段故事组成。索尔金的剧本会聚焦乔布斯生前三件关键性产品的发布时刻——1984年第一台Mac电脑的问世、乔布斯离开苹果后创立的NeXT电脑公司和1998年苹果首次推出的iMac。',
 'is_new': False,
 'name': '史蒂夫·乔布斯：机器人生',
 'platforms': '',
 'publishdate': '2015-10-23',
 'rate': 7.6,
 'sectionid': 'rrmj_1399',
 'tags': ['剧情', '传记'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/25850443/'}
2020-04-30 14:21:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%A5%BF%E8%92%99%C2%B7%E9%98%BF%E5%A7%86%E6%96%AF%E7%89%B9%E5%B0%94%EF%BC%9A%E9%A1%BA%E5%85%B6%E8%87%AA%E7%84%B6> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:21:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26324631/> (referer: https://www.douban.com/search?q=%E6%9C%88%E7%90%83%E4%B8%8A%E7%9A%84%E5%A4%96%E6%98%9F%E4%BA%BA%3A%20%E7%9C%9F%E7%9B%B8%E6%8A%AB%E9%9C%B2)
2020-04-30 14:21:39 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26324631/>
{'cover': 'http://img.rr.tv/album/20190807/o_1565161030628.png',
 'data_type': 'movie',
 'id': 'rrmj_15565',
 'intro': '播放地址：-documentary-aliens-on-the-moon-revealing-the-truth/                                                                    \u3000\u3000'
          'Never-before-aired NASA footage presents evidence that the Moon is '
          'being used as a base.',
 'is_new': False,
 'name': '月球上的外星人: 真相披露',
 'platforms': '',
 'publishdate': '2014-07-20',
 'rate': 7.3,
 'sectionid': 'rrmj_1416',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26324631/'}
2020-04-30 14:21:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%BF%88%E5%85%8B%E5%B0%94%C2%B7%E6%9D%B0%E5%85%8B%E9%80%8A%EF%BC%9A%E5%81%B6%E5%83%8F%E7%9A%84%E4%B8%80%E7%94%9F> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:21:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/6851218/> (referer: https://www.douban.com/search?q=%E7%BE%8E%E5%9B%BD%E5%A4%A7%E5%B8%88%E7%B3%BB%E5%88%97%E4%B9%8B%E4%BC%8D%E8%BF%AA%C2%B7%E8%89%BE%E4%BC%A6)
2020-04-30 14:21:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%B5%81%E8%A1%8C%E7%97%85%EF%BC%9A%E5%A6%82%E4%BD%95%E9%A2%84%E9%98%B2%E6%B5%81%E6%84%9F%E5%A4%A7%E7%88%86%E5%8F%91> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:21:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/6851218/>
{'cover': 'http://img.rr.tv/cover/20190910/o_1568101269276.webp',
 'data_type': 'movie',
 'id': 'rrmj_15805',
 'intro': '一转眼，伍迪艾伦（Woody '
          'Allen）这个老头已经陪伴我们度过了数十个年头，从黑发到白发，从壮年到老年，我们作为观众，几乎可以说是在电影里目睹了伍迪艾伦的整个后半生。从最初的无厘头喜剧《傻瓜入狱记》到最新的爱情小品《爱在罗马》，伍迪艾伦在电影中完成了对人生和爱情的讨论和探究。                                                                    \u3000\u3000'
          '在自己的电影中，伍迪艾伦扮演过无数个让人啼笑皆非的角色，然而，在现实中，他究竟是个怎样的人，我们无从而知。同时，不时传出的花边新闻也让这个在影片里絮絮叨叨的男人的身影愈加的模糊起来。影片采访了这些年来和伍迪艾伦合作过的演员和导演们，通过他们的语言拼凑出了一个陌生但真实的伍迪艾伦。',
 'is_new': False,
 'name': '美国大师系列之伍迪·艾伦',
 'platforms': '',
 'publishdate': '2011-11-20',
 'rate': 8.7,
 'sectionid': 'rrmj_1405',
 'tags': ['纪录片', '传记'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/6851218/'}
2020-04-30 14:21:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27179258/> (referer: https://www.douban.com/search?q=%E5%87%AF%E8%92%82%C2%B7%E6%B4%BE%E7%91%9E%EF%BC%9A%E4%BD%A0%E4%BC%9A%E8%A7%81%E8%AF%81%E6%88%91%E5%90%97)
2020-04-30 14:21:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/27179258/>
{'cover': 'http://img.rr.tv/album/20190423/o_1556016409836.png',
 'data_type': 'movie',
 'id': 'rrmj_14642',
 'intro': '转自@KatyPerryMusic                                                                            \u3000\u3000'
          '【@KatyPerry 全新纪录片Will You Be My '
          'Witness?中英字幕首播！】                                                                            \u3000\u3000'
          'L【铁T字幕组】Katy Perry最新纪录片Will You '
          '...                                                                            \u3000\u3000'
          '新专辑Witness发行当天Katy '
          'Perry以及其团队进行一次“连续四天96小时全天无死角的直播”！直播中水果姐用中文“你好”向中国粉丝打了招呼，除此之外吃饭、睡觉、早起、做瑜伽、做造型、素颜、做饭、接受采访、接受心理治疗以及与好友聊天的样子，也全部真实且无剪辑无修饰的展现在你的眼前。这是她与团队的一次大胆尝试，因为没人能预测到未来四天里会发生什么。纪录片由YouTube '
          'Red原创电影出品，纪录片则展现的是水果姐这四天直播幕后的故事与心声，你会看到RuPaul, America Ferrera, '
          'Caitlyn Jenner, Anna Ke...',
 'is_new': False,
 'name': '凯蒂·派瑞：你会见证我吗',
 'platforms': '',
 'publishdate': '2017-10-04',
 'rate': 7.5,
 'sectionid': 'rrmj_1295',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/27179258/'}
2020-04-30 14:21:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E9%83%91%E8%82%AF%EF%BC%9A%E5%9B%A0%E4%B8%BA%E6%9C%89%E4%BD%A0%EF%BC%8C%E7%94%9F%E5%91%BD%E6%89%8D%E5%AE%8C%E6%95%B4> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:21:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%9C%A8%E9%87%91%E7%89%8C%E7%9A%84%E6%A0%B8%E5%BF%83%EF%BC%9A%E7%BE%8E%E5%9B%BD%E4%BD%93%E6%93%8D%E4%B8%91%E9%97%BB> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:21:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30253080/> (referer: https://www.douban.com/search?q=%E6%B1%89%E7%BA%B3%C2%B7%E7%9B%96%E8%8C%A8%E6%AF%94%E5%91%8A%E5%88%AB%E7%A7%80%EF%BC%9A%E5%A8%9C%E5%A8%9C)
2020-04-30 14:21:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30253080/>
{'cover': 'http://img.rr.tv/album/20190606/o_1559810838166.png',
 'data_type': 'movie',
 'id': 'rrmj_15020',
 'intro': '澳洲知名喜剧人汉纳·加斯比在悉尼歌剧院的告别演出……',
 'is_new': False,
 'name': '汉纳·盖茨比告别秀：娜娜',
 'platforms': '',
 'publishdate': '2018-06-19',
 'rate': 9.3,
 'sectionid': 'rrmj_1421',
 'tags': ['喜剧', '脱口秀'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30253080/'}
2020-04-30 14:21:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30312425/> (referer: https://www.douban.com/search?q=%E4%B8%B9%E5%B0%BC%E5%B0%94%C2%B7%E6%96%AF%E6%B4%9B%E6%96%AF%EF%BC%9A%E7%8E%B0%E5%9C%BA%E8%A1%A8%E6%BC%94)
2020-04-30 14:21:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30312425/>
{'cover': 'http://img.rr.tv/album/20190606/o_1559812447297.png',
 'data_type': 'movie',
 'id': 'rrmj_15028',
 'intro': 'The dark mind of Daniel Sloss is back, and hes ready to find the '
          'funny in some very taboo topics, from the deeply personal to the '
          'highly irreverent.',
 'is_new': False,
 'name': '丹尼尔·斯洛斯：现场表演',
 'platforms': '',
 'publishdate': '2018-09-11',
 'rate': 9.2,
 'sectionid': 'rrmj_1421',
 'tags': ['喜剧'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30312425/'}
2020-04-30 14:21:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%B8%80%E7%BA%A7%E6%96%B9%E7%A8%8B%E5%BC%8F%EF%BC%9A%E7%96%BE%E9%80%9F%E4%BA%89%E8%83%9C%20%E7%AC%AC%E4%BA%8C%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:21:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/21247938/> (referer: https://www.douban.com/search?q=%E5%87%AF%E6%96%87%C2%B7%E5%93%88%E7%89%B9%EF%BC%9A%E6%88%91%E5%8F%AA%E8%B4%9F%E8%B4%A3%E6%AC%A2%E4%B9%90)
2020-04-30 14:21:51 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/21247938/>
{'cover': 'http://img.rr.tv/album/20190530/o_1559200258442.webp',
 'data_type': 'movie',
 'id': 'rrmj_14940',
 'intro': 'Filmed at a sold-out performance at Madison Square Garden, comedian '
          'Kevin Hart delivers material from his 2012 "Let Me Explain" concert '
          'tour.',
 'is_new': False,
 'name': '凯文·哈特：我只负责欢乐',
 'platforms': '',
 'publishdate': '2013-07-03',
 'rate': 8.0,
 'sectionid': 'rrmj_1421',
 'tags': ['喜剧', '纪录片', '音乐'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/21247938/'}
2020-04-30 14:21:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%A4%A7%E5%8D%AB%C2%B7%E5%85%8B%E7%BD%97%E6%96%AF%EF%BC%9A%E8%AE%A9%E7%BE%8E%E5%9B%BD%E5%86%8D%E5%BA%A6%E4%BC%9F%E5%A4%A7> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:21:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/34807113/> (referer: https://www.douban.com/search?q=%E8%B5%B0%E8%BF%9B%E6%AF%94%E5%B0%94%EF%BC%9A%E8%A7%A3%E7%A0%81%E6%AF%94%E5%B0%94%C2%B7%E7%9B%96%E8%8C%A8)
2020-04-30 14:21:55 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/34807113/>
{'cover': 'http://img.rr.tv/album/20190923/o_1569221273336.webp',
 'data_type': 'movie',
 'id': 'rrmj_15932',
 'intro': '奥斯卡金像奖获奖导演戴维斯·古根海姆（《难以忽视的真相》《他叫我马拉拉》）带来新作《走进比尔：解码比尔·盖茨》。这部全新的三集纪录片探索了著名技术先驱、商业领袖和慈善家比尔·盖茨的思想和抱负。在辞去微软首席执行官职务之后，盖茨将时间和出色才智投入到解决一些世界上最持久的问题上，由此便开始了现代史上最伟大的职业生涯第二幕。该剧集深入并真实地描述了比尔·盖茨在人生历程中经历的成功和挫折，以前所未有的深度让我们了解了比尔·盖茨，他的乐观、好奇心和热情曾激发他对微软的初始愿景，现在也激励他为世界上一些最复杂的问题寻求解决方案。《走进比尔》记录了这些努力与个人时刻，采访了比尔和梅琳达·盖茨，以及他们的朋友、家人、慈善事业和商业上的合作伙伴，塑造了一个富于创新的真实的人物形象，在改变世界之后，他可能还将改变人们看待世界的方式。',
 'is_new': False,
 'name': '走进比尔：解码比尔·盖茨',
 'platforms': '',
 'publishdate': '2019-09-20',
 'rate': 9.1,
 'sectionid': 'rrmj_1399',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/34807113/'}
2020-04-30 14:21:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%A9%B9%E5%A7%86%E6%96%AF%C2%B7%E5%8D%A1%E6%A2%85%E9%9A%86%EF%BC%9A%E5%86%8D%E8%A7%81%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:21:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%88%88%E7%99%BB%C2%B7%E6%8B%89%E5%A7%86%E9%BD%90%EF%BC%9A%E7%BE%8E%E9%A3%9F%E7%A7%98%E5%A2%83%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:21:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/34835784/> (referer: https://www.douban.com/search?q=%E5%BC%82%E4%B9%A1%E4%BA%BA%EF%BC%9A%E4%B8%8A%E6%B5%B7%E7%9A%84%E8%8A%A5%E5%B7%9D%E9%BE%99%E4%B9%8B%E4%BB%8B)
2020-04-30 14:21:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/34835784/>
{'cover': 'http://img.rr.tv/cover/20200102/o_1577932821006.jpg',
 'data_type': 'movie',
 'id': 'rrmj_16939',
 'intro': '该剧根据芥川龙之介的《上海游记》改编。影片讲述100多年前，作为《大阪每日新闻》记者的芥川龙之介来到上海的所见所闻。',
 'is_new': False,
 'name': '异乡人：上海的芥川龙之介',
 'platforms': '',
 'publishdate': '2019-12-28',
 'rate': 8.6,
 'sectionid': 'rrmj_745',
 'tags': ['剧情', '传记'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/34835784/'}
2020-04-30 14:21:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%8B%A8%E5%BC%80%E8%BF%B7%E9%9B%BE%EF%BC%9A%E5%B1%B1%E8%BE%BE%E5%9F%BA%E6%95%99%E4%B8%8E%E4%BF%A1%E4%BB%B0%E5%9B%9A%E7%AC%BC> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:22:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/33385724/> (referer: https://www.douban.com/search?q=%E6%9D%83%E5%8A%9B%E7%9A%84%E6%B8%B8%E6%88%8F%EF%BC%9A%E6%9C%80%E5%90%8E%E7%9A%84%E5%AE%88%E5%A4%9C%E4%BA%BA)
2020-04-30 14:22:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/33385724/>
{'cover': 'http://img.rr.tv/album/20190527/o_1558938818230.webp',
 'data_type': 'movie',
 'id': 'rrmj_14924',
 'intro': 'HBO将推出《权力的游戏》纪录片[权力的游戏：最后的守夜人](Game of Thrones: The Last '
          'Watch，暂译)，杰尼·芬利(Jeanie '
          'Finlay)执导。影片将跟随剧组与演员，见证《权力的游戏》最终季的拍摄过程。该纪录片时长2小时，5月19日登陆HBO。',
 'is_new': False,
 'name': '权力的游戏：最后的守夜人',
 'platforms': '',
 'publishdate': '2019-05-26',
 'rate': 8.2,
 'sectionid': 'rrmj_1405',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/33385724/'}
2020-04-30 14:22:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26855732/> (referer: https://www.douban.com/search?q=%E6%B2%A1%E6%9C%89%E7%9C%9F%E7%9B%B8%E7%9A%84%E5%86%85%E5%BF%83%E7%A7%98%E5%AF%86%20%E7%AC%AC%E4%BA%8C%E5%AD%A3)
2020-04-30 14:22:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%AF%94%E5%85%8B%E6%8B%89%E5%A7%86%EF%BC%9A%E7%91%9C%E4%BC%BD%E3%80%81%E5%A4%A7%E5%B8%88%E3%80%81%E6%80%A7%E4%BE%B5%E7%8A%AF> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:22:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26855732/>
{'cover': 'http://img.rr.tv/album/20181218/o_1545148137907.png',
 'data_type': 'movie',
 'id': 'rrmj_13796',
 'intro': 'คงไม่ใช่อกอีแป้นจะแตกหรอกเจ้าค่า '
          'แต่คงเป็นอกอีเก้งจะแตกหล่ะคราวเนี้ยยยย '
          'เมื่อคู่จิ้นขวัญใจเก้งบี้-ธรรศภาคย์ กับพิช-วิชญ์วิสิฐ '
          'คัมแบ็คมาสปาร์คไฟรักเก่าให้แฟนละครได้ฟินลืมกันอีกครั้ง ในโปรเจ็ค '
          '‘สงครามแย่งผู้ To Be Continued ตอน ความลับของหัวใจที่ไม่มีจริง’ '
          'ช่อง GMM 25 ไม่เจอกันนานก็ต้องมีรื้อฟื้นความหลัง '
          'ทบทวนความทรงจำกับรังรักเก่ากันซะหน่อย อู๊ยๆ '
          'แค่คิดก็ฟินแล้วค่า                                                                            \u3000\u3000'
          'เป็นฉากที่บอส...',
 'is_new': False,
 'name': '没有真相的内心秘密 第二季',
 'platforms': '',
 'publishdate': '2016-08-17',
 'rate': 5.5,
 'sectionid': 'rrmj_989',
 'tags': ['剧情', '爱情', '同性'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26855732/'}
2020-04-30 14:22:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%9D%B0%E7%91%9E%C2%B7%E5%AE%8B%E9%A3%9E%EF%BC%9A%E8%80%81%E5%AD%90%E6%9C%80%E5%90%8E%E8%B7%9F%E4%BD%A0%E8%AF%B4%E4%B8%80%E6%AC%A1> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:22:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30227139/> (referer: https://www.douban.com/search?q=%E4%BA%86%E4%B8%8D%E8%B5%B7%E7%9A%84%E9%BA%A6%E7%91%9F%E5%B0%94%E5%A4%AB%E4%BA%BA%20%E7%AC%AC%E4%B8%89%E5%AD%A3)
2020-04-30 14:22:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30227139/>
{'cover': 'http://img.rr.tv/album/20191114/o_1573715335531.jpg',
 'data_type': 'movie',
 'id': 'rrmj_16588',
 'intro': 'Midge和Susie发现与Shy一起旅游的生活很迷人，但却令人谦逊，他们学到了他们永远不会忘记的演艺事业的教训。 '
          'Joel在追求自己的梦想的同时努力支持Midge。 Abe接受了新的使命，Rose也知道她有自己的才能。',
 'is_new': False,
 'name': '了不起的麦瑟尔夫人 第三季',
 'platforms': '',
 'publishdate': '2019-12-06',
 'rate': 8.6,
 'sectionid': 'rrmj_742',
 'tags': ['剧情', '喜剧'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30227139/'}
2020-04-30 14:22:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/34969009/> (referer: https://www.douban.com/search?q=%E7%B4%A7%E6%80%A5%E6%8A%A5%E5%91%8A%20%E6%96%B0%E5%9E%8B%E5%86%A0%E7%8A%B6%E7%97%85%E6%AF%92%E8%82%BA%E7%82%8E)
2020-04-30 14:22:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/34969009/>
{'cover': 'http://img.rr.tv/cover/20200218/o_1582006371971.png',
 'data_type': 'movie',
 'id': 'rrmj_17191',
 'intro': '上个月9日，WHO（世界卫生组织）公布了在中国武汉市蔓延的肺炎是由新型日冕病毒引起的。之后，中国感染新型病毒的患者不断增加，人数超过2万4000人，死亡人数达到490人。WHO宣布“国际上令人担忧的公共卫生上的紧急事态”，决定派遣由专家组成的调查小组到中国。在国内被确认感染者达到23人的日本，厚生劳动省也通知全国的自治体扩大病毒检查的对象等，加强了警戒(2月5日6点现在)。新型病毒认定1个月。在节目中，一边更新关于新型病毒肺炎的最新信息，一边直播一边面对观众的“不安”“疑问”。在各地的报道和最新的研究成果，与WHO本部的转播交织的同时，凝视着全球化了的世界和未知的病毒的战斗的新的局面。',
 'is_new': False,
 'name': '紧急报告 新型冠状病毒肺炎',
 'platforms': '',
 'publishdate': '2020-02-09',
 'rate': 7.6,
 'sectionid': 'rrmj_1693',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/34969009/'}
2020-04-30 14:22:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%B8%AD%E5%9B%BD%E5%8A%B3%E5%B7%A5%E5%85%B5%E5%9B%A2%EF%BC%9A%E8%8B%B1%E5%9B%BD%E8%A2%AB%E9%81%97%E5%BF%98%E7%9A%84%E5%86%9B%E9%98%9F> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:22:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30377729/> (referer: https://www.douban.com/search?q=3%E5%B9%B4A%E7%8F%AD%20%E4%BB%8E%E7%8E%B0%E5%9C%A8%E8%B5%B7%E5%A4%A7%E5%AE%B6%E9%83%BD%E6%98%AF%E4%BA%BA%E8%B4%A8)
2020-04-30 14:22:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30377729/>
{'cover': 'http://img.rr.tv/album/20190110/o_1547084198644.jpg',
 'data_type': 'movie',
 'id': 'rrmj_13801',
 'intro': '讲述了控制了毕业10天的高中3年级29名学生的美术老师柊一颯的最后一课的校园推理剧。菅田将晖饰演柊一颯，永野芽郁饰演因某件事而封闭内心的女学生茅野樱。',
 'is_new': False,
 'name': '3年A班 从现在起大家都是人质',
 'platforms': '',
 'publishdate': '2019-01-06',
 'rate': 8.4,
 'sectionid': 'rrmj_747',
 'tags': ['剧情', '悬疑'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30377729/'}
2020-04-30 14:22:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%BD%B1%E5%AD%90%E5%8F%B8%E4%BB%A4%EF%BC%9A%E4%BC%8A%E6%9C%97%E5%86%9B%E4%BA%8B%E5%A4%A7%E5%B8%88%E8%8B%8F%E8%8E%B1%E6%9B%BC%E5%B0%BC> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:22:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%B9%B3%E5%85%8B%E5%BC%97%E6%B4%9B%E4%BC%8A%E5%BE%B7%E9%9F%B3%E4%B9%90%E4%BC%A0%E8%AE%B0.%E6%9C%88%E4%B9%8B%E9%98%B4%E6%9A%97%E9%9D%A2> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:22:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/6309377/> (referer: https://www.douban.com/search?q=%E8%A5%BF%E8%92%99%C2%B7%E9%98%BF%E5%A7%86%E6%96%AF%E7%89%B9%E5%B0%94%EF%BC%9A%E9%A1%BA%E5%85%B6%E8%87%AA%E7%84%B6)
2020-04-30 14:22:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/6309377/>
{'cover': 'http://img.rr.tv/album/20190530/o_1559202754743.webp',
 'data_type': 'movie',
 'id': 'rrmj_14963',
 'intro': '',
 'is_new': False,
 'name': '西蒙·阿姆斯特尔：顺其自然',
 'platforms': '',
 'publishdate': '2018-02-23',
 'rate': 9.4,
 'sectionid': 'rrmj_1421',
 'tags': ['喜剧'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/6309377/'}
2020-04-30 14:22:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%8C%AE%E7%BB%99%E5%A5%A5%E9%80%8A%E7%9A%84%E6%9C%80%E7%BB%88%E5%89%AA%E8%BE%91%EF%BC%9A40%E5%B9%B4%E5%88%B6%E4%BD%9C%E5%8E%86%E7%A8%8B> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:22:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/6961193/> (referer: https://www.douban.com/search?q=%E8%BF%88%E5%85%8B%E5%B0%94%C2%B7%E6%9D%B0%E5%85%8B%E9%80%8A%EF%BC%9A%E5%81%B6%E5%83%8F%E7%9A%84%E4%B8%80%E7%94%9F)
2020-04-30 14:22:14 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/6961193/>
{'cover': 'http://img.rr.tv/album/20190731/o_1564555588521.webp',
 'data_type': 'movie',
 'id': 'rrmj_15502',
 'intro': '这部纪录片将呈现迈克尔最亲密朋友和家人口中的故事，铺开公开和私人的回忆，并将首度公开部分前所未见的家庭照片和演出视频。这部电影也将关注迈克尔人生中最困难的时期，包括因为娈童案而被捕和接受审判，以及2005年的审判是怎样影响了他和家人的生活。                                                                    \u3000\u3000                                                                    \u3000\u3000'
          '这部由迈克尔的挚友执导的影片，得到了杰克逊家族的认可，首度披露了众多珍贵私藏影像，从“杰克逊五兄弟”时代，到不断受丑闻困扰的流行巨星，迈克尔到底是神还是人......',
 'is_new': False,
 'name': '迈克尔·杰克逊：偶像的一生',
 'platforms': '',
 'publishdate': '2011-11-02',
 'rate': 8.6,
 'sectionid': 'rrmj_1399',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/6961193/'}
2020-04-30 14:22:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%BA%A6%E7%BF%B0%C2%B7%E6%9C%A8%E5%85%B0%E5%B0%BC%EF%BC%9A%E6%97%A0%E7%BA%BF%E7%94%B5%E5%9F%8E%E7%9A%84%E4%BF%8A%E5%B0%8F%E4%BC%99%E5%84%BF> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:22:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26881168/> (referer: https://www.douban.com/search?q=%E5%9F%83%E8%8E%B1%E6%89%8E%C2%B7%E6%96%BD%E8%8E%B1%E8%BE%9B%E6%A0%BC%EF%BC%9A%E7%A1%AE%E8%AE%A4%E5%87%BB%E6%9D%80)
2020-04-30 14:22:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26881168/>
{'cover': 'http://img.rr.tv/album/20190530/o_1559201905613.png',
 'data_type': 'movie',
 'id': 'rrmj_14959',
 'intro': '',
 'is_new': False,
 'name': '埃莱扎·施莱辛格：确认击杀',
 'platforms': '',
 'publishdate': '2016-09-23',
 'rate': 6.7,
 'sectionid': 'rrmj_1421',
 'tags': ['喜剧'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26881168/'}
2020-04-30 14:22:19 [scrapy.extensions.logstats] INFO: Crawled 554 pages (at 48 pages/min), scraped 272 items (at 25 items/min)
2020-04-30 14:22:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27055998/> (referer: https://www.douban.com/search?q=%E5%A4%A7%E5%8D%AB%C2%B7%E9%B2%8D%E4%BC%8A%EF%BC%9A%E6%94%B9%E5%8F%98%E4%B8%96%E7%95%8C%E7%9A%84%E7%94%B7%E4%BA%BA)
2020-04-30 14:22:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/27055998/>
{'cover': 'http://img.rr.tv/album/20190410/o_1554876674118.jpg',
 'data_type': 'movie',
 'id': 'rrmj_14506',
 'intro': 'BOWIE is a fascinating exploration of the life of a rock and roll '
          'icon who inspired a whole generation to become heroes.',
 'is_new': False,
 'name': '大卫·鲍伊：改变世界的男人',
 'platforms': '',
 'publishdate': '2018-02-23',
 'rate': 6.8,
 'sectionid': 'rrmj_1399',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/27055998/'}
2020-04-30 14:22:19 [scrapy.core.engine] DEBUG: Crawled (200) <POST https://api.rr.tv/v3plus/index/channel> (referer: None)
2020-04-30 14:22:19 [rrmj] DEBUG: Read 1 requests from 'rrmj:spider:strat_urls'
2020-04-30 14:22:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1912',
 'sectionImg': '',
 'sectionName': '看剧鉴渣男手撕不心软'}
2020-04-30 14:22:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1917',
 'sectionImg': '',
 'sectionName': '抖音爆火洗脑剧'}
2020-04-30 14:22:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1726',
 'sectionImg': '',
 'sectionName': '这些剧大家都在追'}
2020-04-30 14:22:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1904',
 'sectionImg': '',
 'sectionName': '台剧新来袭！！'}
2020-04-30 14:22:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1646',
 'sectionImg': '',
 'sectionName': '急诊室的人间冷暖'}
2020-04-30 14:22:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1903',
 'sectionImg': '',
 'sectionName': '恶魔在人间'}
2020-04-30 14:22:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1693',
 'sectionImg': '',
 'sectionName': '病毒藏在每个角落'}
2020-04-30 14:22:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_742',
 'sectionImg': '',
 'sectionName': '热剧回归！'}
2020-04-30 14:22:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1871',
 'sectionImg': '',
 'sectionName': '金融危机，股价暴跌！'}
2020-04-30 14:22:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1883',
 'sectionImg': '',
 'sectionName': '吃货必备！这些纪录片很“下饭”'}
2020-04-30 14:22:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1399',
 'sectionImg': '',
 'sectionName': '他改变了世界'}
2020-04-30 14:22:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1729',
 'sectionImg': '',
 'sectionName': '【电影】获奖佳片集结'}
2020-04-30 14:22:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1405',
 'sectionImg': '',
 'sectionName': '幕后更精彩'}
2020-04-30 14:22:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_745',
 'sectionImg': '',
 'sectionName': '本周新剧'}
2020-04-30 14:22:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1431',
 'sectionImg': '',
 'sectionName': 'LGBT人生纪实 '}
2020-04-30 14:22:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1416',
 'sectionImg': '',
 'sectionName': '怪奇世界物语'}
2020-04-30 14:22:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1421',
 'sectionImg': '',
 'sectionName': '笑到飞起的脱口秀'}
2020-04-30 14:22:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1295',
 'sectionImg': '',
 'sectionName': '巨星的诞生'}
2020-04-30 14:22:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1425',
 'sectionImg': '',
 'sectionName': '大家都在看'}
2020-04-30 14:22:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1657',
 'sectionImg': '',
 'sectionName': '奥斯卡最佳纪录片'}
2020-04-30 14:22:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1420',
 'sectionImg': '',
 'sectionName': '特朗普的「美国梦」'}
2020-04-30 14:22:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1005',
 'sectionImg': '',
 'sectionName': '德国之声特辑'}
2020-04-30 14:22:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1384',
 'sectionImg': '',
 'sectionName': '歪果仁看中国'}
2020-04-30 14:22:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1244',
 'sectionImg': '',
 'sectionName': '我不喜欢这世界只喜欢你'}
2020-04-30 14:22:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_989',
 'sectionImg': '',
 'sectionName': '腐眼看人基'}
2020-04-30 14:22:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_747',
 'sectionImg': '',
 'sectionName': '完结力推'}
2020-04-30 14:22:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30430701/> (referer: https://www.douban.com/search?q=%E9%83%91%E8%82%AF%EF%BC%9A%E5%9B%A0%E4%B8%BA%E6%9C%89%E4%BD%A0%EF%BC%8C%E7%94%9F%E5%91%BD%E6%89%8D%E5%AE%8C%E6%95%B4)
2020-04-30 14:22:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%87%B4%E5%91%BD%E5%A5%B3%E4%BA%BA> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:22:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30430701/>
{'cover': 'http://img.rr.tv/album/20190530/o_1559203408710.jpg',
 'data_type': 'movie',
 'id': 'rrmj_14965',
 'intro': 'Stand-up performance of comedian Ken Jeong recorded live at '
          'Pasadena, California.',
 'is_new': False,
 'name': '郑肯：因为有你，生命才完整',
 'platforms': '',
 'publishdate': '2019-02-14',
 'rate': 5.8,
 'sectionid': 'rrmj_1421',
 'tags': ['喜剧', '脱口秀'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30430701/'}
2020-04-30 14:22:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%BB%9D%E4%B8%8D%E6%8A%98%E4%B8%AD%EF%BC%9A%E7%BB%9D%E5%91%BD%E6%AF%92%E5%B8%88%E6%9C%80%E7%BB%88%E5%AD%A3%E5%88%B6%E4%BD%9C%E8%AE%B0%E5%BD%95> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:22:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/34935806/> (referer: https://www.douban.com/search?q=%E6%B5%81%E8%A1%8C%E7%97%85%EF%BC%9A%E5%A6%82%E4%BD%95%E9%A2%84%E9%98%B2%E6%B5%81%E6%84%9F%E5%A4%A7%E7%88%86%E5%8F%91)
2020-04-30 14:22:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/34935806/>
{'cover': 'http://img.rr.tv/cover/20200125/o_1579919034093.png',
 'data_type': 'movie',
 'id': 'rrmj_17080',
 'intro': '跟随这部系列纪录片认识那些奋战在抗击流感第一线的英雄们，了解他们为阻止下一场全球疫情的爆发所做出的努力。',
 'is_new': False,
 'name': '流行病：如何预防流感大爆发',
 'platforms': '',
 'publishdate': '2020-01-22',
 'rate': 8.4,
 'sectionid': 'rrmj_1693',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/34935806/'}
2020-04-30 14:22:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/33218414/> (referer: https://www.douban.com/search?q=%E5%9C%A8%E9%87%91%E7%89%8C%E7%9A%84%E6%A0%B8%E5%BF%83%EF%BC%9A%E7%BE%8E%E5%9B%BD%E4%BD%93%E6%93%8D%E4%B8%91%E9%97%BB)
2020-04-30 14:22:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/33218414/>
{'cover': 'http://img.rr.tv/album/20190730/o_1564479435111.webp',
 'data_type': 'movie',
 'id': 'rrmj_15485',
 'intro': '2016年，美国国家体操队队医拉里·纳萨尔数十年间对于年轻运动员的性侵遭到披露。震惊了美国体操。 '
          '艾琳·李·卡尔的这部纪录片勇于揭开丑闻、示人以藏掖的事实及其影响，使幸存者得以发声。',
 'is_new': False,
 'name': '在金牌的核心：美国体操丑闻',
 'platforms': '',
 'publishdate': '2019-05-03',
 'rate': 8.9,
 'sectionid': 'rrmj_1903',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/33218414/'}
2020-04-30 14:22:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/34678530/> (referer: https://www.douban.com/search?q=%E4%B8%80%E7%BA%A7%E6%96%B9%E7%A8%8B%E5%BC%8F%EF%BC%9A%E7%96%BE%E9%80%9F%E4%BA%89%E8%83%9C%20%E7%AC%AC%E4%BA%8C%E5%AD%A3)
2020-04-30 14:22:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/34678530/>
{'cover': 'http://img.rr.tv/cover/20200228/o_1582889264774.png',
 'data_type': 'movie',
 'id': 'rrmj_17264',
 'intro': '这部活力四射的剧集带着 10 集新内容回归，聚焦这项世界最快运动的惊险和刺激时刻。只有 20 '
          '名车手可以参加一级方程式赛车比赛，加上一些顶级赛车手开始为新车队效力，2019 '
          '年被证明是一个风云变幻、风起云涌的赛季。                                                                    \u3000\u3000'
          '今年，包括梅赛德斯车队和法拉利车队在内的 10 支车队首次向 Netflix '
          '开放内部权限，展示了他们在世界顶级系列赛中争夺胜利的历程。                                                                    \u3000\u3000'
          '该剧集走进车手、车队负责人和车队老板的幕后生活，以独特和不加修饰的视角展示他们在赛场上下的生活，以及这项运动专属的紧张感和魅力。                                                                    \u3000\u3000'
          '该剧集由奥斯卡金像奖得主詹姆斯·盖伊·里斯（《艾米》《永远的车神》）和代表 Box to Box Films '
          '的保罗·马丁（《马拉多纳》）担任监制。',
 'is_new': False,
 'name': '一级方程式：疾速争胜 第二季',
 'platforms': '',
 'publishdate': '2020-02-28',
 'rate': 9.6,
 'sectionid': 'rrmj_1425',
 'tags': ['纪录片', '运动'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/34678530/'}
2020-04-30 14:22:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%B8%AD%E5%9B%BD%E7%8E%8B%E6%9C%9D%20%E8%8B%B1%E9%9B%84%E4%BB%AC%E7%9A%84%E4%BC%A0%E8%AF%B4%20%E5%B7%A8%E5%A4%A7%E9%81%97%E4%BA%A7%E4%B9%8B%E8%B0%9C> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:22:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/7065117/> (referer: https://www.douban.com/search?q=%E8%A9%B9%E5%A7%86%E6%96%AF%C2%B7%E5%8D%A1%E6%A2%85%E9%9A%86%EF%BC%9A%E5%86%8D%E8%A7%81%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B)
2020-04-30 14:22:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/7065117/>
{'cover': 'http://img.rr.tv/album/20190731/o_1564553446043.webp',
 'data_type': 'movie',
 'id': 'rrmj_15496',
 'intro': '1912年，一艘名为泰坦尼克号的大船永远的沉没在了大西洋的最深处。1997年，一部名为《泰坦尼克号》的电影横空出世，赚取了足以淹没另一艘大船的眼泪。2012年，这艘大船改头换面，套上3D的外衣重回大荧幕，巩固了电影经久不衰的传奇地位。然而，对于大船的湮没，最伤感的永远都不是观众，而是一个躲在幕后，年近六十的男人——电影的导演詹姆斯·卡梅隆（James '
          'Cameron）。                                                                    \u3000\u3000'
          '卡梅隆和泰坦尼克号的缘分还未尽，这一次，他带领着他的尖端团队，从物理、数学、历史和艺术史等方面再次探究了大船沉没的根源，甚至还原了每一块碎片的运动轨迹。伴随着一次次的演算和推导，这位创造过无数奇迹的导演也在和这艘感动过亿万观众的大船进行着漫长的告别。',
 'is_new': False,
 'name': '詹姆斯·卡梅隆：再见泰坦尼克',
 'platforms': '',
 'publishdate': '2012-04-08',
 'rate': 8.6,
 'sectionid': 'rrmj_1405',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/7065117/'}
2020-04-30 14:22:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%BE%BE%E4%BC%A6%C2%B7%E5%B8%83%E6%9C%97%EF%BC%9A%E6%8C%91%E6%88%98%E4%B8%8D%E5%8F%AF%E8%83%BD%E7%9A%84%E8%89%BA%E6%9C%AF%E7%9B%97%E7%AA%83%20> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:22:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%BA%AA%E5%AE%9E72%E5%B0%8F%E6%97%B6%20%E6%96%B0%E5%AE%BF%E4%BA%8C%E4%B8%81%E7%9B%AE%20%E6%B7%B1%E5%A4%9C%E7%9A%84%E5%AE%B6%E5%B8%B8%E5%91%B3%E9%81%93> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:22:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26851191/> (referer: https://www.douban.com/search?q=%E5%A4%A7%E5%8D%AB%C2%B7%E5%85%8B%E7%BD%97%E6%96%AF%EF%BC%9A%E8%AE%A9%E7%BE%8E%E5%9B%BD%E5%86%8D%E5%BA%A6%E4%BC%9F%E5%A4%A7)
2020-04-30 14:22:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26851191/>
{'cover': 'http://img.rr.tv/album/20190530/o_1559201261962.png',
 'data_type': 'movie',
 'id': 'rrmj_14949',
 'intro': 'Actor/Comedian David Cross skewers Donald Trump, takes shots at '
          'religious taboos, and american swagger in a hilarious yet '
          'provocative night of comedy at the Paramount Theatre in Austin, TX.',
 'is_new': False,
 'name': '大卫·克罗斯：让美国再度伟大',
 'platforms': '',
 'publishdate': '2018-02-23',
 'rate': 8.0,
 'sectionid': 'rrmj_1421',
 'tags': ['脱口秀'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26851191/'}
2020-04-30 14:22:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%83%88%E7%84%B0%E5%8D%87%E8%85%BE%EF%BC%9A%E9%BB%91%E6%9A%97%E9%AA%91%E5%A3%AB%E4%B8%89%E9%83%A8%E6%9B%B2%E8%AF%9E%E7%94%9F%E5%8F%8A%E5%BD%B1%E5%93%8D%20> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:22:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26279366/> (referer: https://www.douban.com/search?q=%E6%8B%A8%E5%BC%80%E8%BF%B7%E9%9B%BE%EF%BC%9A%E5%B1%B1%E8%BE%BE%E5%9F%BA%E6%95%99%E4%B8%8E%E4%BF%A1%E4%BB%B0%E5%9B%9A%E7%AC%BC)
2020-04-30 14:22:34 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26279366/>
{'cover': 'http://img.rr.tv/album/20190725/o_1564034718209.webp',
 'data_type': 'movie',
 'id': 'rrmj_15460',
 'intro': '奥斯卡最佳纪录长片导演亚历克斯·吉布尼的新作，根据LawrenceWright的报告文学改编，关于8位前科学教的信徒，解密他们在好莱坞的秘闻，片子由影像资料、高层的演讲和场景重现等组成。',
 'is_new': False,
 'name': '拨开迷雾：山达基教与信仰囚笼',
 'platforms': '',
 'publishdate': '2015-01-25',
 'rate': 8.3,
 'sectionid': 'rrmj_1416',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26279366/'}
2020-04-30 14:22:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/34461518/> (referer: https://www.douban.com/search?q=%E6%88%88%E7%99%BB%C2%B7%E6%8B%89%E5%A7%86%E9%BD%90%EF%BC%9A%E7%BE%8E%E9%A3%9F%E7%A7%98%E5%A2%83%20%E7%AC%AC%E4%B8%80%E5%AD%A3)
2020-04-30 14:22:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/34461518/>
{'cover': 'http://img.rr.tv/album/20190824/o_1566632964862.webp',
 'data_type': 'movie',
 'id': 'rrmj_15683',
 'intro': '戈登拉姆齐与国家地理频道合作的六集美食纪录片《戈登拉姆齐：美食秘境》(Gordon Ramsay: '
          'Uncharted)正式定档，戈登拉姆齐来到阿拉斯加、老挝、摩洛哥、新西兰、夏威夷、秘鲁等国进行美食探寻，于7月21日播出',
 'is_new': False,
 'name': '戈登·拉姆齐：美食秘境 第一季',
 'platforms': '',
 'publishdate': '2019-07-21',
 'rate': 7.9,
 'sectionid': 'rrmj_1883',
 'tags': ['真人秀'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/34461518/'}
2020-04-30 14:22:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%B8%97%E9%80%8F> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:22:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/34806138/> (referer: https://www.douban.com/search?q=%E6%AF%94%E5%85%8B%E6%8B%89%E5%A7%86%EF%BC%9A%E7%91%9C%E4%BC%BD%E3%80%81%E5%A4%A7%E5%B8%88%E3%80%81%E6%80%A7%E4%BE%B5%E7%8A%AF)
2020-04-30 14:22:40 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/34806138/>
{'cover': 'http://img.rr.tv/album/20191127/o_1574838026601.webp',
 'data_type': 'movie',
 'id': 'rrmj_16697',
 'intro': '《比克拉姆：瑜伽、大师、性侵犯》审视了颇具争议的高温瑜伽创始人比克拉姆·乔杜里跌宕起伏的一生。20 世纪 70 '
          '年代初，乔杜里从印度加尔各答来到比弗利山庄，他很快就拥有了一批名人追随者，并打造了全球健身帝国，这为他带来了巨额财富。但直到 21 '
          '世纪 10 '
          '年代，随着大量性侵指控的出现，以及有关他充满攻击性、类似邪教的训练环境的故事浮出水面，诉讼开始增多，乔杜里的非法教学风格成为头条新闻。Netflix '
          '原创纪录片《比克拉姆：瑜伽、大师、性侵犯》由奥斯卡金像奖得主伊娃·奥尔纳（《开往暗处的的士》《避难亦遭难》）执导，萨拉·安东尼（《神山》《反叛者》）担任制片人，讲述了那些打倒乔杜里的女性的故事，并针对这门疗愈性学科如何在帮助人的同时给许多人带来伤害这一问题，探索了其中的矛盾。',
 'is_new': False,
 'name': '比克拉姆：瑜伽、大师、性侵犯',
 'platforms': '',
 'publishdate': '2019-11-20',
 'rate': 6.9,
 'sectionid': 'rrmj_1903',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/34806138/'}
2020-04-30 14:22:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=Good%20Doctor> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:22:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%8A%A0%E5%B8%83%E9%87%8C%E5%9F%83%E5%B0%94%C2%B7%E4%BC%8A%E6%A0%BC%E8%8E%B1%E8%A5%BF%E4%BA%9A%E6%96%AF%EF%BC%9A%E8%80%81%E5%B0%91%E5%92%B8%E5%AE%9C%E7%A7%80> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:22:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/2045978/> (referer: https://www.douban.com/search?q=%E6%9D%B0%E7%91%9E%C2%B7%E5%AE%8B%E9%A3%9E%EF%BC%9A%E8%80%81%E5%AD%90%E6%9C%80%E5%90%8E%E8%B7%9F%E4%BD%A0%E8%AF%B4%E4%B8%80%E6%AC%A1)
2020-04-30 14:22:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/2045978/>
{'cover': 'http://img.rr.tv/album/20190530/o_1559199772312.webp',
 'data_type': 'movie',
 'id': 'rrmj_14938',
 'intro': '在jerry结束了他的连续剧和stand-up talk show以后拍了这部电影版的comedy '
          'show，引用一些台词：                                                                            \u3000\u3000'
          '[On the space shuttle and the moon] What the hell were they doin '
          'with a car on the god damn moon? Youre on the moon already! Isnt '
          'that far '
          'enough?                                                                            \u3000\u3000'
          'I was the best man to a wedding one time, that was pretty good. '
          'Pretty good title, I thought, best man. I thought it was a bit '
          'much. I thought wed have the groom and ...',
 'is_new': False,
 'name': '杰瑞·宋飞：老子最后跟你说一次',
 'platforms': '',
 'publishdate': '1998-08-09',
 'rate': 8.3,
 'sectionid': 'rrmj_1421',
 'tags': ['喜剧', '舞台艺术'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/2045978/'}
2020-04-30 14:22:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%AF%8D%E4%BA%B2> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:22:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27197072/> (referer: https://www.douban.com/search?q=%E4%B8%AD%E5%9B%BD%E5%8A%B3%E5%B7%A5%E5%85%B5%E5%9B%A2%EF%BC%9A%E8%8B%B1%E5%9B%BD%E8%A2%AB%E9%81%97%E5%BF%98%E7%9A%84%E5%86%9B%E9%98%9F)
2020-04-30 14:22:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/27197072/>
{'cover': 'http://img.rr.tv/album/20190809/o_1565338352889.webp',
 'data_type': 'movie',
 'id': 'rrmj_15576',
 'intro': 'The story of the 140,000 Chinese workers who left their homes and '
          'came to war-torn Europe in 1917 and risked their lives for the '
          'Allied war effort, but whose vital contribution seems to have been '
          'airbrushed from history.',
 'is_new': False,
 'name': '中国劳工兵团：英国被遗忘的军队',
 'platforms': '',
 'publishdate': '2017-11-12',
 'rate': 8.2,
 'sectionid': 'rrmj_1384',
 'tags': ['纪录片', '历史', '战争'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/27197072/'}
2020-04-30 14:22:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%91%97%E9%AD%94> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:22:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30477147/> (referer: https://www.douban.com/search?q=%E5%BD%B1%E5%AD%90%E5%8F%B8%E4%BB%A4%EF%BC%9A%E4%BC%8A%E6%9C%97%E5%86%9B%E4%BA%8B%E5%A4%A7%E5%B8%88%E8%8B%8F%E8%8E%B1%E6%9B%BC%E5%B0%BC)
2020-04-30 14:22:47 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30477147/>
{'cover': 'http://img.rr.tv/cover/20200108/o_1578475103246.webp',
 'data_type': 'movie',
 'id': 'rrmj_16988',
 'intro': '1 '
          '2020年伊始，苏莱曼尼以死在中外博得大名，而其实他早已声名显赫                                                                    \u3000\u3000'
          '2 '
          '这是2019年3月BBC给他制作的纪录片，描述其传奇一生                                                                    \u3000\u3000'
          '3 '
          '简单说，近20多年中东或伊斯兰各重大冲突，都脱不来他的身影，而且是扮演主角                                                                    \u3000\u3000'
          '4 和美国或友或敌，致力扩张什叶新月，插手之多，无人可及',
 'is_new': False,
 'name': '影子司令：伊朗军事大师苏莱曼尼',
 'platforms': '',
 'publishdate': '2019-03-14',
 'rate': 7.1,
 'sectionid': 'rrmj_1420',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30477147/'}
2020-04-30 14:22:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%A6%86%E6%B4%BB> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:22:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/1499895/> (referer: https://www.douban.com/search?q=%E5%B9%B3%E5%85%8B%E5%BC%97%E6%B4%9B%E4%BC%8A%E5%BE%B7%E9%9F%B3%E4%B9%90%E4%BC%A0%E8%AE%B0.%E6%9C%88%E4%B9%8B%E9%98%B4%E6%9A%97%E9%9D%A2)
2020-04-30 14:22:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/1499895/>
{'cover': 'http://img.rr.tv/album/20190424/o_1556089331869.webp',
 'data_type': 'movie',
 'id': 'rrmj_14662',
 'intro': '这张DVD是为这张经典专辑的30周年纪念版。',
 'is_new': False,
 'name': '平克弗洛伊德音乐传记.月之阴暗面',
 'platforms': '',
 'publishdate': '2003-08-26',
 'rate': 6.0,
 'sectionid': 'rrmj_1295',
 'tags': ['纪录片', '音乐'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/1499895/'}
2020-04-30 14:22:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%B6%8A%E7%95%8C> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:22:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%8D%97%E4%BA%AC> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:22:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30351368/> (referer: https://www.douban.com/search?q=%E7%8C%AE%E7%BB%99%E5%A5%A5%E9%80%8A%E7%9A%84%E6%9C%80%E7%BB%88%E5%89%AA%E8%BE%91%EF%BC%9A40%E5%B9%B4%E5%88%B6%E4%BD%9C%E5%8E%86%E7%A8%8B)
2020-04-30 14:22:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30351368/>
{'cover': 'http://img.rr.tv/album/20181107/o_1541565128052.png',
 'data_type': 'movie',
 'id': 'rrmj_13496',
 'intro': '电影大师奥逊·威尔斯的遗作《风的另一边》的花絮纪录片，详细介绍了这部影片的重见天日的详细过程。',
 'is_new': False,
 'name': '献给奥逊的最终剪辑：40年制作历程',
 'platforms': '',
 'publishdate': '2018-11-02',
 'rate': 7.7,
 'sectionid': 'rrmj_1405',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30351368/'}
2020-04-30 14:22:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30197746/> (referer: https://www.douban.com/search?q=%E7%BA%A6%E7%BF%B0%C2%B7%E6%9C%A8%E5%85%B0%E5%B0%BC%EF%BC%9A%E6%97%A0%E7%BA%BF%E7%94%B5%E5%9F%8E%E7%9A%84%E4%BF%8A%E5%B0%8F%E4%BC%99%E5%84%BF)
2020-04-30 14:22:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30197746/>
{'cover': 'http://img.rr.tv/album/20190530/o_1559206359397.png',
 'data_type': 'movie',
 'id': 'rrmj_14974',
 'intro': 'John Mulaney relays stories from his childhood and Saturday Night '
          'Live (1975), eviscerates the value of college, and laments getting '
          'older in this comedy special. Other topics qiwan.cc include the '
          'church, his family, Trump and pedophiles abducting kids.',
 'is_new': False,
 'name': '约翰·木兰尼：无线电城的俊小伙儿',
 'platforms': '',
 'publishdate': '2018-05-01',
 'rate': 7.5,
 'sectionid': 'rrmj_1421',
 'tags': ['喜剧', '脱口秀'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30197746/'}
2020-04-30 14:22:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%89%BE%E7%B1%B3%20> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:22:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/25779043/> (referer: https://www.douban.com/search?q=%E7%BB%9D%E4%B8%8D%E6%8A%98%E4%B8%AD%EF%BC%9A%E7%BB%9D%E5%91%BD%E6%AF%92%E5%B8%88%E6%9C%80%E7%BB%88%E5%AD%A3%E5%88%B6%E4%BD%9C%E8%AE%B0%E5%BD%95)
2020-04-30 14:22:56 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/25779043/>
{'cover': 'http://img.rr.tv/album/20191010/o_1570688016375.webp',
 'data_type': 'movie',
 'id': 'rrmj_16107',
 'intro': '随着美剧《绝命毒师》全五季完结，一段荧屏上的传奇之旅就此结束。尽管故事已经完结，然而精彩还在继续。日前，纪录片《绝不折中》以及剧集的第五季蓝光和DVD光碟在美国洛杉矶同步进行发售。当天，《绝命毒师》主创团队都悉数到场。男主角布赖恩·克兰斯顿和鲍勃·奥登科克、迪恩·诺里斯等纷纷现身，引来了影迷们的围观。据主创团队介绍，纪录片深度探索了最后一季《绝命毒师》。',
 'is_new': False,
 'name': '绝不折中：绝命毒师最终季制作记录',
 'platforms': '',
 'publishdate': '2013-11-26',
 'rate': 9.4,
 'sectionid': 'rrmj_1405',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/25779043/'}
2020-04-30 14:22:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%BC%A6%E6%95%A6%E6%B2%B3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:22:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30464626/> (referer: https://www.douban.com/search?q=%E4%B8%AD%E5%9B%BD%E7%8E%8B%E6%9C%9D%20%E8%8B%B1%E9%9B%84%E4%BB%AC%E7%9A%84%E4%BC%A0%E8%AF%B4%20%E5%B7%A8%E5%A4%A7%E9%81%97%E4%BA%A7%E4%B9%8B%E8%B0%9C)
2020-04-30 14:22:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30464626/>
{'cover': 'http://img.rr.tv/album/20190307/o_1551939629088.jpg',
 'data_type': 'movie',
 'id': 'rrmj_14255',
 'intro': '新発見が続く中国の考古学界。「万里の長城」「大運河」「長安城」の謎を3週連続で追う！なぜこれらの巨大遺産は造られたのか？新たに分かった真の目的とは？ナビゲーターは、2019年度後期連続テレビ小説〈スカーレット〉のヒロイン・戸田恵梨香。',
 'is_new': False,
 'name': '中国王朝 英雄们的传说 巨大遗产之谜',
 'platforms': '',
 'publishdate': '2019-02-27',
 'rate': 7.7,
 'sectionid': 'rrmj_1384',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30464626/'}
2020-04-30 14:23:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%9B%BC%E5%BE%B7%E6%8B%89> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:23:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/25806456/> (referer: https://www.douban.com/search?q=%E8%BE%BE%E4%BC%A6%C2%B7%E5%B8%83%E6%9C%97%EF%BC%9A%E6%8C%91%E6%88%98%E4%B8%8D%E5%8F%AF%E8%83%BD%E7%9A%84%E8%89%BA%E6%9C%AF%E7%9B%97%E7%AA%83%20)
2020-04-30 14:23:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/25806456/>
{'cover': 'http://img.rr.tv/album/20190828/o_1566975530623.webp',
 'data_type': 'movie',
 'id': 'rrmj_15714',
 'intro': 'Derren Brown 2013年的作品。在这个节目中，Derren 向英国的百万富翁Ivan '
          'Massow下盗窃战书，达伦明确告知对方将要偷盗的作品，盗窃发生的日期和精准时间，甚至给了行窃者的照片，达伦将利用魔术的原理，训练一批老年人帮他完成这个不可能的任务。',
 'is_new': False,
 'name': '达伦·布朗：挑战不可能的艺术盗窃 ',
 'platforms': '',
 'publishdate': '2013-12-13',
 'rate': 8.1,
 'sectionid': 'rrmj_1416',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/25806456/'}
2020-04-30 14:23:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%B8%B8%E6%B3%B3%E6%B1%A0> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:23:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26306674/> (referer: https://www.douban.com/search?q=%E7%BA%AA%E5%AE%9E72%E5%B0%8F%E6%97%B6%20%E6%96%B0%E5%AE%BF%E4%BA%8C%E4%B8%81%E7%9B%AE%20%E6%B7%B1%E5%A4%9C%E7%9A%84%E5%AE%B6%E5%B8%B8%E5%91%B3%E9%81%93)
2020-04-30 14:23:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26306674/>
{'cover': 'http://img.rr.tv/album/20190711/o_1562825004912.png',
 'data_type': 'movie',
 'id': 'rrmj_15309',
 'intro': '新宿二丁目是日本屈指可数的重点景点。在那个地方的一个小角落里，有一家只在深夜才开的定食屋。有名气的菜品是烤鱼加猪肉汉堡。她们家做的菜肴很受男同性恋者和女同性恋者喜欢。作为69岁当地有名的妈妈桑·小莉说，人们只有在这里才能把自己内心的声音说出口，之后人才会变得有点精神。我们的节目还在注视着，在这个深夜里正在传播着的某种不知从何而来的温暖人心的人际关系。',
 'is_new': False,
 'name': '纪实72小时 新宿二丁目 深夜的家常味道',
 'platforms': '',
 'publishdate': '2014-12-19',
 'rate': 8.6,
 'sectionid': 'rrmj_1431',
 'tags': ['纪录片', '短片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26306674/'}
2020-04-30 14:23:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%B8%9D%E7%BB%B8%E4%B9%8B%E8%B7%AF%C2%B7%E7%A7%98%E5%A2%83%E7%9A%84%E4%BD%8F%E6%B0%91%20~%E5%A1%94%E5%85%8B%E6%8B%89%E7%8E%9B%E5%B9%B2%E6%B2%99%E6%BC%A0%E4%B8%AD%E7%9A%84%E6%A5%BC%E5%85%B0%E5%90%8E%E8%A3%94%EF%BC%9F> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:23:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%B8%BB%E5%8E%A8%E7%A7%80> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:23:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/25926760/> (referer: https://www.douban.com/search?q=%E7%83%88%E7%84%B0%E5%8D%87%E8%85%BE%EF%BC%9A%E9%BB%91%E6%9A%97%E9%AA%91%E5%A3%AB%E4%B8%89%E9%83%A8%E6%9B%B2%E8%AF%9E%E7%94%9F%E5%8F%8A%E5%BD%B1%E5%93%8D%20)
2020-04-30 14:23:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/25926760/>
{'cover': 'http://img.rr.tv/album/20190509/o_1557391640678.webp',
 'data_type': 'movie',
 'id': 'rrmj_14792',
 'intro': '',
 'is_new': False,
 'name': '烈焰升腾：黑暗骑士三部曲诞生及影响 ',
 'platforms': '',
 'publishdate': '2013-09-24',
 'rate': 8.8,
 'sectionid': 'rrmj_1405',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/25926760/'}
2020-04-30 14:23:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%8C%BB%E7%94%9F%E4%BB%AC> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:23:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30427294/> (referer: https://www.douban.com/search?q=%E5%8A%A0%E5%B8%83%E9%87%8C%E5%9F%83%E5%B0%94%C2%B7%E4%BC%8A%E6%A0%BC%E8%8E%B1%E8%A5%BF%E4%BA%9A%E6%96%AF%EF%BC%9A%E8%80%81%E5%B0%91%E5%92%B8%E5%AE%9C%E7%A7%80)
2020-04-30 14:23:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30427294/>
{'cover': 'http://img.rr.tv/album/20190530/o_1559201598759.png',
 'data_type': 'movie',
 'id': 'rrmj_14956',
 'intro': '在本部中，加布里埃尔·伊格莱西亚斯将聊到他青春期的儿子和巧遇史努比狗狗的故事...',
 'is_new': False,
 'name': '加布里埃尔·伊格莱西亚斯：老少咸宜秀',
 'platforms': '',
 'publishdate': '2019-01-29',
 'rate': 7.7,
 'sectionid': 'rrmj_1421',
 'tags': ['喜剧', '脱口秀'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30427294/'}
2020-04-30 14:23:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%A5%BD%E5%8C%BB%E7%94%9F> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:23:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/4303624/> (referer: https://www.douban.com/search?q=%E6%AF%8D%E4%BA%B2)
2020-04-30 14:23:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/4303624/>
{'cover': 'http://img.rr.tv/album/20180405/o_1522911085815.png',
 'data_type': 'movie',
 'id': 'rrmj_11976',
 'intro': '35岁的铃原奈绪（松雪泰子 '
          '饰）只身漂泊北国。似乎因某种原因，在过去的10年里她从未回到家中。奈绪喜欢观察鸟类，却阴差阳错成为一名小学教员。在此期间，她邂逅了7岁的小女孩道木怜南（芦田爱菜 '
          '饰）。怜南想法独特，性格开朗，只是身边没有一个朋友。她生长在单亲的家庭里，母亲和 '
          '情人同居，过着寥落破败的生活。怜南的特立独行和其身上偶然发现的伤痕引起奈绪和校方的注意。他们意识到这个小女孩正遭受来自母亲的虐待，几经波折，奈绪的母性被唤起。她决定“诱拐”怜南，担当起作为母亲的责任。                                                                    \u3000\u3000'
          '那个飘雪的日子，奈绪和怜南乔装打扮，相约离开寒冷的北国，启程去寻找一个温馨幸福的家园……',
 'is_new': False,
 'name': '母亲',
 'platforms': '',
 'publishdate': '2010-04-14',
 'rate': 9.5,
 'sectionid': 'rrmj_1726',
 'tags': ['剧情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/4303624/'}
2020-04-30 14:23:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%80%A7%E8%A7%A3%E5%AF%86> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:23:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/25780594/> (referer: https://www.douban.com/search?q=%E6%B8%97%E9%80%8F)
2020-04-30 14:23:14 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/25780594/>
{'cover': 'http://img.rr.tv/album/20190329/o_1553855103421.jpg',
 'data_type': 'movie',
 'id': 'rrmj_14441',
 'intro': '故事发生在1945年的陪都重庆。国民党特训班学生许忠义（沙溢 '
          '饰）因留级奉命进入沈阳的军统组织，他的任务是打入中共部队做卧底，军统沈阳站特务头子陈明（赵纯阳 '
          '饰）不明就里，对许的突返东北心存疑虑，许忠义设局巧妙地化解了陈的猜疑。由于许忠义当年是被迫加入军统组织，逐渐被共产党仁义精神教化，最终向我党自首，经过对他严格考查，党决定让他在敌人内部为我党发挥作用。投诚的许忠义利用敌人连吃败仗的厌战心理，在其内部分化瓦解，并为我军提供了大量急需的军用物资。原先他在军统的老对手齐公子（曹炳琨 '
          '饰）来到沈阳，带来了上峰拟定的“渗透”行动方案，许忠义深知山雨欲来……',
 'is_new': False,
 'name': '渗透',
 'platforms': '',
 'publishdate': '2013-12-03',
 'rate': 6.4,
 'sectionid': 'rrmj_747',
 'tags': ['剧情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/25780594/'}
2020-04-30 14:23:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%BD%AA%E6%A2%A6%E8%80%85> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:23:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/1297203/> (referer: https://www.douban.com/search?q=%E8%91%97%E9%AD%94)
2020-04-30 14:23:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/1297203/>
{'cover': 'http://img.rr.tv/cover/20200414/o_1586835321249.jpg',
 'data_type': 'movie',
 'id': 'rrmj_17487',
 'intro': '马克（Sam Neill 饰）的妻子安娜（Isabelle Adjani 伊莎贝尔•阿佳妮 '
          '饰）未留下任何原因离家出走，他一度认为安娜与一个名叫海恩里克（Heinz Bennent '
          '饰）的男人有染，却发现海恩里克也在寻找许久未见的安娜。马克于是雇佣私家侦探调查。但随着线索的逐一呈现，事实的真相反倒令马克等人难以置信。安娜所耽恋的对象竟然是……                                                                    \u3000\u3000'
          '本片分别荣获1982年戛纳国际电影节和法国凯撒电影节最佳女演员奖、1983年葡萄牙奇幻电影节观众大奖和最佳女主角奖、1981年西班牙圣保罗国际电影节评论奖。',
 'is_new': False,
 'name': '著魔',
 'platforms': '',
 'publishdate': '1981-05-25',
 'rate': 7.3,
 'sectionid': 'rrmj_1904',
 'tags': ['剧情', '恐怖'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/1297203/'}
2020-04-30 14:23:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26888731/> (referer: https://www.douban.com/search?q=Good%20Doctor)
2020-04-30 14:23:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26888731/>
{'cover': 'http://img.rr.tv/album/20180808/o_1533714171038.png',
 'data_type': 'movie',
 'id': 'rrmj_12938',
 'intro': '《豪斯医生 House》主创David Shore联同Daniel Dae Kim开发ABC医务剧《好医生 The Good '
          'Doctor》，根据韩剧所改篇的《好医生》由David '
          'Shore编剧，讲述一个年轻﹑有学者症候群（在某种艺术或学术上有超乎常人的能力， 有10%自闭症患者有这种症候群）的外科医生Shaun '
          'Murphy加入了一间著名医院San Jose St. '
          'Bonaventure，这令所有人都起了这疑问：一个没法和常人建立关系的医生，真的能治疗患者？                                                                            \u3000\u3000'
          '在《贝兹旅馆 Bates Motel》饰演著名精神病杀人魔Norman Bates的Freddie '
          'Highmore加盟饰演患有自闭症的主角Shaun '
          'Murphy，他虽然不擅长社交，不过有着具魅力的诚实及率直；学者症候群患者的他挨过了麻烦的童年，并成为了一个天才医生。Nicholas '
          'G...',
 'is_new': False,
 'name': 'Good Doctor',
 'platforms': '',
 'publishdate': '2017-09-25',
 'rate': 8.0,
 'sectionid': 'rrmj_1646',
 'tags': ['剧情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26888731/'}
2020-04-30 14:23:19 [scrapy.extensions.logstats] INFO: Crawled 605 pages (at 51 pages/min), scraped 324 items (at 52 items/min)
2020-04-30 14:23:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%96%B0%E8%A1%A3%E8%8D%89> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:23:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/34927982/> (referer: https://www.douban.com/search?q=%E8%A6%86%E6%B4%BB)
2020-04-30 14:23:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/34927982/>
{'cover': 'http://img.rr.tv/cover/20200413/o_1586768728455.png',
 'data_type': 'movie',
 'id': 'rrmj_17484',
 'intro': '午夜，熊熊大火正吞噬著一棟民宅，程佑寬身陷火海之中，但他知道屋子裡面還有人！他一邊嗆咳著，一邊拼命尋找，終於看見一個被束縛住手腳，哭喊救援的女子，當程佑寬正要伸手救援時，一陣熟悉的心痛感襲來，讓他驚醒！                                                                    \u3000\u3000'
          '原來，這是佑寬的夢境，他可以預先夢見將死之人，但卻無法出手援救，因為每當他想要救人時，他的眼中就會長出妖豔的彼岸花，一路蔓生到心臟，揪心之痛讓他無法再前進一步！於是，佑寬就算夢見了，知道了，也只能眼睜睜看著人們在他面前死去，十九年來每一天，每一晚都是如此，這就是他的宿命，他的詛咒……                                                                    \u3000\u3000'
          '當年十歲的佑寬因為被同學欺負，將自己被霸凌的原因，全都歸咎於害他被人誤會是小偷的同校同學-畢克葳，於是當他生病高燒命危時，他心有不甘的向看不見的力量許願，願望的內容就是，希望克葳代替自己承受劫難……                                                                    \u3000\u3000'
          '從今以後，佑寬、克葳彼此覆蓋的命運，到底有誰能活下去？',
 'is_new': False,
 'name': '覆活',
 'platforms': '',
 'publishdate': '2020-03-28',
 'rate': 8.2,
 'sectionid': 'rrmj_1904',
 'tags': [],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/34927982/'}
2020-04-30 14:23:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E9%82%A3%E4%B8%80%E5%A4%A9> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:23:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27598317/> (referer: https://www.douban.com/search?q=%E8%B6%8A%E7%95%8C)
2020-04-30 14:23:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/27598317/>
{'cover': 'http://img.rr.tv/cover/20200415/o_1586940372364.png',
 'data_type': 'movie',
 'id': 'rrmj_17505',
 'intro': '夏宇豪原本只是一名爱打架讲义气的高中男生，因打架闹事被迫转学至志弘中学，死党跟班王振文也与没血缘关系的哥哥王振武一同转来。在某次的翻墙逃学中，被排球队长贺承恩与球队经理邱子轩看见，贺承恩开始展开热烈追求希望夏宇豪加入排球队，加入排球队后的不良少年，与邱子轩互相陪伴、激励之中，两人相知相惜的感情，也擦出了爱的火花；王家两兄弟随着宇豪一起加入排球队，弟弟振文对于没血缘关系的哥哥有着不同于兄弟间的情愫，但一直逃避与闪避哥哥对他的一切好，只希望自己的情感不要被哥哥发现，而振武对于弟弟的保护与照顾更是无微不至，誓言要保护他一辈子，但是对于弟弟也有着一些说不出的情愫，两兄弟心中相互隐藏的情感，因为加入排球后有了不一样的变化，四名少年因为加入排球队后逐渐展开一段段交织汗水与青春的爱情故事。',
 'is_new': False,
 'name': '越界',
 'platforms': '',
 'publishdate': '2018-03-06',
 'rate': 8.5,
 'sectionid': 'rrmj_1904',
 'tags': ['爱情', '同性'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/27598317/'}
2020-04-30 14:23:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%81%B7%E7%AA%A5%E8%80%85> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:23:25 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/352686/> (referer: https://www.douban.com/search?q=%E5%8D%97%E4%BA%AC)
2020-04-30 14:23:26 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/352686/>: HTTP status code is not handled or not allowed
2020-04-30 14:23:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/24532442/> (referer: https://www.douban.com/search?q=%E8%89%BE%E7%B1%B3%20)
2020-04-30 14:23:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/24532442/>
{'cover': 'https://img.rr.tv/video/20160310/o_1457597333739.jpg',
 'data_type': 'movie',
 'id': 'rrmj_1232',
 'intro': '曾获得7座格莱美奖杯的艾米·怀恩豪斯，于2011年7月23日，因饮酒中毒而去世，享年27岁。此纪录片公开了一些艾米生前的私人影像，并且希望从艾米本人的角度来揭开这场悲剧的背后真相。制片人James '
          'Gay-Rees表示：“这样一部拥有当代性的影片，能够抓住时代精神，以其 '
          '他电影无法达到的方式来解读我们所处的世界。”                                                                    \u3000\u3000'
          '艾米·怀恩豪斯被认为是这个时代最杰出的爵士女歌手之一，除了慵懒沙哑的嗓音，她总是顶着高耸蓬乱的蜂巢头，化着极致夸张的烟熏妆，穿着凌乱暴露的衣衫，让所有人的视线都被她吸引。她的歌曲仿佛来自深不可测的心底，有一种蛊惑的魔力。然而可悲的是，艾米却成为了自己的成功、媒体、情感和生活方式的囚徒。这个社会中，人们一方面赞赏她的才华，在另一方面也毫不留情地在伤害和消费着她。',
 'is_new': False,
 'name': '艾米 ',
 'platforms': '',
 'publishdate': '2015-05-16',
 'rate': 8.5,
 'sectionid': 'rrmj_1295',
 'tags': ['纪录片', '音乐', '传记'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/24532442/'}
2020-04-30 14:23:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%88%AB%E5%9B%9E%E5%A4%B4> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:23:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/1308459/> (referer: https://www.douban.com/search?q=%E6%B8%B8%E6%B3%B3%E6%B1%A0)
2020-04-30 14:23:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/1308459/>
{'cover': 'http://img.rr.tv/cover/20191106/o_1573033349817.webp',
 'data_type': 'movie',
 'id': 'rrmj_16520',
 'intro': '阿兰·德龙与罗密·施奈德合作的一部影片，这时已经是他们金童玉女时代之后的事情了，虽然爱情已逝，却又还没老，正是他们青春的顶峰，恰到好处，脱了甜蜜，却又还没有世故，只是已开始有了些感慨的样子。导演尽情展露他们的完美身体，一多半戏都是发生在游泳池边。他们在片中演一对恋人，但是那时他们在生活中已经不爱了，这也容易让人想入非非。影片展现了阿兰·德龙和罗密·施奈德的青春盛时之美。',
 'is_new': False,
 'name': '游泳池',
 'platforms': '',
 'publishdate': '1969-01-31',
 'rate': 7.4,
 'sectionid': 'rrmj_1729',
 'tags': ['剧情', '犯罪'],
 'type': 'movie',
 'url': 'https://movie.douban.com/subject/1308459/'}
2020-04-30 14:23:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%9D%83%E5%BF%97%E9%BE%99> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:23:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/3073109/> (referer: https://www.douban.com/search?q=%E4%BC%A6%E6%95%A6%E6%B2%B3)
2020-04-30 14:23:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/3073109/>
{'cover': 'http://img.rr.tv/cover/20191107/o_1573107145326.webp',
 'data_type': 'movie',
 'id': 'rrmj_16530',
 'intro': '2005年7月英国伦敦遭遇了前所未有的恐怖袭击。袭击事件之后，一些父母陆续来到伦敦寻找自己的子女，以确认他们在袭击中没有伤亡。正是这样的恐怖袭击，将生活在伦敦的孩子，和孩子们的父母，和这座城市紧密联系到了一起，也成为这部电影的主题……',
 'is_new': False,
 'name': '伦敦河',
 'platforms': '',
 'publishdate': '2009-09-23',
 'rate': 7.2,
 'sectionid': 'rrmj_1729',
 'tags': ['剧情', '悬疑'],
 'type': 'movie',
 'url': 'https://movie.douban.com/subject/3073109/'}
2020-04-30 14:23:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%8B%A9%E7%8C%8E%E5%9C%BA> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:23:34 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/671246/> (referer: https://www.douban.com/search?q=%E7%BD%AA%E6%A2%A6%E8%80%85)
2020-04-30 14:23:34 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/671246/>: HTTP status code is not handled or not allowed
2020-04-30 14:23:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%99%BD%E6%A1%A6%E6%A0%91> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:23:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/11614065/> (referer: https://www.douban.com/search?q=%E6%9B%BC%E5%BE%B7%E6%8B%89)
2020-04-30 14:23:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/11614065/>
{'cover': 'http://img.rr.tv/cover/20191106/o_1573022648554.webp',
 'data_type': 'movie',
 'id': 'rrmj_16506',
 'intro': '本片改编自前南非总统曼德拉在1994年出版的同名自传。                                                                            \u3000\u3000'
          '他是个赤脚通山走的乡村男孩；他是个高呼自由万岁的热血青年律师；他是反政府的武装革命领袖；他是个被监禁、放逐及劳役27年的政治犯；他是南非史上首个民主选举中当选的第一位黑人总统，他的名字叫曼德拉。                                                                            \u3000\u3000'
          '曼德拉（伊德里斯·艾尔巴 Idris Elba '
          '饰）奉献一生反抗种族隔离政策，他由革命战士变成和平斗士，把一个严重种族分裂的国家变成平等和谐国度，为全世界树立榜样，但却付出了沉重代价。曼德拉43岁时被控以企图推翻政府等罪名判处无期徒刑，与妻子温妮（娜奥米·哈里斯 '
          'Naomie Harris '
          '饰）天各一方，从此没有机会陪伴自己的子孙成长。即使在监禁27年后他终于重获自由，更成为万民敬仰的总统及英雄人物，但却失去了一生中最爱的女人——长年的分离与政治迫害，把两夫妻的距离越拉越远，当曼德拉宣扬和平宽容的理念，...',
 'is_new': False,
 'name': '曼德拉',
 'platforms': '',
 'publishdate': '2014-07-18',
 'rate': 7.9,
 'sectionid': 'rrmj_1399',
 'tags': ['剧情', '传记'],
 'type': 'movie',
 'url': 'https://movie.douban.com/subject/11614065/'}
2020-04-30 14:23:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%9F%BA%E5%8F%8B%E8%AE%B02> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:23:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26811883/> (referer: https://www.douban.com/search?q=%E4%B8%9D%E7%BB%B8%E4%B9%8B%E8%B7%AF%C2%B7%E7%A7%98%E5%A2%83%E7%9A%84%E4%BD%8F%E6%B0%91%20~%E5%A1%94%E5%85%8B%E6%8B%89%E7%8E%9B%E5%B9%B2%E6%B2%99%E6%BC%A0%E4%B8%AD%E7%9A%84%E6%A5%BC%E5%85%B0%E5%90%8E%E8%A3%94%EF%BC%9F)
2020-04-30 14:23:39 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26811883/>
{'cover': 'http://img.rr.tv/album/20190910/o_1568106311188.jpg',
 'data_type': 'movie',
 'id': 'rrmj_15586',
 'intro': '塔克拉玛干沙漠，又称死亡之海，久经烈阳灼烤的黄沙勾勒出天地一线的画面。但是在这深处，仍有着一群秘境的住民，以生活本色传承着自己的文化。',
 'is_new': False,
 'name': '丝绸之路·秘境的住民 ~塔克拉玛干沙漠中的楼兰后裔？',
 'platforms': '',
 'publishdate': '2016-05-28',
 'rate': 8.5,
 'sectionid': 'rrmj_1384',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26811883/'}
2020-04-30 14:23:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=1%E9%A1%B5%E4%B9%8B%E6%81%8B> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:23:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/2270536/> (referer: https://www.douban.com/search?q=%E8%96%B0%E8%A1%A3%E8%8D%89)
2020-04-30 14:23:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/2270536/>
{'cover': 'http://img.rr.tv/cover/20200415/o_1586953369963.jpg',
 'data_type': 'movie',
 'id': 'rrmj_17509',
 'intro': '患有先天复杂性心脏病的以薰(陈怡蓉 '
          '饰)从小就跟体育绝缘，每逢体育课她都被老师安排在一旁休息。看着同学们在操场上蹦蹦跳跳，以薰心里倍感孤独。幸有同班同学晴川（许绍洋 '
          '饰）经常陪在以薰身边，她才聊以解慰。转眼间，晴川一家要移民美国了，出国前晴川带着以薰来到了他的秘密基地——一个种满薰衣草的废气花坊，晴川交给以薰一个装满薰衣草的瓶子，相约在以薰20岁生日那天两人回到小学校门前重逢。                                                                            \u3000\u3000'
          '时光飞逝，长大后的以薰在一家花房工作，同事兼好友小童（王建龙 '
          '饰）一直暗恋着她，只是以薰一直在守候童年的爱情。以薰20岁的生日快到了，这天她从电视上认出了国外归来的偶像LEO就是她等候多年的晴川！这时LEO正在举办一个名为“寻找薰衣草恋人”的个唱，脸红心跳的以薰又惊又怕，惊喜的是自己终于见到了初恋情人，害怕的是不知晴川找的薰衣草恋人是否就是自己。这晚在LEO的演唱会上，以薰鼓...',
 'is_new': False,
 'name': '薰衣草',
 'platforms': '',
 'publishdate': '2001-12-06',
 'rate': 6.8,
 'sectionid': 'rrmj_1904',
 'tags': ['剧情', '爱情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/2270536/'}
2020-04-30 14:23:43 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/676537/> (referer: https://www.douban.com/search?q=%E9%82%A3%E4%B8%80%E5%A4%A9)
2020-04-30 14:23:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%A4%A7%E4%BC%81%E4%B8%9A%20> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:23:44 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/676537/>: HTTP status code is not handled or not allowed
2020-04-30 14:23:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=HIStory3-%E5%9C%88%E5%A5%97> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:23:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/24736583/> (referer: https://www.douban.com/search?q=%E5%A5%BD%E5%8C%BB%E7%94%9F)
2020-04-30 14:23:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/24736583/>
{'cover': 'http://img.rr.tv/album/20180717/o_1531796979960.jpg',
 'data_type': 'movie',
 'id': 'rrmj_12551',
 'intro': '住院医生朴诗温（朱元 '
          '饰）童年时在家暴中生活，同时患有自闭症和发育障碍，但在日后却凭超人的人体空间感悟力和记忆力成为韩国成元大学医术最精湛的儿科医生。他一直喜欢着漂亮机智的女医生车允书（文彩元 '
          '饰），不过暗恋多年一直未表白。小儿外科副教授金道韩（朱相昱 '
          '饰）是年纪最轻就获得资格认证的实力派，他对医术精益求精，不容本科医生出半点差错，哪怕对方是德高望重的前辈，他都一视同仁。面对诸多诱导，他都不肯离开环境恶劣的小儿科，因为他心中藏着童年永远抹不去的痛。企划室长俞彩京（金敏瑞 '
          '饰）是美国斯坦福大学的海归，看似无所畏惧的她內心却有着幼年母亲去世、父亲再婚带来的伤痛记忆......',
 'is_new': False,
 'name': '好医生',
 'platforms': '',
 'publishdate': '2013-08-05',
 'rate': 8.3,
 'sectionid': 'rrmj_1646',
 'tags': ['剧情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/24736583/'}
2020-04-30 14:23:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=BBC%EF%BC%9A%E9%9D%9E%E6%B4%B2> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:23:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26700713/> (referer: https://www.douban.com/search?q=%E5%8C%BB%E7%94%9F%E4%BB%AC)
2020-04-30 14:23:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26700713/>
{'cover': 'http://img.rr.tv/album/20180914/o_1536911614892.jpg',
 'data_type': 'movie',
 'id': 'rrmj_11114',
 'intro': '刘慧静（朴信惠饰）曾是一个人人畏惧的女流氓，拳脚功夫了得的她曾因犯事而招来牢狱之灾。然而，监狱将是改变她人生轨迹的新起点。在监狱中，她明白了原本生活的错误，幡然醒悟的她决定痛改前非。于是，刑满释放后，头脑聪明的她决定发愤图强，砺志成为一个人人敬仰的女医生。而这个愿望也在数百个书不离手的日子后实现了。然而，身为女医生的惠静将面临着更为艰难的挑战。',
 'is_new': False,
 'name': '医生们',
 'platforms': '',
 'publishdate': '2016-06-20',
 'rate': 7.0,
 'sectionid': 'rrmj_1726',
 'tags': ['剧情', '爱情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26700713/'}
2020-04-30 14:23:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=8%E5%8F%B7%E6%8F%90%E6%A1%88%20> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:23:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/33455077/> (referer: https://www.douban.com/search?q=%E4%B8%BB%E5%8E%A8%E7%A7%80)
2020-04-30 14:23:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/33455077/>
{'cover': 'http://img.rr.tv/album/20190610/o_1560157714875.jpg',
 'data_type': 'movie',
 'id': 'rrmj_15045',
 'intro': '乔恩·费儒执导的Netflix美食类节目《主厨秀》(The Chef '
          'Show，暂译)首曝预告！小罗伯特·唐尼、汤姆·霍兰德、安东尼·罗素、乔·罗素等现身，与费儒共同做美食。该节目将于6月7日上线。',
 'is_new': False,
 'name': '主厨秀',
 'platforms': '',
 'publishdate': '2019-06-07',
 'rate': 8.0,
 'sectionid': 'rrmj_1883',
 'tags': ['真人秀'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/33455077/'}
2020-04-30 14:23:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%B8%A4%E5%B0%8F%E6%97%A0%E7%8C%9C> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:23:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/1305223/> (referer: https://www.douban.com/search?q=%E5%88%AB%E5%9B%9E%E5%A4%B4)
2020-04-30 14:23:54 [scrapy.core.scraper] ERROR: Error processing {'cover': 'http://img.rr.tv/album/20190424/o_1556087565938.webp',
 'data_type': 'movie',
 'id': 'rrmj_14659',
 'intro': '这部纪录片是对鲍勃迪伦1965年英国巡演的忠实记录，导演彭内贝克用影像清晰的说明那时的鲍勃迪伦与披头士是多么的不同。与同时期的《苦难日之夜》相比，《别回头》更直接，深刻，对自己的拍摄对象也没有造星般的刻意吹捧，甚至还毫不掩饰的可以嘲讽，但是，再冷静的镜头都无法掩盖年轻迪伦的灿烂光芒，同现在的老迪伦相比，年轻的他无与伦比的傲慢，机智，激情洋溢，而其中一段以垮掉派代表艾伦金斯堡为背景的开场更是弥足珍贵。',
 'is_new': False,
 'name': '别回头',
 'platforms': '',
 'publishdate': '',
 'rate': 8.5,
 'sectionid': 'rrmj_1295',
 'tags': ['纪录片', '音乐'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/1305223/'}
Traceback (most recent call last):
  File "/usr/python37/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/python37/lib/python3.7/site-packages/scrapy/utils/defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/root/spider/scrapyspider/spiderV1/pipelines.py", line 262, in process_item
    timeStruct = time.strptime(publishdate, '%Y-%m-%d')
  File "/usr/python37/lib/python3.7/_strptime.py", line 571, in _strptime_time
    tt = _strptime(data_string, format)[0]
  File "/usr/python37/lib/python3.7/_strptime.py", line 359, in _strptime
    (data_string, format))
ValueError: time data '' does not match format '%Y-%m-%d'
2020-04-30 14:23:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%AF%BF%E5%8F%B8%E4%B9%8B%E7%A5%9E> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:23:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/34935798/> (referer: https://www.douban.com/search?q=%E6%80%A7%E8%A7%A3%E5%AF%86)
2020-04-30 14:23:55 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/34935798/>
{'cover': 'http://img.rr.tv/cover/20200108/o_1578465548288.png',
 'data_type': 'movie',
 'id': 'rrmj_16979',
 'intro': '从生物学上的吸引到节育的历史，这部有趣且发人深省的剧集带您探索性的方方面面。',
 'is_new': False,
 'name': '性解密',
 'platforms': '',
 'publishdate': '2020-01-02',
 'rate': 8.1,
 'sectionid': 'rrmj_1416',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/34935798/'}
2020-04-30 14:23:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%9C%9F%E7%88%B1%E8%87%B3%E4%B8%8A> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:23:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26279369/> (referer: https://www.douban.com/search?q=%E7%8B%A9%E7%8C%8E%E5%9C%BA)
2020-04-30 14:23:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26279369/>
{'cover': 'http://img.rr.tv/cover/20200413/o_1586759005590.webp',
 'data_type': 'movie',
 'id': 'rrmj_17481',
 'intro': '继美军性侵丑闻的【隐秘的战争】提名了奥斯卡最佳纪录长片提名之后，科比·迪克导演再拍美国高校的性侵事件，背后各种阴暗的利害关系，影片最近也刚入围了圣丹斯电影节。',
 'is_new': False,
 'name': '狩猎场',
 'platforms': '',
 'publishdate': '2015-01-23',
 'rate': 8.5,
 'sectionid': 'rrmj_1903',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26279369/'}
2020-04-30 14:24:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%A2%A8%E6%B3%B0%E9%99%A2Class> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:24:00 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/27083910/> (referer: https://www.douban.com/search?q=%E5%81%B7%E7%AA%A5%E8%80%85)
2020-04-30 14:24:00 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/27083910/>: HTTP status code is not handled or not allowed
2020-04-30 14:24:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%A4%84%E5%AD%90%E4%B9%8B%E5%B1%B1> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:24:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30327459/> (referer: https://www.douban.com/search?q=%E6%9D%83%E5%BF%97%E9%BE%99)
2020-04-30 14:24:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30327459/>
{'cover': 'http://img.rr.tv/cover/20191204/o_1575428466863.webp',
 'data_type': 'movie',
 'id': 'rrmj_16753',
 'intro': 'Kwon Ji Yong is a full-length documentary that reveals the real '
          'Kwon Ji Yong AKA G-Dragon, the leader of one of the most successful '
          'K-pop bands in history, BIGBANG. As the camera follows him '
          'throughout his last solo tour before he heads to the military, '
          'never-before-seen intimate footage bears naked the inner struggles '
          'and the challenges of living under the '
          'microscope.                                                                            \u3000\u3000'
          '(Source:...',
 'is_new': False,
 'name': '权志龙',
 'platforms': '',
 'publishdate': '2018-09-05',
 'rate': 9.4,
 'sectionid': 'rrmj_1295',
 'tags': ['纪录片', '音乐'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30327459/'}
2020-04-30 14:24:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%B5%A9%E5%8A%AB%E6%B1%82%E7%94%9F> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:24:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26990799/> (referer: https://www.douban.com/search?q=%E5%9F%BA%E5%8F%8B%E8%AE%B02)
2020-04-30 14:24:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26990799/>
{'cover': 'http://img.rr.tv/album/20190509/o_1557384505650.jpg',
 'data_type': 'movie',
 'id': 'rrmj_14762',
 'intro': 'March 19, 2017 Every Sunday 8.00 pm on LineTV',
 'is_new': False,
 'name': '基友记2',
 'platforms': '',
 'publishdate': '2017-03-19',
 'rate': 9.0,
 'sectionid': 'rrmj_989',
 'tags': ['爱情', '同性'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26990799/'}
2020-04-30 14:24:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30330957/> (referer: https://www.douban.com/search?q=%E7%99%BD%E6%A1%A6%E6%A0%91)
2020-04-30 14:24:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30330957/>
{'cover': 'http://img.rr.tv/cover/20191012/o_1570846931034.webp',
 'data_type': 'movie',
 'id': 'rrmj_16135',
 'intro': '改编自同名短片，聚焦三名青少年男女以及一个在森林深处的嗜血妖怪。这群少年男女的人生因嗜血怪物而永远改变。一旦为了寻求保护召唤白桦树妖，你将永远无法逃脱。',
 'is_new': False,
 'name': '白桦树',
 'platforms': '',
 'publishdate': '2019-10-11',
 'rate': 7.7,
 'sectionid': 'rrmj_1917',
 'tags': ['恐怖'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30330957/'}
2020-04-30 14:24:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%B5%B7%E8%A7%92%E4%B8%83%E5%8F%B7> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:24:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30403240/> (referer: https://www.douban.com/search?q=1%E9%A1%B5%E4%B9%8B%E6%81%8B)
2020-04-30 14:24:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30403240/>
{'cover': 'http://img.rr.tv/album/20190118/o_1547792335445.jpg',
 'data_type': 'movie',
 'id': 'rrmj_14006',
 'intro': '桥本环奈将主演AbemaTV日剧《1页的恋爱》，这也是桥本环奈首次主演电视连续剧！她将在剧中饰演主人公水濑明，和初恋森田郁巳（板垣瑞生）、青梅竹马乾大和（滨田龙臣）、成熟男子星野有利（古川雄辉）三位男性展开恋爱故事…共演还有大野丝。',
 'is_new': False,
 'name': '1页之恋',
 'platforms': '',
 'publishdate': '2019-02-18',
 'rate': 5.2,
 'sectionid': 'rrmj_1244',
 'tags': ['剧情', '爱情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30403240/'}
2020-04-30 14:24:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%8F%B2%E6%B4%9B%E6%A2%85%E5%A8%9C> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:24:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/1401906/> (referer: https://www.douban.com/search?q=%E5%A4%A7%E4%BC%81%E4%B8%9A%20)
2020-04-30 14:24:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/1401906/>
{'cover': 'http://img.rr.tv/album/20190712/o_1562914611066.webp',
 'data_type': 'movie',
 'id': 'rrmj_15337',
 'intro': '本部纪录片以深入浅出的手法，从现代企业的本质、演变、冲击和可能的未来四个方面，批判地揭示了现代企业所隐含的内在运作、发展的历史、其所带来极具争议性的冲击及未来的可能发展。影片开篇便采用了“世卫组织国际疾病分类第10版”和“心理疾病诊断统计手册第4版”的诊断标准，对那些财团法人或大企业进行人格检查，试图揭开跨国大企业的真面目。本片耗时六年完成，采访了来自不同业界的40位人士，这些业界精英现身说法，道出了企业机构以牟取利润为终极使命的惊人秘密。我们的确患病了，唯利是图、人情冷漠、反社会人格等等，我们所能做的就是依靠我们的勇气、智慧和决心去阻止它。                                                                            \u3000\u3000'
          '由马克·阿克巴与詹尼弗·阿尔伯特联合执导的发人深省的纪录片《大企业》，根据乔尔·巴肯的《企业的性格与命运》改编拍摄而成。本片荣获2004年圣丹斯电影节世界电影单元-纪录片大奖在内的26项国际大奖以及10项观众票...',
 'is_new': False,
 'name': '大企业 ',
 'platforms': '',
 'publishdate': '2003-09-10',
 'rate': 8.4,
 'sectionid': 'rrmj_1871',
 'tags': ['纪录片', '历史'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/1401906/'}
2020-04-30 14:24:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%B8%8D%E6%9C%9F%E8%80%8C%E7%88%B1> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:24:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%8F%8C%E5%AD%90%E5%81%B7%E5%BF%83> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:24:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/4766100/> (referer: https://www.douban.com/search?q=8%E5%8F%B7%E6%8F%90%E6%A1%88%20)
2020-04-30 14:24:14 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/4766100/>
{'cover': 'http://img.rr.tv/album/20180705/o_1530761295151.png',
 'data_type': 'movie',
 'id': 'rrmj_12604',
 'intro': '影片讲述的是美国禁止同性婚姻的8号提案。在2009年，数千名同志被剥夺了公民的民事权利。于是摩门教开始了全国性的组织活动，并带头融资和带头作用，努力制止超过三十年的婚姻平等地位。                                                                    \u3000\u3000'
          '导演Reed '
          'Cowan一开始只是想拍一部关于犹他州年轻同志的纪录片，这些年轻人有许多是无家可归，当中更不乏有人选择自杀一途，但导演很快就发现让慈爱的父母变得「恐同」的原因，竟是摩门教教义使然，本片将纪录这些同志们如何起身抵抗「八号提案」，若是摩门教会在加州提出的八号提案通过，那么同志人权将遭遇前所未有的压制，更将丧失决定自己人生的权力。',
 'is_new': False,
 'name': '8号提案 ',
 'platforms': '',
 'publishdate': '2010-06-18',
 'rate': 8.8,
 'sectionid': 'rrmj_1431',
 'tags': ['纪录片', '同性'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/4766100/'}
2020-04-30 14:24:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%9B%A0%E4%B8%BA%E6%83%B3%E4%BD%A0> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:24:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/20488575/> (referer: https://www.douban.com/search?q=BBC%EF%BC%9A%E9%9D%9E%E6%B4%B2)
2020-04-30 14:24:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/20488575/>
{'cover': 'http://img.rr.tv/album/20180703/o_1530604505001.jpg',
 'data_type': 'movie',
 'id': 'rrmj_12558',
 'intro': '《非洲》由《Life》原班人马打造，是一部大型原生态纪录片。镜头将跟随主持人David '
          'Attenborough一起穿越神奇的非洲大陆，探索那些从未被发现、被记录的生物物种和壮观的非洲奇迹。',
 'is_new': False,
 'name': 'BBC：非洲',
 'platforms': '',
 'publishdate': '2013-08-19',
 'rate': 9.7,
 'sectionid': 'rrmj_1425',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/20488575/'}
2020-04-30 14:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30373690/> (referer: https://www.douban.com/search?q=HIStory3-%E5%9C%88%E5%A5%97)
2020-04-30 14:24:19 [scrapy.extensions.logstats] INFO: Crawled 655 pages (at 50 pages/min), scraped 344 items (at 20 items/min)
2020-04-30 14:24:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30373690/>
{'cover': 'http://img.rr.tv/cover/20200414/o_1586831124415.png',
 'data_type': 'movie',
 'id': 'rrmj_17486',
 'intro': '想抓犯人，却抓到爱人！                                                                    \u3000\u3000'
          '一场枪杀命案，死了一个警察和一个黑道老大，背后隐藏什么秘密？唯一的生还者如今成了行天盟当家少主唐毅（吴承洋饰演），唐毅设局抓凶手报仇，正义刑警孟少飞（徐钧浩饰演）在追查命案真相的过程中逐步陷入唐毅的「爱情圈套」。',
 'is_new': False,
 'name': 'HIStory3-圈套',
 'platforms': '',
 'publishdate': '2019-04-16',
 'rate': 7.7,
 'sectionid': 'rrmj_1904',
 'tags': ['剧情', '爱情', '同性', '犯罪'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30373690/'}
2020-04-30 14:24:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%A4%A9%E7%A9%BA%E4%B9%8B%E5%9F%8E> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:24:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%98%8E%E6%97%A5%E5%AE%B6%E6%97%8F> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:24:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%B7%B1%E8%93%9D%E4%B9%8B%E5%90%BB> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:24:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%88%B1%E6%83%85%E6%95%88%E5%BA%94> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:24:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%BC%98%E6%9D%A5%E8%AA%93%E4%BD%A0> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:24:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%B6%85%E8%83%BD%E8%AD%A6%E6%8E%A2> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:24:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%B8%89%E9%87%8D%E6%9A%A7%E6%98%A7> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:24:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%BC%BC%E6%87%82%E9%9D%9E%E6%87%82> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:24:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%BF%AF%E7%9E%B0%E5%BE%B7%E5%9B%BD> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:24:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%8C%BB%E7%94%9F%E8%80%80%E6%B1%89> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:24:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%A4%8D%E4%BB%87%E7%AC%94%E8%AE%B0> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:24:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%AE%8C%E7%BE%8E%E4%B8%96%E7%95%8C> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:24:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%AF%BB%E7%88%B1%E6%B3%95%E6%9C%AF> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:24:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%BD%BC%E5%B2%B8%E4%B9%8B%E5%AB%81> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:24:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%80%AA%E5%A5%87%E8%83%8C%E5%90%8E> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:24:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%97%A0%E4%BA%BA%E7%9F%A5%E6%99%93> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:24:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%97%A5%E6%9C%AC%E4%B9%8B%E8%80%BB> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:24:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%9C%AB%E4%BB%A3%E6%B2%99%E7%9A%87> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:25:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%BB%91%E6%9D%BF%E5%B0%91%E5%B9%B4> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:25:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%82%AB%E8%BD%A6%E9%85%B7%E9%A9%BE> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:25:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%99%BD%E8%89%B2%E5%B7%A8%E5%A1%94> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:25:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%9B%91%E5%AE%88%E8%87%AA%E7%9B%97> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:25:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%9D%80%E8%A3%85%E5%AE%88%E5%88%99> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:25:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%A5%9E%E6%8E%A2%E6%9E%97%E8%82%AF> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:25:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%A6%81%E5%BF%8C%E5%A5%B3%E5%AD%A9> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:25:19 [scrapy.extensions.logstats] INFO: Crawled 680 pages (at 25 pages/min), scraped 345 items (at 1 items/min)
2020-04-30 14:25:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%BB%9D%E5%AF%B9%E8%BE%BE%E4%BB%A4> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:25:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%BB%BF%E5%85%89%E6%A3%AE%E6%9E%97> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:25:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%BB%BF%E5%8C%96%E4%B8%96%E7%95%8C> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:25:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%BE%8E%E5%9B%BD%E5%B7%A5%E5%8E%82> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:25:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%BE%8E%E9%A3%9F%E4%B8%8D%E7%BE%8E> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:25:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%A7%A6%E5%8F%8A%E7%9C%9F%E5%BF%83> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:25:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%AF%B7%E8%9E%8D%E5%8C%96%E6%88%91> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:25:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E9%87%8E%E7%94%9F%E4%B8%96%E7%95%8C> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:25:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E9%87%91%E9%92%B1%E6%B8%B8%E6%88%8F> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:25:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%BC%8A%E5%8D%A1%E6%B4%9B%E6%96%AF> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:25:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%8D%96%E8%BA%AB%E7%94%B7%E5%AD%90> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:25:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%90%8C%E5%BF%97%E5%AE%9D%E8%B4%9D> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:25:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%9C%A3%E6%B4%81%E5%9C%B0%E7%8B%B1> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:25:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/1292401/> (referer: https://www.douban.com/search?q=%E7%9C%9F%E7%88%B1%E8%87%B3%E4%B8%8A)
2020-04-30 14:25:47 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/1292401/>
{'cover': 'http://img.rr.tv/album/20191018/o_1571382762803.jpg',
 'data_type': 'movie',
 'id': 'rrmj_16229',
 'intro': '这是一出10个爱情故事串成的喜剧杂烩：                                                                    \u3000\u3000'
          '失去母亲的小男孩终日郁郁寡欢，继父不知该如何安慰。当他得知继子喜欢上学校里最美的女孩，便热烈地鼓励儿子去追。小男孩为了赢得小女孩的关注，废寝忘食地练习架子鼓，只为了在圣诞节的晚会上能与她同台演出。勇敢的他，甚至为了最后的一记道别潇 '
          '洒地突破机场的安检区。                                                                    \u3000\u3000'
          '两个孩子的母亲面对了婚姻危机。丈夫感情出轨，把项链送给了别的女人，给她的，则仅是一张她热爱的女歌手的CD。她找了借口仓皇躲入卧室，在歌声中隐忍啜泣。转个身，又夸张地大笑着，迎向娇女爱子欢喜的面容。 '
          '丈夫最终幡然醒悟。                                                                    \u3000\u3000'
          '……                                                                    \u3000\u3000'
          '如此的小故事共有十出，温暖你我的心。',
 'is_new': False,
 'name': '真爱至上',
 'platforms': '',
 'publishdate': '2003-09-07',
 'rate': 8.6,
 'sectionid': 'rrmj_1917',
 'tags': ['剧情', '喜剧', '爱情'],
 'type': 'movie',
 'url': 'https://movie.douban.com/subject/1292401/'}
2020-04-30 14:25:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/1308817/> (referer: https://www.douban.com/search?q=%E4%B8%A4%E5%B0%8F%E6%97%A0%E7%8C%9C)
2020-04-30 14:25:48 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/1308817/>
{'cover': 'http://img.rr.tv/album/20191016/o_1571215867558.jpg',
 'data_type': 'movie',
 'id': 'rrmj_16189',
 'intro': '当一个人问另一个人“敢不敢”的时候，另一个人必须说“敢”，这就是游戏的规则。小男孩于连和小女孩苏菲的相遇即开始于这样一场孩童的闹剧，一个精美的铁盒子就是他们游戏的见证。说脏话，扰乱课堂，在校长室小便，内衣外穿……一个游戏两人一玩十多年，他们什么都敢，除了承认彼此相爱。                                                                            \u3000\u3000'
          '苏菲（玛丽昂·歌迪亚 Marion Cotillard 饰）提议两人分别四年，挑战的内容是于连（吉约姆·卡内 Guillaume '
          'Canet '
          '饰）敢不敢伤害苏菲。恍惚四年逝去，于连找到苏菲，为了游戏的进行他决定另娶她人，邀请苏菲做伴娘。受到伤害的苏菲在于连的婚礼上抛出铁盒子“你敢悔婚么？”原本最最亲密的朋友相互伤害最深。同样心痛的两个人相约再次分别十年。                                                                            \u3000\u3000'
          '十年里，于连拥有了一切，家庭、事业、朋友，只是没了苏菲宛如没了心，原来丧失激情的生活这般索然无味。                                                                            \u3000\u3000'
          '终于十年过去，“Love me,...',
 'is_new': False,
 'name': '两小无猜',
 'platforms': '',
 'publishdate': '2003-09-17',
 'rate': 8.1,
 'sectionid': 'rrmj_1729',
 'tags': ['剧情', '喜剧', '爱情'],
 'type': 'movie',
 'url': 'https://movie.douban.com/subject/1308817/'}
2020-04-30 14:25:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%9D%9A%E5%BC%BA%E4%B9%8B%E5%B2%9B> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:25:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/6146955/> (referer: https://www.douban.com/search?q=%E5%AF%BF%E5%8F%B8%E4%B9%8B%E7%A5%9E)
2020-04-30 14:25:51 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/6146955/>
{'cover': 'http://img.rr.tv/album/20180517/o_1526542837295.jpg',
 'data_type': 'movie',
 'id': 'rrmj_12221',
 'intro': '《寿司之神》是由大卫·贾柏拍摄的一部关于寿司的纪录片。他是一个道道地地的纽约客！从小热爱寿司的他被小野二郎的职人精神而感动，干脆扛着摄影机至日本拍摄。                                                                    \u3000\u3000'
          '现年86岁的小野二郎是全球最年长的三星大厨，被称为“寿司之神”。在日本地位崇高，“寿司第一人”的美誉更远播全世界。终其一生，他都在握寿司，永远以最高标准要求自己跟学徒，观察客人的用餐状况微调寿司，确保客人享受到究极美味，甚至为了保护创造寿司的双手，不工作时永远带着手套，连睡觉也不懈怠。                                                                    \u3000\u3000'
          '他的寿司店“数寄屋桥次郎”远近驰名，从食材、制作到入口瞬间，每个步骤都经过縝密计算。这间隐身东京办公大楼地下室的小店面，曾连续两年荣获美食圣经《米其林指南》三颗星最高评鉴。被誉为值得花一辈子排队等待的美味。',
 'is_new': False,
 'name': '寿司之神',
 'platforms': '',
 'publishdate': '2011-11-08',
 'rate': 8.7,
 'sectionid': 'rrmj_1883',
 'tags': ['纪录片'],
 'type': 'movie',
 'url': 'https://movie.douban.com/subject/6146955/'}
2020-04-30 14:25:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%A4%A7%E8%B1%A1%E5%A5%B3%E7%8E%8B> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:25:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%94%BE%E5%BC%83%E6%B1%82%E7%94%9F> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:25:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%9C%88%E4%BA%8B%E9%9D%A9%E5%91%BD> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:25:59 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/687788/> (referer: https://www.douban.com/search?q=%E7%BC%98%E6%9D%A5%E8%AA%93%E4%BD%A0)
2020-04-30 14:25:59 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/687788/>: HTTP status code is not handled or not allowed
2020-04-30 14:26:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%9D%80%E6%88%AE%E6%BC%94%E7%BB%8E> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:26:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/3158990/> (referer: https://www.douban.com/search?q=%E6%B5%B7%E8%A7%92%E4%B8%83%E5%8F%B7)
2020-04-30 14:26:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/3158990/>
{'cover': 'http://img.rr.tv/cover/20191102/o_1572680206554.webp',
 'data_type': 'movie',
 'id': 'rrmj_16459',
 'intro': '依傍大海的美丽小镇恒春上，音乐梦想在台北遭受打击的年轻人阿嘉（范逸臣）冷眼旁观着一切。虽在民代主席后父的帮忙下成了代班邮差，信件和邮包却被他乱堆在房间，而对一个寄自日本的无法送至的邮包，他也没按老邮差茂伯（林宗仁）的吩咐将之退回，而是私自拆阅查看：里面除一张泛黄的少女照片，是几封写于60年前的信件。其时日本在二战中战败，在台日籍教师（中孝介）随日军撤退时遗弃了相约私奔的女友，归日途中，他将爱意和悔意化为文字，但信件直到去世才被其女儿代为寄出。                                                                            \u3000\u3000'
          '在台湾留学、工作的日本女孩友子（田中千绘）有心成为模特，却被认为形象过时只能做负责日本超级“疗伤歌手”中孝介（中孝介）在恒春的演出事宜的公关。按惯例，中孝介演出之前会有乐团暖场，友子原本联络了日本某乐团，但民代坚持用本地乐团，友子无奈与包括阿嘉在内的几个年龄、工作、个性都有较大差异的当地音乐爱好者——因意外事件...',
 'is_new': False,
 'name': '海角七号',
 'platforms': '',
 'publishdate': '2008-08-22',
 'rate': 7.5,
 'sectionid': 'rrmj_1729',
 'tags': ['剧情', '喜剧', '爱情'],
 'type': 'movie',
 'url': 'https://movie.douban.com/subject/3158990/'}
2020-04-30 14:26:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%88%B1%E7%9A%84%E7%9D%80%E9%99%86> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:26:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/5207904/> (referer: https://www.douban.com/search?q=%E6%B5%A9%E5%8A%AB%E6%B1%82%E7%94%9F)
2020-04-30 14:26:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/5207904/>
{'cover': 'http://img.rr.tv/album/20180528/o_1527496386406.jpg',
 'data_type': 'movie',
 'id': 'rrmj_623',
 'intro': '摘要                                                                            \u3000\u3000'
          '浩劫求生，又名：灾难求生，英文名：Surviving '
          'Disaster，是美国探索频道推出的一部，模拟真实生活环境下的灾难系列教学纪录片。由前海豹突击队员凯德·科特立主持。每集模拟一个灾难，都会假设是最坏的条件下的状况，会教你如何利用最新的求生知识和军队技巧，让你在浩劫面前，顺利逃生！ '
          '目前，浩劫求生已播出10集，第二季暂时未听说有。                                                                            \u3000\u3000'
          '编辑本段情节概要                                                                            \u3000\u3000                                                                            \u3000\u3000'
          '每一集，主持人凯德·科特立，将会和五个人进入一个或者多个相同类型的灾难模拟当中。支持人将全程参与到节目中，但是主要给予其他五个人一些指导，并且会不定时提示要点和注意的地方。此外，还将采访一些相关的专家和类似灾难的幸存者，对一些专业名词等进行解析和讲述灾难发生时的经历。 \u3000\u3000'
          '有时，在一集节目中也会模拟多个类似的灾难的不同情境：比如在“毒气攻击”中分别说了流行病疫情和在地铁内的人为释放毒气两个灾难...',
 'is_new': False,
 'name': '浩劫求生',
 'platforms': '',
 'publishdate': '2009-09-01',
 'rate': 9.5,
 'sectionid': 'rrmj_1693',
 'tags': ['动作', '纪录片', '冒险'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/5207904/'}
2020-04-30 14:26:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%B4%A7%E6%80%A5%E6%95%91%E5%91%BD> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:26:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%BA%BD%E7%BA%A6%E9%BC%A0%E6%82%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:26:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/1291583/> (referer: https://www.douban.com/search?q=%E5%A4%A9%E7%A9%BA%E4%B9%8B%E5%9F%8E)
2020-04-30 14:26:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/1291583/>
{'cover': 'http://img.rr.tv/album/20181112/o_1542001610961.jpg',
 'data_type': 'movie',
 'id': 'rrmj_13526',
 'intro': '古老帝国拉比达是一座漂浮在空中的巨大的机器岛，传说那里已经无人居住，蕴藏着巨大的财富。因此，无论军方还是海盗，都在找寻着这座传说中的飞行岛。                                                                    \u3000\u3000'
          '矿工帕克这天偶遇拉比达继承人希达，两人一见如故。因为希达身上有找寻拉比达帝国的重要物件飞行石，军方和海盗两帮人马都在追杀希达。帕克带着希达一起逃亡，最终都没有逃出军方的手中，希达被军队掳走了。                                                                    \u3000\u3000'
          '为救朋友，帕克只能选择与海盗合作。帕克与海盗成功救出了希达，同时，他们也发现了军方的邪恶计划。为了阻止军方邪恶计划的实施，他们和海盗一起踏上了寻找拉比达之旅。',
 'is_new': False,
 'name': '天空之城',
 'platforms': '',
 'publishdate': '1992-05-01',
 'rate': 9.1,
 'sectionid': 'rrmj_747',
 'tags': ['动画', '奇幻', '冒险'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/1291583/'}
2020-04-30 14:26:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%9C%82%E8%9C%9C%E4%B9%8B%E5%9C%B0> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:26:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/19973780/> (referer: https://www.douban.com/search?q=%E8%8F%B2%E6%B4%9B%E6%A2%85%E5%A8%9C)
2020-04-30 14:26:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/19973780/>
{'cover': 'http://img.rr.tv/cover/20191106/o_1573031514186.webp',
 'data_type': 'movie',
 'id': 'rrmj_16512',
 'intro': '1952年的爱尔兰，社会风气保守。少女菲洛米娜（朱迪·丹奇 Judi Dench '
          '饰）因未婚怀孕，被家人送往修道院从事苦役，每天只有1小时与爱子安东尼相处。在安东尼3岁的时候，他被修女们强行抱走，送往美国寄养家庭。此后整整五十年菲洛米娜都沉浸在对爱子的思念中。她将故事告诉了一位记者马汀（史蒂夫·库根 '
          'Steve Coogan '
          '饰），后者决定与她一同踏上寻子之旅。这对个性迥异、看似不可能成立的搭档，在希望与失落之间，展开的不只是慈母寻子的冒险，更是跨越友谊的见证。菲洛米娜慢慢了解到儿子不平凡的一生和鲜为人知的秘密，她这份迟来的爱能传递到失散多年的安东尼身上吗？                                                                            \u3000\u3000                                                                            \u3000\u3000'
          '《菲洛梅娜》改编自 '
          'BBC记者马汀·斯克斯史密斯的纪实文学《菲洛梅娜遗失的孩子》，取材自真人真事。电影围绕一位母亲半个世纪后的跨海寻子，用喜剧的外观包装悲剧故事，让人在笑泪交织中收获感动，并且...',
 'is_new': False,
 'name': '菲洛梅娜',
 'platforms': '',
 'publishdate': '2013-08-31',
 'rate': 8.4,
 'sectionid': 'rrmj_1729',
 'tags': ['剧情', '同性', '家庭', '传记'],
 'type': 'movie',
 'url': 'https://movie.douban.com/subject/19973780/'}
2020-04-30 14:26:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26304901/> (referer: https://www.douban.com/search?q=%E5%A4%84%E5%AD%90%E4%B9%8B%E5%B1%B1)
2020-04-30 14:26:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26304901/>
{'cover': 'http://img.rr.tv/album/20191018/o_1571388223806.webp',
 'data_type': 'movie',
 'id': 'rrmj_16240',
 'intro': '已过不惑之年的单身狗Fúsi 是一个机场搬运工 精通机械却不善言辞 他的生活单调到除了工作就是金属乐，各种模型手办 '
          '在家人的鼓动下他尝试去了一个舞蹈班并终于认识了妹子 但害羞怯懦的他最后能走出自己的世界吗',
 'is_new': False,
 'name': '处子之山',
 'platforms': '',
 'publishdate': '2015-02-09',
 'rate': 8.7,
 'sectionid': 'rrmj_1729',
 'tags': ['剧情'],
 'type': 'movie',
 'url': 'https://movie.douban.com/subject/26304901/'}
2020-04-30 14:26:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%B6%85%E7%BA%A7%E4%B8%AD%E5%9B%BD> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:26:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%BF%AA%E5%A5%A5%E4%B8%8E%E6%88%91> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:26:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/34617196/> (referer: https://www.douban.com/search?q=%E6%A2%A8%E6%B3%B0%E9%99%A2Class)
2020-04-30 14:26:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/34617196/>
{'cover': 'http://img.rr.tv/cover/20200117/o_1579231171388.jpg',
 'data_type': 'movie',
 'id': 'rrmj_16969',
 'intro': '改编自同名网漫，讲述在不合理的世上，因为意志和活力聚集在一起的年轻人们的“hip”的反叛故事。在微缩世界梨泰院这个小街道上，自由追求着各自价值观，谱写创业神话。                                                                    \u3000\u3000'
          '朴叙俊饰演朴塞路，他是不会对不正义妥协的直进型青年，因为无法抹去的愤怒他投身到梨泰院，开始挑战全新的梦想，他将会对餐饮界大企业“张家”展开痛快的反击。                                                                    \u3000\u3000'
          '金多美饰演赵以瑞，她是有着神赐予的头脑的“高智能”且具备独特魅力的人物，是SNS明星也是网络影响力人物，具备天使般的外貌和反转性格。她和朴塞路因为恶缘而结缘并一起在梨泰院发展。                                                                    \u3000\u3000'
          '刘在明饰演餐饮界大企业“张家”的会长张大熙，他因为小时候饿肚子的记忆所以投身餐饮业，凭借一己之力成为以他为中心的财阀，是一个权威主义者。因为儿子的意外，他再次和眼中钉朴塞路争锋相对，如同铁壁的他的人生逐渐动摇。',
 'is_new': False,
 'name': '梨泰院Class',
 'platforms': '',
 'publishdate': '2020-01-31',
 'rate': 8.8,
 'sectionid': 'rrmj_1726',
 'tags': ['剧情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/34617196/'}
2020-04-30 14:26:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E9%80%9A%E7%81%B5%E6%8A%A4%E5%A3%AB> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:26:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/2085015/> (referer: https://www.douban.com/search?q=%E7%BB%BF%E5%85%89%E6%A3%AE%E6%9E%97)
2020-04-30 14:26:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/2085015/>
{'cover': 'http://img.rr.tv/cover/20200416/o_1587022214564.png',
 'data_type': 'movie',
 'id': 'rrmj_17515',
 'intro': '故事发生在如童话般美好的绿光森林里。美丽善良的女孩苏菲（刘品言饰）是音乐世家中的独生女，一直幸福快乐的生活。一次车祸中苏家司机不幸丧生，苏家夫妇收养了他的女儿罗珊（宋智爱饰），并为她改名为苏珊，视如己出。苏姗自卑又好强，不仅一直妒忌着苏菲生来所拥有的一切，更是对与苏菲两小无猜的靳欧文（阮经天饰）也萌生爱恋。在史宾赛皇家音乐学院，苏菲遇见了王子威廉史宾赛（立威廉饰）。                                                                    \u3000\u3000'
          '长大后，苏菲成为绿光小学的老师，苏珊成为史宾赛音乐学院的艺术总监，威廉回国继承父亲的音乐学院史宾赛，欧文学成归来成为名满世界的小提琴家。然而史宾赛学院要关掉绿光小学，对绿光小学有深厚感情的苏菲，为了守护绿光而奋斗……',
 'is_new': False,
 'name': '绿光森林',
 'platforms': '',
 'publishdate': '2005-10-23',
 'rate': 6.3,
 'sectionid': 'rrmj_1904',
 'tags': ['剧情', '爱情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/2085015/'}
2020-04-30 14:26:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/2150220/> (referer: https://www.douban.com/search?q=%E7%99%BD%E8%89%B2%E5%B7%A8%E5%A1%94)
2020-04-30 14:26:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E9%9A%90%E5%BD%A2%E6%9D%80%E6%89%8B> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:26:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/2150220/>
{'cover': 'http://img.rr.tv/album/20180505/o_1525502535718.png',
 'data_type': 'movie',
 'id': 'rrmj_12120',
 'intro': '财前五郎（唐泽寿明 饰）和里见修二（江口洋介 '
          '饰）是同期实习的医生，但二者却走上了截然不同的道路。财前凭借高超的个人技术成为了外科部实际上的第一教授。财前的咄咄逼人让即将退休的第一外科教授东真藏（石坂浩二 '
          '饰）感到威胁，东教授决定另立他人。因此极具野心的财前寻求其岳父— —财前妇产诊所院长财前又一（西田敏行 '
          '饰）和第一内科教授鹈饲（伊武雅刀 '
          '饰）的帮助，通过贿赂和拉帮结派，历经波折，最终获得了第一外科教授的职位。而他的同期，第一内科助教里见却是位实事求是，热心研究的学者。二者的不同选择导致了最后不同的命运。位高权重的财前终于到达梦想的高处，却发现不胜寒风，悲剧也因此上演。                                                                    \u3000\u3000'
          '本剧改编自山崎丰子的同名巨作。号称“日本国民级小说”。前后经历过五次翻拍，数次被搬上荧屏。内容直指医院的黑暗面，时隔多年，依旧具有现实意义。',
 'is_new': False,
 'name': '白色巨塔',
 'platforms': '',
 'publishdate': '2003-10-09',
 'rate': 9.5,
 'sectionid': 'rrmj_1646',
 'tags': ['剧情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/2150220/'}
2020-04-30 14:26:19 [scrapy.extensions.logstats] INFO: Crawled 718 pages (at 38 pages/min), scraped 356 items (at 11 items/min)
2020-04-30 14:26:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/2373162/> (referer: https://www.douban.com/search?q=%E7%BB%BF%E5%8C%96%E4%B8%96%E7%95%8C)
2020-04-30 14:26:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/2373162/>
{'cover': 'http://img.rr.tv/album/20190906/o_1567767436458.png',
 'data_type': 'movie',
 'id': 'rrmj_15142',
 'intro': 'Four adventurers descend to the depths of the ocean when the cable '
          'on their underwater diving bell snaps. The rest of their '
          'expedition, believing them to be lost, abandons hope of finding '
          'them. Exiting the diving bell, the party finds themselves in a '
          'network of underwater caverns. They encounter a shipwreck survivor. '
          'He tells them he has been there for 14 years and that there i...',
 'is_new': False,
 'name': '绿化世界',
 'platforms': '',
 'publishdate': '2018-02-23',
 'rate': 0.0,
 'sectionid': 'rrmj_1005',
 'tags': ['科幻', '冒险'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/2373162/'}
2020-04-30 14:26:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%BF%83%E8%84%8F%E4%BF%A1%E5%8F%B73> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:26:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/4843480/> (referer: https://www.douban.com/search?q=%E7%9B%91%E5%AE%88%E8%87%AA%E7%9B%97)
2020-04-30 14:26:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/4843480/>
{'cover': 'http://img.rr.tv/album/20180705/o_1530759256403.png',
 'data_type': 'movie',
 'id': 'rrmj_12601',
 'intro': '2008年，全球金融海啸，多国陷入金融危机，损失高达20万亿美元，数以百万计人加入失业大军，甚至丧失家园……本片通过详尽的资料搜集，追访全球金融业界猛人、政客、财经记者，披露金融大鳄的崛兴之路，公开业内和学界贪污腐败的政策背后的惊人真相。',
 'is_new': False,
 'name': '监守自盗',
 'platforms': '',
 'publishdate': '2010-10-08',
 'rate': 8.7,
 'sectionid': 'rrmj_1871',
 'tags': ['纪录片', '犯罪'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/4843480/'}
2020-04-30 14:26:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=BJ%E5%8D%95%E8%BA%AB%E6%97%A5%E8%AE%B0> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:26:25 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/4881630/> (referer: https://www.douban.com/search?q=%E7%82%AB%E8%BD%A6%E9%85%B7%E9%A9%BE)
2020-04-30 14:26:25 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/4881630/>: HTTP status code is not handled or not allowed
2020-04-30 14:26:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30291579/> (referer: https://www.douban.com/search?q=%E4%B8%8D%E6%9C%9F%E8%80%8C%E7%88%B1)
2020-04-30 14:26:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30291579/>
{'cover': 'http://img.rr.tv/album/20181011/o_1539244237423.jpg',
 'data_type': 'movie',
 'id': 'rrmj_12922',
 'intro': '该剧讲述在工程学院中，有八位性格迥异的男生，他们各怀不同的梦想，上演着不一样的人生。Ae（Perth-王俊勇饰）善良慷慨、不计回报，不畏权势；Pete（Saint-黄明明饰）善良，单纯，生活在象牙塔中涉世未深的懵懂少年，但勇于面对内心真实的自己；Tin（Mean-洪天逸饰）商业世家继承人，冷酷、自信。信奉人与人之间是利益关系，没有真情；Can（Plan-林乐杰饰）活泼厚脸皮、讲义气，路见不平拔刀相助，愿为朋友两肋插刀；Techno（Gun-陈智霆饰）学院足球队队长，温柔耐心，暖心的大哥哥；Kengkla（Mark-陈瑞书饰）聪明可爱、有点小腹黑。他们同在工程学院读书，虽然身份背景、性格爱好都不相同，但却不妨碍他们成为各自成长路上的小伙伴、好朋友，相互扶持、陪伴自己共同成长。',
 'is_new': False,
 'name': '不期而爱',
 'platforms': '',
 'publishdate': '2018-08-03',
 'rate': 8.6,
 'sectionid': 'rrmj_989',
 'tags': ['爱情', '同性'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30291579/'}
2020-04-30 14:26:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%B8%80%E5%90%BB%E5%AE%9A%E6%83%851> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:26:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30372302/> (referer: https://www.douban.com/search?q=%E6%B7%B1%E8%93%9D%E4%B9%8B%E5%90%BB)
2020-04-30 14:26:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30372302/>
{'cover': 'http://img.rr.tv/cover/20191009/o_1570616516789.jpg',
 'data_type': 'movie',
 'id': 'rrmj_16099',
 'intro': '《深蓝之吻》是Kiss Me series的延伸，改编自泰国同名人气小说。故事中的Kao和Pete起初互相看不顺眼，后来却激发感情。 '
          '《深蓝》描述两人交往之后的恋爱日常，男男恋爱难以向家人坦白。Pete&Kao人气CP甜蜜回归，还有暖男店长Sun收服不良少年Mork的热血爱情浪漫插曲。',
 'is_new': False,
 'name': '深蓝之吻',
 'platforms': '',
 'publishdate': '2019-10-12',
 'rate': 8.6,
 'sectionid': 'rrmj_989',
 'tags': ['爱情', '同性'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30372302/'}
2020-04-30 14:26:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%B8%89%E9%87%8D%E6%9A%A7%E6%98%A72> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:26:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%BA%BA%E7%B1%BB-%E5%8A%A8%E7%89%A9> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:26:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30488639/> (referer: https://www.douban.com/search?q=%E5%8F%8C%E5%AD%90%E5%81%B7%E5%BF%83)
2020-04-30 14:26:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30488639/>
{'cover': 'http://img.rr.tv/album/20190426/o_1556250588376.jpg',
 'data_type': 'movie',
 'id': 'rrmj_14673',
 'intro': '爱情来了第一部的主演Pak和Mild再次合体之作。                                                                            \u3000\u3000'
          'The Best '
          'Twins《双子偷心》这部剧是讲述一对双胞胎兄弟的故事。                                                                            \u3000\u3000'
          'Pond和Per是一对双胞胎兄弟，Per是弟弟喜欢女孩子，是个直男，Pond是喜欢男孩子的，Pond的男友是隔壁的邻居Bon老师。这对双胞胎的姐姐Pad反对Per和男生交往，不接受弟弟的性向，这让他们的家庭关系受到震动。                                                                            \u3000\u3000'
          '不仅如此，当Pond的前男友Tee回来时，让事情变得更复杂。Pond在现任男友，前男友和姐姐之间的关系让他感到崩溃。                                                                            \u3000\u3000'
          '在剧集中，哥哥Pond是大学教授，弟弟Per是电影编辑，虽然他们的姐姐Pad很反对弟弟是个gay，但是Pad内心是十分疼爱两个弟弟，Pad的职业是高中老师。                                                                            \u3000\u3000'
          'Mild扮演的Tee是Per的前男友，是一名大学生，究竟这对双胞胎兄弟将如何处理生活和情感上的这几层关系呢？一切答案让我们期待3月30...',
 'is_new': False,
 'name': '双子偷心',
 'platforms': '',
 'publishdate': '2019-03-30',
 'rate': 5.6,
 'sectionid': 'rrmj_989',
 'tags': ['爱情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30488639/'}
2020-04-30 14:26:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%A9%BA%E7%99%BD%E7%9A%8413%E5%B9%B4> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:26:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/33218295/> (referer: https://www.douban.com/search?q=%E7%88%B1%E6%83%85%E6%95%88%E5%BA%94)
2020-04-30 14:26:34 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/33218295/>
{'cover': 'http://img.rr.tv/cover/20190919/o_1568874061248.jpg',
 'data_type': 'movie',
 'id': 'rrmj_15913',
 'intro': '泰剧爱情效应是根据泰国网络小说《The '
          'Effect》改编而成。                                                                    \u3000\u3000'
          'Keng是这所学校里人见人爱花见花开的大帅哥，不仅学习厉害各方面都非常优秀。                                                                    \u3000\u3000'
          'Chin是一个不善于交谈的大一新生，经常最好的朋友Pramote待在一起。                                                                    \u3000\u3000'
          '突然有一天Chin不小心撞到了Keng，当他和他相遇之后，两人之间多次的相见让他们很快的有了好感，但是偶然的间他们相依相偎的照片被上传到网络之后，一瞬间都在讨论Chin和Keng的事情，网络的暴力让Chin无法承受，所以决定和Keng分手，但是Keng非常的喜欢Chin所有在情急之下Keng就把Chin给强奸了，他们的爱情看似非常的偶然，其实他们是双向暗恋哟，他们的爱情虽然坎坷备受网友的质疑，他们的爱情能否不顾世俗的眼光而成功走向胜利吗？这个8月敬请期待……',
 'is_new': False,
 'name': '爱情效应',
 'platforms': '',
 'publishdate': '2019-10-11',
 'rate': 8.0,
 'sectionid': 'rrmj_989',
 'tags': ['爱情', '同性'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/33218295/'}
2020-04-30 14:26:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%AF%BB%20%E7%AC%AC%E4%BA%8C%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:26:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/33418663/> (referer: https://www.douban.com/search?q=%E5%9B%A0%E4%B8%BA%E6%83%B3%E4%BD%A0)
2020-04-30 14:26:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/33418663/>
{'cover': 'http://img.rr.tv/album/20190429/o_1556510626519.jpg',
 'data_type': 'movie',
 'id': 'rrmj_14686',
 'intro': '我想我喜欢的始终是那份像夏天一样炙热的感情。至于白船他们作为演员不可能永远只被这两个角色困住，当我看到预告的时候先是激动万分，随即有一点失落，因为我很难从现在这个英俊帅气的船身上找到闹闹的青涩和烂漫。那个小平头200斤大腿和基友们弹吉他唱歌的音乐社社长，长大了更帅气也更成熟了。这可能是成长的过程是不可逆的，所以我想算了船会长大，闹闹又何尝不是呢，能够现在发糖让我们怀念一下初心，怀念一下曾经追剧的欢乐时光也没什么不好。而白白深情的杏仁眼真的还是那个学生会秘书长啊～',
 'is_new': False,
 'name': '因为想你',
 'platforms': '',
 'publishdate': '2019-04-17',
 'rate': 6.8,
 'sectionid': 'rrmj_989',
 'tags': ['剧情', '同性'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/33418663/'}
2020-04-30 14:26:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%8A%B1%E8%BF%87%E5%A4%A9%E6%99%B4%20> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:26:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/34894678/> (referer: https://www.douban.com/search?q=%E6%98%8E%E6%97%A5%E5%AE%B6%E6%97%8F)
2020-04-30 14:26:39 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/34894678/>
{'cover': 'http://img.rr.tv/cover/20200107/o_1578385259299.jpg',
 'data_type': 'movie',
 'id': 'rrmj_16978',
 'intro': '小野寺理纱（宫崎葵饰）四年前在婚礼上遭遇新郎逃婚，现如今心情已经平复，一直跟父母生活在一起。其父亲俊作（松重丰饰）曾经是糕点生产公司的营业部部长，现因人事变动被调到了其他的部门，而该部门新上任的部长就是俊作曾经的下属兵头幸太郎（永山瑛太饰）。其母真知子（松坂庆子饰）是一个性格开朗的家庭主妇，经常去仓桥响子（一路真辉饰）开的插花班上课。仓桥响子的前夫村上洋一（六平直政饰）是俊作的发小兼前辈，他经营了一家小酒馆，俊作是他家的常客。                                                                            \u3000\u3000'
          '四年前父亲俊作为了想和女儿女婿住在一起建了一栋双户型的别墅，然而因为理纱被逃婚，现在就理纱、俊作以及真知子，这一家三口住在别墅里。某天理纱说自己被求婚了，要带个对象回来给俊作和真知子看看，谁知带回来的人竟然是兵头幸太郎。之前的下属，现如今成了自己的上司兼准女婿……                                                                            \u3000\u3000'
          '理纱和幸太郎的感情究竟会如何发展？理纱、幸太郎会和俊作及真知子...',
 'is_new': False,
 'name': '明日家族',
 'platforms': '',
 'publishdate': '2020-01-05',
 'rate': 8.1,
 'sectionid': 'rrmj_745',
 'tags': ['剧情', '家庭'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/34894678/'}
2020-04-30 14:26:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%97%B6%E5%B0%9A%E5%A4%A7%E5%B8%9D%20> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:26:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/34908103/> (referer: https://www.douban.com/search?q=%E8%B6%85%E8%83%BD%E8%AD%A6%E6%8E%A2)
2020-04-30 14:26:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/34908103/>
{'cover': 'http://img.rr.tv/cover/20200224/o_1582513500113.jpg',
 'data_type': 'movie',
 'id': 'rrmj_17222',
 'intro': '该剧改编自同名人气网漫，讲述失忆的超能力刑警“东柏”遇到连续杀人事件后发生的故事。                                                                    \u3000\u3000'
          '由电影《邻居》《石雕宅邸杀人案》的金辉导演、《恩珠的房间》苏在贤导演共同执导，2020年播出。',
 'is_new': False,
 'name': '超能警探',
 'platforms': '',
 'publishdate': '2020-03-11',
 'rate': 8.0,
 'sectionid': 'rrmj_745',
 'tags': ['悬疑', '犯罪', '奇幻'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/34908103/'}
2020-04-30 14:26:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/3184572/> (referer: https://www.douban.com/search?q=%E7%B4%A7%E6%80%A5%E6%95%91%E5%91%BD)
2020-04-30 14:26:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/3184572/>
{'cover': 'http://img.rr.tv/album/20180504/o_1525417199063.webp',
 'data_type': 'movie',
 'id': 'rrmj_12110',
 'intro': '拥有直升机紧急救援的大学附属医院迎来了一批实习医生。他们分别是蓝泽耕作（山下智久 饰）、白石惠（新垣结衣 饰）、绯山美帆子（户田绘里香 '
          '饰）和滕川一男（浅利阳介 '
          '饰）。直升机每天平均运送7到8个急救患者，能协助医生坐上直升飞机是对其应变能力和医术的证明，大家都跃跃欲试。                                                                    \u3000\u3000'
          '四人的性格各不相同。蓝泽最有能力但过于冷静；白石理论知识很强但缺乏魄力；绯山表现欲强但易冲动；滕川则相对平庸做事马虎。最初开始的紧急救援让大家手忙脚乱，看似拉风的直升机需要与之相应的能力与魄力。在一系列救援的过程中，他们直面死亡与无奈，也鉴证奇迹，体味人情。互为竞争对手的他们，谁能最终留下来？还是携手共进？',
 'is_new': False,
 'name': '紧急救命',
 'platforms': '',
 'publishdate': '2008-07-03',
 'rate': 8.2,
 'sectionid': 'rrmj_1646',
 'tags': ['剧情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/3184572/'}
2020-04-30 14:26:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/1304585/> (referer: https://www.douban.com/search?q=BJ%E5%8D%95%E8%BA%AB%E6%97%A5%E8%AE%B0)
2020-04-30 14:26:47 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/1304585/>
{'cover': 'http://img.rr.tv/album/20191015/o_1571110114218.jpg',
 'data_type': 'movie',
 'id': 'rrmj_16158',
 'intro': '布里奇特•琼斯（蕾妮•齐维格 '
          '饰）是一个32岁的单身女子。她的工作及生活都是平淡无奇的，她唯一想得到一份真挚的爱情，就算有一众好友在身边及时安慰，布里奇特还是没有好过点。新的一年里，她要过一种新的生活。她选择用日记把自己生活里的点点滴滴都记录下来，她开始变得喜悦起来。                                                                    \u3000\u3000'
          '这时在她与风流倜傥的上司丹尼尔•克里弗（休•格兰特 '
          '饰）产生了感情，丹尼尔原来早与女友订婚，使布里奇特伤心不已。高傲却真实的马克•达西（科林•菲尔斯 '
          '饰）也表示对她的爱慕之情。布里奇特周旋在两个男人之间，不知如何选择。',
 'is_new': False,
 'name': 'BJ单身日记',
 'platforms': '',
 'publishdate': '2001-04-04',
 'rate': 8.0,
 'sectionid': 'rrmj_1729',
 'tags': ['喜剧', '爱情'],
 'type': 'movie',
 'url': 'https://movie.douban.com/subject/1304585/'}
2020-04-30 14:26:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/5907534/> (referer: https://www.douban.com/search?q=%E5%8D%96%E8%BA%AB%E7%94%B7%E5%AD%90)
2020-04-30 14:26:50 [scrapy.core.scraper] ERROR: Error processing {'cover': 'http://img.rr.tv/album/20190613/o_1560419542385.webp',
 'data_type': 'movie',
 'id': 'rrmj_15083',
 'intro': 'An intimate and unflinching look over 12 months at the hardscrabble '
          'lives of hustlers in downtown Montreal.',
 'is_new': False,
 'name': '卖身男子',
 'platforms': '',
 'publishdate': '',
 'rate': 7.3,
 'sectionid': 'rrmj_1416',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/5907534/'}
Traceback (most recent call last):
  File "/usr/python37/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/python37/lib/python3.7/site-packages/scrapy/utils/defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/root/spider/scrapyspider/spiderV1/pipelines.py", line 262, in process_item
    timeStruct = time.strptime(publishdate, '%Y-%m-%d')
  File "/usr/python37/lib/python3.7/_strptime.py", line 571, in _strptime_time
    tt = _strptime(data_string, format)[0]
  File "/usr/python37/lib/python3.7/_strptime.py", line 359, in _strptime
    (data_string, format))
ValueError: time data '' does not match format '%Y-%m-%d'
2020-04-30 14:26:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/10787752/> (referer: https://www.douban.com/search?q=%E4%BF%AF%E7%9E%B0%E5%BE%B7%E5%9B%BD)
2020-04-30 14:26:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/10787752/>
{'cover': 'http://img.rr.tv/album/20190906/o_1567768083406.png',
 'data_type': 'movie',
 'id': 'rrmj_15136',
 'intro': '俯瞰德国第一季分城市、乡村、河流三集不同地貌特征鸟瞰全景，在展示自然景致的同时，也涉及到很多当代科技和历史文化，是一部很不错的国家形象宣传片。',
 'is_new': False,
 'name': '俯瞰德国',
 'platforms': '',
 'publishdate': '2010-05-23',
 'rate': 9.2,
 'sectionid': 'rrmj_1005',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/10787752/'}
2020-04-30 14:26:54 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/27028198/> (referer: https://www.douban.com/search?q=%E7%9D%80%E8%A3%85%E5%AE%88%E5%88%99)
2020-04-30 14:26:54 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/27028198/>: HTTP status code is not handled or not allowed
2020-04-30 14:26:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27183365/> (referer: https://www.douban.com/search?q=%E6%80%AA%E5%A5%87%E8%83%8C%E5%90%8E)
2020-04-30 14:26:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/27183365/>
{'cover': 'http://img.rr.tv/album/20190509/o_1557389195531.png',
 'data_type': 'movie',
 'id': 'rrmj_14783',
 'intro': 'Netflix叫好叫座剧《怪奇物语 Stranger '
          'Things》第二季即将上线，而该媒体表示紧接主剧上线后，其访谈节目《Beyond Stranger '
          'Things》亦会同日上线。《怪奇背后》由编剧/制作人/演员Jim Rash主持，会有幕后故事﹑第二季分析及解答一些问题。',
 'is_new': False,
 'name': '怪奇背后',
 'platforms': '',
 'publishdate': '2017-10-27',
 'rate': 8.8,
 'sectionid': 'rrmj_1405',
 'tags': ['脱口秀'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/27183365/'}
2020-04-30 14:27:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27186532/> (referer: https://www.douban.com/search?q=%E5%A4%8D%E4%BB%87%E7%AC%94%E8%AE%B0)
2020-04-30 14:27:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/27186532/>
{'cover': 'http://img.rr.tv/album/20180530/o_1527670847400.jpg',
 'data_type': 'movie',
 'id': 'rrmj_12313',
 'intro': '讲述了一个爱管闲事,平凡的女高中生,通过某一天给自己的复仇笔记软件解决了自己冤屈的事情,明白了家人和朋友的珍贵,自我成长的故事。',
 'is_new': False,
 'name': '复仇笔记',
 'platforms': '',
 'publishdate': '2017-10-27',
 'rate': 8.0,
 'sectionid': 'rrmj_1244',
 'tags': ['剧情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/27186532/'}
2020-04-30 14:27:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27611421/> (referer: https://www.douban.com/search?q=%E6%BB%91%E6%9D%BF%E5%B0%91%E5%B9%B4)
2020-04-30 14:27:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/27611421/>
{'cover': 'http://img.rr.tv/album/20190717/o_1563347739090.jpg',
 'data_type': 'movie',
 'id': 'rrmj_15359',
 'intro': '导演刘冰将镜头对准了从小与自己一起玩滑板的好友们。年纪最大的Zack初为人父，新生儿的降临似乎让Zack一夜之间长大，但随之而来的生存压力与家庭矛盾也让他接近崩溃。Keira刚刚成年，初入社会的他充满迷茫，纪录片的拍摄给了他重新审视自己的过往与家庭，以及周遭一切的契机。刘冰也交出镜头，讲述了自己的故事，是什么让他选择了滑板？又是什么促使他拍摄了这部纪录片？',
 'is_new': False,
 'name': '滑板少年',
 'platforms': '',
 'publishdate': '2018-01-21',
 'rate': 8.7,
 'sectionid': 'rrmj_1657',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/27611421/'}
2020-04-30 14:27:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30127189/> (referer: https://www.douban.com/search?q=%E7%BE%8E%E9%A3%9F%E4%B8%8D%E7%BE%8E)
2020-04-30 14:27:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30127189/>
{'cover': 'http://img.rr.tv/album/20180704/o_1530666490901.jpg',
 'data_type': 'movie',
 'id': 'rrmj_12562',
 'intro': 'NetFlix原创纪录片，味道至上，绝不废话。明星大厨 David Chang '
          '带朋友们踏上令人口水直流的跨文化之旅，探寻世上最令人满意的美味佳肴。',
 'is_new': False,
 'name': '美食不美',
 'platforms': '',
 'publishdate': '2018-02-23',
 'rate': 8.8,
 'sectionid': 'rrmj_1883',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30127189/'}
2020-04-30 14:27:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30171321/> (referer: https://www.douban.com/search?q=%E7%BB%9D%E5%AF%B9%E8%BE%BE%E4%BB%A4)
2020-04-30 14:27:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30171321/>
{'cover': 'http://img.rr.tv/album/20190510/o_1557459792403.jpg',
 'data_type': 'movie',
 'id': 'rrmj_14628',
 'intro': '该剧是由日本人气漫画《绝对达令》改编，讲述了因受情伤变得心硬如铁的特殊化妆师多多，在大明星马王俊和恋爱用人偶英久之间纠缠不断的恋爱故事的奇幻浪漫喜剧。',
 'is_new': False,
 'name': '绝对达令',
 'platforms': '',
 'publishdate': '2019-05-15',
 'rate': 6.9,
 'sectionid': 'rrmj_1244',
 'tags': ['喜剧', '爱情', '科幻', '奇幻'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30171321/'}
2020-04-30 14:27:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30263943/> (referer: https://www.douban.com/search?q=%E6%97%A5%E6%9C%AC%E4%B9%8B%E8%80%BB)
2020-04-30 14:27:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30263943/>
{'cover': 'http://img.rr.tv/album/20180808/o_1533695713924.jpg',
 'data_type': 'movie',
 'id': 'rrmj_12934',
 'intro': '这部电影讲述了一位29岁的日本记者伊藤诗织的动人故事，她声称自己是在2015年的一次工作晚餐会上被时任东京广播公司华盛顿分社的社长、日本首相安倍晋三的传记作者山口敬之强奸。但山口先生强烈否认了这一说法。                                                                    \u3000\u3000'
          '尽管向警方报案，但警方要求伊藤用真人大小的娃娃重新模拟所谓的强奸案，该案件经过一年的调查后被撤销。当伊藤采取前所未有的决定公开她的指控并揭露她的身份时，她遭到了公开的羞辱和仇恨邮件。                                                                    \u3000\u3000'
          '这部影片在上映后的一年内，以独特的方式记录了伊藤。虽然全球MeToo运动激励全世界的女性大肆宣传他们对性侵犯的指控，但在日本的回应却很平静。伊藤没有被吓倒，她访问了认为她失败的机构，并见了其他害怕不敢说话的女性。这部电影将伊藤的故事与日本更广泛的社会背景交织在一起，直到2017年，强奸的最低刑期短于盗窃。',
 'is_new': False,
 'name': '日本之耻',
 'platforms': '',
 'publishdate': '2018-06-28',
 'rate': 9.1,
 'sectionid': 'rrmj_1903',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30263943/'}
2020-04-30 14:27:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30304086/> (referer: https://www.douban.com/search?q=%E8%A7%A6%E5%8F%8A%E7%9C%9F%E5%BF%83)
2020-04-30 14:27:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30304086/>
{'cover': 'http://img.rr.tv/album/20190111/o_1547175327204.jpg',
 'data_type': 'movie',
 'id': 'rrmj_13854',
 'intro': '该剧翻拍自同名网络小说，讲述巨星演员吴允书因突然爆发的和富三代之间的丑闻而一落千丈，为了出演著名编剧的电视剧，不惜伪装成以龟毛而出名的韩国顶尖律师权政录的秘书。',
 'is_new': False,
 'name': '触及真心',
 'platforms': '',
 'publishdate': '2019-02-06',
 'rate': 7.7,
 'sectionid': 'rrmj_1244',
 'tags': ['剧情', '喜剧', '爱情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30304086/'}
2020-04-30 14:27:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%A6%96%E6%80%AA%E4%BA%BA%E9%97%B4> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:27:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30327894/> (referer: https://www.douban.com/search?q=%E7%A6%81%E5%BF%8C%E5%A5%B3%E5%AD%A9)
2020-04-30 14:27:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30327894/>
{'cover': 'http://img.rr.tv/album/20190822/o_1566484306145.jpg',
 'data_type': 'movie',
 'id': 'rrmj_14094',
 'intro': '来自未名地方的新生 Nanno '
          '如伊甸园的毒蛇，放大人们的欲望，揭露心灵深处的黑暗。他是令人尊敬的老师，一场视频风波揭露了老师背后的肮脏行为，性侵、威胁，道貌岸然的样子由 '
          'Nanno 来放大！',
 'is_new': False,
 'name': '禁忌女孩',
 'platforms': '',
 'publishdate': '2018-08-08',
 'rate': 8.3,
 'sectionid': 'rrmj_1917',
 'tags': ['剧情', '惊悚', '犯罪'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30327894/'}
2020-04-30 14:27:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30332529/> (referer: https://www.douban.com/search?q=%E6%9C%AB%E4%BB%A3%E6%B2%99%E7%9A%87)
2020-04-30 14:27:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30332529/>
{'cover': 'http://img.rr.tv/album/20190703/o_1562145215465.png',
 'data_type': 'movie',
 'id': 'rrmj_15237',
 'intro': '社会动荡席卷20世纪初的俄罗斯。沙皇尼古拉斯二世抵制变革，从而引发了一场革命，结束了王朝。',
 'is_new': False,
 'name': '末代沙皇',
 'platforms': '',
 'publishdate': '2019-07-03',
 'rate': 8.0,
 'sectionid': 'rrmj_1425',
 'tags': ['剧情', '传记', '古装'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30332529/'}
2020-04-30 14:27:19 [scrapy.extensions.logstats] INFO: Crawled 752 pages (at 34 pages/min), scraped 377 items (at 21 items/min)
2020-04-30 14:27:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30337518/> (referer: https://www.douban.com/search?q=%E9%87%8E%E7%94%9F%E4%B8%96%E7%95%8C)
2020-04-30 14:27:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30337518/>
{'cover': 'http://img.rr.tv/album/20190906/o_1567763988823.png',
 'data_type': 'movie',
 'id': 'rrmj_15135',
 'intro': '野生世界里，女人上赤星天堂，男人则变为原始野兽。为了解救人类，一个失控的女孩和一个流氓赏金猎人，浪迹野生世界，希冀找到神话庇护所，或拯救人类或毁灭人类……',
 'is_new': False,
 'name': '野生世界',
 'platforms': '',
 'publishdate': '2018-09-28',
 'rate': 7.0,
 'sectionid': 'rrmj_1005',
 'tags': ['科幻', '惊悚', '恐怖', '奇幻', '冒险'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30337518/'}
2020-04-30 14:27:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30382485/> (referer: https://www.douban.com/search?q=%E7%A5%9E%E6%8E%A2%E6%9E%97%E8%82%AF)
2020-04-30 14:27:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30382485/>
{'cover': 'http://img.rr.tv/cover/20200108/o_1578484800713.webp',
 'data_type': 'movie',
 'id': 'rrmj_16989',
 'intro': '小说改编剧《神探林肯 Lincoln Rhyme: Hunt for the Bone Collector》由原作作者Jeffery '
          'Deaver创作， VJ Boyd及Mark Bianculli负责剧本﹑Seth '
          'Gordon执导。《神探林肯》讲述天才法医犯罪学家Lincoln Rhyme因追捕连环杀手「Bone '
          'Collector」时受重伤，故此只好退休。但当凶手重出江湖后，他决定复出并与充满野心的警探Amelia '
          'Sachs组成拍档，合作追捕「Bone Collector」及其他危险罪犯。《格林 Grimm》主演Russell '
          'Hornsby将饰演主角Lincoln Rhyme﹑Arielle Kebbel饰演聪明﹑坚守立场的Amelia '
          'Sachs。                                                                            \u3000\u3000'
          'Michael Imperioli饰演纽约警探Rick Sellitto，Lincoln的...',
 'is_new': False,
 'name': '神探林肯',
 'platforms': '',
 'publishdate': '2020-01-10',
 'rate': 7.8,
 'sectionid': 'rrmj_745',
 'tags': ['剧情', '惊悚', '犯罪'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30382485/'}
2020-04-30 14:27:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30384336/> (referer: https://www.douban.com/search?q=%E5%AF%BB%E7%88%B1%E6%B3%95%E6%9C%AF)
2020-04-30 14:27:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30384336/>
{'cover': 'http://img.rr.tv/album/20190513/o_1557730308192.png',
 'data_type': 'movie',
 'id': 'rrmj_14809',
 'intro': '该剧讲述对现实充满失望的女主请求神婆魔法相助，被送到了三年后的未来。三年后的她居然结婚有丈夫了！饰她的丈夫还喜欢扰乱她的身心！于是女主就千方百计想回到最初的人生，可却在遭遇各种磨难中不小心将心交给了男主! '
          '当时光之轮重启，女主回到现实世界，开始寻找未来的他之旅…',
 'is_new': False,
 'name': '寻爱法术',
 'platforms': '',
 'publishdate': '2019-05-12',
 'rate': 6.1,
 'sectionid': 'rrmj_1244',
 'tags': ['爱情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30384336/'}
2020-04-30 14:27:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30390700/> (referer: https://www.douban.com/search?q=%E7%BE%8E%E5%9B%BD%E5%B7%A5%E5%8E%82)
2020-04-30 14:27:28 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30390700/>
{'cover': 'http://img.rr.tv/album/20190910/o_1568105826908.jpg',
 'data_type': 'movie',
 'id': 'rrmj_15688',
 'intro': '《美国工厂》是一部 Netflix 原创纪录片，由 Higher Ground Productions 和 Participant '
          'Media 出品，荣获奥斯卡金像奖®提名并斩获艾美奖®的朱莉娅·赖克特和史蒂文·博格纳尔（《最后一辆车：通用王国的破产》《A Lion '
          'in the '
          'House》《正观“红色”》）打造。这部广受好评的电影深入研究了后工业时代的俄亥俄州，一位中国亿万富翁在当地一家废弃的通用汽车工厂中开设新工厂，并雇佣了 '
          '2000 名美国蓝领工人。随着高科技中国企业与美国工人阶级产生冲突，最初的希望和乐观遭受了挫折。',
 'is_new': False,
 'name': '美国工厂',
 'platforms': '',
 'publishdate': '2019-01-25',
 'rate': 8.4,
 'sectionid': 'rrmj_1425',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30390700/'}
2020-04-30 14:27:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30401122/> (referer: https://www.douban.com/search?q=%E8%87%B4%E5%91%BD%E5%A5%B3%E4%BA%BA)
2020-04-30 14:27:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30401122/>
{'cover': 'http://img.rr.tv/album/20190822/o_1566457500356.jpg',
 'data_type': 'movie',
 'id': 'rrmj_15622',
 'intro': '贝斯（金妮弗·古德温 Ginnifer Goodwin 饰）从小的梦想就是能够成为一名家庭主妇，如今她嫁给了罗伯特（山姆·贾格 Sam '
          'Jaeger '
          '饰）为妻，总算是实现了理想。没想到第三者的出现将她美好的生活幻影撕成了碎片。                                                                    \u3000\u3000'
          '社交名媛西蒙尼（刘玉玲 饰）嫁给了非常疼爱她的卡尔（杰克·达文波特 Jack Davenport '
          '饰），哪知道竟然在偶然之中发现卡尔竟然是一名同性恋者，在守住秘密和守住尊严之间，西蒙尼必须做出选择。                                                                    \u3000\u3000'
          '泰勒（柯尔比·豪威尔-巴普蒂斯特 Kirby Howell-Baptiste 饰）和埃里（瑞德·斯科特 Reid Scott '
          '饰）正在进行一场开放式婚姻，泰勒的情人杰德（亚历珊德拉·达达里奥 Alexandra Daddario '
          '饰）的出现让埃里开始觉得，在他们两个人里面再加一个人似乎也是个不错的主意。',
 'is_new': False,
 'name': '致命女人',
 'platforms': '',
 'publishdate': '2019-07-21',
 'rate': 9.4,
 'sectionid': 'rrmj_1912',
 'tags': ['剧情', '喜剧', '犯罪'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30401122/'}
2020-04-30 14:27:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30434771/> (referer: https://www.douban.com/search?q=%E5%8C%BB%E7%94%9F%E8%80%80%E6%B1%89)
2020-04-30 14:27:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30434771/>
{'cover': 'http://img.rr.tv/album/20190716/o_1563243019322.jpg',
 'data_type': 'movie',
 'id': 'rrmj_15300',
 'intro': '这是一部关于医生专门从事疼痛管理的医学剧，把医生寻找病人神秘疼痛的原因描绘成一场惊心动魄的追逐，几乎就像一名侦探在未解决的犯罪背后追捕犯罪者。',
 'is_new': False,
 'name': '医生耀汉',
 'platforms': '',
 'publishdate': '2019-07-19',
 'rate': 8.3,
 'sectionid': 'rrmj_1646',
 'tags': ['剧情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30434771/'}
2020-04-30 14:27:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30448601/> (referer: https://www.douban.com/search?q=%E5%BD%BC%E5%B2%B8%E4%B9%8B%E5%AB%81)
2020-04-30 14:27:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30448601/>
{'cover': 'http://img.rr.tv/cover/20200416/o_1587016193250.png',
 'data_type': 'movie',
 'id': 'rrmj_17514',
 'intro': 'Netflix中文新片《彼岸之嫁》(小说《鬼新娘》电影版)宣布开机的同时，也发布先导预告。主演吴慷仁(《白蚁：欲望谜网》《下一站，幸福》)、黄姵嘉(《宝米恰恰》)、林路迪(《海王》)亮相，浓浓年代感。改编自美籍华裔作家朱洋熹的同名小说，故事混合了冥婚等中国民俗和浪漫爱情、超自然元素。设定在1890年代，殖民地时期的马六甲，讲述一个体面的华人人家的女儿丽兰因为家道中落，被要求去当富人家林家的“鬼新娘”——嫁给这户人家已死去的儿子。她能衣食无忧，但嫁给死人这件事将跟随她的余生，想逃走更加困难。此后，丽兰被卷入阴间，发现了“夫家”的黑暗秘密，也发现了自己家族的往事。                                                                    \u3000\u3000'
          '马来西亚导演郭修篆(《光》)和何宇恒(《K女士》)执导。编剧团队来自好莱坞和台湾，领头的是《汉尼拔》《闪电侠》编剧之一Wu Kai '
          'Yu。上线日期尚未确定。',
 'is_new': False,
 'name': '彼岸之嫁',
 'platforms': '',
 'publishdate': '2020-01-23',
 'rate': 7.0,
 'sectionid': 'rrmj_1904',
 'tags': ['剧情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30448601/'}
2020-04-30 14:27:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30449306/> (referer: https://www.douban.com/search?q=%E5%AE%8C%E7%BE%8E%E4%B8%96%E7%95%8C)
2020-04-30 14:27:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30449306/>
{'cover': 'http://img.rr.tv/album/20190426/o_1556270118406.jpg',
 'data_type': 'movie',
 'id': 'rrmj_14487',
 'intro': '本作改编自同名漫画《完美世界》。                                                                    \u3000\u3000'
          '因为遭遇事故而下身残疾，只能依靠轮椅生活的主人公鮎川樹（松坂桃李），在同学会上和高中同学川奈つぐみ（山本美月）再会。在心动之后，两人却要直面双亲的反对、疾病与伤痛、生活上的障碍、以及残疾所带来的并发症等等问题。                                                                    \u3000\u3000'
          '「究竟什么是幸福？」两人会做出怎样的选择呢？',
 'is_new': False,
 'name': '完美世界',
 'platforms': '',
 'publishdate': '2019-04-16',
 'rate': 8.1,
 'sectionid': 'rrmj_1244',
 'tags': ['剧情', '爱情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30449306/'}
2020-04-30 14:27:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/32493816/> (referer: https://www.douban.com/search?q=%E4%BC%BC%E6%87%82%E9%9D%9E%E6%87%82)
2020-04-30 14:27:39 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/32493816/>
{'cover': 'http://img.rr.tv/album/20190311/o_1552284033334.jpg',
 'data_type': 'movie',
 'id': 'rrmj_14276',
 'intro': '剧情讲述拥有「能听到别人内心话」的特殊能力和漂亮外貌，但却是边缘人的学妹，遇见了「不知道为什么总是听不见他内心想法」的暖男学长（김강민饰）后，所发生的一系列浪漫日常和成长改变的故事。是一部青春甜蜜的网剧。',
 'is_new': False,
 'name': '似懂非懂',
 'platforms': '',
 'publishdate': '2019-03-12',
 'rate': 7.3,
 'sectionid': 'rrmj_1244',
 'tags': ['爱情', '奇幻'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/32493816/'}
2020-04-30 14:27:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/32579502/> (referer: https://www.douban.com/search?q=%E4%B8%89%E9%87%8D%E6%9A%A7%E6%98%A7)
2020-04-30 14:27:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/32579502/>
{'cover': 'http://img.rr.tv/album/20190329/o_1553841813342.jpg',
 'data_type': 'movie',
 'id': 'rrmj_14404',
 'intro': '网络电视剧《三倍的暧昧》是以校内三个长得帅的男主人公为中心，讲述了新学期开始的同时发生的一系列趣事。',
 'is_new': False,
 'name': '三重暧昧',
 'platforms': '',
 'publishdate': '2019-03-14',
 'rate': 6.7,
 'sectionid': 'rrmj_1244',
 'tags': ['剧情', '爱情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/32579502/'}
2020-04-30 14:27:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/33425801/> (referer: https://www.douban.com/search?q=%E8%AF%B7%E8%9E%8D%E5%8C%96%E6%88%91)
2020-04-30 14:27:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/33425801/>
{'cover': 'http://img.rr.tv/album/20190828/o_1566983781685.jpg',
 'data_type': 'movie',
 'id': 'rrmj_15728',
 'intro': '该剧讲述了参与了24小时冷冻人类项目的男女，因为神秘的阴谋20年后才醒来时迎来的感人故事。池昌旭实验20年间作为冷冻人活着的异能局PD马东灿。',
 'is_new': False,
 'name': '请融化我',
 'platforms': '',
 'publishdate': '2019-09-28',
 'rate': 7.2,
 'sectionid': 'rrmj_1726',
 'tags': ['剧情', '爱情', '科幻'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/33425801/'}
2020-04-30 14:27:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/33446371/> (referer: https://www.douban.com/search?q=%E6%97%A0%E4%BA%BA%E7%9F%A5%E6%99%93)
2020-04-30 14:27:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/33446371/>
{'cover': 'http://img.rr.tv/cover/20200218/o_1581995496717.jpg',
 'data_type': 'movie',
 'id': 'rrmj_17185',
 'intro': '该剧讲述女主角因为连环杀人案痛失最爱的朋友，时隔19年她再次追踪连环杀人案，揭发巨大的恶的真实面貌的故事。                                                                    \u3000\u3000'
          '金瑞亨饰演重案组刑警车英真，她因年幼时没有守护最爱的朋友，怀揣罪恶感和愧疚，负重前行，立誓要揪出凶手。                                                                    \u3000\u3000'
          '柳德焕饰演新星中学科学教师李善宇一角。他对学生倾注了多少的感情，就受到了多 '
          '少的伤害，甚至更深。本意想要离开教团的他却在周围人的挽留和劝导下，来到了姐夫担任理事长的新星中学。在那里他遇到了内心多情温暖的孩子。',
 'is_new': False,
 'name': '无人知晓',
 'platforms': '',
 'publishdate': '2020-03-02',
 'rate': 9.0,
 'sectionid': 'rrmj_1726',
 'tags': ['剧情', '悬疑'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/33446371/'}
2020-04-30 14:27:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/33468614/> (referer: https://www.douban.com/search?q=%E9%87%91%E9%92%B1%E6%B8%B8%E6%88%8F)
2020-04-30 14:27:48 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/33468614/>
{'cover': 'http://img.rr.tv/cover/20200106/o_1578290075849.jpg',
 'data_type': 'movie',
 'id': 'rrmj_16968',
 'intro': '该剧讲述围绕着卖掉投入大量公共资金的廷仁银行（政府持股50%）而发生的纠葛的故事。将描写想把银行转手给国内其他单位的人们和想把银行卖给海外私募基金的人们之间的争斗。                                                                    \u3000\u3000'
          '由《付岩洞复仇者们》《春天来了，春天》金相浩导演执导，李英美编剧执笔，预计下半年播出。',
 'is_new': False,
 'name': '金钱游戏',
 'platforms': '',
 'publishdate': '2020-01-15',
 'rate': 8.5,
 'sectionid': 'rrmj_1871',
 'tags': ['剧情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/33468614/'}
2020-04-30 14:27:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/11538029/> (referer: https://www.douban.com/search?q=%E6%9D%80%E6%88%AE%E6%BC%94%E7%BB%8E)
2020-04-30 14:27:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/11538029/>
{'cover': 'http://img.rr.tv/album/20180712/o_1531365787209.webp',
 'data_type': 'movie',
 'id': 'rrmj_12756',
 'intro': '1965年，印尼政府被军政府推翻，那些反对军事独裁的人都被认定为“共产党人”，并遭遇了血腥屠杀，一年之内，就有超过100万“共产党人”丧命，其中就包括农民还有一些当地的华人。本片的主角Anwar '
          'Congo和他的朋友们就参与了当年的屠杀活动，他如今是印尼最大的准军事组织Pemuda '
          'Pancasila的元老人物。Anwar和他的朋友接受导演的邀请，在镜头前重新演绎当年他们是如何处死那些“共产党人”的，他们通过拍摄电影的方式，重现了当年的场景，再次拿起了那些沾满鲜血的用来勒死人的铁丝。Anwar讲述了他的故事，其中就包含着他年轻时候对美国黑帮电影的喜爱，而他所属的准军事组织Pemuda '
          'Pancasila虽然是维护国家安全的力量，恰恰也被人视为印尼最大的黑帮......',
 'is_new': False,
 'name': '杀戮演绎',
 'platforms': '',
 'publishdate': '2012-08-31',
 'rate': 8.3,
 'sectionid': 'rrmj_1416',
 'tags': ['纪录片', '历史', '犯罪'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/11538029/'}
2020-04-30 14:27:52 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/20310762/> (referer: https://www.douban.com/search?q=%E9%9A%90%E5%BD%A2%E6%9D%80%E6%89%8B)
2020-04-30 14:27:52 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/20310762/>: HTTP status code is not handled or not allowed
2020-04-30 14:27:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/25850103/> (referer: https://www.douban.com/search?q=%E8%BF%AA%E5%A5%A5%E4%B8%8E%E6%88%91)
2020-04-30 14:27:55 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/25850103/>
{'cover': 'http://img.rr.tv/album/20190711/o_1562824461042.webp',
 'data_type': 'movie',
 'id': 'rrmj_15306',
 'intro': '第一部纪录Raf Simons 入主巴黎老牌时装屋Christian Dior 迪奥的纪录片将于4月17日Tribeca Film '
          'Festival 翠贝卡电影节期间作全球首映，并参与Tribeca '
          '翠贝卡世界纪录片竞赛单元。                                                                    \u3000\u3000'
          '名为《Dior et moi（英译Dior and I，中译Dior 与我）》的纪录电影追踪了Raf Simons '
          '加盟Christian Dior 迪奥后创造首个高级定制系列的全过程。由Frédéric Tcheng '
          '执导的该片让外界得以窥视一个时装系列诞生的背后，一群热忱、迷人和幽默的协作者之间对工作的真挚投入，是对高级时装屋作坊中的裁缝们的生动致敬。',
 'is_new': False,
 'name': '迪奥与我',
 'platforms': '',
 'publishdate': '2014-04-17',
 'rate': 8.3,
 'sectionid': 'rrmj_1399',
 'tags': ['纪录片', '传记'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/25850103/'}
2020-04-30 14:27:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26317338/> (referer: https://www.douban.com/search?q=%E8%B6%85%E7%BA%A7%E4%B8%AD%E5%9B%BD)
2020-04-30 14:27:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26317338/>
{'cover': 'http://img.rr.tv/album/20180527/o_1527406286761.webp',
 'data_type': 'movie',
 'id': 'rrmj_12281',
 'intro': '韩国KBS电视台推出的这个纪录片共分七集，分别从人口、经济、外交军事、土地、文化、政治六个方面介绍中国发展现状。摄制组周游世界各国，以政府官员、研究学者、企业家及普通民众的视野，观察中国为世界带来的改变。也想让韩国更加了解自己周围的强大邻居及朋友。                                                                    \u3000\u3000'
          '人口：十三亿人的力量                                                                    \u3000\u3000'
          '在外国人眼中，中国这个“超级中国，庞大的人口规模，是一种优势，更是一种威胁。                                                                    \u3000\u3000'
          '经济：钱的力量                                                                    \u3000\u3000'
          '超级中国，外汇储备绝对的1位，购入世界的矿山、企业、机场、港口                                                                    \u3000\u3000'
          '外交军事：中国治世                                                                    \u3000\u3000'
          '急剧的军费扩张，与美国的竞争，中国走向顶尖国家的雄心                                                                    \u3000\u3000'
          '土地：                                                                    \u3000\u3000'
          '文化：                                                                    \u3000\u3000'
          '政治：',
 'is_new': False,
 'name': '超级中国',
 'platforms': '',
 'publishdate': '2015-01-15',
 'rate': 6.6,
 'sectionid': 'rrmj_1384',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26317338/'}
2020-04-30 14:28:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26381767/> (referer: https://www.douban.com/search?q=%E5%90%8C%E5%BF%97%E5%AE%9D%E8%B4%9D)
2020-04-30 14:28:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26381767/>
{'cover': 'http://img.rr.tv/album/20190725/o_1564035764507.webp',
 'data_type': 'movie',
 'id': 'rrmj_15462',
 'intro': '本片描寫澳洲四個同志家庭孩子的故事—葛斯、艾寶尼、馬特和葛拉罕，他們的父母剛好都是同性戀。當他們正與青春期裡的諸多挑戰搏鬥時，外面的世界則正在對婚姻平權的議題進行抗爭；少見從小孩視角呈現在同志家庭成長的樣貌，關乎家庭、性別、性與親子關係衝突等議題。在台灣同志領養小孩議題爭議不斷之時，可謂為值得參考的影像紀錄。',
 'is_new': False,
 'name': '同志宝贝',
 'platforms': '',
 'publishdate': '2015-04-29',
 'rate': 8.7,
 'sectionid': 'rrmj_1431',
 'tags': ['纪录片', '同性'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26381767/'}
2020-04-30 14:28:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26679116/> (referer: https://www.douban.com/search?q=%E5%9C%A3%E6%B4%81%E5%9C%B0%E7%8B%B1)
2020-04-30 14:28:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26679116/>
{'cover': 'http://img.rr.tv/album/20190515/o_1557907790154.webp',
 'data_type': 'movie',
 'id': 'rrmj_14829',
 'intro': '在加州的一个邪教团体领导者惊人的真相被公之于众后，一名前成员讲述他在这个组织里从理想主义到觉醒的经过。',
 'is_new': False,
 'name': '圣洁地狱',
 'platforms': '',
 'publishdate': '2016-01-25',
 'rate': 7.6,
 'sectionid': 'rrmj_1416',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26679116/'}
2020-04-30 14:28:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%B5%B7%E8%92%82%E5%92%8C%E7%88%B7%E7%88%B7> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:28:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26797567/> (referer: https://www.douban.com/search?q=%E9%80%9A%E7%81%B5%E6%8A%A4%E5%A3%AB)
2020-04-30 14:28:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26797567/>
{'cover': 'https://img.rr.tv/season/20170524/o_1495630902624.png',
 'data_type': 'movie',
 'id': 'rrmj_4905',
 'intro': 'Phad饰演的女主在医院当护士，她有个异能，就是可以看到鬼魂，她努力保守这个秘密，让自己像正常人。不过现实确实状况百出，导致很多人都躲避女主，只有Mild饰演的护士理解她并陪着她。Phad在医院除了自己的烦恼，还不停遭遇调皮捣蛋鬼（Belle饰演），热血青年医生（Tor饰演），以及严格的前辈医生（Pae饰演）等给出的各种状况事件。',
 'is_new': False,
 'name': '通灵护士',
 'platforms': '',
 'publishdate': '2016-05-07',
 'rate': 6.6,
 'sectionid': 'rrmj_1646',
 'tags': ['剧情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26797567/'}
2020-04-30 14:28:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%A4%8D%E4%BB%87%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:28:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26857719/> (referer: https://www.douban.com/search?q=%E7%BA%BD%E7%BA%A6%E9%BC%A0%E6%82%A3)
2020-04-30 14:28:08 [scrapy.core.scraper] ERROR: Error processing {'cover': 'http://img.rr.tv/album/20190313/o_1552458497157.webp',
 'data_type': 'movie',
 'id': 'rrmj_14294',
 'intro': '深入探索老鼠令人咋舌的世界，见证它们在不同环境的强韧生存能力，如何在人类史上带来灾难。',
 'is_new': False,
 'name': '纽约鼠患',
 'platforms': '',
 'publishdate': '',
 'rate': 7.2,
 'sectionid': 'rrmj_1416',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26857719/'}
Traceback (most recent call last):
  File "/usr/python37/lib/python3.7/site-packages/twisted/internet/defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/usr/python37/lib/python3.7/site-packages/scrapy/utils/defer.py", line 154, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
  File "/root/spider/scrapyspider/spiderV1/pipelines.py", line 262, in process_item
    timeStruct = time.strptime(publishdate, '%Y-%m-%d')
  File "/usr/python37/lib/python3.7/_strptime.py", line 571, in _strptime_time
    tt = _strptime(data_string, format)[0]
  File "/usr/python37/lib/python3.7/_strptime.py", line 359, in _strptime
    (data_string, format))
ValueError: time data '' does not match format '%Y-%m-%d'
2020-04-30 14:28:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26928130/> (referer: https://www.douban.com/search?q=%E4%BC%8A%E5%8D%A1%E6%B4%9B%E6%96%AF)
2020-04-30 14:28:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26928130/>
{'cover': 'http://img.rr.tv/album/20190730/o_1564479690421.webp',
 'data_type': 'movie',
 'id': 'rrmj_15486',
 'intro': '一名美国单车运动员和一位俄罗斯专家在国际体坛引爆严重丑闻后，一场对用药行为的调查引发了全球追逐战。',
 'is_new': False,
 'name': '伊卡洛斯',
 'platforms': '',
 'publishdate': '2017-01-20',
 'rate': 8.4,
 'sectionid': 'rrmj_1657',
 'tags': ['纪录片', '运动'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26928130/'}
2020-04-30 14:28:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%89%B6%E6%A1%91%E8%8A%B1%E5%A5%B3%E5%AD%A9> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:28:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26929016/> (referer: https://www.douban.com/search?q=%E5%9D%9A%E5%BC%BA%E4%B9%8B%E5%B2%9B)
2020-04-30 14:28:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26929016/>
{'cover': 'http://img.rr.tv/cover/20200114/o_1578981943052.webp',
 'data_type': 'movie',
 'id': 'rrmj_17016',
 'intro': '《强岛》（Strong Island） 导演：扬斯·福特（Yance Ford） 入围2017年圣丹斯电影节纪录片单元',
 'is_new': False,
 'name': '坚强之岛',
 'platforms': '',
 'publishdate': '2017-01-15',
 'rate': 5.8,
 'sectionid': 'rrmj_1657',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26929016/'}
2020-04-30 14:28:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%B8%AD%E5%AD%A6%E5%9C%A3%E6%97%A5%E8%AE%B0> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:28:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27663751/> (referer: https://www.douban.com/search?q=%E7%88%B1%E7%9A%84%E7%9D%80%E9%99%86)
2020-04-30 14:28:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%AF%8C%E8%B1%AA%E8%BE%A9%E6%8A%A4%E4%BA%BA> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:28:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/27663751/>
{'cover': 'https://img.rr.tv/season/20180323/o_1521792317735.png',
 'data_type': 'movie',
 'id': 'rrmj_11881',
 'intro': '该剧将空少们的秘密基地为主题讲述几对不同关系男男、男女之间错综复杂的关系,在这场存在金钱利益,爱情阴谋的关系中,深藏攻与零,因爱有基,因爱放纵,谁愿一同登这爱的飞机,探险这段惊险有爱的旅程。',
 'is_new': False,
 'name': '爱的着陆',
 'platforms': '',
 'publishdate': '2018-01-01',
 'rate': 5.9,
 'sectionid': 'rrmj_989',
 'tags': ['喜剧', '同性'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/27663751/'}
2020-04-30 14:28:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%A3%92%E7%90%83%E5%A4%A7%E8%81%94%E7%9B%9F> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:28:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30326966/> (referer: https://www.douban.com/search?q=%E5%A4%A7%E8%B1%A1%E5%A5%B3%E7%8E%8B)
2020-04-30 14:28:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30326966/>
{'cover': 'http://img.rr.tv/album/20191114/o_1573710799349.webp',
 'data_type': 'movie',
 'id': 'rrmj_16580',
 'intro': '雅典娜是一位母亲，当他们被迫离开他们的水坑时，她会尽她所能保护她的牧群。这一史诗般的旅程，由Chiwetel '
          'Ejiofor讲述，带领观众穿越非洲大草原，进入大象家庭的核心。一个关于爱，失去和回家的故事。',
 'is_new': False,
 'name': '大象女王',
 'platforms': '',
 'publishdate': '2018-09-08',
 'rate': 9.1,
 'sectionid': 'rrmj_1425',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30326966/'}
2020-04-30 14:28:19 [scrapy.extensions.logstats] INFO: Crawled 783 pages (at 31 pages/min), scraped 400 items (at 23 items/min)
2020-04-30 14:28:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30391726/> (referer: https://www.douban.com/search?q=%E8%9C%82%E8%9C%9C%E4%B9%8B%E5%9C%B0)
2020-04-30 14:28:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30391726/>
{'cover': 'http://img.rr.tv/cover/20200115/o_1579067866996.webp',
 'data_type': 'movie',
 'id': 'rrmj_17019',
 'intro': '鲜黄衣袂点缀马其顿偏乡的荒芜，与悬崖上野生蜂蜜琼浆的金黄相辉映。喀迪丝是欧洲大地最后一位女采蜂人，与抱病半盲母亲相依为命，依附野蜂为生，坚守「取一半、留一半」黄金定律。游牧民族一家突然欺至，打破宁静生活的不止是七个孩子与一众牲畜的喧闹，还有疯狂掏尽蜂蜜的贪婪，以及破坏生态环境的肆无忌惮。历时三年静观人与蜂和谐共处的隐世生活，以自然曦光与幽微烛照辉映大地，美得教人肃然起敬。获辛丹斯电影节世界纪录片评审团大奖。',
 'is_new': False,
 'name': '蜂蜜之地',
 'platforms': '',
 'publishdate': '2019-01-28',
 'rate': 8.8,
 'sectionid': 'rrmj_1657',
 'tags': ['剧情', '纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30391726/'}
2020-04-30 14:28:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%B8%96%E7%95%8C%E4%BD%B3%E8%82%B4%EF%BC%81> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:28:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30419881/> (referer: https://www.douban.com/search?q=%E6%94%BE%E5%BC%83%E6%B1%82%E7%94%9F)
2020-04-30 14:28:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30419881/>
{'cover': 'http://img.rr.tv/cover/20190919/o_1568877096969.webp',
 'data_type': 'movie',
 'id': 'rrmj_15914',
 'intro': '瑞典的数百名难民儿童面临被驱逐出境的危险，他们饱受放弃求生综合征的折磨，开始逃避现实并陷入一种昏迷般的状态，仿佛被冻结了数月甚至数年。《放弃求生》让观众了解这些患儿父母的痛苦，以及他们如何努力照顾生病的孩子。',
 'is_new': False,
 'name': '放弃求生',
 'platforms': '',
 'publishdate': '2019-01-26',
 'rate': 6.4,
 'sectionid': 'rrmj_1657',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30419881/'}
2020-04-30 14:28:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%B8%AD%E5%9B%BD%E4%BA%BA%E6%9D%A5%E4%BA%86> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:28:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30433802/> (referer: https://www.douban.com/search?q=%E6%9C%88%E4%BA%8B%E9%9D%A9%E5%91%BD)
2020-04-30 14:28:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30433802/>
{'cover': 'http://img.rr.tv/album/20190305/o_1551772242522.webp',
 'data_type': 'movie',
 'id': 'rrmj_14223',
 'intro': '第91届奥斯卡金像奖(2019)最佳纪录短片。这是一部关于月经和卫生巾的纪录片。讲述的是印度德里的一群妇女，为自己以及所有女性获得卫生巾的权利而抗争，而加利福尼亚州的一群高中女生们，给予了她们支持。',
 'is_new': False,
 'name': '月事革命',
 'platforms': '',
 'publishdate': '2018-04-05',
 'rate': 7.5,
 'sectionid': 'rrmj_1657',
 'tags': ['纪录片', '短片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30433802/'}
2020-04-30 14:28:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%BA%BA%E7%94%9F%E5%A6%82%E7%90%83%E5%9C%BA> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:28:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30463668/> (referer: https://www.douban.com/search?q=%E5%BF%83%E8%84%8F%E4%BF%A1%E5%8F%B73)
2020-04-30 14:28:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30463668/>
{'cover': 'http://img.rr.tv/cover/20200320/o_1584699163294.jpg',
 'data_type': 'movie',
 'id': 'rrmj_17350',
 'intro': 'Channel A方面透露人气素人恋爱推理节目《Heart '
          'signal》有望于下半年开拍第三季，电视台方面表示“目前节目组确实正在准备第三季的内容，只不过目前只是制定了下半年开拍的计划，尚未有具体的日程安排出来。”《Heart '
          'signal》为一档恋爱推理节目，青春男女们齐聚信号小屋，共度暧昧时光，再由录影棚内的嘉宾们猜测出演者们的心意，2017年开播，目前已播出两季，第二季播出时曾连续九周创下电视综艺节目话题榜第一的好成绩，出演该节目的素人嘉宾也斩获了不小的人气。',
 'is_new': False,
 'name': '心脏信号3',
 'platforms': '',
 'publishdate': '2020-03-25',
 'rate': 0.0,
 'sectionid': 'rrmj_742',
 'tags': ['真人秀'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30463668/'}
2020-04-30 14:28:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%8D%B0%E5%BA%A6%E7%9A%84%E5%A5%B3%E5%84%BF> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:28:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26877505/> (referer: https://www.douban.com/search?q=%E7%A9%BA%E7%99%BD%E7%9A%8413%E5%B9%B4)
2020-04-30 14:28:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26877505/>
{'cover': 'http://img.rr.tv/album/20191106/o_1573020664850.webp',
 'data_type': 'movie',
 'id': 'rrmj_16495',
 'intro': '故事讲述欠债父亲13年后再次现身，却已身患癌症，时日不多。直到父亲的告别仪式上，才从前来祭拜的人们口中了解真实的父亲。',
 'is_new': False,
 'name': '空白的13年',
 'platforms': '',
 'publishdate': '2017-03-03',
 'rate': 8.3,
 'sectionid': 'rrmj_1729',
 'tags': ['剧情'],
 'type': 'movie',
 'url': 'https://movie.douban.com/subject/26877505/'}
2020-04-30 14:28:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%92%96%E5%95%A1%E4%B8%8E%E9%A6%99%E8%8D%89> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:28:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30263995/> (referer: https://www.douban.com/search?q=%E4%B8%80%E5%90%BB%E5%AE%9A%E6%83%851)
2020-04-30 14:28:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30263995/>
{'cover': 'http://img.rr.tv/album/20180413/o_1523612505081.png',
 'data_type': 'movie',
 'id': 'rrmj_12019',
 'intro': '笨蛋爱上天才，会有结果吗？平凡女孩原湘琴（林允饰）喜欢上了天才少年江直树（王大陆饰），在她表白失败准备放弃之际，爸爸居然带着自己搬进了直树家里？！一个猛追，一个猛逃，热闹欢腾的纯真高中生活就此上演。朝夕相处中，直树渐渐被湘琴乐观的无畏精神吸引，他开始怀疑：湘琴究竟是人生偏差、还是自己的命中注定?',
 'is_new': False,
 'name': '一吻定情1',
 'platforms': '',
 'publishdate': '2019-02-14',
 'rate': 8.3,
 'sectionid': 'rrmj_1244',
 'tags': ['喜剧', '爱情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30263995/'}
2020-04-30 14:28:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%A4%AB%E5%A6%BB%E7%9A%84%E4%B8%96%E7%95%8C> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:28:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/34930835/> (referer: https://www.douban.com/search?q=%E4%BA%BA%E7%B1%BB-%E5%8A%A8%E7%89%A9)
2020-04-30 14:28:34 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/34930835/>
{'cover': 'http://img.rr.tv/cover/20200108/o_1578468604935.jpg',
 'data_type': 'movie',
 'id': 'rrmj_16984',
 'intro': '纪录片《Humanimal》共分为5集，讲述了生存在地球上的人类（Human）与动物（Animal）之间的生与死以及共存的史诗记录。此前，《Humanimal》方面表示演员朴信惠、柳承龙、柳海真与制作人员一同赶赴泰国、美国、南非等10多个国家，亲身体验濒临灭绝的野生动物们面临的悲惨现实。而演员金宇彬将作为最后成员加入，并担任旁白解说。金宇彬将以沉稳有力的声音，生动如实地为观众们传递感动。',
 'is_new': False,
 'name': '人类-动物',
 'platforms': '',
 'publishdate': '2020-01-06',
 'rate': 9.0,
 'sectionid': 'rrmj_1425',
 'tags': ['纪录片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/34930835/'}
2020-04-30 14:28:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%BE%B7%E9%B2%81%E7%BA%B3%E9%85%92%E5%BA%97> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:28:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/34996956/> (referer: https://www.douban.com/search?q=%E4%B8%89%E9%87%8D%E6%9A%A7%E6%98%A72)
2020-04-30 14:28:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/34996956/>
{'cover': 'http://img.rr.tv/album/20190802/o_1564734036543.jpg',
 'data_type': 'movie',
 'id': 'rrmj_15516',
 'intro': '"찾았다. 그 애." 새로 시작한 알바에서 함께 일하게 된 민규. 고등학교 졸업 후 다시 만난 준환. 모두 윤지와 1년 '
          '만에 다시 만났다. 윤지는 누구를, 왜 찾고 있었던 걸까?',
 'is_new': False,
 'name': '三重暧昧2',
 'platforms': '',
 'publishdate': '2020-02-25',
 'rate': 8.0,
 'sectionid': 'rrmj_1244',
 'tags': ['喜剧'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/34996956/'}
2020-04-30 14:28:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%81%8B%E7%88%B1%E6%B2%99%E5%B0%98%E6%9A%B4> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:28:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/25912858/> (referer: https://www.douban.com/search?q=%E5%AF%BB%20%E7%AC%AC%E4%BA%8C%E5%AD%A3)
2020-04-30 14:28:39 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/25912858/>
{'cover': 'http://img.rr.tv/album/20180531/o_1527765300172.jpg',
 'data_type': 'movie',
 'id': 'rrmj_12342',
 'intro': '《寻》是美国HBO有线台2014年开发的剧集，如今已续订第二季。该剧讲述三个同志好友在现代旧金山完全不加过滤的性与生活。他们都在寻找快乐、寻找亲密，同时也在面对所有同志都需要面对的选择和决定......                                                                    \u3000\u3000'
          '《寻》全部在旧金山实景拍摄，导演是《周末时光》的安德鲁·海格，它被认为是继《同志亦凡人》后最写实的同志美剧。',
 'is_new': False,
 'name': '寻 第二季',
 'platforms': '',
 'publishdate': '2015-01-11',
 'rate': 8.8,
 'sectionid': 'rrmj_989',
 'tags': ['剧情', '喜剧', '爱情', '同性'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/25912858/'}
2020-04-30 14:28:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%88%91%E4%BB%AC%E4%B8%80%E5%AE%B6%E4%BA%BA> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:28:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%88%91%E4%BB%AC%E7%9A%84%E6%98%9F%E7%90%83> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:28:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27613082/> (referer: https://www.douban.com/search?q=%E8%8A%B1%E8%BF%87%E5%A4%A9%E6%99%B4%20)
2020-04-30 14:28:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/27613082/>
{'cover': 'http://img.rr.tv/album/20180420/o_1524197335644.jpg',
 'data_type': 'movie',
 'id': 'rrmj_11954',
 'intro': '续作以前作F4毕业之后10年的英德学院为舞台，根据前作漫画家神尾叶子的续集漫画改编。杉咲花饰演前化妆品大厂社长的千金小姐江户川音，因公司倒闭而过着贫穷的生活。平野紫耀饰演神乐木集团的公子，为恢复F4时期英德学园的光辉，成立类似团体C5；他人前自称“道明寺第二”，实则心理脆弱，经不住打击。中川大志饰演江户川音的婚约者，英德学园对手校桃乃圆学院的学生会长。                                                                    \u3000\u3000'
          '杉咲花出生于97年，在日本“冲奥片”《滚烫的爱》中与宫泽理惠合作，获得多个大奖的肯定，此次将是她首次在电视剧中担当女主角。平野紫耀与“道明寺”松本润同属杰尼斯事务所，与永濑廉、高桥海人组成小杰尼斯组合Mr.KING。98年的中川大志童星出身，虽年纪轻轻，但有着丰富的表演经历。                                                                    \u3000\u3000'
          '不用等到电视剧播出，光是看着这人设，已经能够脑补出一出三角恋的狗血大戏。不过这万年不变的老梗，还是有人喜欢看呀。',
 'is_new': False,
 'name': '花过天晴 ',
 'platforms': '',
 'publishdate': '2018-04-17',
 'rate': 6.5,
 'sectionid': 'rrmj_1244',
 'tags': ['剧情', '喜剧', '爱情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/27613082/'}
2020-04-30 14:28:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%88%91%E6%98%AF%E5%A4%A7%E5%93%A5%E5%A4%A7> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:28:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%94%BE%E7%BE%8A%E7%9A%84%E6%98%9F%E6%98%9F> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:28:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%96%B0%E5%88%9B%E6%96%B0%E5%A4%A9%E5%9C%B0> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:28:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%B5%B7%E8%B1%9A%E6%B9%BE%E6%81%8B%E4%BA%BA> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:28:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%B7%B1%E8%93%9D%E4%B8%8E%E6%9C%88%E5%85%89> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:28:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%8B%90%E7%8B%B8%E6%96%B0%E5%A8%98%E6%98%9F> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:28:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%8E%8B%E5%AD%90%E5%8F%98%E9%9D%92%E8%9B%99> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:29:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%9C%9F%E7%88%B1%E8%B6%81%E7%8E%B0%E5%9C%A8> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:29:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%87%AA%E5%B7%B1%E5%8A%A8%E6%89%8B%E5%81%9A> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:29:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E9%BB%91%E7%B3%96%E7%8E%9B%E5%A5%87%E6%9C%B5> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:29:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E9%BB%91%E8%89%B2%E6%AD%A2%E8%A1%80%E9%92%B3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:29:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%B8%AD%E5%9B%BD%E7%9A%84%E9%87%8D%E7%94%9F> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:29:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%BA%92%E8%81%94%E7%BD%91%E4%B9%8B%E5%AD%90> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:29:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%8F%98%E6%80%A7%E5%88%87%E5%B0%94%E8%A5%BF> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:29:19 [scrapy.extensions.logstats] INFO: Crawled 817 pages (at 34 pages/min), scraped 410 items (at 10 items/min)
2020-04-30 14:29:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%90%8C%E5%BF%97%E6%88%90%E9%95%BF%E8%AE%B0> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:29:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/25853071/> (referer: https://www.douban.com/search?q=%E5%A4%8D%E4%BB%87%E7%AC%AC%E4%B8%80%E5%AD%A3)
2020-04-30 14:29:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/25853071/>
{'cover': 'http://img.rr.tv/album/20180820/o_1534746758243.jpg',
 'data_type': 'movie',
 'id': 'rrmj_179',
 'intro': '某大学文学史专业的学生张庆熟读古典名著，但他用现代观念剖析古代文学史的论文命题不被叶教授所认可。为了让叶教授成为自己的研究生导师，张庆决定通过写小说的方式，进一步阐述自己想要表达的观点。                                                                    \u3000\u3000'
          '在他的小说中，身世神秘的少年——范闲，自小跟随奶奶生活在海边小城澹州，随着一位老师的突然造访，他看似平静的生活开始直面重重的危机与考验。在神秘老师和一位蒙眼守护者的指点下，范闲熟识药性药理，修炼霸道真气并精进武艺，而后接连化解了诸多危局。因对身世之谜的好奇，范闲离开澹州，前赴京都。                                                                    \u3000\u3000'
          '在京都，范闲凭借过人的智谋与勇武成为年轻一代的佼佼者，他先以诗文冠绝京都，而后出使邻国，营救人质，整合谍报网，查处震动朝野的走私案……这个过程中，范闲饱尝人间冷暖并坚守对正义、良善的坚持，历经家族、江湖、庙堂的种种考验与锤炼，书写了光彩的人生传奇。',
 'is_new': False,
 'name': '复仇第一季',
 'platforms': '',
 'publishdate': '2019-11-26',
 'rate': 8.0,
 'sectionid': 'rrmj_1912',
 'tags': ['剧情', '古装'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/25853071/'}
2020-04-30 14:29:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%A4%A9%E5%A0%82%E5%A4%A7%E5%A1%9E%E8%BD%A6> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:29:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%A9%9A%E5%A7%BB%E5%B9%B3%E6%9D%83%E8%B7%AF> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:29:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%96%B0%E4%B8%9D%E7%BB%B8%E4%B9%8B%E8%B7%AF> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:29:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%B0%91%E4%B8%BB%E7%9A%84%E8%BE%B9%E7%BC%98> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:29:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%A7%91%E6%AF%94%E7%9A%84%E7%BC%AA%E6%96%AF> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:29:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%BB%88%E5%AE%88%E9%98%BF%E5%8B%92%E6%B3%A2> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:29:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%BE%8E%E5%88%A9%E5%9D%9A%E5%A5%B3%E5%A3%AB> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:29:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30183785/> (referer: https://www.douban.com/search?q=%E6%88%91%E6%98%AF%E5%A4%A7%E5%93%A5%E5%A4%A7)
2020-04-30 14:29:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30183785/>
{'cover': 'http://img.rr.tv/album/20181204/o_1543890113475.jpg',
 'data_type': 'movie',
 'id': 'rrmj_13123',
 'intro': '故事发生在20世纪80年代，中学生三桥贵志（贺来贤人 饰）和伊藤真司（伊藤健太郎 '
          '饰）转学来到新的学校，为了看起来凶恶一点，他们不约而同改换了不良少年的打扮。刚刚入学，两人意外打倒十人，一战成名。此后他们结识了女校的戏精大姐大早川京子（桥本环奈 '
          '饰）、男校的大嗓门傻老大今井（太贺 饰）、今井的小跟班谷川（矢本悠马 饰）以及本校的功夫纪律委员赤坂理子（清野菜名 '
          '饰）。在与黑道分子和其他学校不良少年的抗争过程中，少男少女的友情不断加深，而爆笑沙雕的故事也接二连三的发生。三桥与伊藤的确度过了一段难忘的青春岁月……                                                                    \u3000\u3000'
          '本片根据同名漫画改编。',
 'is_new': False,
 'name': '我是大哥大',
 'platforms': '',
 'publishdate': '2018-10-14',
 'rate': 9.4,
 'sectionid': 'rrmj_1917',
 'tags': ['剧情', '喜剧'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30183785/'}
2020-04-30 14:29:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E9%98%BF%E5%A7%86%E6%96%AF%E7%89%B9%E6%9C%97> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:29:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/34851294/> (referer: https://www.douban.com/search?q=%E5%A4%AB%E5%A6%BB%E7%9A%84%E4%B8%96%E7%95%8C)
2020-04-30 14:29:40 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/34851294/>
{'cover': 'http://img.rr.tv/cover/20200312/o_1583994488192.jpg',
 'data_type': 'movie',
 'id': 'rrmj_17315',
 'intro': '该剧是讲述原以为是相爱着的夫妻的缘分因为背叛而终结，并被卷入复仇的旋涡的故事。将描写想毁掉对方的憎恨成为一种爱的形式，拼死勒住彼此的脖子的激烈的爱情。                                                                    \u3000\u3000'
          '由《Misty》毛完日导演执导，《玉氏南政基》朱贤编剧执笔，接档《梨泰院Class》播出。',
 'is_new': False,
 'name': '夫妻的世界',
 'platforms': '',
 'publishdate': '2020-03-27',
 'rate': 8.3,
 'sectionid': 'rrmj_1912',
 'tags': ['剧情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/34851294/'}
2020-04-30 14:29:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=Nicki%20Minaj%3A%20My%20Time%20Again> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:29:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%B8%BB%E5%8E%A8%E7%9A%84%E9%A4%90%E6%A1%8C> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:29:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%BF%83%E9%87%8C%E7%9A%84%E5%A3%B0%E9%9F%B32> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:29:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%A4%8D%E4%BB%87%20%E7%AC%AC%E4%BA%8C%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:29:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%8E%8B%E5%9B%BD%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:29:49 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/6017331/> (referer: https://www.douban.com/search?q=%E5%A4%8D%E4%BB%87%20%E7%AC%AC%E4%BA%8C%E5%AD%A3)
2020-04-30 14:29:49 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/6017331/>: HTTP status code is not handled or not allowed
2020-04-30 14:29:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%BE%9E%E8%80%BB%20%E7%AC%AC%E4%B8%89%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:29:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%A1%80%E6%97%8F%20%E7%AC%AC%E4%BA%8C%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:29:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=IT%E7%8B%82%E4%BA%BA%E8%AF%B4%E6%98%8E%E4%B9%A6> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:30:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%BA%BF%E4%B8%87%20%E7%AC%AC%E5%9B%9B%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:30:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%B1%89%E5%A8%9C%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:30:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%8E%8B%E5%9B%BD%20%E7%AC%AC%E4%BA%8C%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:30:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%A1%80%E7%96%AB%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:30:07 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/686641/> (referer: https://www.douban.com/search?q=%E7%8E%8B%E5%9B%BD%20%E7%AC%AC%E4%BA%8C%E5%AD%A3)
2020-04-30 14:30:07 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/686641/>: HTTP status code is not handled or not allowed
2020-04-30 14:30:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E9%BB%91%E9%92%B1%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:30:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%B7%9F%E9%B2%A8%E9%B1%BC%E6%8E%A5%E5%90%BB> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:30:13 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/650155493/> (referer: https://www.douban.com/search?q=%E9%BB%91%E9%92%B1%20%E7%AC%AC%E4%B8%80%E5%AD%A3)
2020-04-30 14:30:13 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/650155493/>: HTTP status code is not handled or not allowed
2020-04-30 14:30:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%B8%91%E9%97%BB%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:30:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%8D%9A%E6%96%AF%20%E7%AC%AC%E5%85%AD%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:30:19 [scrapy.extensions.logstats] INFO: Crawled 848 pages (at 31 pages/min), scraped 413 items (at 3 items/min)
2020-04-30 14:30:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/5969408/> (referer: https://www.douban.com/search?q=%E4%B8%91%E9%97%BB%20%E7%AC%AC%E4%B8%80%E5%AD%A3)
2020-04-30 14:30:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/5969408/>
{'cover': 'http://img.rr.tv/seasonCover/20200424/o_1587712722916.png',
 'data_type': 'movie',
 'id': 'rrmj_192',
 'intro': '该剧是《实习医生格蕾》、《私人诊所》和《人在异乡》创作者Shonda Rhimes多年来打造的第一部非医学剧，根据Judy '
          'Smith的真人真事改编。故事主要描述一名危机处理专家及其所领导的团队的工作与生活。                                                                            \u3000\u3000'
          '从媒体关系顾问到总统新闻顾问，Olivia Pope（Kerry '
          'Washington扮演）一辈子都在保护美国的秘密－－对她来说，维护美国精英阶层的形象、避免让各种丑闻曝光对这个国家来说是极其重要的事情。小布什的总统任期结束后，和布什关系密切的Olivia离开了白宫，创办了自己的公关公司，希望就此揭开人生的新篇章－－无论工作还是生活。可是她似乎无法完全摆脱过去－－无论是她还是她的精英团队，他们能够「修复」任何人的生活，但却对自己生活中出现的问题无能为力。                                                                            \u3000\u3000'
          '来自《迷失》的Henry Ian Cusick扮演男主人公Stephen，诉讼律师，为Ol...',
 'is_new': False,
 'name': '丑闻 第一季',
 'platforms': '',
 'publishdate': '2012-04-05',
 'rate': 7.5,
 'sectionid': 'rrmj_1912',
 'tags': ['剧情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/5969408/'}
2020-04-30 14:30:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%90%8C%E8%A1%8C%20%E7%AC%AC%E4%BA%8C%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:30:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%92%B2%E5%85%AC%E8%8B%B1%E7%9A%84%E7%81%B0%E5%B0%98> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:30:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E9%BE%99%E7%8E%8B%E5%AD%90%E7%AC%AC%E4%BA%8C%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:30:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%B8%AD%E5%9B%BD%E8%80%81%E5%B8%88%E6%9D%A5%E4%BA%86> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:30:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%85%A8%E7%90%83%E7%8E%AF%E4%BF%9D%E5%88%9B%E6%84%8F> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:30:26 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/30807716/> (referer: https://www.douban.com/search?q=%E8%92%B2%E5%85%AC%E8%8B%B1%E7%9A%84%E7%81%B0%E5%B0%98)
2020-04-30 14:30:26 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/30807716/>: HTTP status code is not handled or not allowed
2020-04-30 14:30:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%8F%8D%E6%AD%A3%E6%98%AF%E7%BA%AA%E5%BF%B5%E6%97%A5> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:30:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%A4%A7%E7%86%8A%E7%8C%AB%E7%9A%84%E7%94%9F%E6%B4%BB> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:30:31 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/401792/> (referer: https://www.douban.com/search?q=%E5%8F%8D%E6%AD%A3%E6%98%AF%E7%BA%AA%E5%BF%B5%E6%97%A5)
2020-04-30 14:30:31 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/401792/>: HTTP status code is not handled or not allowed
2020-04-30 14:30:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%AD%A4%E9%AB%98%E7%9A%84%E6%89%8B%E6%9C%AF%E5%88%80> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:30:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%AE%A1%E5%88%A4%E5%85%AB%E5%8F%B7%E6%8F%90%E6%A1%88> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:30:35 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/27590805/> (referer: https://www.douban.com/search?q=%E5%85%A8%E7%90%83%E7%8E%AF%E4%BF%9D%E5%88%9B%E6%84%8F)
2020-04-30 14:30:35 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/27590805/>: HTTP status code is not handled or not allowed
2020-04-30 14:30:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%B0%8F%E5%B0%8F%E5%B7%B4%E9%BB%8E%E5%8E%A8%E6%88%BF> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:30:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%88%91%E7%9A%84%E6%81%90%E6%80%96%E5%A6%BB%E5%AD%90> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:30:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%B7%B1%E5%85%A5%E5%AE%8C%E6%95%B4%E6%8A%A5%E9%81%93> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:30:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%8B%97%E7%9A%84%E7%A7%98%E5%AF%86%E7%94%9F%E6%B4%BB> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:30:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26741568/> (referer: https://www.douban.com/search?q=%E6%88%91%E7%9A%84%E6%81%90%E6%80%96%E5%A6%BB%E5%AD%90)
2020-04-30 14:30:46 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/7058113/> (referer: https://www.douban.com/search?q=%E7%8B%97%E7%9A%84%E7%A7%98%E5%AF%86%E7%94%9F%E6%B4%BB)
2020-04-30 14:30:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26741568/>
{'cover': 'http://img.rr.tv/album/20180322/o_1521715597521.jpg',
 'data_type': 'movie',
 'id': 'rrmj_11849',
 'intro': '居住在某富人社区的望月夫妇过着令人欣羡的幸福生活。望月幸平（伊藤英明 饰）出身贫寒，不过他的妻子真理亚（木村佳乃 '
          '饰）家境优渥。真理亚的父母去世后留下了丰厚的遗产，利用这笔钱幸平经营了一家咖啡店。日常里幸平的衣食起居全由真理亚一人照顾，妻子体贴入微，甚至连望月老家的母亲和姐姐也都关爱有加。可就是这样一位近乎完美的妻子，却因无微不至的关怀而引来幸平越来越多的反感。他与咖啡店主厨北里杏男（相武纱季 '
          '饰）陷入不伦之恋，后者则怂恿他杀掉妻子。                                                                    \u3000\u3000'
          '就当计划准备实施当天，妻子疑似遭人绑架。对方索要两亿日元赎金，否则将杀掉真理亚。看似老天帮助了幸平，然而接下来的事实却让他惊恐万分……',
 'is_new': False,
 'name': '我的恐怖妻子',
 'platforms': '',
 'publishdate': '2016-04-19',
 'rate': 9.0,
 'sectionid': 'rrmj_1912',
 'tags': ['剧情', '悬疑'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26741568/'}
2020-04-30 14:30:46 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/7058113/>: HTTP status code is not handled or not allowed
2020-04-30 14:30:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%A7%A3%E8%AF%B4%E4%B8%96%E7%95%8C%E7%BB%8F%E6%B5%8E> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:30:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%B4%9E%E7%A9%B4%E9%87%8C%E7%9A%84%E5%8C%BB%E9%99%A2> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:30:50 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/26976855/> (referer: https://www.douban.com/search?q=%E8%A7%A3%E8%AF%B4%E4%B8%96%E7%95%8C%E7%BB%8F%E6%B5%8E)
2020-04-30 14:30:50 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/26976855/>: HTTP status code is not handled or not allowed
2020-04-30 14:30:52 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/30441470/> (referer: https://www.douban.com/search?q=%E6%B4%9E%E7%A9%B4%E9%87%8C%E7%9A%84%E5%8C%BB%E9%99%A2)
2020-04-30 14:30:52 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/30441470/>: HTTP status code is not handled or not allowed
2020-04-30 14:30:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%98%9F%E7%96%AB%E6%B1%82%E7%94%9F%E6%8C%87%E5%8D%97> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:30:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%89%AF%E5%8C%BB%20%E7%AC%AC%E4%B8%89%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:30:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%BC%9E%E5%AD%A6%E9%99%A2%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:31:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%85%BB%E8%82%B2%E8%80%85%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:31:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%A5%B3%E6%9C%8B%E5%8F%8B%20%E7%AC%AC%E4%BA%8C%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:31:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%8C%8E%E9%AD%94%E4%BA%BA%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:31:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E9%BB%91%E6%AD%BB%E7%97%85%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:31:07 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/34956504/> (referer: https://www.douban.com/search?q=%E7%8C%8E%E9%AD%94%E4%BA%BA%20%E7%AC%AC%E4%B8%80%E5%AD%A3)
2020-04-30 14:31:07 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/34956504/>: HTTP status code is not handled or not allowed
2020-04-30 14:31:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%B8%8B%E4%B8%80%E7%AB%99%EF%BC%8C%E5%B9%B8%E7%A6%8F> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:31:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%AE%88%E6%8A%A4%E8%80%85%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:31:12 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/681930/> (referer: https://www.douban.com/search?q=%E4%B8%8B%E4%B8%80%E7%AB%99%EF%BC%8C%E5%B9%B8%E7%A6%8F)
2020-04-30 14:31:12 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/681930/>: HTTP status code is not handled or not allowed
2020-04-30 14:31:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%BA%B8%E9%92%9E%E5%B1%8B%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:31:15 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/8245946/> (referer: https://www.douban.com/search?q=%E5%AE%88%E6%8A%A4%E8%80%85%20%E7%AC%AC%E4%B8%80%E5%AD%A3)
2020-04-30 14:31:15 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/8245946/>: HTTP status code is not handled or not allowed
2020-04-30 14:31:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%B1%89%E5%B0%BC%E6%8B%94%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:31:19 [scrapy.extensions.logstats] INFO: Crawled 885 pages (at 37 pages/min), scraped 415 items (at 2 items/min)
2020-04-30 14:31:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%BF%99%E6%A0%B7%E4%B8%8DOK%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:31:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%9B%9B%E5%A4%84%E6%95%A3%E8%90%BD%E7%9A%84%E7%A2%8E%E7%89%87> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:31:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E9%A3%9E%E4%B8%8D%E8%B5%B7%E6%9D%A5%E7%9A%84%E7%AB%A5%E5%B9%B4> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:31:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%BD%90%E4%BC%8A%E7%9A%84%E8%AF%BB%E5%BF%83%E6%AD%8C%E5%8D%95> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:31:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%9B%A0%E4%B8%BA%E7%88%B1%E6%83%85%E5%BE%88%E5%A4%8D%E6%9D%82> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:31:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%88%9D%E6%9D%A5%E4%B9%8D%E5%88%B0%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:31:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%B0%8F%E9%95%87%E6%BB%8B%E5%91%B3%E7%AC%AC%E4%B8%89%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:31:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%9C%BA%E6%99%BA%E7%9A%84%E5%8C%BB%E7%94%9F%E7%94%9F%E6%B4%BB> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:31:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%B8%85%E6%98%8E%E6%97%B6%E8%8A%82%E7%88%B1%E4%B8%8A%E6%88%91> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:31:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%BB%9D%E5%AF%B9%E9%9B%B6%E5%BA%A6%E7%AC%AC%E5%9B%9B%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:31:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%91%BD%E4%B8%AD%E6%B3%A8%E5%AE%9A%E6%88%91%E7%88%B1%E4%BD%A0> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:31:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%96%9C%E6%AC%A2%E7%9A%84%E8%AF%9D%E8%AF%B7%E5%93%8D%E9%93%83> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:31:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%98%8E%E5%98%8E%EF%BC%9A%E4%BA%94%E5%B0%BA%E4%BA%8C%E5%AF%B8> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:31:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%A4%84%E5%A5%B3%E6%83%85%E7%BC%98%E7%AC%AC%E4%BA%94%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:31:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%B0%86%E6%81%8B%E7%88%B1%E8%BF%9B%E8%A1%8C%E5%88%B0%E5%BA%95> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:31:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%81%90%E6%80%96%E5%88%86%E5%AD%90%E7%9A%84%E5%AD%A9%E5%AD%90> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:32:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%8A%A2%E6%95%91%E5%88%87%E5%B0%94%E8%AF%BA%E8%B4%9D%E5%88%A9> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:32:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%98%AF%E7%9C%9F%E7%88%B1%E8%BF%98%E6%98%AF%E5%B8%8C%E6%9C%9B> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:32:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%B5%AA%E6%BC%AB%E5%8C%BB%E7%94%9F%E9%87%91%E5%B8%88%E5%82%85> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:32:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/10539856/> (referer: https://www.douban.com/search?q=%E6%B1%89%E5%B0%BC%E6%8B%94%20%E7%AC%AC%E4%B8%80%E5%AD%A3)
2020-04-30 14:32:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/10539856/>
{'cover': 'http://img.rr.tv/seasonCover/20200426/o_1587869823434.png',
 'data_type': 'movie',
 'id': 'rrmj_262',
 'intro': '本剧根据著名畅销小说《红龙》（Red '
          'Dragon）和同名电影改编。                                                                    \u3000\u3000'
          'Will Graham（休·丹西 Hugh Dancy '
          '饰）是FBI的特别调查顾问，也是一名犯罪分析师。Will有一种特别的能力：可以在犯罪现场根据线索还原犯罪经过。他正在调查一起凶残的连环杀人案，凶手非常狡猾，每次作案留下的线索都很少。为了破案，Will向著名的心理医生Hannibal '
          'Lecter（麦德斯·米科尔森 Mads Mikkelsen '
          '饰）寻求帮助。在案件调查的过程中，这位学术精湛又极具个人品味的Hannibal都对Will有所启发，让他感觉离揭开凶手的真正身份又近了一步。但在亲手击毙罪犯之后Will陷入了自责和幻境中，不得不再次向Hannibal寻求帮助。渐渐，Will越发依赖这位受人尊重和爱戴的医生。但是，故事似乎才刚刚开始......',
 'is_new': False,
 'name': '汉尼拔 第一季',
 'platforms': '',
 'publishdate': '2013-04-04',
 'rate': 8.1,
 'sectionid': 'rrmj_1917',
 'tags': ['悬疑', '惊悚', '犯罪'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/10539856/'}
2020-04-30 14:32:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%88%B1%E5%B0%94%E5%85%B0%E4%BA%BA%EF%BC%9A%E5%AF%B9%E8%AF%9D> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:32:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%89%B9%E6%9C%97%E6%99%AE%E7%9A%84%E7%BE%8E%E5%9B%BD%E6%A2%A6> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:32:11 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/388250/> (referer: https://www.douban.com/search?q=%E6%B8%85%E6%98%8E%E6%97%B6%E8%8A%82%E7%88%B1%E4%B8%8A%E6%88%91)
2020-04-30 14:32:11 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/388250/>: HTTP status code is not handled or not allowed
2020-04-30 14:32:13 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/682917/> (referer: https://www.douban.com/search?q=%E6%9C%BA%E6%99%BA%E7%9A%84%E5%8C%BB%E7%94%9F%E7%94%9F%E6%B4%BB)
2020-04-30 14:32:13 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/682917/>: HTTP status code is not handled or not allowed
2020-04-30 14:32:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%9C%9F%E5%A5%BD%E5%95%8A%EF%BC%81%E5%85%89%E6%BA%90%E6%B0%8F> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:32:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%A1%97%E5%A4%B4%E7%BE%8E%E9%A3%9F%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:32:16 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/26675381/> (referer: https://www.douban.com/search?q=%E5%9B%9B%E5%A4%84%E6%95%A3%E8%90%BD%E7%9A%84%E7%A2%8E%E7%89%87)
2020-04-30 14:32:16 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/26675381/>: HTTP status code is not handled or not allowed
2020-04-30 14:32:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E9%BB%84%E9%98%BF%E4%B8%BD%EF%BC%9A%E9%93%81%E5%A8%98%E5%AD%90> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:32:19 [scrapy.extensions.logstats] INFO: Crawled 913 pages (at 28 pages/min), scraped 416 items (at 1 items/min)
2020-04-30 14:32:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%86%8D%E8%A7%81%EF%BC%8C%E6%88%91%E7%9A%84%E6%96%B0%E9%83%8E> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:32:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%9D%82%E6%9C%AC%E9%BE%99%E4%B8%80%EF%BC%9A%E7%BB%88%E6%9B%B2> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:32:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%88%91%E4%B8%8D%E6%98%AF%E4%BD%A0%E7%9A%84%E9%BB%91%E9%AC%BC> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:32:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%89%AC%E5%AD%90%E6%B1%9F%E4%B8%AD%E7%9A%84%E5%A4%A7%E9%B3%84> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:32:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%98%AF%E7%9C%9F%E7%88%B1%E8%BF%98%E6%98%AF%E5%9B%B0%E6%83%91> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:32:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%B5%81%E6%B5%AA%E6%B1%89%E4%B8%8E%E7%8B%AC%E8%A3%81%E8%80%85> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:32:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%BF%80%E9%9C%87%E7%89%B9%E6%9C%97%E6%99%AE%E6%97%B6%E4%BB%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:32:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%8D%B1%E6%9C%BA%E8%BE%B9%E7%BC%98%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:32:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E9%BB%91%E5%B0%94%E9%83%A1%E7%9A%84%E6%97%A5%E4%B8%8E%E5%A4%9C> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:32:42 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/381711/> (referer: https://www.douban.com/search?q=%E7%88%B1%E5%B0%94%E5%85%B0%E4%BA%BA%EF%BC%9A%E5%AF%B9%E8%AF%9D)
2020-04-30 14:32:42 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/381711/>: HTTP status code is not handled or not allowed
2020-04-30 14:32:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%BD%97%E9%A9%AC%EF%BC%9A%E5%B9%95%E5%90%8E%E7%BA%AA%E5%AE%9E> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:32:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=Shawn%20Mendes%E5%85%A8%E6%96%B0%E7%BA%AA%E5%BD%95%E7%89%87> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:32:44 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/643175/> (referer: https://www.douban.com/search?q=%E7%9C%9F%E5%A5%BD%E5%95%8A%EF%BC%81%E5%85%89%E6%BA%90%E6%B0%8F)
2020-04-30 14:32:44 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/643175/>: HTTP status code is not handled or not allowed
2020-04-30 14:32:45 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/5366745/> (referer: https://www.douban.com/search?q=%E5%9B%A0%E4%B8%BA%E7%88%B1%E6%83%85%E5%BE%88%E5%A4%8D%E6%9D%82)
2020-04-30 14:32:46 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/5366745/>: HTTP status code is not handled or not allowed
2020-04-30 14:32:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%B5%AA%E6%BC%AB%E5%8C%BB%E7%94%9F%E9%87%91%E5%B8%88%E5%82%852> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:32:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%85%88%E8%A7%81%E4%B9%8B%E6%98%8E%20%E7%AC%AC%E4%BA%8C%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:32:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%90%8D%E6%A0%A1%E9%A3%8E%E6%9A%B4%20%E7%AC%AC%E4%B8%89%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:32:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%91%BD%E8%BF%90%E8%88%AA%E7%8F%AD%20%E7%AC%AC%E4%BA%8C%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:32:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%9B%9B%E5%A4%84%E7%BA%A6%E4%BC%9A%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:32:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%98%8E%E6%97%A5%E4%BC%A0%E5%A5%87%20%E7%AC%AC%E4%BA%94%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:33:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%B1%AA%E6%96%AF%E5%8C%BB%E7%94%9F%20%E7%AC%AC%E5%85%AB%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:33:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%82%B2%E6%83%A8%E4%B8%96%E7%95%8C%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:33:03 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/1488929/> (referer: https://www.douban.com/search?q=%E7%89%B9%E6%9C%97%E6%99%AE%E7%9A%84%E7%BE%8E%E5%9B%BD%E6%A2%A6)
2020-04-30 14:33:03 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/1488929/>: HTTP status code is not handled or not allowed
2020-04-30 14:33:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%8B%8D%E7%A9%B9%E6%B5%A9%E7%80%9A%20%E7%AC%AC%E5%9B%9B%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:33:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%BD%AE%E5%9B%9E%E6%B4%BE%E5%AF%B9%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:33:06 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/173597166/> (referer: https://www.douban.com/search?q=%E9%A3%9E%E4%B8%8D%E8%B5%B7%E6%9D%A5%E7%9A%84%E7%AB%A5%E5%B9%B4)
2020-04-30 14:33:06 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/173597166/>: HTTP status code is not handled or not allowed
2020-04-30 14:33:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E9%A3%8E%E9%AA%9A%E5%BE%8B%E5%B8%88%20%E7%AC%AC%E4%BA%94%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:33:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E9%BB%91%E8%89%B2%E7%AB%A5%E8%AF%9D%20%E7%AC%AC%E4%BA%8C%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:33:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E9%BB%91%E9%92%B1%E8%83%9C%E5%9C%B0%20%E7%AC%AC%E4%B8%89%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:33:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%82%B2%E9%AA%A8%E8%B4%A4%E5%A6%BB%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:33:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%82%B2%E9%AA%A8%E8%B4%A4%E5%A6%BB%20%E7%AC%AC%E4%BA%8C%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:33:19 [scrapy.extensions.logstats] INFO: Crawled 944 pages (at 31 pages/min), scraped 416 items (at 0 items/min)
2020-04-30 14:33:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%85%AC%E5%85%B3%E5%8D%B1%E6%9C%BA%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:33:19 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/681682/> (referer: https://www.douban.com/search?q=%E6%B5%AA%E6%BC%AB%E5%8C%BB%E7%94%9F%E9%87%91%E5%B8%88%E5%82%852)
2020-04-30 14:33:19 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/681682/>: HTTP status code is not handled or not allowed
2020-04-30 14:33:22 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/5921014/> (referer: https://www.douban.com/search?q=%E7%BD%97%E9%A9%AC%EF%BC%9A%E5%B9%95%E5%90%8E%E7%BA%AA%E5%AE%9E)
2020-04-30 14:33:22 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/5921014/>: HTTP status code is not handled or not allowed
2020-04-30 14:33:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%85%AC%E5%85%B3%E5%8D%B1%E6%9C%BA%20%E7%AC%AC%E4%BA%8C%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:33:24 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/58415122/> (referer: https://www.douban.com/search?q=%E8%A1%97%E5%A4%B4%E7%BE%8E%E9%A3%9F%E7%AC%AC%E4%B8%80%E5%AD%A3)
2020-04-30 14:33:24 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/58415122/>: HTTP status code is not handled or not allowed
2020-04-30 14:33:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%9B%BD%E5%9C%9F%E5%AE%89%E5%85%A8%20%E7%AC%AC%E5%85%AB%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:33:27 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/746291694/> (referer: https://www.douban.com/search?q=%E5%B0%8F%E9%95%87%E6%BB%8B%E5%91%B3%E7%AC%AC%E4%B8%89%E5%AD%A3)
2020-04-30 14:33:27 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/746291694/>: HTTP status code is not handled or not allowed
2020-04-30 14:33:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%9B%BC%E8%BE%BE%E6%B4%9B%E4%BA%BA%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:33:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%88%B1%E7%8A%AC%E6%83%85%E6%B7%B1%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:33:30 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/31894920/> (referer: https://www.douban.com/search?q=%E5%8D%B1%E6%9C%BA%E8%BE%B9%E7%BC%98%20%E7%AC%AC%E4%B8%80%E5%AD%A3)
2020-04-30 14:33:30 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/31894920/>: HTTP status code is not handled or not allowed
2020-04-30 14:33:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%9B%91%E6%9F%A5%E5%BD%B9%20%E9%87%8E%E5%B4%8E%E4%BF%AE%E5%B9%B3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:33:32 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/147655718/> (referer: https://www.douban.com/search?q=%E5%91%BD%E4%B8%AD%E6%B3%A8%E5%AE%9A%E6%88%91%E7%88%B1%E4%BD%A0)
2020-04-30 14:33:32 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/147655718/>: HTTP status code is not handled or not allowed
2020-04-30 14:33:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%BA%A6%E4%BC%9A%E7%94%B7%E5%A5%B3%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:33:34 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/8135855/> (referer: https://www.douban.com/search?q=%E5%82%B2%E9%AA%A8%E8%B4%A4%E5%A6%BB%20%E7%AC%AC%E4%BA%8C%E5%AD%A3)
2020-04-30 14:33:34 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/8135855/>: HTTP status code is not handled or not allowed
2020-04-30 14:33:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%BE%8E%E5%A6%99%E4%B9%8B%E7%89%A9%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:33:37 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/680463072/> (referer: https://www.douban.com/search?q=%E5%85%88%E8%A7%81%E4%B9%8B%E6%98%8E%20%E7%AC%AC%E4%BA%8C%E5%AD%A3)
2020-04-30 14:33:37 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/680463072/>: HTTP status code is not handled or not allowed
2020-04-30 14:33:38 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/707249355/> (referer: https://www.douban.com/search?q=%E6%98%8E%E6%97%A5%E4%BC%A0%E5%A5%87%20%E7%AC%AC%E4%BA%94%E5%AD%A3)
2020-04-30 14:33:39 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/707249355/>: HTTP status code is not handled or not allowed
2020-04-30 14:33:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%B8%80%E5%96%84%E4%B9%8B%E5%B7%AE%20%E7%AC%AC%E4%BA%8C%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:33:41 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/719380895/> (referer: https://www.douban.com/search?q=%E8%B1%AA%E6%96%AF%E5%8C%BB%E7%94%9F%20%E7%AC%AC%E5%85%AB%E5%AD%A3)
2020-04-30 14:33:41 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/719380895/>: HTTP status code is not handled or not allowed
2020-04-30 14:33:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%A4%A7%E5%B0%8F%E8%B0%8E%E8%A8%80%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:33:43 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/744815038/> (referer: https://www.douban.com/search?q=%E8%8B%8D%E7%A9%B9%E6%B5%A9%E7%80%9A%20%E7%AC%AC%E5%9B%9B%E5%AD%A3)
2020-04-30 14:33:43 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/744815038/>: HTTP status code is not handled or not allowed
2020-04-30 14:33:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%82%B2%E9%AA%A8%E4%B9%8B%E6%88%98%20%E7%AC%AC%E5%9B%9B%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:33:45 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/751759958/> (referer: https://www.douban.com/search?q=%E5%91%BD%E8%BF%90%E8%88%AA%E7%8F%AD%20%E7%AC%AC%E4%BA%8C%E5%AD%A3)
2020-04-30 14:33:46 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/751759958/>: HTTP status code is not handled or not allowed
2020-04-30 14:33:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%9D%80%E6%AD%BB%E4%BC%8A%E8%8A%99%20%E7%AC%AC%E4%B8%89%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:33:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%B5%B4%E8%A1%80%E9%BB%91%E5%B8%AE%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:33:47 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/752118678/> (referer: https://www.douban.com/search?q=%E5%90%8D%E6%A0%A1%E9%A3%8E%E6%9A%B4%20%E7%AC%AC%E4%B8%89%E5%AD%A3)
2020-04-30 14:33:48 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/752118678/>: HTTP status code is not handled or not allowed
2020-04-30 14:33:50 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/740380620/> (referer: https://www.douban.com/search?q=%E7%9B%91%E6%9F%A5%E5%BD%B9%20%E9%87%8E%E5%B4%8E%E4%BF%AE%E5%B9%B3)
2020-04-30 14:33:50 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/740380620/>: HTTP status code is not handled or not allowed
2020-04-30 14:33:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%BE%8E%E9%A3%9F%E4%B8%8D%E7%BE%8E%20%E7%AC%AC%E4%BA%8C%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:33:52 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/31558848/> (referer: https://www.douban.com/search?q=%E4%B8%80%E5%96%84%E4%B9%8B%E5%B7%AE%20%E7%AC%AC%E4%BA%8C%E5%AD%A3)
2020-04-30 14:33:53 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/31558848/>: HTTP status code is not handled or not allowed
2020-04-30 14:33:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%A5%BF%E9%83%A8%E4%B8%96%E7%95%8C%20%E7%AC%AC%E4%B8%89%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:33:55 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/758487855/> (referer: https://www.douban.com/search?q=%E5%82%B2%E9%AA%A8%E4%B9%8B%E6%88%98%20%E7%AC%AC%E5%9B%9B%E5%AD%A3)
2020-04-30 14:33:55 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/758487855/>: HTTP status code is not handled or not allowed
2020-04-30 14:33:57 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/758586301/> (referer: https://www.douban.com/search?q=%E6%9D%80%E6%AD%BB%E4%BC%8A%E8%8A%99%20%E7%AC%AC%E4%B8%89%E5%AD%A3)
2020-04-30 14:33:57 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/758586301/>: HTTP status code is not handled or not allowed
2020-04-30 14:33:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%BF%A1%E4%BB%B0%E8%B4%BE%E6%96%AF%E6%B1%80%C2%B7%E6%AF%94%E4%BC%AF> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:33:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E9%BA%BB%E6%9C%A8%E4%B8%8D%E4%BB%81%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:34:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%88%90%E4%B8%BA%E6%B2%83%E4%BC%A6%C2%B7%E5%B7%B4%E8%8F%B2%E7%89%B9> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:34:00 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/27096421/> (referer: https://www.douban.com/search?q=%E4%BF%A1%E4%BB%B0%E8%B4%BE%E6%96%AF%E6%B1%80%C2%B7%E6%AF%94%E4%BC%AF)
2020-04-30 14:34:00 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/27096421/>: HTTP status code is not handled or not allowed
2020-04-30 14:34:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%BE%BE%E4%BC%A6%C2%B7%E5%B8%83%E6%9C%97%EF%BC%9A%E5%B0%B1%E8%8C%83> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:34:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30190634/> (referer: https://www.douban.com/search?q=%E9%BA%BB%E6%9C%A8%E4%B8%8D%E4%BB%81%20%E7%AC%AC%E4%B8%80%E5%AD%A3)
2020-04-30 14:34:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30190634/>
{'cover': 'http://img.rr.tv/album/20190504/o_1556969372335.webp',
 'data_type': 'movie',
 'id': 'rrmj_14700',
 'intro': '詹姆斯·麦斯登、艾德·阿斯纳(《飞屋环游记》《圣诞精灵》)加盟Netflix新剧《Dead to '
          'Me》，琳达·卡德里尼、克里斯蒂娜·艾伯盖特(《老友记》《坏妈妈》)参演。丽兹·费尔德曼(《破产姐妹》《幸福大家庭》)编写剧本，威尔·法瑞尔和亚当·麦凯的制片公司联合CBS '
          'TV制作。                                                                    \u3000\u3000'
          '该剧共10集，被描述为喜剧版的《大小谎言》，聚焦寡妇珍(艾伯盖特)和无拘无束、拥有惊人秘密的朱迪(卡德里尼)之间的一段强大的友谊。                                                                    \u3000\u3000'
          '麦斯登饰演朱迪的爱慕对象，看起来很自信也很有逻辑，但其实是一个有着复杂过去的脆弱男人，被朱迪宽阔的胸怀和自由的精神所吸引。阿斯纳饰演的Abe住在朱迪工作的一个生活机构里，他比大多数人都机智敏捷，和朱迪关系甜蜜，经常依靠对方度过生活的波折。',
 'is_new': False,
 'name': '麻木不仁 第一季',
 'platforms': '',
 'publishdate': '2019-05-03',
 'rate': 7.8,
 'sectionid': 'rrmj_1912',
 'tags': ['喜剧'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30190634/'}
2020-04-30 14:34:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%B4%AB%E6%B0%91%E7%AA%9F%E7%9A%84%E7%99%BE%E4%B8%87%E5%AF%8C%E7%BF%81> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:34:05 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/1088630/> (referer: https://www.douban.com/search?q=%E6%88%90%E4%B8%BA%E6%B2%83%E4%BC%A6%C2%B7%E5%B7%B4%E8%8F%B2%E7%89%B9)
2020-04-30 14:34:06 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/1088630/>: HTTP status code is not handled or not allowed
2020-04-30 14:34:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%B8%80%E7%9D%81%E7%9C%BC%EF%BC%8C%E4%B8%89%E5%90%8D%E7%94%B7%E5%8F%8B> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:34:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%B8%AD%E5%9B%BD%EF%BC%9A%E6%91%87%E6%99%83%E7%9A%84%E5%B7%A8%E4%BA%BA> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:34:08 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/3622445/> (referer: https://www.douban.com/search?q=%E8%B4%AB%E6%B0%91%E7%AA%9F%E7%9A%84%E7%99%BE%E4%B8%87%E5%AF%8C%E7%BF%81)
2020-04-30 14:34:08 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/3622445/>: HTTP status code is not handled or not allowed
2020-04-30 14:34:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%9B%BD%E7%8E%8B%EF%BC%9A%E6%B0%B8%E8%BF%9C%E7%9A%84%E5%90%9B%E4%B8%BB> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:34:11 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/654857/> (referer: https://www.douban.com/search?q=%E4%B8%AD%E5%9B%BD%EF%BC%9A%E6%91%87%E6%99%83%E7%9A%84%E5%B7%A8%E4%BA%BA)
2020-04-30 14:34:11 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/654857/>: HTTP status code is not handled or not allowed
2020-04-30 14:34:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%98%A8%E6%99%9A%E8%BF%87%E5%BE%97%E5%BE%88%E6%84%89%E5%BF%AB%E5%90%A7> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:34:13 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/686526/> (referer: https://www.douban.com/search?q=%E5%9B%BD%E7%8E%8B%EF%BC%9A%E6%B0%B8%E8%BF%9C%E7%9A%84%E5%90%9B%E4%B8%BB)
2020-04-30 14:34:14 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/686526/>: HTTP status code is not handled or not allowed
2020-04-30 14:34:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%B9%94%E6%B2%BB%E5%85%8B%E9%B2%81%E5%B0%BC%E7%9A%84%E6%9B%BF%E5%A3%B0> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:34:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%BE%8E%E5%9B%BD%E5%95%86%E4%B8%9A%E5%A4%A7%E4%BA%A8%E4%BC%A0%E5%A5%87> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:34:19 [scrapy.extensions.logstats] INFO: Crawled 993 pages (at 49 pages/min), scraped 417 items (at 1 items/min)
2020-04-30 14:34:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%BA%BA%E4%BD%93%E5%99%A8%E5%AE%98%E4%BA%A4%E6%98%93%E5%AE%9E%E5%BD%95> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:34:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%A5%B3%E5%A4%A7%E6%B3%95%E5%AE%98%E9%87%91%E6%96%AF%E4%BC%AF%E6%A0%BC> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:34:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%BD%92%E5%AE%B6%EF%BC%9A%E7%A2%A7%E6%98%82%E4%B8%9D%E4%BD%9C%E5%93%81> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:34:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%9C%9F%E5%AE%9E%E7%9A%84%E5%BE%B7%E9%9B%B7%E5%B0%94%E4%B8%80%E5%AE%B6> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:34:29 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/7807048/> (referer: https://www.douban.com/search?q=%E6%98%A8%E6%99%9A%E8%BF%87%E5%BE%97%E5%BE%88%E6%84%89%E5%BF%AB%E5%90%A7)
2020-04-30 14:34:29 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/7807048/>: HTTP status code is not handled or not allowed
2020-04-30 14:34:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%89%B9%E6%9C%97%E6%99%AE%E7%9A%84%E7%99%BD%E5%AE%AB%E4%B9%8B%E8%B7%AF> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:34:32 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/89297/> (referer: https://www.douban.com/search?q=%E7%9C%9F%E5%AE%9E%E7%9A%84%E5%BE%B7%E9%9B%B7%E5%B0%94%E4%B8%80%E5%AE%B6)
2020-04-30 14:34:32 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/89297/>: HTTP status code is not handled or not allowed
2020-04-30 14:34:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%87%B4%E6%9B%BE%E7%BB%8F%E7%BE%8E%E5%A5%BD%E7%9A%84%E6%88%91%E4%BB%AC> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:34:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%A5%9E%E7%A7%98%E5%8D%9A%E5%A3%AB%20%E7%AC%AC%E5%8D%81%E4%BA%8C%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:34:35 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/328606/> (referer: https://www.douban.com/search?q=%E8%87%B4%E6%9B%BE%E7%BB%8F%E7%BE%8E%E5%A5%BD%E7%9A%84%E6%88%91%E4%BB%AC)
2020-04-30 14:34:35 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/328606/>: HTTP status code is not handled or not allowed
2020-04-30 14:34:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%B8%80%E5%A4%9C%E6%A1%83%E8%8A%B1%E8%BF%90%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:34:37 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/3260963/> (referer: https://www.douban.com/search?q=%E4%BA%BA%E4%BD%93%E5%99%A8%E5%AE%98%E4%BA%A4%E6%98%93%E5%AE%9E%E5%BD%95)
2020-04-30 14:34:37 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/3260963/>: HTTP status code is not handled or not allowed
2020-04-30 14:34:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30165318/> (referer: https://www.douban.com/search?q=%E7%BE%8E%E5%9B%BD%E5%95%86%E4%B8%9A%E5%A4%A7%E4%BA%A8%E4%BC%A0%E5%A5%87)
2020-04-30 14:34:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30165318/>
{'cover': 'https://img.rr.tv/video/20160411/o_1460387515425.jpg',
 'data_type': 'movie',
 'id': 'rrmj_1544',
 'intro': '这部纪录片讲述了著名拓荒者丹尼尔·布恩、刘易斯和克拉克、戴维·克罗基特和特库姆的一生，他们在美国的荒原上开拓了新的道路。                                                                    \u3000\u3000'
          '该系列由坎贝尔·斯科特讲述，约翰·伊勒执导，莱昂纳多·迪卡普里奥执导。',
 'is_new': False,
 'name': '美国商业大亨传奇',
 'platforms': '',
 'publishdate': '2018-03-07',
 'rate': 9.2,
 'sectionid': 'rrmj_1420',
 'tags': ['纪录片', '历史'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30165318/'}
2020-04-30 14:34:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%B8%BB%E5%8E%A8%E7%9A%84%E9%A4%90%E6%A1%8C%20%E7%AC%AC%E5%85%AD%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:34:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%B8%BB%E5%8E%A8%E7%9A%84%E9%A4%90%E6%A1%8C%20%E7%AC%AC%E5%9B%9B%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:34:43 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/25894788/> (referer: https://www.douban.com/search?q=%E5%BD%92%E5%AE%B6%EF%BC%9A%E7%A2%A7%E6%98%82%E4%B8%9D%E4%BD%9C%E5%93%81)
2020-04-30 14:34:43 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/25894788/>: HTTP status code is not handled or not allowed
2020-04-30 14:34:45 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/721299240/> (referer: https://www.douban.com/search?q=%E4%B8%80%E7%9D%81%E7%9C%BC%EF%BC%8C%E4%B8%89%E5%90%8D%E7%94%B7%E5%8F%8B)
2020-04-30 14:34:46 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/721299240/>: HTTP status code is not handled or not allowed
2020-04-30 14:34:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%BD%A0%E5%A5%BD%20%E5%86%8D%E8%A7%81%EF%BC%8C%E5%A6%88%E5%A6%88%EF%BC%81> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:34:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%8F%A4%E6%88%98%E5%9C%BA%E4%BC%A0%E5%A5%87%20%E7%AC%AC%E4%BA%94%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:34:48 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/35021753/> (referer: https://www.douban.com/search?q=%E7%A5%9E%E7%A7%98%E5%8D%9A%E5%A3%AB%20%E7%AC%AC%E5%8D%81%E4%BA%8C%E5%AD%A3)
2020-04-30 14:34:48 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/35021753/>: HTTP status code is not handled or not allowed
2020-04-30 14:34:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%81%B6%E9%AD%94%E5%9C%A8%E4%BA%BA%E9%97%B4%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:34:50 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/687937999/> (referer: https://www.douban.com/search?q=%E4%B8%BB%E5%8E%A8%E7%9A%84%E9%A4%90%E6%A1%8C%20%E7%AC%AC%E5%9B%9B%E5%AD%A3)
2020-04-30 14:34:50 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/687937999/>: HTTP status code is not handled or not allowed
2020-04-30 14:34:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%8D%8D%E5%8D%AB%E9%9B%85%E5%90%84%E5%B8%83%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:34:53 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/731619374/> (referer: https://www.douban.com/search?q=%E5%8F%A4%E6%88%98%E5%9C%BA%E4%BC%A0%E5%A5%87%20%E7%AC%AC%E4%BA%94%E5%AD%A3)
2020-04-30 14:34:53 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/731619374/>: HTTP status code is not handled or not allowed
2020-04-30 14:34:55 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/746430652/> (referer: https://www.douban.com/search?q=%E4%B8%BB%E5%8E%A8%E7%9A%84%E9%A4%90%E6%A1%8C%20%E7%AC%AC%E5%85%AD%E5%AD%A3)
2020-04-30 14:34:55 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/746430652/>: HTTP status code is not handled or not allowed
2020-04-30 14:34:58 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/758250762/> (referer: https://www.douban.com/search?q=%E6%81%B6%E9%AD%94%E5%9C%A8%E4%BA%BA%E9%97%B4%20%E7%AC%AC%E4%B8%80%E5%AD%A3)
2020-04-30 14:34:58 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/758250762/>: HTTP status code is not handled or not allowed
2020-04-30 14:34:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%8A%AF%E7%BD%AA%E5%BF%83%E7%90%86%20%E7%AC%AC%E5%8D%81%E4%BA%94%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:35:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%B4%AA%E5%98%B4%E6%84%8F%E5%A4%A7%E5%88%A9%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:35:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26387829/> (referer: https://www.douban.com/search?q=%E7%8A%AF%E7%BD%AA%E5%BF%83%E7%90%86%20%E7%AC%AC%E5%8D%81%E4%BA%94%E5%AD%A3)
2020-04-30 14:35:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26387829/>
{'cover': 'http://img.rr.tv/cover/20200110/o_1578623174709.webp',
 'data_type': 'movie',
 'id': 'rrmj_16994',
 'intro': '《犯罪心理》第十一季正式续订。讲述了美国联邦调查局总部下属的行为分析科部门（简称“BAU”）中，行为分析师们剖析最棘手的案件，分析凶手的心理和作案特征，并在他们再次施暴前预测出他们的下一步行动，协助当地警察捉拿凶手。',
 'is_new': False,
 'name': '犯罪心理 第十五季',
 'platforms': '',
 'publishdate': '2015-09-30',
 'rate': 8.3,
 'sectionid': 'rrmj_742',
 'tags': ['剧情', '悬疑', '犯罪'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26387829/'}
2020-04-30 14:35:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E9%BB%91%E6%9A%97%E7%B3%BB%E6%B8%B8%E5%AE%A2%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:35:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E9%BB%91%E8%89%B2%E6%98%9F%E6%9C%9F%E4%B8%80%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:35:05 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/405695061/> (referer: https://www.douban.com/search?q=%E9%BB%91%E6%9A%97%E7%B3%BB%E6%B8%B8%E5%AE%A2%20%E7%AC%AC%E4%B8%80%E5%AD%A3)
2020-04-30 14:35:05 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/405695061/>: HTTP status code is not handled or not allowed
2020-04-30 14:35:06 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%2595%25A6%25E5%2595%25A6%25E9%2598%259F%25E5%25A5%25B3%25E7%258E%258B%2520%25E7%25AC%25AC%25E4%25B8%2580%25E5%25AD%25A3> from <GET https://www.douban.com/search?q=%E5%95%A6%E5%95%A6%E9%98%9F%E5%A5%B3%E7%8E%8B%20%E7%AC%AC%E4%B8%80%E5%AD%A3>
2020-04-30 14:35:08 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E7%2594%259F%25E6%25AD%25BB%25E4%25B8%258E%25E8%25BD%25AE%25E5%259B%259E%2520%25E7%25AC%25AC%25E4%25B8%2580%25E5%25AD%25A3> from <GET https://www.douban.com/search?q=%E7%94%9F%E6%AD%BB%E4%B8%8E%E8%BD%AE%E5%9B%9E%20%E7%AC%AC%E4%B8%80%E5%AD%A3>
2020-04-30 14:35:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E9%BB%91%E8%89%B2%E6%98%9F%E6%9C%9F%E4%B8%80%20%E7%AC%AC%E4%BA%8C%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:35:09 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fmovie.douban.com%2Fsubject%2F31365364%2F> from <GET https://movie.douban.com/subject/31365364/>
2020-04-30 14:35:11 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E8%25B4%25AA%25E5%2598%25B4%25E6%2584%258F%25E5%25A4%25A7%25E5%2588%25A9%2520%25E7%25AC%25AC%25E4%25BA%258C%25E5%25AD%25A3> from <GET https://www.douban.com/search?q=%E8%B4%AA%E5%98%B4%E6%84%8F%E5%A4%A7%E5%88%A9%20%E7%AC%AC%E4%BA%8C%E5%AD%A3>
2020-04-30 14:35:11 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fmovie.douban.com%2Fsubject%2F31365364%2F> (referer: https://www.douban.com/search?q=%E9%BB%91%E8%89%B2%E6%98%9F%E6%9C%9F%E4%B8%80%20%E7%AC%AC%E4%B8%80%E5%AD%A3)
2020-04-30 14:35:11 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fmovie.douban.com%2Fsubject%2F31365364%2F>: HTTP status code is not handled or not allowed
2020-04-30 14:35:13 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%259D%25A5%25E5%258B%25BE%25E5%25BC%2595%25E6%2588%2591%25E7%2594%25B7%25E5%258F%258B%25E5%2590%25A7%25EF%25BC%2581> from <GET https://www.douban.com/search?q=%E6%9D%A5%E5%8B%BE%E5%BC%95%E6%88%91%E7%94%B7%E5%8F%8B%E5%90%A7%EF%BC%81>
2020-04-30 14:35:14 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E7%25A6%258F%25E6%2596%25AF%25E7%2589%25B9%25E5%258C%25BB%25E7%2594%259F%2520%25E7%25AC%25AC%25E4%25B8%2580%25E5%25AD%25A3> from <GET https://www.douban.com/search?q=%E7%A6%8F%E6%96%AF%E7%89%B9%E5%8C%BB%E7%94%9F%20%E7%AC%AC%E4%B8%80%E5%AD%A3>
2020-04-30 14:35:17 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E7%25A6%258F%25E6%2596%25AF%25E7%2589%25B9%25E5%258C%25BB%25E7%2594%259F%2520%25E7%25AC%25AC%25E4%25BA%258C%25E5%25AD%25A3> from <GET https://www.douban.com/search?q=%E7%A6%8F%E6%96%AF%E7%89%B9%E5%8C%BB%E7%94%9F%20%E7%AC%AC%E4%BA%8C%E5%AD%A3>
2020-04-30 14:35:19 [scrapy.extensions.logstats] INFO: Crawled 1027 pages (at 34 pages/min), scraped 419 items (at 2 items/min)
2020-04-30 14:35:19 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E8%25B7%25AF%25E6%2598%2593%25C2%25B7C%25C2%25B7K%25EF%25BC%259A%25E8%2580%2581%25E6%258B%259B%25E7%25AC%2591%25E4%25BA%2586> from <GET https://www.douban.com/search?q=%E8%B7%AF%E6%98%93%C2%B7C%C2%B7K%EF%BC%9A%E8%80%81%E6%8B%9B%E7%AC%91%E4%BA%86>
2020-04-30 14:35:22 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E8%25B4%25BE%25E6%2596%25AF%25E6%25B1%2580%25C2%25B7%25E6%25AF%2594%25E4%25BC%25AF%25EF%25BC%259A%25E5%25AD%25A3%25E8%258A%2582> from <GET https://www.douban.com/search?q=%E8%B4%BE%E6%96%AF%E6%B1%80%C2%B7%E6%AF%94%E4%BC%AF%EF%BC%9A%E5%AD%A3%E8%8A%82>
2020-04-30 14:35:25 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%25A8%2598%25E5%25A8%2598%25E8%2585%2594%25E7%259A%2584%25E6%2597%25A5%25E8%25AE%25B0%25E7%25AC%25AC%25E4%25BA%258C%25E5%25AD%25A3> from <GET https://www.douban.com/search?q=%E5%A8%98%E5%A8%98%E8%85%94%E7%9A%84%E6%97%A5%E8%AE%B0%E7%AC%AC%E4%BA%8C%E5%AD%A3>
2020-04-30 14:35:28 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%2597%25A0%25E6%25B3%2595%25E6%2588%2590%25E4%25B8%25BA%25E9%2587%258E%25E5%2585%25BD%25E7%259A%2584%25E6%2588%2591%25E4%25BB%25AC> from <GET https://www.douban.com/search?q=%E6%97%A0%E6%B3%95%E6%88%90%E4%B8%BA%E9%87%8E%E5%85%BD%E7%9A%84%E6%88%91%E4%BB%AC>
2020-04-30 14:35:30 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E4%25B8%25BB%25E5%258E%25A8%25E7%259A%2584%25E9%25A4%2590%25E6%25A1%258C%25EF%25BC%259A%25E6%25B3%2595%25E5%259B%25BD%25E7%25AF%2587> from <GET https://www.douban.com/search?q=%E4%B8%BB%E5%8E%A8%E7%9A%84%E9%A4%90%E6%A1%8C%EF%BC%9A%E6%B3%95%E5%9B%BD%E7%AF%87>
2020-04-30 14:35:32 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%258A%25AB%25E5%25A4%25B4%25E5%25A3%25AB%25E5%25A6%2582%25E4%25BD%2595%25E6%2594%25B9%25E5%258F%2598%25E4%25B8%2596%25E7%2595%258C> from <GET https://www.douban.com/search?q=%E6%8A%AB%E5%A4%B4%E5%A3%AB%E5%A6%82%E4%BD%95%E6%94%B9%E5%8F%98%E4%B8%96%E7%95%8C>
2020-04-30 14:35:34 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E7%25BE%258E%25E5%2588%25A9%25E5%259D%259A%25EF%25BC%259A%25E6%2588%2591%25E4%25BB%25AC%25E7%259A%2584%25E6%2595%2585%25E4%25BA%258B> from <GET https://www.douban.com/search?q=%E7%BE%8E%E5%88%A9%E5%9D%9A%EF%BC%9A%E6%88%91%E4%BB%AC%E7%9A%84%E6%95%85%E4%BA%8B>
2020-04-30 14:35:36 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%259B%25BD%25E5%25AE%259D%25E9%2593%25B6%25E8%25A1%258C%25EF%25BC%259A%25E5%25B0%258F%25E5%258F%25AF%25E5%2585%25A5%25E7%258B%25B1> from <GET https://www.douban.com/search?q=%E5%9B%BD%E5%AE%9D%E9%93%B6%E8%A1%8C%EF%BC%9A%E5%B0%8F%E5%8F%AF%E5%85%A5%E7%8B%B1>
2020-04-30 14:35:39 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%25BD%2593%25E5%2593%2588%25E5%2588%25A9%25E7%25A6%25BB%25E5%2588%25AB%25E9%259C%258D%25E6%25A0%25BC%25E6%25B2%2583%25E8%258C%25A8> from <GET https://www.douban.com/search?q=%E5%BD%93%E5%93%88%E5%88%A9%E7%A6%BB%E5%88%AB%E9%9C%8D%E6%A0%BC%E6%B2%83%E8%8C%A8>
2020-04-30 14:35:41 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%2595%25A6%25E5%2595%25A6%25E9%2598%259F%25E5%25A5%25B3%25E7%258E%258B%2520%25E7%25AC%25AC%25E4%25B8%2580%25E5%25AD%25A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:35:42 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%2595%25A6%25E5%2595%25A6%25E9%2598%259F%25E5%25A5%25B3%25E7%258E%258B%2520%25E7%25AC%25AC%25E4%25B8%2580%25E5%25AD%25A3>: HTTP status code is not handled or not allowed
2020-04-30 14:35:44 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E7%2594%259F%25E6%25AD%25BB%25E4%25B8%258E%25E8%25BD%25AE%25E5%259B%259E%2520%25E7%25AC%25AC%25E4%25B8%2580%25E5%25AD%25A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:35:44 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E7%2594%259F%25E6%25AD%25BB%25E4%25B8%258E%25E8%25BD%25AE%25E5%259B%259E%2520%25E7%25AC%25AC%25E4%25B8%2580%25E5%25AD%25A3>: HTTP status code is not handled or not allowed
2020-04-30 14:35:46 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E8%25B4%25AA%25E5%2598%25B4%25E6%2584%258F%25E5%25A4%25A7%25E5%2588%25A9%2520%25E7%25AC%25AC%25E4%25BA%258C%25E5%25AD%25A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:35:47 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E8%25B4%25AA%25E5%2598%25B4%25E6%2584%258F%25E5%25A4%25A7%25E5%2588%25A9%2520%25E7%25AC%25AC%25E4%25BA%258C%25E5%25AD%25A3>: HTTP status code is not handled or not allowed
2020-04-30 14:35:49 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%259D%258E%25E5%25B0%258F%25E9%25BE%2599%25EF%25BC%259A%25E5%258B%2587%25E5%25A3%25AB%25E7%259A%2584%25E6%2597%2585%25E7%25A8%258B> from <GET https://www.douban.com/search?q=%E6%9D%8E%E5%B0%8F%E9%BE%99%EF%BC%9A%E5%8B%87%E5%A3%AB%E7%9A%84%E6%97%85%E7%A8%8B>
2020-04-30 14:35:52 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%259D%25A5%25E5%258B%25BE%25E5%25BC%2595%25E6%2588%2591%25E7%2594%25B7%25E5%258F%258B%25E5%2590%25A7%25EF%25BC%2581> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:35:52 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%259D%25A5%25E5%258B%25BE%25E5%25BC%2595%25E6%2588%2591%25E7%2594%25B7%25E5%258F%258B%25E5%2590%25A7%25EF%25BC%2581>: HTTP status code is not handled or not allowed
2020-04-30 14:35:54 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E7%25A6%258F%25E6%2596%25AF%25E7%2589%25B9%25E5%258C%25BB%25E7%2594%259F%2520%25E7%25AC%25AC%25E4%25B8%2580%25E5%25AD%25A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:35:54 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E7%25A6%258F%25E6%2596%25AF%25E7%2589%25B9%25E5%258C%25BB%25E7%2594%259F%2520%25E7%25AC%25AC%25E4%25B8%2580%25E5%25AD%25A3>: HTTP status code is not handled or not allowed
2020-04-30 14:35:57 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E7%25A6%258F%25E6%2596%25AF%25E7%2589%25B9%25E5%258C%25BB%25E7%2594%259F%2520%25E7%25AC%25AC%25E4%25BA%258C%25E5%25AD%25A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:35:57 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E7%25A6%258F%25E6%2596%25AF%25E7%2589%25B9%25E5%258C%25BB%25E7%2594%259F%2520%25E7%25AC%25AC%25E4%25BA%258C%25E5%25AD%25A3>: HTTP status code is not handled or not allowed
2020-04-30 14:36:00 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E8%25B7%25AF%25E6%2598%2593%25C2%25B7C%25C2%25B7K%25EF%25BC%259A%25E8%2580%2581%25E6%258B%259B%25E7%25AC%2591%25E4%25BA%2586> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:36:00 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E8%25B7%25AF%25E6%2598%2593%25C2%25B7C%25C2%25B7K%25EF%25BC%259A%25E8%2580%2581%25E6%258B%259B%25E7%25AC%2591%25E4%25BA%2586>: HTTP status code is not handled or not allowed
2020-04-30 14:36:02 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E8%25B4%25BE%25E6%2596%25AF%25E6%25B1%2580%25C2%25B7%25E6%25AF%2594%25E4%25BC%25AF%25EF%25BC%259A%25E5%25AD%25A3%25E8%258A%2582> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:36:02 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E8%25B4%25BE%25E6%2596%25AF%25E6%25B1%2580%25C2%25B7%25E6%25AF%2594%25E4%25BC%25AF%25EF%25BC%259A%25E5%25AD%25A3%25E8%258A%2582>: HTTP status code is not handled or not allowed
2020-04-30 14:36:04 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%25A8%2598%25E5%25A8%2598%25E8%2585%2594%25E7%259A%2584%25E6%2597%25A5%25E8%25AE%25B0%25E7%25AC%25AC%25E4%25BA%258C%25E5%25AD%25A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:36:04 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%25A8%2598%25E5%25A8%2598%25E8%2585%2594%25E7%259A%2584%25E6%2597%25A5%25E8%25AE%25B0%25E7%25AC%25AC%25E4%25BA%258C%25E5%25AD%25A3>: HTTP status code is not handled or not allowed
2020-04-30 14:36:07 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%2597%25A0%25E6%25B3%2595%25E6%2588%2590%25E4%25B8%25BA%25E9%2587%258E%25E5%2585%25BD%25E7%259A%2584%25E6%2588%2591%25E4%25BB%25AC> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:36:07 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%2597%25A0%25E6%25B3%2595%25E6%2588%2590%25E4%25B8%25BA%25E9%2587%258E%25E5%2585%25BD%25E7%259A%2584%25E6%2588%2591%25E4%25BB%25AC>: HTTP status code is not handled or not allowed
2020-04-30 14:36:10 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E4%25B8%25BB%25E5%258E%25A8%25E7%259A%2584%25E9%25A4%2590%25E6%25A1%258C%25EF%25BC%259A%25E6%25B3%2595%25E5%259B%25BD%25E7%25AF%2587> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:36:10 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E4%25B8%25BB%25E5%258E%25A8%25E7%259A%2584%25E9%25A4%2590%25E6%25A1%258C%25EF%25BC%259A%25E6%25B3%2595%25E5%259B%25BD%25E7%25AF%2587>: HTTP status code is not handled or not allowed
2020-04-30 14:36:12 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%258A%25AB%25E5%25A4%25B4%25E5%25A3%25AB%25E5%25A6%2582%25E4%25BD%2595%25E6%2594%25B9%25E5%258F%2598%25E4%25B8%2596%25E7%2595%258C> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:36:12 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%258A%25AB%25E5%25A4%25B4%25E5%25A3%25AB%25E5%25A6%2582%25E4%25BD%2595%25E6%2594%25B9%25E5%258F%2598%25E4%25B8%2596%25E7%2595%258C>: HTTP status code is not handled or not allowed
2020-04-30 14:36:14 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E7%25BE%258E%25E5%2588%25A9%25E5%259D%259A%25EF%25BC%259A%25E6%2588%2591%25E4%25BB%25AC%25E7%259A%2584%25E6%2595%2585%25E4%25BA%258B> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:36:14 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E7%25BE%258E%25E5%2588%25A9%25E5%259D%259A%25EF%25BC%259A%25E6%2588%2591%25E4%25BB%25AC%25E7%259A%2584%25E6%2595%2585%25E4%25BA%258B>: HTTP status code is not handled or not allowed
2020-04-30 14:36:16 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%259B%25BD%25E5%25AE%259D%25E9%2593%25B6%25E8%25A1%258C%25EF%25BC%259A%25E5%25B0%258F%25E5%258F%25AF%25E5%2585%25A5%25E7%258B%25B1> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:36:16 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%259B%25BD%25E5%25AE%259D%25E9%2593%25B6%25E8%25A1%258C%25EF%25BC%259A%25E5%25B0%258F%25E5%258F%25AF%25E5%2585%25A5%25E7%258B%25B1>: HTTP status code is not handled or not allowed
2020-04-30 14:36:19 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%25BD%2593%25E5%2593%2588%25E5%2588%25A9%25E7%25A6%25BB%25E5%2588%25AB%25E9%259C%258D%25E6%25A0%25BC%25E6%25B2%2583%25E8%258C%25A8> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:36:19 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%25BD%2593%25E5%2593%2588%25E5%2588%25A9%25E7%25A6%25BB%25E5%2588%25AB%25E9%259C%258D%25E6%25A0%25BC%25E6%25B2%2583%25E8%258C%25A8>: HTTP status code is not handled or not allowed
2020-04-30 14:36:19 [scrapy.extensions.logstats] INFO: Crawled 1042 pages (at 15 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 14:36:21 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%259E%2584%25E5%25BB%25BA%25E3%2580%258A%25E7%2596%25AF%25E7%258B%2582%25E5%258A%25A8%25E7%2589%25A9%25E5%259F%258E%25E3%2580%258B> from <GET https://www.douban.com/search?q=%E6%9E%84%E5%BB%BA%E3%80%8A%E7%96%AF%E7%8B%82%E5%8A%A8%E7%89%A9%E5%9F%8E%E3%80%8B>
2020-04-30 14:36:24 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E7%259A%2587%25E5%2590%258E%25E4%25B9%2590%25E9%2598%259F%25EF%25BC%259A%25E6%25BC%2594%25E5%2587%25BA%25E5%25B2%2581%25E6%259C%2588> from <GET https://www.douban.com/search?q=%E7%9A%87%E5%90%8E%E4%B9%90%E9%98%9F%EF%BC%9A%E6%BC%94%E5%87%BA%E5%B2%81%E6%9C%88>
2020-04-30 14:36:27 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E8%25B4%25A9%25E5%258D%2596%25E3%2580%258C%25E7%2588%25B1%25E3%2580%258D%25E7%259A%2584%25E7%2594%25B7%25E5%25AD%2590%25E4%25BB%25AC> from <GET https://www.douban.com/search?q=%E8%B4%A9%E5%8D%96%E3%80%8C%E7%88%B1%E3%80%8D%E7%9A%84%E7%94%B7%E5%AD%90%E4%BB%AC>
2020-04-30 14:36:29 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%259D%258E%25E5%25B0%258F%25E9%25BE%2599%25EF%25BC%259A%25E5%258B%2587%25E5%25A3%25AB%25E7%259A%2584%25E6%2597%2585%25E7%25A8%258B> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:36:29 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%259D%258E%25E5%25B0%258F%25E9%25BE%2599%25EF%25BC%259A%25E5%258B%2587%25E5%25A3%25AB%25E7%259A%2584%25E6%2597%2585%25E7%25A8%258B>: HTTP status code is not handled or not allowed
2020-04-30 14:36:32 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%2588%2591%25E7%259A%2584%25E5%25A4%25A9%25E6%2589%258D%25E5%25A5%25B3%25E5%258F%258B%2520%25E7%25BA%25AA%25E5%25BD%2595%25E7%2589%2587> from <GET https://www.douban.com/search?q=%E6%88%91%E7%9A%84%E5%A4%A9%E6%89%8D%E5%A5%B3%E5%8F%8B%20%E7%BA%AA%E5%BD%95%E7%89%87>
2020-04-30 14:36:34 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%2595%25A6%25E7%2585%258C%25E8%258E%25AB%25E9%25AB%2598%25E7%25AA%259F%2520%25E7%25BE%258E%25E7%259A%2584%25E5%2585%25A8%25E8%25B2%258C> from <GET https://www.douban.com/search?q=%E6%95%A6%E7%85%8C%E8%8E%AB%E9%AB%98%E7%AA%9F%20%E7%BE%8E%E7%9A%84%E5%85%A8%E8%B2%8C>
2020-04-30 14:36:37 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E7%2589%25B9%25E6%2596%25AF%25E6%258B%2589%25EF%25BC%259A%25E9%2597%25AA%25E7%2594%25B5%25E7%259A%2584%25E4%25B8%25BB%25E4%25BA%25BA%2520> from <GET https://www.douban.com/search?q=%E7%89%B9%E6%96%AF%E6%8B%89%EF%BC%9A%E9%97%AA%E7%94%B5%E7%9A%84%E4%B8%BB%E4%BA%BA%20>
2020-04-30 14:36:40 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%2580%25A5%25E8%25AF%258A%25E5%25AE%25A4%25E7%259A%2584%25E6%2595%2585%25E4%25BA%258B%2520%25E7%25AC%25AC%25E4%25BA%258C%25E5%25AD%25A3> from <GET https://www.douban.com/search?q=%E6%80%A5%E8%AF%8A%E5%AE%A4%E7%9A%84%E6%95%85%E4%BA%8B%20%E7%AC%AC%E4%BA%8C%E5%AD%A3>
2020-04-30 14:36:42 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E4%25BA%259A%25E5%25BD%2593%25C2%25B7%25E6%25A1%2591%25E5%25BE%25B7%25E5%258B%2592%25EF%25BC%259A100%2525%25E6%2596%25B0%25E9%25B2%259C> from <GET https://www.douban.com/search?q=%E4%BA%9A%E5%BD%93%C2%B7%E6%A1%91%E5%BE%B7%E5%8B%92%EF%BC%9A100%25%E6%96%B0%E9%B2%9C>
2020-04-30 14:36:44 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%2587%25AF%25E6%2596%2587%25C2%25B7%25E5%2593%2588%25E7%2589%25B9%25EF%25BC%259A%25E4%25B8%258D%25E8%25B4%259F%25E8%25B4%25A3%25E4%25BB%25BB> from <GET https://www.douban.com/search?q=%E5%87%AF%E6%96%87%C2%B7%E5%93%88%E7%89%B9%EF%BC%9A%E4%B8%8D%E8%B4%9F%E8%B4%A3%E4%BB%BB>
2020-04-30 14:36:45 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%2597%25BA%25E8%25BE%25BE%25C2%25B7%25E5%25A1%259E%25E5%2585%258B%25E4%25B8%259D%25EF%25BC%259A%25E4%25B8%258D%25E6%25AD%25A3%25E5%25B8%25B8> from <GET https://www.douban.com/search?q=%E6%97%BA%E8%BE%BE%C2%B7%E5%A1%9E%E5%85%8B%E4%B8%9D%EF%BC%9A%E4%B8%8D%E6%AD%A3%E5%B8%B8>
2020-04-30 14:36:48 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E7%25BA%25A6%25E7%25BF%25B0%25C2%25B7%25E5%2588%2597%25E4%25BE%25AC%25E7%259A%2584%25E7%2590%2586%25E6%2583%25B3%25E4%25B8%2596%25E7%2595%258C> from <GET https://www.douban.com/search?q=%E7%BA%A6%E7%BF%B0%C2%B7%E5%88%97%E4%BE%AC%E7%9A%84%E7%90%86%E6%83%B3%E4%B8%96%E7%95%8C>
2020-04-30 14:36:51 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E4%25BA%25BA%25E4%25BD%2593%25E5%25A5%25A5%25E5%25A6%2599%25E4%25B9%258B%25E7%25BB%2586%25E8%2583%259E%25E7%259A%2584%25E6%259A%2597%25E6%2588%2598> from <GET https://www.douban.com/search?q=%E4%BA%BA%E4%BD%93%E5%A5%A5%E5%A6%99%E4%B9%8B%E7%BB%86%E8%83%9E%E7%9A%84%E6%9A%97%E6%88%98>
2020-04-30 14:36:53 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%258D%2595%25E5%2590%2591%25E4%25B9%2590%25E9%2598%259F%25EF%25BC%259A%25E8%25BF%2599%25E5%25B0%25B1%25E6%2598%25AF%25E6%2588%2591%25E4%25BB%25AC> from <GET https://www.douban.com/search?q=%E5%8D%95%E5%90%91%E4%B9%90%E9%98%9F%EF%BC%9A%E8%BF%99%E5%B0%B1%E6%98%AF%E6%88%91%E4%BB%AC>
2020-04-30 14:36:56 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%2588%2591%25E7%259A%2584%25E5%25BB%25BA%25E7%25AD%2591%25E5%25B8%2588%25EF%25BC%259A%25E5%25AF%25BB%25E7%2588%25B6%25E4%25B9%258B%25E6%2597%2585> from <GET https://www.douban.com/search?q=%E6%88%91%E7%9A%84%E5%BB%BA%E7%AD%91%E5%B8%88%EF%BC%9A%E5%AF%BB%E7%88%B6%E4%B9%8B%E6%97%85>
2020-04-30 14:36:58 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%258F%25AD%25E7%25A7%2598%25EF%25BC%259A%25E9%2587%2591%25E5%25AD%2597%25E5%25A1%2594%25E9%25BB%2591%25E6%259A%2597%25E4%25B9%258B%25E8%25B0%259C> from <GET https://www.douban.com/search?q=%E6%8F%AD%E7%A7%98%EF%BC%9A%E9%87%91%E5%AD%97%E5%A1%94%E9%BB%91%E6%9A%97%E4%B9%8B%E8%B0%9C>
2020-04-30 14:37:00 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%259E%2584%25E5%25BB%25BA%25E3%2580%258A%25E7%2596%25AF%25E7%258B%2582%25E5%258A%25A8%25E7%2589%25A9%25E5%259F%258E%25E3%2580%258B> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:37:00 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%259E%2584%25E5%25BB%25BA%25E3%2580%258A%25E7%2596%25AF%25E7%258B%2582%25E5%258A%25A8%25E7%2589%25A9%25E5%259F%258E%25E3%2580%258B>: HTTP status code is not handled or not allowed
2020-04-30 14:37:03 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E7%259A%2587%25E5%2590%258E%25E4%25B9%2590%25E9%2598%259F%25EF%25BC%259A%25E6%25BC%2594%25E5%2587%25BA%25E5%25B2%2581%25E6%259C%2588> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:37:03 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E7%259A%2587%25E5%2590%258E%25E4%25B9%2590%25E9%2598%259F%25EF%25BC%259A%25E6%25BC%2594%25E5%2587%25BA%25E5%25B2%2581%25E6%259C%2588>: HTTP status code is not handled or not allowed
2020-04-30 14:37:05 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E8%25B4%25A9%25E5%258D%2596%25E3%2580%258C%25E7%2588%25B1%25E3%2580%258D%25E7%259A%2584%25E7%2594%25B7%25E5%25AD%2590%25E4%25BB%25AC> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:37:05 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E8%25B4%25A9%25E5%258D%2596%25E3%2580%258C%25E7%2588%25B1%25E3%2580%258D%25E7%259A%2584%25E7%2594%25B7%25E5%25AD%2590%25E4%25BB%25AC>: HTTP status code is not handled or not allowed
2020-04-30 14:37:08 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E7%2589%25B9%25E6%259C%2597%25E6%2599%25AE%25E5%2592%258C%25E5%25B8%258C%25E6%258B%2589%25E9%2587%258C%25E7%259A%2584%25E6%2595%2585%25E4%25BA%258B> from <GET https://www.douban.com/search?q=%E7%89%B9%E6%9C%97%E6%99%AE%E5%92%8C%E5%B8%8C%E6%8B%89%E9%87%8C%E7%9A%84%E6%95%85%E4%BA%8B>
2020-04-30 14:37:10 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%2588%2591%25E7%259A%2584%25E5%25A4%25A9%25E6%2589%258D%25E5%25A5%25B3%25E5%258F%258B%2520%25E7%25BA%25AA%25E5%25BD%2595%25E7%2589%2587> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:37:10 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%2588%2591%25E7%259A%2584%25E5%25A4%25A9%25E6%2589%258D%25E5%25A5%25B3%25E5%258F%258B%2520%25E7%25BA%25AA%25E5%25BD%2595%25E7%2589%2587>: HTTP status code is not handled or not allowed
2020-04-30 14:37:13 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%2595%25A6%25E7%2585%258C%25E8%258E%25AB%25E9%25AB%2598%25E7%25AA%259F%2520%25E7%25BE%258E%25E7%259A%2584%25E5%2585%25A8%25E8%25B2%258C> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:37:13 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%2595%25A6%25E7%2585%258C%25E8%258E%25AB%25E9%25AB%2598%25E7%25AA%259F%2520%25E7%25BE%258E%25E7%259A%2584%25E5%2585%25A8%25E8%25B2%258C>: HTTP status code is not handled or not allowed
2020-04-30 14:37:15 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E7%2589%25B9%25E6%2596%25AF%25E6%258B%2589%25EF%25BC%259A%25E9%2597%25AA%25E7%2594%25B5%25E7%259A%2584%25E4%25B8%25BB%25E4%25BA%25BA%2520> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:37:15 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E7%2589%25B9%25E6%2596%25AF%25E6%258B%2589%25EF%25BC%259A%25E9%2597%25AA%25E7%2594%25B5%25E7%259A%2584%25E4%25B8%25BB%25E4%25BA%25BA%2520>: HTTP status code is not handled or not allowed
2020-04-30 14:37:18 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%2580%25A5%25E8%25AF%258A%25E5%25AE%25A4%25E7%259A%2584%25E6%2595%2585%25E4%25BA%258B%2520%25E7%25AC%25AC%25E4%25BA%258C%25E5%25AD%25A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:37:18 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%2580%25A5%25E8%25AF%258A%25E5%25AE%25A4%25E7%259A%2584%25E6%2595%2585%25E4%25BA%258B%2520%25E7%25AC%25AC%25E4%25BA%258C%25E5%25AD%25A3>: HTTP status code is not handled or not allowed
2020-04-30 14:37:19 [scrapy.extensions.logstats] INFO: Crawled 1050 pages (at 8 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 14:37:19 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E4%25BA%259A%25E5%25BD%2593%25C2%25B7%25E6%25A1%2591%25E5%25BE%25B7%25E5%258B%2592%25EF%25BC%259A100%2525%25E6%2596%25B0%25E9%25B2%259C> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:37:19 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E4%25BA%259A%25E5%25BD%2593%25C2%25B7%25E6%25A1%2591%25E5%25BE%25B7%25E5%258B%2592%25EF%25BC%259A100%2525%25E6%2596%25B0%25E9%25B2%259C>: HTTP status code is not handled or not allowed
2020-04-30 14:37:22 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%2587%25AF%25E6%2596%2587%25C2%25B7%25E5%2593%2588%25E7%2589%25B9%25EF%25BC%259A%25E4%25B8%258D%25E8%25B4%259F%25E8%25B4%25A3%25E4%25BB%25BB> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:37:22 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%2587%25AF%25E6%2596%2587%25C2%25B7%25E5%2593%2588%25E7%2589%25B9%25EF%25BC%259A%25E4%25B8%258D%25E8%25B4%259F%25E8%25B4%25A3%25E4%25BB%25BB>: HTTP status code is not handled or not allowed
2020-04-30 14:37:24 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%2597%25BA%25E8%25BE%25BE%25C2%25B7%25E5%25A1%259E%25E5%2585%258B%25E4%25B8%259D%25EF%25BC%259A%25E4%25B8%258D%25E6%25AD%25A3%25E5%25B8%25B8> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:37:24 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%2597%25BA%25E8%25BE%25BE%25C2%25B7%25E5%25A1%259E%25E5%2585%258B%25E4%25B8%259D%25EF%25BC%259A%25E4%25B8%258D%25E6%25AD%25A3%25E5%25B8%25B8>: HTTP status code is not handled or not allowed
2020-04-30 14:37:26 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E7%25BA%25A6%25E7%25BF%25B0%25C2%25B7%25E5%2588%2597%25E4%25BE%25AC%25E7%259A%2584%25E7%2590%2586%25E6%2583%25B3%25E4%25B8%2596%25E7%2595%258C> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:37:26 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E7%25BA%25A6%25E7%25BF%25B0%25C2%25B7%25E5%2588%2597%25E4%25BE%25AC%25E7%259A%2584%25E7%2590%2586%25E6%2583%25B3%25E4%25B8%2596%25E7%2595%258C>: HTTP status code is not handled or not allowed
2020-04-30 14:37:29 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E4%25BA%25BA%25E4%25BD%2593%25E5%25A5%25A5%25E5%25A6%2599%25E4%25B9%258B%25E7%25BB%2586%25E8%2583%259E%25E7%259A%2584%25E6%259A%2597%25E6%2588%2598> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:37:29 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E4%25BA%25BA%25E4%25BD%2593%25E5%25A5%25A5%25E5%25A6%2599%25E4%25B9%258B%25E7%25BB%2586%25E8%2583%259E%25E7%259A%2584%25E6%259A%2597%25E6%2588%2598>: HTTP status code is not handled or not allowed
2020-04-30 14:37:31 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%258D%2595%25E5%2590%2591%25E4%25B9%2590%25E9%2598%259F%25EF%25BC%259A%25E8%25BF%2599%25E5%25B0%25B1%25E6%2598%25AF%25E6%2588%2591%25E4%25BB%25AC> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:37:31 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%258D%2595%25E5%2590%2591%25E4%25B9%2590%25E9%2598%259F%25EF%25BC%259A%25E8%25BF%2599%25E5%25B0%25B1%25E6%2598%25AF%25E6%2588%2591%25E4%25BB%25AC>: HTTP status code is not handled or not allowed
2020-04-30 14:37:33 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%2588%2591%25E7%259A%2584%25E5%25BB%25BA%25E7%25AD%2591%25E5%25B8%2588%25EF%25BC%259A%25E5%25AF%25BB%25E7%2588%25B6%25E4%25B9%258B%25E6%2597%2585> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:37:33 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%2588%2591%25E7%259A%2584%25E5%25BB%25BA%25E7%25AD%2591%25E5%25B8%2588%25EF%25BC%259A%25E5%25AF%25BB%25E7%2588%25B6%25E4%25B9%258B%25E6%2597%2585>: HTTP status code is not handled or not allowed
2020-04-30 14:37:36 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%258F%25AD%25E7%25A7%2598%25EF%25BC%259A%25E9%2587%2591%25E5%25AD%2597%25E5%25A1%2594%25E9%25BB%2591%25E6%259A%2597%25E4%25B9%258B%25E8%25B0%259C> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:37:36 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%258F%25AD%25E7%25A7%2598%25EF%25BC%259A%25E9%2587%2591%25E5%25AD%2597%25E5%25A1%2594%25E9%25BB%2591%25E6%259A%2597%25E4%25B9%258B%25E8%25B0%259C>: HTTP status code is not handled or not allowed
2020-04-30 14:37:37 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E8%25AF%259A%25E9%2582%2580%25E8%25BE%25A3%25E5%25A6%25B9%25EF%25BC%259A%25E7%25BD%2591%25E7%25BB%259C%25E6%2580%25A7%25E4%25B8%258E%25E7%2588%25B1> from <GET https://www.douban.com/search?q=%E8%AF%9A%E9%82%80%E8%BE%A3%E5%A6%B9%EF%BC%9A%E7%BD%91%E7%BB%9C%E6%80%A7%E4%B8%8E%E7%88%B1>
2020-04-30 14:37:39 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E9%25B2%258D%25E5%258B%2583%25C2%25B7%25E6%258B%2589%25E6%2589%258E%25EF%25BC%259A51%25E5%258C%25BA%25E5%2592%258C%25E9%25A3%259E%25E7%25A2%259F> from <GET https://www.douban.com/search?q=%E9%B2%8D%E5%8B%83%C2%B7%E6%8B%89%E6%89%8E%EF%BC%9A51%E5%8C%BA%E5%92%8C%E9%A3%9E%E7%A2%9F>
2020-04-30 14:37:42 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E4%25B8%2580%25E7%25BA%25A7%25E6%2596%25B9%25E7%25A8%258B%25E5%25BC%258F%25EF%25BC%259A%25E7%2596%25BE%25E9%2580%259F%25E4%25BA%2589%25E8%2583%259C> from <GET https://www.douban.com/search?q=%E4%B8%80%E7%BA%A7%E6%96%B9%E7%A8%8B%E5%BC%8F%EF%BC%9A%E7%96%BE%E9%80%9F%E4%BA%89%E8%83%9C>
2020-04-30 14:37:44 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E7%2589%25B9%25E6%259C%2597%25E6%2599%25AE%25E5%2592%258C%25E5%25B8%258C%25E6%258B%2589%25E9%2587%258C%25E7%259A%2584%25E6%2595%2585%25E4%25BA%258B> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:37:44 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E7%2589%25B9%25E6%259C%2597%25E6%2599%25AE%25E5%2592%258C%25E5%25B8%258C%25E6%258B%2589%25E9%2587%258C%25E7%259A%2584%25E6%2595%2585%25E4%25BA%258B>: HTTP status code is not handled or not allowed
2020-04-30 14:37:45 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%259B%259E%25E5%25BF%2586%25E5%25BD%2595%25EF%25BC%259A%25E5%25BC%2582%25E5%25BD%25A2%25E8%25B5%25B7%25E6%25BA%2590%25E6%2595%2585%25E4%25BA%258B> from <GET https://www.douban.com/search?q=%E5%9B%9E%E5%BF%86%E5%BD%95%EF%BC%9A%E5%BC%82%E5%BD%A2%E8%B5%B7%E6%BA%90%E6%95%85%E4%BA%8B>
2020-04-30 14:37:48 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%259C%25B0%25E5%25B9%25B3%25E7%25BA%25BF%25E7%25B3%25BB%25E5%2588%2597%25EF%25BC%259A%25E8%25B7%25A8%25E6%2580%25A7%25E5%2588%25AB%25E8%2580%2585> from <GET https://www.douban.com/search?q=%E5%9C%B0%E5%B9%B3%E7%BA%BF%E7%B3%BB%E5%88%97%EF%BC%9A%E8%B7%A8%E6%80%A7%E5%88%AB%E8%80%85>
2020-04-30 14:37:50 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%25B0%25B8%25E4%25B8%258D%25E5%2585%25A5%25E7%259D%25A1%25EF%25BC%259A%25E7%258C%259B%25E9%25AC%25BC%25E8%25A1%2597%25E4%25BC%25A0%25E5%25A5%2587> from <GET https://www.douban.com/search?q=%E6%B0%B8%E4%B8%8D%E5%85%A5%E7%9D%A1%EF%BC%9A%E7%8C%9B%E9%AC%BC%E8%A1%97%E4%BC%A0%E5%A5%87>
2020-04-30 14:37:53 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E4%25BF%259D%25E7%25BD%2597%25E6%2595%2599%25E4%25BD%25A0%25E5%2581%259A%25E9%259D%25A2%25E5%258C%2585%2520%25E7%25AC%25AC%25E4%25B8%2580%25E5%25AD%25A3> from <GET https://www.douban.com/search?q=%E4%BF%9D%E7%BD%97%E6%95%99%E4%BD%A0%E5%81%9A%E9%9D%A2%E5%8C%85%20%E7%AC%AC%E4%B8%80%E5%AD%A3>
2020-04-30 14:37:55 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%25AE%259E%25E4%25B9%25A0%25E5%258C%25BB%25E7%2594%259F%25E6%25A0%25BC%25E8%2595%25BE%2520%25E7%25AC%25AC%25E5%258D%2581%25E5%2585%25AD%25E5%25AD%25A3> from <GET https://www.douban.com/search?q=%E5%AE%9E%E4%B9%A0%E5%8C%BB%E7%94%9F%E6%A0%BC%E8%95%BE%20%E7%AC%AC%E5%8D%81%E5%85%AD%E5%AD%A3>
2020-04-30 14:37:57 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E9%25BB%2591%25E6%259A%2597%25E7%2589%25A9%25E8%25B4%25A8%25E4%25B8%2589%25E9%2583%25A8%25E6%259B%25B2%2520%25E7%25AC%25AC%25E4%25B8%2580%25E5%25AD%25A3> from <GET https://www.douban.com/search?q=%E9%BB%91%E6%9A%97%E7%89%A9%E8%B4%A8%E4%B8%89%E9%83%A8%E6%9B%B2%20%E7%AC%AC%E4%B8%80%E5%AD%A3>
2020-04-30 14:37:59 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%2587%25AF%25E7%2591%259F%25E7%2590%25B3%25C2%25B7%25E8%25B5%2596%25E6%2581%25A9%25EF%25BC%259A%25E8%2580%2580%25E7%259C%25BC%25E5%25A6%2582%25E5%2588%259D> from <GET https://www.douban.com/search?q=%E5%87%AF%E7%91%9F%E7%90%B3%C2%B7%E8%B5%96%E6%81%A9%EF%BC%9A%E8%80%80%E7%9C%BC%E5%A6%82%E5%88%9D>
2020-04-30 14:38:02 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%25B3%25B0%25E5%258B%2592%25C2%25B7%25E6%2596%25AF%25E5%25A8%2581%25E5%25A4%25AB%25E7%2589%25B9%25E6%2597%25A0%25E7%2595%258F%25E4%25B9%258B%25E6%2597%2585> from <GET https://www.douban.com/search?q=%E6%B3%B0%E5%8B%92%C2%B7%E6%96%AF%E5%A8%81%E5%A4%AB%E7%89%B9%E6%97%A0%E7%95%8F%E4%B9%8B%E6%97%85>
2020-04-30 14:38:05 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%2590%2589%25E5%25A7%2586%25C2%25B7%25E5%258A%25A0%25E8%258F%25B2%25E6%25A0%25B9%25EF%25BC%259A%25E5%25AE%2587%25E5%25AE%2599%25E5%2585%2588%25E7%2594%259F> from <GET https://www.douban.com/search?q=%E5%90%89%E5%A7%86%C2%B7%E5%8A%A0%E8%8F%B2%E6%A0%B9%EF%BC%9A%E5%AE%87%E5%AE%99%E5%85%88%E7%94%9F>
2020-04-30 14:38:07 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%2593%2588%25E5%2588%25A9%25C2%25B7%25E6%25B3%25A2%25E7%2589%25B9%25EF%25BC%259A%25E4%25B8%2580%25E6%25AE%25B5%25E9%25AD%2594%25E6%25B3%2595%25E5%258F%25B2> from <GET https://www.douban.com/search?q=%E5%93%88%E5%88%A9%C2%B7%E6%B3%A2%E7%89%B9%EF%BC%9A%E4%B8%80%E6%AE%B5%E9%AD%94%E6%B3%95%E5%8F%B2>
2020-04-30 14:38:10 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E9%2598%25BF%25E9%2587%258C%25C2%25B7%25E6%25B2%2599%25E8%258F%25B2%25E5%25B0%2594%25EF%25BC%259A%25E5%258F%258C%25E9%2587%258D%25E5%2590%25A6%25E5%25AE%259A> from <GET https://www.douban.com/search?q=%E9%98%BF%E9%87%8C%C2%B7%E6%B2%99%E8%8F%B2%E5%B0%94%EF%BC%9A%E5%8F%8C%E9%87%8D%E5%90%A6%E5%AE%9A>
2020-04-30 14:38:12 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E9%25A9%25AC%25E9%25BE%2599%25C2%25B7%25E9%259F%25A6%25E6%2581%25A9%25E6%2596%25AF%25EF%25BC%259A%25E5%258D%258A%25E9%2586%2592%25E4%25B8%258D%25E9%2586%2592> from <GET https://www.douban.com/search?q=%E9%A9%AC%E9%BE%99%C2%B7%E9%9F%A6%E6%81%A9%E6%96%AF%EF%BC%9A%E5%8D%8A%E9%86%92%E4%B8%8D%E9%86%92>
2020-04-30 14:38:15 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E8%25AF%259A%25E9%2582%2580%25E8%25BE%25A3%25E5%25A6%25B9%25EF%25BC%259A%25E7%25BD%2591%25E7%25BB%259C%25E6%2580%25A7%25E4%25B8%258E%25E7%2588%25B1> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:38:15 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E8%25AF%259A%25E9%2582%2580%25E8%25BE%25A3%25E5%25A6%25B9%25EF%25BC%259A%25E7%25BD%2591%25E7%25BB%259C%25E6%2580%25A7%25E4%25B8%258E%25E7%2588%25B1>: HTTP status code is not handled or not allowed
2020-04-30 14:38:17 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E9%25B2%258D%25E5%258B%2583%25C2%25B7%25E6%258B%2589%25E6%2589%258E%25EF%25BC%259A51%25E5%258C%25BA%25E5%2592%258C%25E9%25A3%259E%25E7%25A2%259F> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:38:17 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E9%25B2%258D%25E5%258B%2583%25C2%25B7%25E6%258B%2589%25E6%2589%258E%25EF%25BC%259A51%25E5%258C%25BA%25E5%2592%258C%25E9%25A3%259E%25E7%25A2%259F>: HTTP status code is not handled or not allowed
2020-04-30 14:38:19 [scrapy.extensions.logstats] INFO: Crawled 1061 pages (at 11 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 14:38:20 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E4%25B8%2580%25E7%25BA%25A7%25E6%2596%25B9%25E7%25A8%258B%25E5%25BC%258F%25EF%25BC%259A%25E7%2596%25BE%25E9%2580%259F%25E4%25BA%2589%25E8%2583%259C> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:38:20 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E4%25B8%2580%25E7%25BA%25A7%25E6%2596%25B9%25E7%25A8%258B%25E5%25BC%258F%25EF%25BC%259A%25E7%2596%25BE%25E9%2580%259F%25E4%25BA%2589%25E8%2583%259C>: HTTP status code is not handled or not allowed
2020-04-30 14:38:23 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E7%259F%25B3%25E5%258E%259F%25E9%2587%258C%25E7%25BE%258E%25E7%259A%2584%25E5%25B8%258C%25E8%2585%258A%25E6%259C%25AC%25E8%2589%25B2%25E6%2597%2585%25E8%25A1%258C> from <GET https://www.douban.com/search?q=%E7%9F%B3%E5%8E%9F%E9%87%8C%E7%BE%8E%E7%9A%84%E5%B8%8C%E8%85%8A%E6%9C%AC%E8%89%B2%E6%97%85%E8%A1%8C>
2020-04-30 14:38:25 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%259B%259E%25E5%25BF%2586%25E5%25BD%2595%25EF%25BC%259A%25E5%25BC%2582%25E5%25BD%25A2%25E8%25B5%25B7%25E6%25BA%2590%25E6%2595%2585%25E4%25BA%258B> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:38:25 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%259B%259E%25E5%25BF%2586%25E5%25BD%2595%25EF%25BC%259A%25E5%25BC%2582%25E5%25BD%25A2%25E8%25B5%25B7%25E6%25BA%2590%25E6%2595%2585%25E4%25BA%258B>: HTTP status code is not handled or not allowed
2020-04-30 14:38:28 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%259C%25B0%25E5%25B9%25B3%25E7%25BA%25BF%25E7%25B3%25BB%25E5%2588%2597%25EF%25BC%259A%25E8%25B7%25A8%25E6%2580%25A7%25E5%2588%25AB%25E8%2580%2585> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:38:28 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%259C%25B0%25E5%25B9%25B3%25E7%25BA%25BF%25E7%25B3%25BB%25E5%2588%2597%25EF%25BC%259A%25E8%25B7%25A8%25E6%2580%25A7%25E5%2588%25AB%25E8%2580%2585>: HTTP status code is not handled or not allowed
2020-04-30 14:38:31 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%25B0%25B8%25E4%25B8%258D%25E5%2585%25A5%25E7%259D%25A1%25EF%25BC%259A%25E7%258C%259B%25E9%25AC%25BC%25E8%25A1%2597%25E4%25BC%25A0%25E5%25A5%2587> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:38:31 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%25B0%25B8%25E4%25B8%258D%25E5%2585%25A5%25E7%259D%25A1%25EF%25BC%259A%25E7%258C%259B%25E9%25AC%25BC%25E8%25A1%2597%25E4%25BC%25A0%25E5%25A5%2587>: HTTP status code is not handled or not allowed
2020-04-30 14:38:33 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E4%25BF%259D%25E7%25BD%2597%25E6%2595%2599%25E4%25BD%25A0%25E5%2581%259A%25E9%259D%25A2%25E5%258C%2585%2520%25E7%25AC%25AC%25E4%25B8%2580%25E5%25AD%25A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:38:33 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E4%25BF%259D%25E7%25BD%2597%25E6%2595%2599%25E4%25BD%25A0%25E5%2581%259A%25E9%259D%25A2%25E5%258C%2585%2520%25E7%25AC%25AC%25E4%25B8%2580%25E5%25AD%25A3>: HTTP status code is not handled or not allowed
2020-04-30 14:38:36 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%25AE%259E%25E4%25B9%25A0%25E5%258C%25BB%25E7%2594%259F%25E6%25A0%25BC%25E8%2595%25BE%2520%25E7%25AC%25AC%25E5%258D%2581%25E5%2585%25AD%25E5%25AD%25A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:38:36 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%25AE%259E%25E4%25B9%25A0%25E5%258C%25BB%25E7%2594%259F%25E6%25A0%25BC%25E8%2595%25BE%2520%25E7%25AC%25AC%25E5%258D%2581%25E5%2585%25AD%25E5%25AD%25A3>: HTTP status code is not handled or not allowed
2020-04-30 14:38:38 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E9%25BB%2591%25E6%259A%2597%25E7%2589%25A9%25E8%25B4%25A8%25E4%25B8%2589%25E9%2583%25A8%25E6%259B%25B2%2520%25E7%25AC%25AC%25E4%25B8%2580%25E5%25AD%25A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:38:38 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E9%25BB%2591%25E6%259A%2597%25E7%2589%25A9%25E8%25B4%25A8%25E4%25B8%2589%25E9%2583%25A8%25E6%259B%25B2%2520%25E7%25AC%25AC%25E4%25B8%2580%25E5%25AD%25A3>: HTTP status code is not handled or not allowed
2020-04-30 14:38:40 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%2587%25AF%25E7%2591%259F%25E7%2590%25B3%25C2%25B7%25E8%25B5%2596%25E6%2581%25A9%25EF%25BC%259A%25E8%2580%2580%25E7%259C%25BC%25E5%25A6%2582%25E5%2588%259D> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:38:40 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%2587%25AF%25E7%2591%259F%25E7%2590%25B3%25C2%25B7%25E8%25B5%2596%25E6%2581%25A9%25EF%25BC%259A%25E8%2580%2580%25E7%259C%25BC%25E5%25A6%2582%25E5%2588%259D>: HTTP status code is not handled or not allowed
2020-04-30 14:38:43 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%25B3%25B0%25E5%258B%2592%25C2%25B7%25E6%2596%25AF%25E5%25A8%2581%25E5%25A4%25AB%25E7%2589%25B9%25E6%2597%25A0%25E7%2595%258F%25E4%25B9%258B%25E6%2597%2585> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:38:43 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%25B3%25B0%25E5%258B%2592%25C2%25B7%25E6%2596%25AF%25E5%25A8%2581%25E5%25A4%25AB%25E7%2589%25B9%25E6%2597%25A0%25E7%2595%258F%25E4%25B9%258B%25E6%2597%2585>: HTTP status code is not handled or not allowed
2020-04-30 14:38:46 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%2590%2589%25E5%25A7%2586%25C2%25B7%25E5%258A%25A0%25E8%258F%25B2%25E6%25A0%25B9%25EF%25BC%259A%25E5%25AE%2587%25E5%25AE%2599%25E5%2585%2588%25E7%2594%259F> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:38:46 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%2590%2589%25E5%25A7%2586%25C2%25B7%25E5%258A%25A0%25E8%258F%25B2%25E6%25A0%25B9%25EF%25BC%259A%25E5%25AE%2587%25E5%25AE%2599%25E5%2585%2588%25E7%2594%259F>: HTTP status code is not handled or not allowed
2020-04-30 14:38:48 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%2593%2588%25E5%2588%25A9%25C2%25B7%25E6%25B3%25A2%25E7%2589%25B9%25EF%25BC%259A%25E4%25B8%2580%25E6%25AE%25B5%25E9%25AD%2594%25E6%25B3%2595%25E5%258F%25B2> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:38:49 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%2593%2588%25E5%2588%25A9%25C2%25B7%25E6%25B3%25A2%25E7%2589%25B9%25EF%25BC%259A%25E4%25B8%2580%25E6%25AE%25B5%25E9%25AD%2594%25E6%25B3%2595%25E5%258F%25B2>: HTTP status code is not handled or not allowed
2020-04-30 14:38:51 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E9%2598%25BF%25E9%2587%258C%25C2%25B7%25E6%25B2%2599%25E8%258F%25B2%25E5%25B0%2594%25EF%25BC%259A%25E5%258F%258C%25E9%2587%258D%25E5%2590%25A6%25E5%25AE%259A> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:38:51 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E9%2598%25BF%25E9%2587%258C%25C2%25B7%25E6%25B2%2599%25E8%258F%25B2%25E5%25B0%2594%25EF%25BC%259A%25E5%258F%258C%25E9%2587%258D%25E5%2590%25A6%25E5%25AE%259A>: HTTP status code is not handled or not allowed
2020-04-30 14:38:54 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E9%25A9%25AC%25E9%25BE%2599%25C2%25B7%25E9%259F%25A6%25E6%2581%25A9%25E6%2596%25AF%25EF%25BC%259A%25E5%258D%258A%25E9%2586%2592%25E4%25B8%258D%25E9%2586%2592> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:38:54 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E9%25A9%25AC%25E9%25BE%2599%25C2%25B7%25E9%259F%25A6%25E6%2581%25A9%25E6%2596%25AF%25EF%25BC%259A%25E5%258D%258A%25E9%2586%2592%25E4%25B8%258D%25E9%2586%2592>: HTTP status code is not handled or not allowed
2020-04-30 14:38:56 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E4%25BB%258E%25E6%259A%2597%25E5%2588%25B0%25E6%2598%258E%25EF%25BC%259A%25E7%2594%25B5%25E8%25A7%2586%25E4%25B8%258E%25E5%25BD%25A9%25E8%2599%25B9%25E5%258F%25B2> from <GET https://www.douban.com/search?q=%E4%BB%8E%E6%9A%97%E5%88%B0%E6%98%8E%EF%BC%9A%E7%94%B5%E8%A7%86%E4%B8%8E%E5%BD%A9%E8%99%B9%E5%8F%B2>
2020-04-30 14:38:59 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E7%2588%25B1%25E5%259B%25A0%25E6%2596%25AF%25E5%259D%25A6%25E9%259A%25BE%25E8%25A7%25A3%25E7%259A%2584%25E9%2587%258F%25E5%25AD%2590%25E4%25B9%258B%25E8%25B0%259C> from <GET https://www.douban.com/search?q=%E7%88%B1%E5%9B%A0%E6%96%AF%E5%9D%A6%E9%9A%BE%E8%A7%A3%E7%9A%84%E9%87%8F%E5%AD%90%E4%B9%8B%E8%B0%9C>
2020-04-30 14:39:01 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E7%2589%25B9%25E6%259C%2597%25E6%2599%25AE%25E5%25AE%25B6%25E6%2597%258F%25E4%25BB%258E%25E7%25A7%25BB%25E6%25B0%2591%25E5%2588%25B0%25E6%2580%25BB%25E7%25BB%259F> from <GET https://www.douban.com/search?q=%E7%89%B9%E6%9C%97%E6%99%AE%E5%AE%B6%E6%97%8F%E4%BB%8E%E7%A7%BB%E6%B0%91%E5%88%B0%E6%80%BB%E7%BB%9F>
2020-04-30 14:39:04 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E7%259F%25B3%25E5%258E%259F%25E9%2587%258C%25E7%25BE%258E%25E7%259A%2584%25E5%25B8%258C%25E8%2585%258A%25E6%259C%25AC%25E8%2589%25B2%25E6%2597%2585%25E8%25A1%258C> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:39:04 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E7%259F%25B3%25E5%258E%259F%25E9%2587%258C%25E7%25BE%258E%25E7%259A%2584%25E5%25B8%258C%25E8%2585%258A%25E6%259C%25AC%25E8%2589%25B2%25E6%2597%2585%25E8%25A1%258C>: HTTP status code is not handled or not allowed
2020-04-30 14:39:07 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E9%2592%25B1%25E4%25BF%25A1%25E4%25BC%258A%25EF%25BC%259A%25E4%25BA%259A%25E6%25B4%25B2%25E7%25AC%2591%25E6%2598%259F%25E9%2597%25B9%25E7%25BE%258E%25E5%259B%25BD> from <GET https://www.douban.com/search?q=%E9%92%B1%E4%BF%A1%E4%BC%8A%EF%BC%9A%E4%BA%9A%E6%B4%B2%E7%AC%91%E6%98%9F%E9%97%B9%E7%BE%8E%E5%9B%BD>
2020-04-30 14:39:09 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E9%2598%25BF%25E5%2587%25A1%25E8%25BE%25BE%25EF%25BC%259A%25E5%2588%259B%25E5%25BB%25BA%25E6%25BD%2598%25E5%25A4%259A%25E6%258B%2589%25E4%25B8%2596%25E7%2595%258C> from <GET https://www.douban.com/search?q=%E9%98%BF%E5%87%A1%E8%BE%BE%EF%BC%9A%E5%88%9B%E5%BB%BA%E6%BD%98%E5%A4%9A%E6%8B%89%E4%B8%96%E7%95%8C>
2020-04-30 14:39:12 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%2590%258E%25E8%25A1%2597%25E7%2594%25B7%25E5%25AD%25A9%25EF%25BC%259A%25E4%25BA%258C%25E5%258D%2581%25E5%25B9%25B4%25E5%2585%25A8%25E8%25AE%25B0%25E5%25BD%2595> from <GET https://www.douban.com/search?q=%E5%90%8E%E8%A1%97%E7%94%B7%E5%AD%A9%EF%BC%9A%E4%BA%8C%E5%8D%81%E5%B9%B4%E5%85%A8%E8%AE%B0%E5%BD%95>
2020-04-30 14:39:14 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E7%2588%25B1%25EF%25BC%258C%25E6%25AD%25BB%25E4%25BA%25A1%25E5%2592%258C%25E6%259C%25BA%25E5%2599%25A8%25E4%25BA%25BA%2520%25E7%25AC%25AC%25E4%25B8%2580%25E5%25AD%25A3> from <GET https://www.douban.com/search?q=%E7%88%B1%EF%BC%8C%E6%AD%BB%E4%BA%A1%E5%92%8C%E6%9C%BA%E5%99%A8%E4%BA%BA%20%E7%AC%AC%E4%B8%80%E5%AD%A3>
2020-04-30 14:39:17 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%2588%2591%25E4%25BB%25AC%25E5%259C%25A8%25E6%25AE%25A1%25E4%25BB%25AA%25E9%25A6%2586%25E5%25B7%25A5%25E4%25BD%259C%2520%25E7%25AC%25AC%25E4%25B8%2580%25E5%25AD%25A3> from <GET https://www.douban.com/search?q=%E6%88%91%E4%BB%AC%E5%9C%A8%E6%AE%A1%E4%BB%AA%E9%A6%86%E5%B7%A5%E4%BD%9C%20%E7%AC%AC%E4%B8%80%E5%AD%A3>
2020-04-30 14:39:19 [scrapy.extensions.logstats] INFO: Crawled 1075 pages (at 14 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 14:39:20 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%259D%25BE%25E5%259D%2582%25E6%25A1%2583%25E6%259D%258E%2520%25E9%2581%25A5%25E8%25BF%259C%25E7%259A%2584%25E4%25B8%259D%25E8%25B7%25AF%25E4%25B9%258B%25E6%2597%2585> from <GET https://www.douban.com/search?q=%E6%9D%BE%E5%9D%82%E6%A1%83%E6%9D%8E%20%E9%81%A5%E8%BF%9C%E7%9A%84%E4%B8%9D%E8%B7%AF%E4%B9%8B%E6%97%85>
2020-04-30 14:39:22 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E4%25B8%25B9%25E5%25B0%25BC%25E5%25B0%2594%25C2%25B7%25E6%2596%25AF%25E6%25B4%259B%25E6%2596%25AF%25EF%25BC%259A%25E7%258E%25B0%25E5%259C%25BA%25E8%25A1%25A8%25E6%25BC%2594> from <GET https://www.douban.com/search?q=%E4%B8%B9%E5%B0%BC%E5%B0%94%C2%B7%E6%96%AF%E6%B4%9B%E6%96%AF%EF%BC%9A%E7%8E%B0%E5%9C%BA%E8%A1%A8%E6%BC%94>
2020-04-30 14:39:24 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%2587%25AF%25E8%2592%2582%25C2%25B7%25E6%25B4%25BE%25E7%2591%259E%25EF%25BC%259A%25E4%25BD%25A0%25E4%25BC%259A%25E8%25A7%2581%25E8%25AF%2581%25E6%2588%2591%25E5%2590%2597> from <GET https://www.douban.com/search?q=%E5%87%AF%E8%92%82%C2%B7%E6%B4%BE%E7%91%9E%EF%BC%9A%E4%BD%A0%E4%BC%9A%E8%A7%81%E8%AF%81%E6%88%91%E5%90%97>
2020-04-30 14:39:27 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%258F%25B2%25E8%2592%2582%25E5%25A4%25AB%25C2%25B7%25E4%25B9%2594%25E5%25B8%2583%25E6%2596%25AF%25EF%25BC%259A%25E6%259C%25BA%25E5%2599%25A8%25E4%25BA%25BA%25E7%2594%259F> from <GET https://www.douban.com/search?q=%E5%8F%B2%E8%92%82%E5%A4%AB%C2%B7%E4%B9%94%E5%B8%83%E6%96%AF%EF%BC%9A%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%94%9F>
2020-04-30 14:39:30 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%259C%2588%25E7%2590%2583%25E4%25B8%258A%25E7%259A%2584%25E5%25A4%2596%25E6%2598%259F%25E4%25BA%25BA%253A%2520%25E7%259C%259F%25E7%259B%25B8%25E6%258A%25AB%25E9%259C%25B2> from <GET https://www.douban.com/search?q=%E6%9C%88%E7%90%83%E4%B8%8A%E7%9A%84%E5%A4%96%E6%98%9F%E4%BA%BA%3A%20%E7%9C%9F%E7%9B%B8%E6%8A%AB%E9%9C%B2>
2020-04-30 14:39:32 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%25B1%2589%25E7%25BA%25B3%25C2%25B7%25E7%259B%2596%25E8%258C%25A8%25E6%25AF%2594%25E5%2591%258A%25E5%2588%25AB%25E7%25A7%2580%25EF%25BC%259A%25E5%25A8%259C%25E5%25A8%259C> from <GET https://www.douban.com/search?q=%E6%B1%89%E7%BA%B3%C2%B7%E7%9B%96%E8%8C%A8%E6%AF%94%E5%91%8A%E5%88%AB%E7%A7%80%EF%BC%9A%E5%A8%9C%E5%A8%9C>
2020-04-30 14:39:35 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%2587%25AF%25E6%2596%2587%25C2%25B7%25E5%2593%2588%25E7%2589%25B9%25EF%25BC%259A%25E6%2588%2591%25E5%258F%25AA%25E8%25B4%259F%25E8%25B4%25A3%25E6%25AC%25A2%25E4%25B9%2590> from <GET https://www.douban.com/search?q=%E5%87%AF%E6%96%87%C2%B7%E5%93%88%E7%89%B9%EF%BC%9A%E6%88%91%E5%8F%AA%E8%B4%9F%E8%B4%A3%E6%AC%A2%E4%B9%90>
2020-04-30 14:39:37 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E4%25BB%258E%25E6%259A%2597%25E5%2588%25B0%25E6%2598%258E%25EF%25BC%259A%25E7%2594%25B5%25E8%25A7%2586%25E4%25B8%258E%25E5%25BD%25A9%25E8%2599%25B9%25E5%258F%25B2> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:39:37 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E4%25BB%258E%25E6%259A%2597%25E5%2588%25B0%25E6%2598%258E%25EF%25BC%259A%25E7%2594%25B5%25E8%25A7%2586%25E4%25B8%258E%25E5%25BD%25A9%25E8%2599%25B9%25E5%258F%25B2>: HTTP status code is not handled or not allowed
2020-04-30 14:39:40 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E7%2588%25B1%25E5%259B%25A0%25E6%2596%25AF%25E5%259D%25A6%25E9%259A%25BE%25E8%25A7%25A3%25E7%259A%2584%25E9%2587%258F%25E5%25AD%2590%25E4%25B9%258B%25E8%25B0%259C> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:39:40 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E7%2588%25B1%25E5%259B%25A0%25E6%2596%25AF%25E5%259D%25A6%25E9%259A%25BE%25E8%25A7%25A3%25E7%259A%2584%25E9%2587%258F%25E5%25AD%2590%25E4%25B9%258B%25E8%25B0%259C>: HTTP status code is not handled or not allowed
2020-04-30 14:39:43 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E7%2589%25B9%25E6%259C%2597%25E6%2599%25AE%25E5%25AE%25B6%25E6%2597%258F%25E4%25BB%258E%25E7%25A7%25BB%25E6%25B0%2591%25E5%2588%25B0%25E6%2580%25BB%25E7%25BB%259F> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:39:43 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E7%2589%25B9%25E6%259C%2597%25E6%2599%25AE%25E5%25AE%25B6%25E6%2597%258F%25E4%25BB%258E%25E7%25A7%25BB%25E6%25B0%2591%25E5%2588%25B0%25E6%2580%25BB%25E7%25BB%259F>: HTTP status code is not handled or not allowed
2020-04-30 14:39:46 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%25B8%25A9%25E6%2596%25AF%25E9%25A1%25BF%25C2%25B7%25E4%25B8%2598%25E5%2590%2589%25E5%25B0%2594%25EF%25BC%259A%25E4%25B8%2596%25E7%25BA%25AA%25E5%25B7%25A8%25E4%25BA%25BA> from <GET https://www.douban.com/search?q=%E6%B8%A9%E6%96%AF%E9%A1%BF%C2%B7%E4%B8%98%E5%90%89%E5%B0%94%EF%BC%9A%E4%B8%96%E7%BA%AA%E5%B7%A8%E4%BA%BA>
2020-04-30 14:39:49 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E9%2592%25B1%25E4%25BF%25A1%25E4%25BC%258A%25EF%25BC%259A%25E4%25BA%259A%25E6%25B4%25B2%25E7%25AC%2591%25E6%2598%259F%25E9%2597%25B9%25E7%25BE%258E%25E5%259B%25BD> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:39:49 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E9%2592%25B1%25E4%25BF%25A1%25E4%25BC%258A%25EF%25BC%259A%25E4%25BA%259A%25E6%25B4%25B2%25E7%25AC%2591%25E6%2598%259F%25E9%2597%25B9%25E7%25BE%258E%25E5%259B%25BD>: HTTP status code is not handled or not allowed
2020-04-30 14:39:51 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E9%2598%25BF%25E5%2587%25A1%25E8%25BE%25BE%25EF%25BC%259A%25E5%2588%259B%25E5%25BB%25BA%25E6%25BD%2598%25E5%25A4%259A%25E6%258B%2589%25E4%25B8%2596%25E7%2595%258C> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:39:51 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E9%2598%25BF%25E5%2587%25A1%25E8%25BE%25BE%25EF%25BC%259A%25E5%2588%259B%25E5%25BB%25BA%25E6%25BD%2598%25E5%25A4%259A%25E6%258B%2589%25E4%25B8%2596%25E7%2595%258C>: HTTP status code is not handled or not allowed
2020-04-30 14:39:54 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%2590%258E%25E8%25A1%2597%25E7%2594%25B7%25E5%25AD%25A9%25EF%25BC%259A%25E4%25BA%258C%25E5%258D%2581%25E5%25B9%25B4%25E5%2585%25A8%25E8%25AE%25B0%25E5%25BD%2595> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:39:54 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%2590%258E%25E8%25A1%2597%25E7%2594%25B7%25E5%25AD%25A9%25EF%25BC%259A%25E4%25BA%258C%25E5%258D%2581%25E5%25B9%25B4%25E5%2585%25A8%25E8%25AE%25B0%25E5%25BD%2595>: HTTP status code is not handled or not allowed
2020-04-30 14:39:56 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E7%2588%25B1%25EF%25BC%258C%25E6%25AD%25BB%25E4%25BA%25A1%25E5%2592%258C%25E6%259C%25BA%25E5%2599%25A8%25E4%25BA%25BA%2520%25E7%25AC%25AC%25E4%25B8%2580%25E5%25AD%25A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:39:57 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E7%2588%25B1%25EF%25BC%258C%25E6%25AD%25BB%25E4%25BA%25A1%25E5%2592%258C%25E6%259C%25BA%25E5%2599%25A8%25E4%25BA%25BA%2520%25E7%25AC%25AC%25E4%25B8%2580%25E5%25AD%25A3>: HTTP status code is not handled or not allowed
2020-04-30 14:39:59 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%2588%2591%25E4%25BB%25AC%25E5%259C%25A8%25E6%25AE%25A1%25E4%25BB%25AA%25E9%25A6%2586%25E5%25B7%25A5%25E4%25BD%259C%2520%25E7%25AC%25AC%25E4%25B8%2580%25E5%25AD%25A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:39:59 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%2588%2591%25E4%25BB%25AC%25E5%259C%25A8%25E6%25AE%25A1%25E4%25BB%25AA%25E9%25A6%2586%25E5%25B7%25A5%25E4%25BD%259C%2520%25E7%25AC%25AC%25E4%25B8%2580%25E5%25AD%25A3>: HTTP status code is not handled or not allowed
2020-04-30 14:40:02 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%259D%25BE%25E5%259D%2582%25E6%25A1%2583%25E6%259D%258E%2520%25E9%2581%25A5%25E8%25BF%259C%25E7%259A%2584%25E4%25B8%259D%25E8%25B7%25AF%25E4%25B9%258B%25E6%2597%2585> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:40:02 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%259D%25BE%25E5%259D%2582%25E6%25A1%2583%25E6%259D%258E%2520%25E9%2581%25A5%25E8%25BF%259C%25E7%259A%2584%25E4%25B8%259D%25E8%25B7%25AF%25E4%25B9%258B%25E6%2597%2585>: HTTP status code is not handled or not allowed
2020-04-30 14:40:05 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E4%25B8%25B9%25E5%25B0%25BC%25E5%25B0%2594%25C2%25B7%25E6%2596%25AF%25E6%25B4%259B%25E6%2596%25AF%25EF%25BC%259A%25E7%258E%25B0%25E5%259C%25BA%25E8%25A1%25A8%25E6%25BC%2594> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:40:05 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E4%25B8%25B9%25E5%25B0%25BC%25E5%25B0%2594%25C2%25B7%25E6%2596%25AF%25E6%25B4%259B%25E6%2596%25AF%25EF%25BC%259A%25E7%258E%25B0%25E5%259C%25BA%25E8%25A1%25A8%25E6%25BC%2594>: HTTP status code is not handled or not allowed
2020-04-30 14:40:07 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%2587%25AF%25E8%2592%2582%25C2%25B7%25E6%25B4%25BE%25E7%2591%259E%25EF%25BC%259A%25E4%25BD%25A0%25E4%25BC%259A%25E8%25A7%2581%25E8%25AF%2581%25E6%2588%2591%25E5%2590%2597> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:40:07 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%2587%25AF%25E8%2592%2582%25C2%25B7%25E6%25B4%25BE%25E7%2591%259E%25EF%25BC%259A%25E4%25BD%25A0%25E4%25BC%259A%25E8%25A7%2581%25E8%25AF%2581%25E6%2588%2591%25E5%2590%2597>: HTTP status code is not handled or not allowed
2020-04-30 14:40:09 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%258F%25B2%25E8%2592%2582%25E5%25A4%25AB%25C2%25B7%25E4%25B9%2594%25E5%25B8%2583%25E6%2596%25AF%25EF%25BC%259A%25E6%259C%25BA%25E5%2599%25A8%25E4%25BA%25BA%25E7%2594%259F> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:40:09 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%258F%25B2%25E8%2592%2582%25E5%25A4%25AB%25C2%25B7%25E4%25B9%2594%25E5%25B8%2583%25E6%2596%25AF%25EF%25BC%259A%25E6%259C%25BA%25E5%2599%25A8%25E4%25BA%25BA%25E7%2594%259F>: HTTP status code is not handled or not allowed
2020-04-30 14:40:11 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%259C%2588%25E7%2590%2583%25E4%25B8%258A%25E7%259A%2584%25E5%25A4%2596%25E6%2598%259F%25E4%25BA%25BA%253A%2520%25E7%259C%259F%25E7%259B%25B8%25E6%258A%25AB%25E9%259C%25B2> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:40:11 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%259C%2588%25E7%2590%2583%25E4%25B8%258A%25E7%259A%2584%25E5%25A4%2596%25E6%2598%259F%25E4%25BA%25BA%253A%2520%25E7%259C%259F%25E7%259B%25B8%25E6%258A%25AB%25E9%259C%25B2>: HTTP status code is not handled or not allowed
2020-04-30 14:40:13 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%25B1%2589%25E7%25BA%25B3%25C2%25B7%25E7%259B%2596%25E8%258C%25A8%25E6%25AF%2594%25E5%2591%258A%25E5%2588%25AB%25E7%25A7%2580%25EF%25BC%259A%25E5%25A8%259C%25E5%25A8%259C> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:40:14 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%25B1%2589%25E7%25BA%25B3%25C2%25B7%25E7%259B%2596%25E8%258C%25A8%25E6%25AF%2594%25E5%2591%258A%25E5%2588%25AB%25E7%25A7%2580%25EF%25BC%259A%25E5%25A8%259C%25E5%25A8%259C>: HTTP status code is not handled or not allowed
2020-04-30 14:40:16 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%2587%25AF%25E6%2596%2587%25C2%25B7%25E5%2593%2588%25E7%2589%25B9%25EF%25BC%259A%25E6%2588%2591%25E5%258F%25AA%25E8%25B4%259F%25E8%25B4%25A3%25E6%25AC%25A2%25E4%25B9%2590> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:40:16 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%2587%25AF%25E6%2596%2587%25C2%25B7%25E5%2593%2588%25E7%2589%25B9%25EF%25BC%259A%25E6%2588%2591%25E5%258F%25AA%25E8%25B4%259F%25E8%25B4%25A3%25E6%25AC%25A2%25E4%25B9%2590>: HTTP status code is not handled or not allowed
2020-04-30 14:40:18 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E7%25BE%258E%25E5%259B%25BD%25E5%25A4%25A7%25E5%25B8%2588%25E7%25B3%25BB%25E5%2588%2597%25E4%25B9%258B%25E4%25BC%258D%25E8%25BF%25AA%25C2%25B7%25E8%2589%25BE%25E4%25BC%25A6> from <GET https://www.douban.com/search?q=%E7%BE%8E%E5%9B%BD%E5%A4%A7%E5%B8%88%E7%B3%BB%E5%88%97%E4%B9%8B%E4%BC%8D%E8%BF%AA%C2%B7%E8%89%BE%E4%BC%A6>
2020-04-30 14:40:19 [scrapy.extensions.logstats] INFO: Crawled 1090 pages (at 15 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 14:40:22 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E8%25B5%25B0%25E8%25BF%259B%25E6%25AF%2594%25E5%25B0%2594%25EF%25BC%259A%25E8%25A7%25A3%25E7%25A0%2581%25E6%25AF%2594%25E5%25B0%2594%25C2%25B7%25E7%259B%2596%25E8%258C%25A8> from <GET https://www.douban.com/search?q=%E8%B5%B0%E8%BF%9B%E6%AF%94%E5%B0%94%EF%BC%9A%E8%A7%A3%E7%A0%81%E6%AF%94%E5%B0%94%C2%B7%E7%9B%96%E8%8C%A8>
2020-04-30 14:40:24 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%25BC%2582%25E4%25B9%25A1%25E4%25BA%25BA%25EF%25BC%259A%25E4%25B8%258A%25E6%25B5%25B7%25E7%259A%2584%25E8%258A%25A5%25E5%25B7%259D%25E9%25BE%2599%25E4%25B9%258B%25E4%25BB%258B> from <GET https://www.douban.com/search?q=%E5%BC%82%E4%B9%A1%E4%BA%BA%EF%BC%9A%E4%B8%8A%E6%B5%B7%E7%9A%84%E8%8A%A5%E5%B7%9D%E9%BE%99%E4%B9%8B%E4%BB%8B>
2020-04-30 14:40:26 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%25B8%25A9%25E6%2596%25AF%25E9%25A1%25BF%25C2%25B7%25E4%25B8%2598%25E5%2590%2589%25E5%25B0%2594%25EF%25BC%259A%25E4%25B8%2596%25E7%25BA%25AA%25E5%25B7%25A8%25E4%25BA%25BA> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:40:26 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%25B8%25A9%25E6%2596%25AF%25E9%25A1%25BF%25C2%25B7%25E4%25B8%2598%25E5%2590%2589%25E5%25B0%2594%25EF%25BC%259A%25E4%25B8%2596%25E7%25BA%25AA%25E5%25B7%25A8%25E4%25BA%25BA>: HTTP status code is not handled or not allowed
2020-04-30 14:40:29 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%259D%2583%25E5%258A%259B%25E7%259A%2584%25E6%25B8%25B8%25E6%2588%258F%25EF%25BC%259A%25E6%259C%2580%25E5%2590%258E%25E7%259A%2584%25E5%25AE%2588%25E5%25A4%259C%25E4%25BA%25BA> from <GET https://www.douban.com/search?q=%E6%9D%83%E5%8A%9B%E7%9A%84%E6%B8%B8%E6%88%8F%EF%BC%9A%E6%9C%80%E5%90%8E%E7%9A%84%E5%AE%88%E5%A4%9C%E4%BA%BA>
2020-04-30 14:40:31 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E4%25BA%2586%25E4%25B8%258D%25E8%25B5%25B7%25E7%259A%2584%25E9%25BA%25A6%25E7%2591%259F%25E5%25B0%2594%25E5%25A4%25AB%25E4%25BA%25BA%2520%25E7%25AC%25AC%25E4%25B8%2589%25E5%25AD%25A3> from <GET https://www.douban.com/search?q=%E4%BA%86%E4%B8%8D%E8%B5%B7%E7%9A%84%E9%BA%A6%E7%91%9F%E5%B0%94%E5%A4%AB%E4%BA%BA%20%E7%AC%AC%E4%B8%89%E5%AD%A3>
2020-04-30 14:40:33 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%25B2%25A1%25E6%259C%2589%25E7%259C%259F%25E7%259B%25B8%25E7%259A%2584%25E5%2586%2585%25E5%25BF%2583%25E7%25A7%2598%25E5%25AF%2586%2520%25E7%25AC%25AC%25E4%25BA%258C%25E5%25AD%25A3> from <GET https://www.douban.com/search?q=%E6%B2%A1%E6%9C%89%E7%9C%9F%E7%9B%B8%E7%9A%84%E5%86%85%E5%BF%83%E7%A7%98%E5%AF%86%20%E7%AC%AC%E4%BA%8C%E5%AD%A3>
2020-04-30 14:40:35 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E7%25B4%25A7%25E6%2580%25A5%25E6%258A%25A5%25E5%2591%258A%2520%25E6%2596%25B0%25E5%259E%258B%25E5%2586%25A0%25E7%258A%25B6%25E7%2597%2585%25E6%25AF%2592%25E8%2582%25BA%25E7%2582%258E> from <GET https://www.douban.com/search?q=%E7%B4%A7%E6%80%A5%E6%8A%A5%E5%91%8A%20%E6%96%B0%E5%9E%8B%E5%86%A0%E7%8A%B6%E7%97%85%E6%AF%92%E8%82%BA%E7%82%8E>
2020-04-30 14:40:38 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D3%25E5%25B9%25B4A%25E7%258F%25AD%2520%25E4%25BB%258E%25E7%258E%25B0%25E5%259C%25A8%25E8%25B5%25B7%25E5%25A4%25A7%25E5%25AE%25B6%25E9%2583%25BD%25E6%2598%25AF%25E4%25BA%25BA%25E8%25B4%25A8> from <GET https://www.douban.com/search?q=3%E5%B9%B4A%E7%8F%AD%20%E4%BB%8E%E7%8E%B0%E5%9C%A8%E8%B5%B7%E5%A4%A7%E5%AE%B6%E9%83%BD%E6%98%AF%E4%BA%BA%E8%B4%A8>
2020-04-30 14:40:41 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%259F%2583%25E8%258E%25B1%25E6%2589%258E%25C2%25B7%25E6%2596%25BD%25E8%258E%25B1%25E8%25BE%259B%25E6%25A0%25BC%25EF%25BC%259A%25E7%25A1%25AE%25E8%25AE%25A4%25E5%2587%25BB%25E6%259D%2580> from <GET https://www.douban.com/search?q=%E5%9F%83%E8%8E%B1%E6%89%8E%C2%B7%E6%96%BD%E8%8E%B1%E8%BE%9B%E6%A0%BC%EF%BC%9A%E7%A1%AE%E8%AE%A4%E5%87%BB%E6%9D%80>
2020-04-30 14:40:44 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%25A4%25A7%25E5%258D%25AB%25C2%25B7%25E9%25B2%258D%25E4%25BC%258A%25EF%25BC%259A%25E6%2594%25B9%25E5%258F%2598%25E4%25B8%2596%25E7%2595%258C%25E7%259A%2584%25E7%2594%25B7%25E4%25BA%25BA> from <GET https://www.douban.com/search?q=%E5%A4%A7%E5%8D%AB%C2%B7%E9%B2%8D%E4%BC%8A%EF%BC%9A%E6%94%B9%E5%8F%98%E4%B8%96%E7%95%8C%E7%9A%84%E7%94%B7%E4%BA%BA>
2020-04-30 14:40:46 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E8%25A5%25BF%25E8%2592%2599%25C2%25B7%25E9%2598%25BF%25E5%25A7%2586%25E6%2596%25AF%25E7%2589%25B9%25E5%25B0%2594%25EF%25BC%259A%25E9%25A1%25BA%25E5%2585%25B6%25E8%2587%25AA%25E7%2584%25B6> from <GET https://www.douban.com/search?q=%E8%A5%BF%E8%92%99%C2%B7%E9%98%BF%E5%A7%86%E6%96%AF%E7%89%B9%E5%B0%94%EF%BC%9A%E9%A1%BA%E5%85%B6%E8%87%AA%E7%84%B6>
2020-04-30 14:40:49 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E8%25BF%2588%25E5%2585%258B%25E5%25B0%2594%25C2%25B7%25E6%259D%25B0%25E5%2585%258B%25E9%2580%258A%25EF%25BC%259A%25E5%2581%25B6%25E5%2583%258F%25E7%259A%2584%25E4%25B8%2580%25E7%2594%259F> from <GET https://www.douban.com/search?q=%E8%BF%88%E5%85%8B%E5%B0%94%C2%B7%E6%9D%B0%E5%85%8B%E9%80%8A%EF%BC%9A%E5%81%B6%E5%83%8F%E7%9A%84%E4%B8%80%E7%94%9F>
2020-04-30 14:40:51 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%25B5%2581%25E8%25A1%258C%25E7%2597%2585%25EF%25BC%259A%25E5%25A6%2582%25E4%25BD%2595%25E9%25A2%2584%25E9%2598%25B2%25E6%25B5%2581%25E6%2584%259F%25E5%25A4%25A7%25E7%2588%2586%25E5%258F%2591> from <GET https://www.douban.com/search?q=%E6%B5%81%E8%A1%8C%E7%97%85%EF%BC%9A%E5%A6%82%E4%BD%95%E9%A2%84%E9%98%B2%E6%B5%81%E6%84%9F%E5%A4%A7%E7%88%86%E5%8F%91>
2020-04-30 14:40:54 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E9%2583%2591%25E8%2582%25AF%25EF%25BC%259A%25E5%259B%25A0%25E4%25B8%25BA%25E6%259C%2589%25E4%25BD%25A0%25EF%25BC%258C%25E7%2594%259F%25E5%2591%25BD%25E6%2589%258D%25E5%25AE%258C%25E6%2595%25B4> from <GET https://www.douban.com/search?q=%E9%83%91%E8%82%AF%EF%BC%9A%E5%9B%A0%E4%B8%BA%E6%9C%89%E4%BD%A0%EF%BC%8C%E7%94%9F%E5%91%BD%E6%89%8D%E5%AE%8C%E6%95%B4>
2020-04-30 14:40:56 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%259C%25A8%25E9%2587%2591%25E7%2589%258C%25E7%259A%2584%25E6%25A0%25B8%25E5%25BF%2583%25EF%25BC%259A%25E7%25BE%258E%25E5%259B%25BD%25E4%25BD%2593%25E6%2593%258D%25E4%25B8%2591%25E9%2597%25BB> from <GET https://www.douban.com/search?q=%E5%9C%A8%E9%87%91%E7%89%8C%E7%9A%84%E6%A0%B8%E5%BF%83%EF%BC%9A%E7%BE%8E%E5%9B%BD%E4%BD%93%E6%93%8D%E4%B8%91%E9%97%BB>
2020-04-30 14:40:58 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E7%25BE%258E%25E5%259B%25BD%25E5%25A4%25A7%25E5%25B8%2588%25E7%25B3%25BB%25E5%2588%2597%25E4%25B9%258B%25E4%25BC%258D%25E8%25BF%25AA%25C2%25B7%25E8%2589%25BE%25E4%25BC%25A6> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:40:58 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E7%25BE%258E%25E5%259B%25BD%25E5%25A4%25A7%25E5%25B8%2588%25E7%25B3%25BB%25E5%2588%2597%25E4%25B9%258B%25E4%25BC%258D%25E8%25BF%25AA%25C2%25B7%25E8%2589%25BE%25E4%25BC%25A6>: HTTP status code is not handled or not allowed
2020-04-30 14:41:01 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E8%25B5%25B0%25E8%25BF%259B%25E6%25AF%2594%25E5%25B0%2594%25EF%25BC%259A%25E8%25A7%25A3%25E7%25A0%2581%25E6%25AF%2594%25E5%25B0%2594%25C2%25B7%25E7%259B%2596%25E8%258C%25A8> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:41:01 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E8%25B5%25B0%25E8%25BF%259B%25E6%25AF%2594%25E5%25B0%2594%25EF%25BC%259A%25E8%25A7%25A3%25E7%25A0%2581%25E6%25AF%2594%25E5%25B0%2594%25C2%25B7%25E7%259B%2596%25E8%258C%25A8>: HTTP status code is not handled or not allowed
2020-04-30 14:41:04 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%25BC%2582%25E4%25B9%25A1%25E4%25BA%25BA%25EF%25BC%259A%25E4%25B8%258A%25E6%25B5%25B7%25E7%259A%2584%25E8%258A%25A5%25E5%25B7%259D%25E9%25BE%2599%25E4%25B9%258B%25E4%25BB%258B> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:41:04 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%25BC%2582%25E4%25B9%25A1%25E4%25BA%25BA%25EF%25BC%259A%25E4%25B8%258A%25E6%25B5%25B7%25E7%259A%2584%25E8%258A%25A5%25E5%25B7%259D%25E9%25BE%2599%25E4%25B9%258B%25E4%25BB%258B>: HTTP status code is not handled or not allowed
2020-04-30 14:41:06 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E4%25B8%2580%25E7%25BA%25A7%25E6%2596%25B9%25E7%25A8%258B%25E5%25BC%258F%25EF%25BC%259A%25E7%2596%25BE%25E9%2580%259F%25E4%25BA%2589%25E8%2583%259C%2520%25E7%25AC%25AC%25E4%25BA%258C%25E5%25AD%25A3> from <GET https://www.douban.com/search?q=%E4%B8%80%E7%BA%A7%E6%96%B9%E7%A8%8B%E5%BC%8F%EF%BC%9A%E7%96%BE%E9%80%9F%E4%BA%89%E8%83%9C%20%E7%AC%AC%E4%BA%8C%E5%AD%A3>
2020-04-30 14:41:09 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%259D%2583%25E5%258A%259B%25E7%259A%2584%25E6%25B8%25B8%25E6%2588%258F%25EF%25BC%259A%25E6%259C%2580%25E5%2590%258E%25E7%259A%2584%25E5%25AE%2588%25E5%25A4%259C%25E4%25BA%25BA> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:41:09 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%259D%2583%25E5%258A%259B%25E7%259A%2584%25E6%25B8%25B8%25E6%2588%258F%25EF%25BC%259A%25E6%259C%2580%25E5%2590%258E%25E7%259A%2584%25E5%25AE%2588%25E5%25A4%259C%25E4%25BA%25BA>: HTTP status code is not handled or not allowed
2020-04-30 14:41:12 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E4%25BA%2586%25E4%25B8%258D%25E8%25B5%25B7%25E7%259A%2584%25E9%25BA%25A6%25E7%2591%259F%25E5%25B0%2594%25E5%25A4%25AB%25E4%25BA%25BA%2520%25E7%25AC%25AC%25E4%25B8%2589%25E5%25AD%25A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:41:12 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E4%25BA%2586%25E4%25B8%258D%25E8%25B5%25B7%25E7%259A%2584%25E9%25BA%25A6%25E7%2591%259F%25E5%25B0%2594%25E5%25A4%25AB%25E4%25BA%25BA%2520%25E7%25AC%25AC%25E4%25B8%2589%25E5%25AD%25A3>: HTTP status code is not handled or not allowed
2020-04-30 14:41:14 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%25B2%25A1%25E6%259C%2589%25E7%259C%259F%25E7%259B%25B8%25E7%259A%2584%25E5%2586%2585%25E5%25BF%2583%25E7%25A7%2598%25E5%25AF%2586%2520%25E7%25AC%25AC%25E4%25BA%258C%25E5%25AD%25A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:41:14 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%25B2%25A1%25E6%259C%2589%25E7%259C%259F%25E7%259B%25B8%25E7%259A%2584%25E5%2586%2585%25E5%25BF%2583%25E7%25A7%2598%25E5%25AF%2586%2520%25E7%25AC%25AC%25E4%25BA%258C%25E5%25AD%25A3>: HTTP status code is not handled or not allowed
2020-04-30 14:41:17 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E7%25B4%25A7%25E6%2580%25A5%25E6%258A%25A5%25E5%2591%258A%2520%25E6%2596%25B0%25E5%259E%258B%25E5%2586%25A0%25E7%258A%25B6%25E7%2597%2585%25E6%25AF%2592%25E8%2582%25BA%25E7%2582%258E> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:41:17 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E7%25B4%25A7%25E6%2580%25A5%25E6%258A%25A5%25E5%2591%258A%2520%25E6%2596%25B0%25E5%259E%258B%25E5%2586%25A0%25E7%258A%25B6%25E7%2597%2585%25E6%25AF%2592%25E8%2582%25BA%25E7%2582%258E>: HTTP status code is not handled or not allowed
2020-04-30 14:41:19 [scrapy.extensions.logstats] INFO: Crawled 1098 pages (at 8 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 14:41:19 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D3%25E5%25B9%25B4A%25E7%258F%25AD%2520%25E4%25BB%258E%25E7%258E%25B0%25E5%259C%25A8%25E8%25B5%25B7%25E5%25A4%25A7%25E5%25AE%25B6%25E9%2583%25BD%25E6%2598%25AF%25E4%25BA%25BA%25E8%25B4%25A8> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:41:19 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D3%25E5%25B9%25B4A%25E7%258F%25AD%2520%25E4%25BB%258E%25E7%258E%25B0%25E5%259C%25A8%25E8%25B5%25B7%25E5%25A4%25A7%25E5%25AE%25B6%25E9%2583%25BD%25E6%2598%25AF%25E4%25BA%25BA%25E8%25B4%25A8>: HTTP status code is not handled or not allowed
2020-04-30 14:41:22 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%259F%2583%25E8%258E%25B1%25E6%2589%258E%25C2%25B7%25E6%2596%25BD%25E8%258E%25B1%25E8%25BE%259B%25E6%25A0%25BC%25EF%25BC%259A%25E7%25A1%25AE%25E8%25AE%25A4%25E5%2587%25BB%25E6%259D%2580> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:41:22 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%259F%2583%25E8%258E%25B1%25E6%2589%258E%25C2%25B7%25E6%2596%25BD%25E8%258E%25B1%25E8%25BE%259B%25E6%25A0%25BC%25EF%25BC%259A%25E7%25A1%25AE%25E8%25AE%25A4%25E5%2587%25BB%25E6%259D%2580>: HTTP status code is not handled or not allowed
2020-04-30 14:41:24 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%25A4%25A7%25E5%258D%25AB%25C2%25B7%25E9%25B2%258D%25E4%25BC%258A%25EF%25BC%259A%25E6%2594%25B9%25E5%258F%2598%25E4%25B8%2596%25E7%2595%258C%25E7%259A%2584%25E7%2594%25B7%25E4%25BA%25BA> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:41:25 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%25A4%25A7%25E5%258D%25AB%25C2%25B7%25E9%25B2%258D%25E4%25BC%258A%25EF%25BC%259A%25E6%2594%25B9%25E5%258F%2598%25E4%25B8%2596%25E7%2595%258C%25E7%259A%2584%25E7%2594%25B7%25E4%25BA%25BA>: HTTP status code is not handled or not allowed
2020-04-30 14:41:27 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E8%25A5%25BF%25E8%2592%2599%25C2%25B7%25E9%2598%25BF%25E5%25A7%2586%25E6%2596%25AF%25E7%2589%25B9%25E5%25B0%2594%25EF%25BC%259A%25E9%25A1%25BA%25E5%2585%25B6%25E8%2587%25AA%25E7%2584%25B6> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:41:27 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E8%25A5%25BF%25E8%2592%2599%25C2%25B7%25E9%2598%25BF%25E5%25A7%2586%25E6%2596%25AF%25E7%2589%25B9%25E5%25B0%2594%25EF%25BC%259A%25E9%25A1%25BA%25E5%2585%25B6%25E8%2587%25AA%25E7%2584%25B6>: HTTP status code is not handled or not allowed
2020-04-30 14:41:30 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E8%25BF%2588%25E5%2585%258B%25E5%25B0%2594%25C2%25B7%25E6%259D%25B0%25E5%2585%258B%25E9%2580%258A%25EF%25BC%259A%25E5%2581%25B6%25E5%2583%258F%25E7%259A%2584%25E4%25B8%2580%25E7%2594%259F> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:41:30 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E8%25BF%2588%25E5%2585%258B%25E5%25B0%2594%25C2%25B7%25E6%259D%25B0%25E5%2585%258B%25E9%2580%258A%25EF%25BC%259A%25E5%2581%25B6%25E5%2583%258F%25E7%259A%2584%25E4%25B8%2580%25E7%2594%259F>: HTTP status code is not handled or not allowed
2020-04-30 14:41:32 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%25B5%2581%25E8%25A1%258C%25E7%2597%2585%25EF%25BC%259A%25E5%25A6%2582%25E4%25BD%2595%25E9%25A2%2584%25E9%2598%25B2%25E6%25B5%2581%25E6%2584%259F%25E5%25A4%25A7%25E7%2588%2586%25E5%258F%2591> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:41:32 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%25B5%2581%25E8%25A1%258C%25E7%2597%2585%25EF%25BC%259A%25E5%25A6%2582%25E4%25BD%2595%25E9%25A2%2584%25E9%2598%25B2%25E6%25B5%2581%25E6%2584%259F%25E5%25A4%25A7%25E7%2588%2586%25E5%258F%2591>: HTTP status code is not handled or not allowed
2020-04-30 14:41:34 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E9%2583%2591%25E8%2582%25AF%25EF%25BC%259A%25E5%259B%25A0%25E4%25B8%25BA%25E6%259C%2589%25E4%25BD%25A0%25EF%25BC%258C%25E7%2594%259F%25E5%2591%25BD%25E6%2589%258D%25E5%25AE%258C%25E6%2595%25B4> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:41:34 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E9%2583%2591%25E8%2582%25AF%25EF%25BC%259A%25E5%259B%25A0%25E4%25B8%25BA%25E6%259C%2589%25E4%25BD%25A0%25EF%25BC%258C%25E7%2594%259F%25E5%2591%25BD%25E6%2589%258D%25E5%25AE%258C%25E6%2595%25B4>: HTTP status code is not handled or not allowed
2020-04-30 14:41:36 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%259C%25A8%25E9%2587%2591%25E7%2589%258C%25E7%259A%2584%25E6%25A0%25B8%25E5%25BF%2583%25EF%25BC%259A%25E7%25BE%258E%25E5%259B%25BD%25E4%25BD%2593%25E6%2593%258D%25E4%25B8%2591%25E9%2597%25BB> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:41:36 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%259C%25A8%25E9%2587%2591%25E7%2589%258C%25E7%259A%2584%25E6%25A0%25B8%25E5%25BF%2583%25EF%25BC%259A%25E7%25BE%258E%25E5%259B%25BD%25E4%25BD%2593%25E6%2593%258D%25E4%25B8%2591%25E9%2597%25BB>: HTTP status code is not handled or not allowed
2020-04-30 14:41:38 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%25A4%25A7%25E5%258D%25AB%25C2%25B7%25E5%2585%258B%25E7%25BD%2597%25E6%2596%25AF%25EF%25BC%259A%25E8%25AE%25A9%25E7%25BE%258E%25E5%259B%25BD%25E5%2586%258D%25E5%25BA%25A6%25E4%25BC%259F%25E5%25A4%25A7> from <GET https://www.douban.com/search?q=%E5%A4%A7%E5%8D%AB%C2%B7%E5%85%8B%E7%BD%97%E6%96%AF%EF%BC%9A%E8%AE%A9%E7%BE%8E%E5%9B%BD%E5%86%8D%E5%BA%A6%E4%BC%9F%E5%A4%A7>
2020-04-30 14:41:41 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E8%25A9%25B9%25E5%25A7%2586%25E6%2596%25AF%25C2%25B7%25E5%258D%25A1%25E6%25A2%2585%25E9%259A%2586%25EF%25BC%259A%25E5%2586%258D%25E8%25A7%2581%25E6%25B3%25B0%25E5%259D%25A6%25E5%25B0%25BC%25E5%2585%258B> from <GET https://www.douban.com/search?q=%E8%A9%B9%E5%A7%86%E6%96%AF%C2%B7%E5%8D%A1%E6%A2%85%E9%9A%86%EF%BC%9A%E5%86%8D%E8%A7%81%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B>
2020-04-30 14:41:43 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%2588%2588%25E7%2599%25BB%25C2%25B7%25E6%258B%2589%25E5%25A7%2586%25E9%25BD%2590%25EF%25BC%259A%25E7%25BE%258E%25E9%25A3%259F%25E7%25A7%2598%25E5%25A2%2583%2520%25E7%25AC%25AC%25E4%25B8%2580%25E5%25AD%25A3> from <GET https://www.douban.com/search?q=%E6%88%88%E7%99%BB%C2%B7%E6%8B%89%E5%A7%86%E9%BD%90%EF%BC%9A%E7%BE%8E%E9%A3%9F%E7%A7%98%E5%A2%83%20%E7%AC%AC%E4%B8%80%E5%AD%A3>
2020-04-30 14:41:45 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E4%25B8%2580%25E7%25BA%25A7%25E6%2596%25B9%25E7%25A8%258B%25E5%25BC%258F%25EF%25BC%259A%25E7%2596%25BE%25E9%2580%259F%25E4%25BA%2589%25E8%2583%259C%2520%25E7%25AC%25AC%25E4%25BA%258C%25E5%25AD%25A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:41:46 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E4%25B8%2580%25E7%25BA%25A7%25E6%2596%25B9%25E7%25A8%258B%25E5%25BC%258F%25EF%25BC%259A%25E7%2596%25BE%25E9%2580%259F%25E4%25BA%2589%25E8%2583%259C%2520%25E7%25AC%25AC%25E4%25BA%258C%25E5%25AD%25A3>: HTTP status code is not handled or not allowed
2020-04-30 14:41:48 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%258B%25A8%25E5%25BC%2580%25E8%25BF%25B7%25E9%259B%25BE%25EF%25BC%259A%25E5%25B1%25B1%25E8%25BE%25BE%25E5%259F%25BA%25E6%2595%2599%25E4%25B8%258E%25E4%25BF%25A1%25E4%25BB%25B0%25E5%259B%259A%25E7%25AC%25BC> from <GET https://www.douban.com/search?q=%E6%8B%A8%E5%BC%80%E8%BF%B7%E9%9B%BE%EF%BC%9A%E5%B1%B1%E8%BE%BE%E5%9F%BA%E6%95%99%E4%B8%8E%E4%BF%A1%E4%BB%B0%E5%9B%9A%E7%AC%BC>
2020-04-30 14:41:50 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%25AF%2594%25E5%2585%258B%25E6%258B%2589%25E5%25A7%2586%25EF%25BC%259A%25E7%2591%259C%25E4%25BC%25BD%25E3%2580%2581%25E5%25A4%25A7%25E5%25B8%2588%25E3%2580%2581%25E6%2580%25A7%25E4%25BE%25B5%25E7%258A%25AF> from <GET https://www.douban.com/search?q=%E6%AF%94%E5%85%8B%E6%8B%89%E5%A7%86%EF%BC%9A%E7%91%9C%E4%BC%BD%E3%80%81%E5%A4%A7%E5%B8%88%E3%80%81%E6%80%A7%E4%BE%B5%E7%8A%AF>
2020-04-30 14:41:53 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%259D%25B0%25E7%2591%259E%25C2%25B7%25E5%25AE%258B%25E9%25A3%259E%25EF%25BC%259A%25E8%2580%2581%25E5%25AD%2590%25E6%259C%2580%25E5%2590%258E%25E8%25B7%259F%25E4%25BD%25A0%25E8%25AF%25B4%25E4%25B8%2580%25E6%25AC%25A1> from <GET https://www.douban.com/search?q=%E6%9D%B0%E7%91%9E%C2%B7%E5%AE%8B%E9%A3%9E%EF%BC%9A%E8%80%81%E5%AD%90%E6%9C%80%E5%90%8E%E8%B7%9F%E4%BD%A0%E8%AF%B4%E4%B8%80%E6%AC%A1>
2020-04-30 14:41:54 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E4%25B8%25AD%25E5%259B%25BD%25E5%258A%25B3%25E5%25B7%25A5%25E5%2585%25B5%25E5%259B%25A2%25EF%25BC%259A%25E8%258B%25B1%25E5%259B%25BD%25E8%25A2%25AB%25E9%2581%2597%25E5%25BF%2598%25E7%259A%2584%25E5%2586%259B%25E9%2598%259F> from <GET https://www.douban.com/search?q=%E4%B8%AD%E5%9B%BD%E5%8A%B3%E5%B7%A5%E5%85%B5%E5%9B%A2%EF%BC%9A%E8%8B%B1%E5%9B%BD%E8%A2%AB%E9%81%97%E5%BF%98%E7%9A%84%E5%86%9B%E9%98%9F>
2020-04-30 14:41:57 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%25BD%25B1%25E5%25AD%2590%25E5%258F%25B8%25E4%25BB%25A4%25EF%25BC%259A%25E4%25BC%258A%25E6%259C%2597%25E5%2586%259B%25E4%25BA%258B%25E5%25A4%25A7%25E5%25B8%2588%25E8%258B%258F%25E8%258E%25B1%25E6%259B%25BC%25E5%25B0%25BC> from <GET https://www.douban.com/search?q=%E5%BD%B1%E5%AD%90%E5%8F%B8%E4%BB%A4%EF%BC%9A%E4%BC%8A%E6%9C%97%E5%86%9B%E4%BA%8B%E5%A4%A7%E5%B8%88%E8%8B%8F%E8%8E%B1%E6%9B%BC%E5%B0%BC>
2020-04-30 14:42:00 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%25B9%25B3%25E5%2585%258B%25E5%25BC%2597%25E6%25B4%259B%25E4%25BC%258A%25E5%25BE%25B7%25E9%259F%25B3%25E4%25B9%2590%25E4%25BC%25A0%25E8%25AE%25B0.%25E6%259C%2588%25E4%25B9%258B%25E9%2598%25B4%25E6%259A%2597%25E9%259D%25A2> from <GET https://www.douban.com/search?q=%E5%B9%B3%E5%85%8B%E5%BC%97%E6%B4%9B%E4%BC%8A%E5%BE%B7%E9%9F%B3%E4%B9%90%E4%BC%A0%E8%AE%B0.%E6%9C%88%E4%B9%8B%E9%98%B4%E6%9A%97%E9%9D%A2>
2020-04-30 14:42:03 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E7%258C%25AE%25E7%25BB%2599%25E5%25A5%25A5%25E9%2580%258A%25E7%259A%2584%25E6%259C%2580%25E7%25BB%2588%25E5%2589%25AA%25E8%25BE%2591%25EF%25BC%259A40%25E5%25B9%25B4%25E5%2588%25B6%25E4%25BD%259C%25E5%258E%2586%25E7%25A8%258B> from <GET https://www.douban.com/search?q=%E7%8C%AE%E7%BB%99%E5%A5%A5%E9%80%8A%E7%9A%84%E6%9C%80%E7%BB%88%E5%89%AA%E8%BE%91%EF%BC%9A40%E5%B9%B4%E5%88%B6%E4%BD%9C%E5%8E%86%E7%A8%8B>
2020-04-30 14:42:05 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E7%25BA%25A6%25E7%25BF%25B0%25C2%25B7%25E6%259C%25A8%25E5%2585%25B0%25E5%25B0%25BC%25EF%25BC%259A%25E6%2597%25A0%25E7%25BA%25BF%25E7%2594%25B5%25E5%259F%258E%25E7%259A%2584%25E4%25BF%258A%25E5%25B0%258F%25E4%25BC%2599%25E5%2584%25BF> from <GET https://www.douban.com/search?q=%E7%BA%A6%E7%BF%B0%C2%B7%E6%9C%A8%E5%85%B0%E5%B0%BC%EF%BC%9A%E6%97%A0%E7%BA%BF%E7%94%B5%E5%9F%8E%E7%9A%84%E4%BF%8A%E5%B0%8F%E4%BC%99%E5%84%BF>
2020-04-30 14:42:08 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%25A4%25A7%25E5%258D%25AB%25C2%25B7%25E5%2585%258B%25E7%25BD%2597%25E6%2596%25AF%25EF%25BC%259A%25E8%25AE%25A9%25E7%25BE%258E%25E5%259B%25BD%25E5%2586%258D%25E5%25BA%25A6%25E4%25BC%259F%25E5%25A4%25A7> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:42:09 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%25A4%25A7%25E5%258D%25AB%25C2%25B7%25E5%2585%258B%25E7%25BD%2597%25E6%2596%25AF%25EF%25BC%259A%25E8%25AE%25A9%25E7%25BE%258E%25E5%259B%25BD%25E5%2586%258D%25E5%25BA%25A6%25E4%25BC%259F%25E5%25A4%25A7>: HTTP status code is not handled or not allowed
2020-04-30 14:42:11 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E8%25A9%25B9%25E5%25A7%2586%25E6%2596%25AF%25C2%25B7%25E5%258D%25A1%25E6%25A2%2585%25E9%259A%2586%25EF%25BC%259A%25E5%2586%258D%25E8%25A7%2581%25E6%25B3%25B0%25E5%259D%25A6%25E5%25B0%25BC%25E5%2585%258B> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:42:11 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E8%25A9%25B9%25E5%25A7%2586%25E6%2596%25AF%25C2%25B7%25E5%258D%25A1%25E6%25A2%2585%25E9%259A%2586%25EF%25BC%259A%25E5%2586%258D%25E8%25A7%2581%25E6%25B3%25B0%25E5%259D%25A6%25E5%25B0%25BC%25E5%2585%258B>: HTTP status code is not handled or not allowed
2020-04-30 14:42:14 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%2588%2588%25E7%2599%25BB%25C2%25B7%25E6%258B%2589%25E5%25A7%2586%25E9%25BD%2590%25EF%25BC%259A%25E7%25BE%258E%25E9%25A3%259F%25E7%25A7%2598%25E5%25A2%2583%2520%25E7%25AC%25AC%25E4%25B8%2580%25E5%25AD%25A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:42:14 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%2588%2588%25E7%2599%25BB%25C2%25B7%25E6%258B%2589%25E5%25A7%2586%25E9%25BD%2590%25EF%25BC%259A%25E7%25BE%258E%25E9%25A3%259F%25E7%25A7%2598%25E5%25A2%2583%2520%25E7%25AC%25AC%25E4%25B8%2580%25E5%25AD%25A3>: HTTP status code is not handled or not allowed
2020-04-30 14:42:17 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%258B%25A8%25E5%25BC%2580%25E8%25BF%25B7%25E9%259B%25BE%25EF%25BC%259A%25E5%25B1%25B1%25E8%25BE%25BE%25E5%259F%25BA%25E6%2595%2599%25E4%25B8%258E%25E4%25BF%25A1%25E4%25BB%25B0%25E5%259B%259A%25E7%25AC%25BC> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:42:17 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%258B%25A8%25E5%25BC%2580%25E8%25BF%25B7%25E9%259B%25BE%25EF%25BC%259A%25E5%25B1%25B1%25E8%25BE%25BE%25E5%259F%25BA%25E6%2595%2599%25E4%25B8%258E%25E4%25BF%25A1%25E4%25BB%25B0%25E5%259B%259A%25E7%25AC%25BC>: HTTP status code is not handled or not allowed
2020-04-30 14:42:19 [scrapy.extensions.logstats] INFO: Crawled 1111 pages (at 13 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 14:42:19 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%25AF%2594%25E5%2585%258B%25E6%258B%2589%25E5%25A7%2586%25EF%25BC%259A%25E7%2591%259C%25E4%25BC%25BD%25E3%2580%2581%25E5%25A4%25A7%25E5%25B8%2588%25E3%2580%2581%25E6%2580%25A7%25E4%25BE%25B5%25E7%258A%25AF> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:42:19 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%25AF%2594%25E5%2585%258B%25E6%258B%2589%25E5%25A7%2586%25EF%25BC%259A%25E7%2591%259C%25E4%25BC%25BD%25E3%2580%2581%25E5%25A4%25A7%25E5%25B8%2588%25E3%2580%2581%25E6%2580%25A7%25E4%25BE%25B5%25E7%258A%25AF>: HTTP status code is not handled or not allowed
2020-04-30 14:42:22 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%259D%25B0%25E7%2591%259E%25C2%25B7%25E5%25AE%258B%25E9%25A3%259E%25EF%25BC%259A%25E8%2580%2581%25E5%25AD%2590%25E6%259C%2580%25E5%2590%258E%25E8%25B7%259F%25E4%25BD%25A0%25E8%25AF%25B4%25E4%25B8%2580%25E6%25AC%25A1> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:42:22 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E6%259D%25B0%25E7%2591%259E%25C2%25B7%25E5%25AE%258B%25E9%25A3%259E%25EF%25BC%259A%25E8%2580%2581%25E5%25AD%2590%25E6%259C%2580%25E5%2590%258E%25E8%25B7%259F%25E4%25BD%25A0%25E8%25AF%25B4%25E4%25B8%2580%25E6%25AC%25A1>: HTTP status code is not handled or not allowed
2020-04-30 14:42:25 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E4%25B8%25AD%25E5%259B%25BD%25E5%258A%25B3%25E5%25B7%25A5%25E5%2585%25B5%25E5%259B%25A2%25EF%25BC%259A%25E8%258B%25B1%25E5%259B%25BD%25E8%25A2%25AB%25E9%2581%2597%25E5%25BF%2598%25E7%259A%2584%25E5%2586%259B%25E9%2598%259F> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:42:25 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E4%25B8%25AD%25E5%259B%25BD%25E5%258A%25B3%25E5%25B7%25A5%25E5%2585%25B5%25E5%259B%25A2%25EF%25BC%259A%25E8%258B%25B1%25E5%259B%25BD%25E8%25A2%25AB%25E9%2581%2597%25E5%25BF%2598%25E7%259A%2584%25E5%2586%259B%25E9%2598%259F>: HTTP status code is not handled or not allowed
2020-04-30 14:42:28 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%25BD%25B1%25E5%25AD%2590%25E5%258F%25B8%25E4%25BB%25A4%25EF%25BC%259A%25E4%25BC%258A%25E6%259C%2597%25E5%2586%259B%25E4%25BA%258B%25E5%25A4%25A7%25E5%25B8%2588%25E8%258B%258F%25E8%258E%25B1%25E6%259B%25BC%25E5%25B0%25BC> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:42:28 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%25BD%25B1%25E5%25AD%2590%25E5%258F%25B8%25E4%25BB%25A4%25EF%25BC%259A%25E4%25BC%258A%25E6%259C%2597%25E5%2586%259B%25E4%25BA%258B%25E5%25A4%25A7%25E5%25B8%2588%25E8%258B%258F%25E8%258E%25B1%25E6%259B%25BC%25E5%25B0%25BC>: HTTP status code is not handled or not allowed
2020-04-30 14:42:30 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%25B9%25B3%25E5%2585%258B%25E5%25BC%2597%25E6%25B4%259B%25E4%25BC%258A%25E5%25BE%25B7%25E9%259F%25B3%25E4%25B9%2590%25E4%25BC%25A0%25E8%25AE%25B0.%25E6%259C%2588%25E4%25B9%258B%25E9%2598%25B4%25E6%259A%2597%25E9%259D%25A2> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:42:31 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E5%25B9%25B3%25E5%2585%258B%25E5%25BC%2597%25E6%25B4%259B%25E4%25BC%258A%25E5%25BE%25B7%25E9%259F%25B3%25E4%25B9%2590%25E4%25BC%25A0%25E8%25AE%25B0.%25E6%259C%2588%25E4%25B9%258B%25E9%2598%25B4%25E6%259A%2597%25E9%259D%25A2>: HTTP status code is not handled or not allowed
2020-04-30 14:42:33 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E7%258C%25AE%25E7%25BB%2599%25E5%25A5%25A5%25E9%2580%258A%25E7%259A%2584%25E6%259C%2580%25E7%25BB%2588%25E5%2589%25AA%25E8%25BE%2591%25EF%25BC%259A40%25E5%25B9%25B4%25E5%2588%25B6%25E4%25BD%259C%25E5%258E%2586%25E7%25A8%258B> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:42:33 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E7%258C%25AE%25E7%25BB%2599%25E5%25A5%25A5%25E9%2580%258A%25E7%259A%2584%25E6%259C%2580%25E7%25BB%2588%25E5%2589%25AA%25E8%25BE%2591%25EF%25BC%259A40%25E5%25B9%25B4%25E5%2588%25B6%25E4%25BD%259C%25E5%258E%2586%25E7%25A8%258B>: HTTP status code is not handled or not allowed
2020-04-30 14:42:35 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E7%25BA%25A6%25E7%25BF%25B0%25C2%25B7%25E6%259C%25A8%25E5%2585%25B0%25E5%25B0%25BC%25EF%25BC%259A%25E6%2597%25A0%25E7%25BA%25BF%25E7%2594%25B5%25E5%259F%258E%25E7%259A%2584%25E4%25BF%258A%25E5%25B0%258F%25E4%25BC%2599%25E5%2584%25BF> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 14:42:35 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://sec.douban.com/b?r=https%3A%2F%2Fwww.douban.com%2Fsearch%3Fq%3D%25E7%25BA%25A6%25E7%25BF%25B0%25C2%25B7%25E6%259C%25A8%25E5%2585%25B0%25E5%25B0%25BC%25EF%25BC%259A%25E6%2597%25A0%25E7%25BA%25BF%25E7%2594%25B5%25E5%259F%258E%25E7%259A%2584%25E4%25BF%258A%25E5%25B0%258F%25E4%25BC%2599%25E5%2584%25BF>: HTTP status code is not handled or not allowed
2020-04-30 14:43:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 7 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 14:44:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 14:45:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 14:46:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 14:47:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 14:48:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 14:49:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 14:50:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 14:51:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 14:52:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 14:53:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 14:54:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 14:55:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 14:56:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 14:57:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 14:58:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 14:59:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 15:00:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 15:01:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 15:02:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 15:03:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 15:04:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 15:05:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 15:06:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 15:07:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 15:08:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 15:09:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 15:10:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 15:11:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 15:12:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 15:13:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 15:14:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 15:15:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 15:16:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 15:17:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 15:18:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 15:19:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 15:20:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 15:21:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 15:22:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 15:23:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 15:24:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 15:25:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 15:26:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 15:27:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 15:28:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 15:29:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 15:30:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 15:31:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 15:32:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 15:33:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 15:34:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 15:35:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 15:36:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 15:37:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 15:38:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 15:39:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 15:40:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 15:41:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 15:42:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 15:43:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 15:44:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 15:45:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 15:46:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 15:47:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 15:48:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 15:49:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 15:50:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 15:51:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 15:52:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 15:53:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 15:54:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 15:55:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 15:56:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 15:57:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 15:58:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 15:59:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 16:00:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 16:01:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 16:02:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 16:03:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 16:04:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 16:05:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 16:06:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 16:07:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 16:08:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 16:09:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 16:10:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 16:11:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 16:12:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 16:13:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 16:14:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 16:15:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 16:16:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 16:17:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 16:18:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 16:19:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 16:20:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 16:21:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 16:22:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 16:23:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 16:24:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 16:25:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 16:26:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 16:27:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 16:28:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 16:29:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 16:30:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 16:31:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 16:32:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 16:33:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 16:34:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 16:35:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 16:36:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 16:37:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 16:38:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 16:39:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 16:40:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 16:41:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 16:42:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 16:43:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 16:44:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 16:45:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 16:46:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 16:47:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 16:48:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 16:49:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 16:50:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 16:51:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 16:52:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 16:53:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 16:54:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 16:55:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 16:56:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 16:57:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 16:58:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 16:59:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 17:00:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 17:01:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 17:02:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 17:03:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 17:04:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 17:05:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 17:06:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 17:07:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 17:08:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 17:09:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 17:10:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 17:11:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 17:12:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 17:13:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 17:14:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 17:15:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 17:16:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 17:17:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 17:18:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 17:19:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 17:20:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 17:21:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 17:22:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 17:23:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 17:24:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 17:25:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 17:26:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 17:27:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 17:28:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 17:29:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 17:30:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 17:31:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 17:32:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 17:33:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 17:34:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 17:35:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 17:36:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 17:37:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 17:38:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 17:39:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 17:40:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 17:41:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 17:42:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 17:43:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 17:44:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 17:45:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 17:46:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 17:47:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 17:48:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 17:49:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 17:50:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 17:51:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 17:52:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 17:53:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 17:54:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 17:55:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 17:56:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 17:57:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 17:58:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 17:59:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 18:00:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 18:01:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 18:02:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 18:03:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 18:04:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 18:05:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 18:06:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 18:07:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 18:08:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 18:09:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 18:10:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 18:11:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 18:12:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 18:13:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 18:14:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 18:15:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 18:16:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 18:17:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 18:18:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 18:19:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 18:20:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 18:21:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 18:22:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 18:23:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 18:24:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 18:25:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 18:26:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 18:27:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 18:28:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 18:29:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 18:30:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 18:31:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 18:32:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 18:33:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 18:34:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 18:35:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 18:36:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 18:37:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 18:38:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 18:39:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 18:40:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 18:41:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 18:42:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 18:43:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 18:44:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 18:45:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 18:46:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 18:47:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 18:48:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 18:49:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 18:50:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 18:51:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 18:52:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 18:53:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 18:54:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 18:55:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 18:56:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 18:57:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 18:58:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 18:59:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 19:00:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 19:01:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 19:02:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 19:03:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 19:04:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 19:05:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 19:06:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 19:07:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 19:08:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 19:09:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 19:10:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 19:11:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 19:12:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 19:13:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 19:14:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 19:15:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 19:16:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 19:17:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 19:18:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 19:19:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 19:20:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 19:21:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 19:22:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 19:23:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 19:24:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 19:25:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 19:26:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 19:27:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 19:28:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 19:29:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 19:30:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 19:31:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 19:32:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 19:33:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 19:34:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 19:35:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 19:36:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 19:37:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 19:38:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 19:39:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 19:40:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 19:41:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 19:42:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 19:43:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 19:44:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 19:45:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 19:46:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 19:47:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 19:48:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 19:49:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 19:50:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 19:51:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 19:52:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 19:53:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 19:54:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 19:55:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 19:56:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 19:57:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 19:58:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 19:59:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 20:00:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 20:01:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 20:02:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 20:03:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 20:04:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 20:05:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 20:06:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 20:07:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 20:08:19 [scrapy.extensions.logstats] INFO: Crawled 1118 pages (at 0 pages/min), scraped 419 items (at 0 items/min)
2020-04-30 20:08:59 [rrmj] DEBUG: Read 1 requests from 'rrmj:spider:strat_urls'
2020-04-30 20:08:59 [scrapy.core.engine] DEBUG: Crawled (200) <POST https://api.rr.tv/v3plus/index/channel> (referer: None)
2020-04-30 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1912',
 'sectionImg': '',
 'sectionName': '看剧鉴渣男手撕不心软'}
2020-04-30 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1917',
 'sectionImg': '',
 'sectionName': '抖音爆火洗脑剧'}
2020-04-30 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1726',
 'sectionImg': '',
 'sectionName': '这些剧大家都在追'}
2020-04-30 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1904',
 'sectionImg': '',
 'sectionName': '台剧新来袭！！'}
2020-04-30 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1244',
 'sectionImg': '',
 'sectionName': '致我们甜甜的恋爱时光'}
2020-04-30 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_822',
 'sectionImg': '',
 'sectionName': '细思极恐 谁是凶手？'}
2020-04-30 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1926',
 'sectionImg': '',
 'sectionName': '力推！豆瓣高分推荐'}
2020-04-30 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1927',
 'sectionImg': '',
 'sectionName': '深夜舔屏福利'}
2020-04-30 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1646',
 'sectionImg': '',
 'sectionName': '急诊室的人间冷暖'}
2020-04-30 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1903',
 'sectionImg': '',
 'sectionName': '恶魔在人间'}
2020-04-30 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1693',
 'sectionImg': '',
 'sectionName': '病毒藏在每个角落'}
2020-04-30 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_742',
 'sectionImg': '',
 'sectionName': '热剧回归！'}
2020-04-30 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_989',
 'sectionImg': '',
 'sectionName': '腐眼看人基'}
2020-04-30 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1883',
 'sectionImg': '',
 'sectionName': '吃货必备！这些纪录片很“下饭”'}
2020-04-30 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1399',
 'sectionImg': '',
 'sectionName': '他改变了世界'}
2020-04-30 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1729',
 'sectionImg': '',
 'sectionName': '【电影】获奖佳片集结'}
2020-04-30 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1405',
 'sectionImg': '',
 'sectionName': '幕后更精彩'}
2020-04-30 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_745',
 'sectionImg': '',
 'sectionName': '本周新剧'}
2020-04-30 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1431',
 'sectionImg': '',
 'sectionName': 'LGBT人生纪实 '}
2020-04-30 20:09:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1416',
 'sectionImg': '',
 'sectionName': '怪奇世界物语'}
2020-04-30 20:09:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1421',
 'sectionImg': '',
 'sectionName': '笑到飞起的脱口秀'}
2020-04-30 20:09:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1295',
 'sectionImg': '',
 'sectionName': '巨星的诞生'}
2020-04-30 20:09:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1425',
 'sectionImg': '',
 'sectionName': '大家都在看'}
2020-04-30 20:09:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1657',
 'sectionImg': '',
 'sectionName': '奥斯卡最佳纪录片'}
2020-04-30 20:09:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1005',
 'sectionImg': '',
 'sectionName': '德国之声特辑'}
2020-04-30 20:09:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_747',
 'sectionImg': '',
 'sectionName': '完结力推'}
2020-04-30 20:09:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%B0%81%E6%98%AF%E8%A2%AB%E5%AE%B3%E8%80%85> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 20:09:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%B3%B0%E7%89%88%E6%B5%AA%E6%BC%AB%E6%BB%A1%E5%B1%8B> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 20:09:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%88%91%E7%9A%84ID%E6%98%AF%E6%B1%9F%E5%8D%97%E7%BE%8E%E4%BA%BA> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 20:09:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%9C%9D5%E6%99%9A9%EF%BC%9A%E5%B8%85%E6%B0%94%E5%92%8C%E5%B0%9A%E7%88%B1%E4%B8%8A%E6%88%91> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 20:09:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%B8%89%E6%B5%81%E4%B9%8B%E8%B7%AF> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 20:09:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%AE%A0%E7%89%A9%E6%83%85%E4%BA%BA> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 20:09:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26972688/> (referer: https://www.douban.com/search?q=%E4%B8%89%E6%B5%81%E4%B9%8B%E8%B7%AF)
2020-04-30 20:09:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26972688/>
{'cover': 'http://img.rr.tv/album/20190910/o_1568093626745.jpg',
 'data_type': 'movie',
 'id': 'rrmj_11025',
 'intro': '讲述没有金钱没有背景过着配角人生的高东万（朴叙俊 饰）和崔爱罗（金智媛 饰）冲破束缚成为业界精英、人生主角的故事。',
 'is_new': False,
 'name': '三流之路',
 'platforms': '',
 'publishdate': '2017-05-22',
 'rate': 8.3,
 'sectionid': 'rrmj_1244',
 'tags': ['剧情', '喜剧', '爱情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26972688/'}
2020-04-30 20:09:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%B8%80%E5%90%BB%E5%AE%9A%E6%83%852> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 20:09:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26788941/> (referer: https://www.douban.com/search?q=%E5%AE%A0%E7%89%A9%E6%83%85%E4%BA%BA)
2020-04-30 20:09:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26788941/>
{'cover': 'https://img.rr.tv/season/20170208/o_1486517651533.jpg',
 'data_type': 'movie',
 'id': 'rrmj_4668',
 'intro': '岩谷（入山法子 '
          '饰）是一名新闻人，缜密的逻辑和利落的作风让她深受上司的信赖，是名副其实的职场女强人。然而，岩谷过分刻板和不苟言笑的性格令她常常遭到周遭的误会，甚至被同事和朋友们排挤。一次，岩谷和上司之间发生了矛盾，岩谷因此被调往了不受欢迎的生活情报部门，与此同时，岩谷发 '
          '现自己相恋多年的男友竟然在外偷腥，爱情事业双双失利的岩谷跌落了生活的谷底。                                                                    \u3000\u3000'
          '某日，岩谷在家门口发现了一个大纸箱，纸箱里竟然睡着一个男人。岩谷将男人带回了家，得知他名叫合田武志（志尊淳 '
          '饰），武志想要留在岩谷的家，岩谷提出要武志当她的宠物，武志竟然欣然应允，就这样，武志和岩谷开始了他们的同居生活。',
 'is_new': False,
 'name': '宠物情人',
 'platforms': '',
 'publishdate': '2017-02-05',
 'rate': 7.6,
 'sectionid': 'rrmj_1244',
 'tags': ['剧情', '爱情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26788941/'}
2020-04-30 20:09:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%93%9D%E8%89%B2%E5%A4%A7%E6%B5%B7%E7%9A%84%E4%BC%A0%E8%AF%B4> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 20:09:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E9%87%91%E7%A7%98%E4%B9%A6%E4%B8%BA%E4%BD%95%E9%82%A3%E6%A0%B7> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 20:09:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/25738842/> (referer: https://www.douban.com/search?q=%E4%B8%80%E5%90%BB%E5%AE%9A%E6%83%852)
2020-04-30 20:09:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/25738842/>
{'cover': 'http://img.rr.tv/album/20180604/o_1528096899769.webp',
 'data_type': 'movie',
 'id': 'rrmj_3414',
 'intro': '历经了无数波澜和考验，体育、学习全能的超级大帅哥入江直树（古川雄辉 饰）终于和傻乎乎聒噪笨拙的琴子（未来穂香 '
          '饰）修成正果，走入婚姻的殿堂。夫妻俩虽然在冲绳度过了快乐的蜜月，但是琴子始终没有入籍，入江又以工作为由一连数天不回家，让不自信的琴子惶恐不安，担心二人的感情出现问题。只不过一向沉着内敛的入江，以自己的方式默默为妻子献上最好的结婚礼物，一波三折过后，两人的生活总算要步入正规。入江朝着一生的目标而努力，琴子则想方设法成为一名优秀的贤内助。在今后的道路上，他们还将迎接更多的挑战，只有真心相爱的人才能携手走完漫长且充满考验的人生吧……                                                                    \u3000\u3000'
          '本片根据多田かおる的原作改编。',
 'is_new': False,
 'name': '一吻定情2',
 'platforms': '',
 'publishdate': '2014-09-12',
 'rate': 7.3,
 'sectionid': 'rrmj_1244',
 'tags': ['剧情', '爱情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/25738842/'}
2020-04-30 20:09:19 [scrapy.extensions.logstats] INFO: Crawled 1131 pages (at 13 pages/min), scraped 448 items (at 29 items/min)
2020-04-30 20:09:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%9C%89%E9%92%B1%E7%94%B7%E4%B8%8E%E8%B4%AB%E7%A9%B7%E5%A5%B3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 20:09:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%AF%B7%E8%BE%93%E5%85%A5%E6%90%9C%E7%B4%A2%E8%AF%8D%EF%BC%9AWWW> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 20:09:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%9C%8B%E5%88%B0%E4%BB%96%E4%BB%AC%E5%B0%B1%E4%BC%9A%E6%98%8E%E7%99%BD> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 20:09:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/34930834/> (referer: https://www.douban.com/search?q=%E8%B0%81%E6%98%AF%E8%A2%AB%E5%AE%B3%E8%80%85)
2020-04-30 20:09:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/34930834/>
{'cover': 'http://img.rr.tv/seasonCover/20200430/o_1588237852053.jpg',
 'data_type': 'movie',
 'id': 'rrmj_17591',
 'intro': '《谁是被害者》改编自推理小说家「天地无限」（徐瑞良）的作品《第四名被害者》                                                                    \u3000\u3000'
          '原著描述一起震惊全台湾的连续杀人案在半年多前发生后，嫌犯方梦鱼坚决不肯透露被害者遗体下落，却在临终之前，暗示还有第四名被害者，并吐露已将受害者遗体线索透过律师交给他的学生周雨洁，让整起案件重回媒体版面。                                                                    \u3000\u3000'
          '随着媒体扑天盖地的攻势，真相慢慢被掩盖，幕后的真凶正要对第四名被害者下手……                                                                    \u3000\u3000'
          '《谁是被害者》将在 Netflix 独家上线',
 'is_new': False,
 'name': '谁是被害者',
 'platforms': '',
 'publishdate': '2020-04-30',
 'rate': 9.0,
 'sectionid': 'rrmj_1904',
 'tags': ['悬疑', '犯罪'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/34930834/'}
2020-04-30 20:09:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%BF%9B%E5%8F%A3%E5%AA%B3%E5%A6%87%E4%B9%8B%E6%88%91%E7%9A%84%E9%9C%B8%E9%81%93%E6%96%B0%E5%A8%98> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 20:09:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%BF%B7%E9%9B%BE> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 20:09:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/1764730/> (referer: https://www.douban.com/search?q=%E6%B3%B0%E7%89%88%E6%B5%AA%E6%BC%AB%E6%BB%A1%E5%B1%8B)
2020-04-30 20:09:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%BD%AE%E5%88%B0%E4%BD%A0%E4%BA%86> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 20:09:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/1764730/>
{'cover': 'http://img.rr.tv/album/20190123/o_1548253255300.png',
 'data_type': 'movie',
 'id': 'rrmj_14036',
 'intro': '韩智恩（宋慧乔 饰）在父母逝世后视父母留下了“Full '
          'House”为自己的家，自己的珍宝。热爱写作的她在网上写作，没有固定职业的她只能在Full '
          'House里过着节衣缩食的生活。没想到的是单纯的智恩被幼时的好朋友虎成及女友陷害，卖掉了Full '
          'House并且拿走了她所有钱。而这间屋子正好卖给了大明星李英宰（Rain '
          '饰）。                                                                            \u3000\u3000'
          '李英宰本想买下这栋房子便向女友惠媛求婚，惠媛却宣布要跟英宰的哥哥结婚。英宰强忍痛苦，闻风而至的记者使英宰不得不向记者表示韩智恩就是自己的未婚妻。这样一来令韩智恩措手不及，对于英宰经理人提出的要求，智恩决定与英宰假结婚，并立下合同希望能借此拿回自己的Full '
          'House。                                                                            \u3000\u3000'
          '两人继而成为了一对欢喜冤家，性格各异的两人生活习惯上有了鲜明的对比，生活在一起的他们没有一天不吵架的。由于李英宰是明星的关系，他们的生活受到了很多的打扰，可能因...',
 'is_new': False,
 'name': '泰版浪漫满屋',
 'platforms': '',
 'publishdate': '2004-07-14',
 'rate': 7.8,
 'sectionid': 'rrmj_1244',
 'tags': ['喜剧', '爱情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/1764730/'}
2020-04-30 20:09:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/1945330/> (referer: https://www.douban.com/search?q=%E8%BF%B7%E9%9B%BE)
2020-04-30 20:09:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/1945330/>
{'cover': 'http://img.rr.tv/album/20190404/o_1554373463601.jpg',
 'data_type': 'movie',
 'id': 'rrmj_11773',
 'intro': '一座风景秀美的小镇被一场突如其来的浓雾瞬间淹没。雾中传来阵阵惨叫，人们惊慌失措地四处逃散。戴维和他的儿子与众多镇上的人被困在小镇超市里，等待雾的消散。浓雾并没有如期望的散开，而走进浓雾的人一去不返。浓雾逐渐露出了它狰狞的面目。恐惧、惊慌、挣扎、悲伤、绝望……人们的精神濒临崩溃。如何才能活着走出迷雾？面对超市里几近癫狂的人们和超市外吞噬一切、不可知的迷雾，戴维紧紧搂着儿子，开始了艰难的求生之路……',
 'is_new': False,
 'name': '迷雾',
 'platforms': '',
 'publishdate': '2007-11-21',
 'rate': 9.3,
 'sectionid': 'rrmj_822',
 'tags': ['科幻', '惊悚', '恐怖'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/1945330/'}
2020-04-30 20:09:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%BB%96%E4%BA%BA%E5%8D%B3%E5%9C%B0%E7%8B%B1> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 20:09:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30446788/> (referer: https://www.douban.com/search?q=%E8%BD%AE%E5%88%B0%E4%BD%A0%E4%BA%86)
2020-04-30 20:09:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30446788/>
{'cover': 'http://img.rr.tv/album/20190627/o_1561602745483.jpg',
 'data_type': 'movie',
 'id': 'rrmj_14428',
 'intro': '新婚夫妇菜奈（原田知世饰）和翔太（田中圭饰）搬进了公寓的新房，幸福甜蜜的两人对新生活充满期待。搬家当天公寓要开居民会，菜奈猜拳输给了翔太，便独自前去参加。                                                                    \u3000\u3000'
          '除会长早苗（木村多江饰）、管理人床岛（竹中直人饰）以外，还有田宫（生濑胜久饰）、黑岛（西野七濑饰）等共十三人参加了居民会。闲聊时，床岛一句“谁都有想杀某个人的瞬间”让众人虽有些犹豫但还是纷纷谈论起恨不得他死的那个人，接着话题就意外地转向了“只要交换杀人目标就不会被抓”。                                                                    \u3000\u3000'
          '床岛向众人提议，每个人都公布自己想杀的人。大家觉得只是个游戏，并未多想，就在多余的投票纸上写下了那个人的名字，随后还抽了签。                                                                    \u3000\u3000'
          '这一次居民会，拉开了菜奈和翔太深陷其中的恐怖杀人游戏的序幕……！',
 'is_new': False,
 'name': '轮到你了',
 'platforms': '',
 'publishdate': '2019-04-14',
 'rate': 7.9,
 'sectionid': 'rrmj_822',
 'tags': ['剧情', '悬疑', '犯罪'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30446788/'}
2020-04-30 20:09:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=Yell> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 20:09:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30442494/> (referer: https://www.douban.com/search?q=%E4%BB%96%E4%BA%BA%E5%8D%B3%E5%9C%B0%E7%8B%B1)
2020-04-30 20:09:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30442494/>
{'cover': 'http://img.rr.tv/album/20190805/o_1564987387505.jpg',
 'data_type': 'movie',
 'id': 'rrmj_15480',
 'intro': '故事根据金容基的网络漫画《惊悚考试院》改编，以考试院为背景，描述从乡村来到首尔生活的一位少年发生的一连串奇怪的事件，而且身旁的每个人也都怪怪的……',
 'is_new': False,
 'name': '他人即地狱',
 'platforms': '',
 'publishdate': '2019-08-31',
 'rate': 8.4,
 'sectionid': 'rrmj_822',
 'tags': ['悬疑', '惊悚', '犯罪'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30442494/'}
2020-04-30 20:09:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=THE%20K2> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 20:09:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30129013/> (referer: https://www.douban.com/search?q=Yell)
2020-04-30 20:09:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E9%9D%92%E7%A9%BA%E4%B9%8B%E5%8D%B5> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 20:09:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30129013/>
{'cover': 'http://img.rr.tv/cover/20200331/o_1585638983046.jpg',
 'data_type': 'movie',
 'id': 'rrmj_17397',
 'intro': '乐于助人的鸠谷小羽，                                                                    \u3000\u3000'
          '在初中即将毕业时了解到了啦啦队活动并被其所吸引，                                                                    \u3000\u3000'
          '在高中与有过啦啦队活动经验的有马日诘、                                                                    \u3000\u3000'
          '青梅竹马的猿渡宇希一起                                                                    \u3000\u3000'
          '成立了啦啦队同好会。                                                                    \u3000\u3000'
          '她们那积极乐观、拼命努力的啦啦队活动，                                                                    \u3000\u3000'
          '今天也能让他人精神振奋！！',
 'is_new': False,
 'name': 'Yell',
 'platforms': '',
 'publishdate': '2018-10-07',
 'rate': 9.0,
 'sectionid': 'rrmj_1926',
 'tags': ['动画'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30129013/'}
2020-04-30 20:09:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26827945/> (referer: https://www.douban.com/search?q=THE%20K2)
2020-04-30 20:09:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26827945/>
{'cover': 'http://img.rr.tv/cover/20191030/o_1572424149236.jpg',
 'data_type': 'movie',
 'id': 'rrmj_13004',
 'intro': 'THE '
          'K2描绘的是的热烈的爱着国家与同僚却被他们抛弃的警卫员，与连爱情都能作为复仇工具使用的有力大选候选人隐藏着的女儿之间的故事。这里还勾画了准第一夫人隐藏的欲望的故事。',
 'is_new': False,
 'name': 'THE K2',
 'platforms': '',
 'publishdate': '2016-09-23',
 'rate': 6.6,
 'sectionid': 'rrmj_1927',
 'tags': ['剧情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26827945/'}
2020-04-30 20:09:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%B4%A4%E8%80%85%E4%B9%8B%E7%88%B1> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 20:09:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%BE%8E%E5%9B%BD%E5%A4%AB%E4%BA%BA> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 20:09:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/11504641/> (referer: https://www.douban.com/search?q=%E9%9D%92%E7%A9%BA%E4%B9%8B%E5%8D%B5)
2020-04-30 20:09:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/11504641/>
{'cover': 'http://img.rr.tv/cover/20191230/o_1577690130548.jpg',
 'data_type': 'movie',
 'id': 'rrmj_16921',
 'intro': '性格开朗的坂木司（井上正大 饰）和鸟井真一（阿久津慎太郎 '
          '饰）是自初中以来的好友。鸟井是位程序设计师，有自闭症，不喜欢出门，不喜欢和坂木以外的人打交道，讨厌不必要的瓜葛，喜欢各地的特产，会做好吃的料理。除了这些特点以外，鸟井天生的观察力和细心也使他成为了一个好侦探。                                                                    \u3000\u3000'
          '热心肠的坂木不断地邂逅了一些奇特的事和人，担忧着别人的故事。不希望看到坂木纠结并因此受到伤害的鸟井，把注意力投注到了除坂木以外的人身上，探索着表象背后的故事。而那些故事或无奈，或悲伤，或震撼，但总会在最后，雨过天青，豁然开朗。',
 'is_new': False,
 'name': '青空之卵',
 'platforms': '',
 'publishdate': '2012-07-28',
 'rate': 7.8,
 'sectionid': 'rrmj_989',
 'tags': ['悬疑', '同性'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/11504641/'}
2020-04-30 20:09:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%BA%BA%E9%97%B4%E8%AF%BE%E5%A0%82> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 20:09:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26820448/> (referer: https://www.douban.com/search?q=%E8%B4%A4%E8%80%85%E4%B9%8B%E7%88%B1)
2020-04-30 20:09:47 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26820448/>
{'cover': 'http://img.rr.tv/album/20191011/o_1570784346334.jpg',
 'data_type': 'movie',
 'id': 'rrmj_11896',
 'intro': '本剧创作灵感来自于谷崎润一郎的《痴人之爱》，讲述了一个长达20年的复仇故事。                                                                    \u3000\u3000'
          '这一切源于少年时期的一场相遇，少女真由子的隔壁搬来了新邻居一家，她与年龄相仿的百合一拍即合，成为了好友。然而，性格内敛的真由子总是被开朗奔放的百合夺去重要的东西，包括珍爱的项链，以及真由子身边最重要的人。成年后，贪得无厌的百合（高冈早纪 '
          '饰）再次夺走了真由子（中山美穗 饰）重要的人——初恋情人谅一（田边诚一 '
          '饰）。百合怀上谅一的孩子，二人奉子成婚。他们的儿子直巳出生的那一刻，就成为真由子的复仇工具，跨越20年的复仇大幕正式拉开了。                                                                    \u3000\u3000'
          '20年后的今天，在真由子的亲手栽培下，直巳（龙星凉 饰）成为了一个理想的美男子，并且深深地迷恋着真由子……',
 'is_new': False,
 'name': '贤者之爱',
 'platforms': '',
 'publishdate': '2016-08-20',
 'rate': 7.5,
 'sectionid': 'rrmj_1927',
 'tags': ['剧情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26820448/'}
2020-04-30 20:09:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30366454/> (referer: https://www.douban.com/search?q=%E7%BE%8E%E5%9B%BD%E5%A4%AB%E4%BA%BA)
2020-04-30 20:09:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30366454/>
{'cover': 'http://img.rr.tv/cover/20200416/o_1587003477763.webp',
 'data_type': 'movie',
 'id': 'rrmj_17512',
 'intro': '20世纪70年代，保守派活动人士菲莉丝·施拉夫利（Phyllis Schlafly，凯特·布兰切特 '
          '饰）领导了一场出人意料的反对“平等权利宪法修正案（Equal Rights '
          'Amendment，ERA）”运动。让我们通过她与一众第二波女性主义者——格洛丽亚·斯泰纳姆（Gloria Steinem，罗丝·伯恩 '
          '饰）、贝蒂·弗里丹（Betty Friedan，特蕾西·奥尔曼 饰）、雪莉·奇瑟姆（Shirley Chisholm，乌佐·阿杜巴 '
          '饰）、贝拉·艾布扎格（Bella Abzug，玛戈·马丁戴尔 饰）和吉尔·拉克尔斯豪斯（Jill '
          'Ruckelshaus，伊丽莎白·班克斯 饰）——重新见证70年代文化战争中最重要的一场攻坚战是如何永远地改变了美国当代政治版图。',
 'is_new': False,
 'name': '美国夫人',
 'platforms': '',
 'publishdate': '2020-04-15',
 'rate': 8.0,
 'sectionid': 'rrmj_1926',
 'tags': ['剧情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30366454/'}
2020-04-30 20:09:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%98%A8%E6%97%A5%E7%9A%84%E7%BE%8E%E9%A3%9F> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 20:09:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/33425663/> (referer: https://www.douban.com/search?q=%E4%BA%BA%E9%97%B4%E8%AF%BE%E5%A0%82)
2020-04-30 20:09:53 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/33425663/>
{'cover': 'http://img.rr.tv/seasonCover/20200430/o_1588213936228.jpg',
 'data_type': 'movie',
 'id': 'rrmj_17413',
 'intro': '《人间课堂》讲述了一个模范生为了赚钱而犯下重大罪行，朋友和身边人也无意间被卷入这一犯罪中而引发的矛盾和事件，以及丧失人性的故事。                                                                    \u3000\u3000'
          '金东熙饰演一心想筹措大学学费而做出错误选择的高中生志秀一角。                                                                    \u3000\u3000'
          '郑多彬饰演敏熙一角。敏熙是一个卷入志秀犯罪中陷入混乱的同年级学生。                                                                    \u3000\u3000'
          '朴珠贤饰演和志秀同一所高中的圭丽，是一个偶然得知志秀的犯罪事实后参与犯罪的人物。',
 'is_new': False,
 'name': '人间课堂',
 'platforms': '',
 'publishdate': '2020-04-29',
 'rate': 8.9,
 'sectionid': 'rrmj_1903',
 'tags': ['剧情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/33425663/'}
2020-04-30 20:09:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%B2%89%E9%BB%98%E7%9A%84%E5%A4%A9%E4%BD%BF> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 20:09:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30442369/> (referer: https://www.douban.com/search?q=%E6%98%A8%E6%97%A5%E7%9A%84%E7%BE%8E%E9%A3%9F)
2020-04-30 20:09:55 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30442369/>
{'cover': 'http://img.rr.tv/album/20190412/o_1555056075476.jpg',
 'data_type': 'movie',
 'id': 'rrmj_14403',
 'intro': '个性认真、擅长料理的律师笕史朗，与温柔体贴的美容师矢吹贤二是一对住在市区小公寓的同志情侣。为了两人的养老基金，笕律师每天上超市捡便宜，左扣男友的零用钱、右向老家伸手讨罐头、还要严格控管每个月的餐费，在柴米油盐酱醋茶的平凡日常中，烹调出一道道省钱却营养美味的「爱」的料理。',
 'is_new': False,
 'name': '昨日的美食',
 'platforms': '',
 'publishdate': '2019-04-05',
 'rate': 8.7,
 'sectionid': 'rrmj_989',
 'tags': ['剧情', '同性', '家庭'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30442369/'}
2020-04-30 20:09:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%9C%9F%E6%8E%A2%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 20:09:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26806061/> (referer: https://www.douban.com/search?q=%E8%93%9D%E8%89%B2%E5%A4%A7%E6%B5%B7%E7%9A%84%E4%BC%A0%E8%AF%B4)
2020-04-30 20:09:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26806061/>
{'cover': 'http://img.rr.tv/album/20190718/o_1563435326591.jpg',
 'data_type': 'movie',
 'id': 'rrmj_11618',
 'intro': '该剧取材于韩国最早民间故事集《於于野谭》中歙谷县令金聃龄（李敏镐饰）将被渔民捕获的人鱼放归大海的人鱼传说。讲述数百年之后濒临灭绝来到都市里的人鱼沈清（全智贤饰）适应陆地生活和天才骗子许俊宰（李敏镐饰）重逢并陷入爱情的故事',
 'is_new': False,
 'name': '蓝色大海的传说',
 'platforms': '',
 'publishdate': '2016-11-16',
 'rate': 7.3,
 'sectionid': 'rrmj_1244',
 'tags': ['爱情', '奇幻'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26806061/'}
2020-04-30 20:09:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%A5%9E%E7%9A%84%E7%A4%BC%E7%89%A9-14%E5%A4%A9> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 20:10:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%A5%BD%E6%83%B3%E5%81%9A%E4%B8%80%E6%AC%A1> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 20:10:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26753903/> (referer: https://www.douban.com/search?q=%E6%B2%89%E9%BB%98%E7%9A%84%E5%A4%A9%E4%BD%BF)
2020-04-30 20:10:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26753903/>
{'cover': 'https://img.rr.tv/season/20180123/o_1516698678103.jpg',
 'data_type': 'movie',
 'id': 'rrmj_11740',
 'intro': '故事发生在1896年的纽约，那时的纽约一片繁荣景象，一边是科技的长足进步，一边是贫富差距的加剧。这时发生了一连串男童妓被残忍杀害的事件，新任警察局长（日后的第26任美国总统）西奥多·罗斯福找来了犯罪心理学家拉兹洛·克莱斯勒、记者约翰·摩尔去秘密调查。他们并非孤军奋战，时任局长秘书（日后成为首位女警探）莎拉·霍华德组织了一个行动小组，利用心理学和新兴的法医学，抽丝剥茧，去抓捕这个连环杀手。',
 'is_new': False,
 'name': '沉默的天使',
 'platforms': '',
 'publishdate': '2018-01-22',
 'rate': 7.7,
 'sectionid': 'rrmj_822',
 'tags': ['剧情', '犯罪'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26753903/'}
2020-04-30 20:10:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%80%A7%E6%95%99%E8%82%B2%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 20:10:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30181455/> (referer: https://www.douban.com/search?q=%E9%87%91%E7%A7%98%E4%B9%A6%E4%B8%BA%E4%BD%95%E9%82%A3%E6%A0%B7)
2020-04-30 20:10:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30181455/>
{'cover': 'http://img.rr.tv/album/20180523/o_1527057151258.png',
 'data_type': 'movie',
 'id': 'rrmj_12261',
 'intro': '该剧改编自郑庆允的2013年同名人气网漫，讲述拥有完美外貌和过人实力的财团副会长李英俊，他的个人秘书金美苏是唯一帮他解决麻烦的人。工作9年，一直在李英俊身边如影随影，能力满分的她, '
          '有一天突然决定要辞职，让李英俊下定决心要用尽方法留住她…',
 'is_new': False,
 'name': '金秘书为何那样',
 'platforms': '',
 'publishdate': '2018-06-06',
 'rate': 8.0,
 'sectionid': 'rrmj_1244',
 'tags': ['喜剧', '爱情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30181455/'}
2020-04-30 20:10:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%80%A7%E6%95%99%E8%82%B2%20%E7%AC%AC%E4%BA%8C%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 20:10:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/10748120/> (referer: https://www.douban.com/search?q=%E7%9C%9F%E6%8E%A2%20%E7%AC%AC%E4%B8%80%E5%AD%A3)
2020-04-30 20:10:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/10748120/>
{'cover': 'http://img.rr.tv/cover/20200410/o_1586487305607.webp',
 'data_type': 'movie',
 'id': 'rrmj_579',
 'intro': '马蒂（伍迪·哈里森 Woody Harrelson 饰）和拉斯特（马修·麦康纳 Matthew McConaughey '
          '饰）是一对合作多年的搭档，马蒂为人开朗圆滑，在警局的同事里很吃得开，而拉斯特则恰恰相反，他性格孤僻沉默寡言，沉浸在自己的世界中无法自拔。然而，令马蒂感到十分钦佩的是，拉斯特拥有极为敏锐强大的观察力、判断力和逻辑推理能力，许多疑难杂案一经他手，便能够被轻松化解。                                                                    \u3000\u3000'
          '尽管马蒂是唯一一个能够受得了拉斯特的人，但两人的合作和友谊却依然产生了无法弥补的裂缝，其原因要归结到1995年所发生的一起神秘古怪的宗教杀人案件之中。如今已经是2012年了，当早已不再联系的两人因为这起案件又重新走到一起之时，会有怎样的真相在等待着他们呢？',
 'is_new': False,
 'name': '真探 第一季',
 'platforms': '',
 'publishdate': '2014-01-12',
 'rate': 9.3,
 'sectionid': 'rrmj_822',
 'tags': ['剧情', '悬疑', '犯罪'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/10748120/'}
2020-04-30 20:10:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/10756863/> (referer: https://www.douban.com/search?q=%E6%9C%89%E9%92%B1%E7%94%B7%E4%B8%8E%E8%B4%AB%E7%A9%B7%E5%A5%B3)
2020-04-30 20:10:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/10756863/>
{'cover': 'https://img.rr.tv/season/20180326/o_1522040602097.png',
 'data_type': 'movie',
 'id': 'rrmj_3073',
 'intro': '数年前，同窗好友日向彻（小栗旬 饰）和朝比奈恒介（井浦新 饰）白手起家创立了IT企业Next '
          'Innovation。短短数年后，NI成为最受瞩目的新创公司，年仅29岁的日向也成为个人资产达250亿日元超级单身富豪。与只有初中文凭的日向形成鲜明对比的是，系出东大名门的大四女生夏井真琴（石原里美 '
          '饰）在就活战线上饱受创伤，身心疲惫不堪。奇妙的机缘将原本没有任何交集的两人联系在一起，性格存在缺陷的日向和谨慎过度的千寻彼此发生着碰撞，又相互吸引与感动。                                                                    \u3000\u3000'
          '现代社会职场中的灰姑娘故事就此上演，而沉着冷静朝比奈和他开朗乐观的妹妹燿子（相武亚季 饰）则见证着这一悲喜交加的现代浪漫故事……',
 'is_new': False,
 'name': '有钱男与贫穷女',
 'platforms': '',
 'publishdate': '2012-07-09',
 'rate': 8.0,
 'sectionid': 'rrmj_1244',
 'tags': ['剧情', '喜剧', '爱情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/10756863/'}
2020-04-30 20:10:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%A4%A7%E5%8F%94%E4%B9%8B%E7%88%B12-in%20the%20sky-> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 20:10:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/25802411/> (referer: https://www.douban.com/search?q=%E7%A5%9E%E7%9A%84%E7%A4%BC%E7%89%A9-14%E5%A4%A9)
2020-04-30 20:10:10 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/25802411/>
{'cover': 'http://img.rr.tv/album/20190213/o_1550052084084.jpg',
 'data_type': 'movie',
 'id': 'rrmj_11219',
 'intro': '美丽女子金秀炫（李宝英 饰）堪称是所有女人羡慕和嫉妒的对象，她拥有完美的家庭，丈夫韩志勋（金泰佑 '
          '饰）从事律师行业，受人尊敬，女儿小星（金柳彬 '
          '饰）乖巧可爱，调皮伶俐。职场上秀炫又是一名小有名气的时事节目作家，可以说她的人生完美得连命运之神都会嫌忌。终于在某一天，巨大的变故砸向这个梦幻般的家庭。小星意外遭人绑架，几经周折后更被抛尸湖中。绝望的秀炫跳入湖中，似乎此时她又受到神明的眷顾，竟然由此穿越时空回到了女儿被杀的两周前。                                                                    \u3000\u3000'
          '提前知晓了悲剧命运的秀炫，绝不肯轻易放弃这个改写自己和女儿人生的最后良机，她和死神展开了争分夺秒的赛跑……',
 'is_new': False,
 'name': '神的礼物-14天',
 'platforms': '',
 'publishdate': '2014-03-03',
 'rate': 9.2,
 'sectionid': 'rrmj_822',
 'tags': ['剧情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/25802411/'}
2020-04-30 20:10:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%AD%A3%E5%B8%B8%E4%BA%BA%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 20:10:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/34463436/> (referer: https://www.douban.com/search?q=%E5%A5%BD%E6%83%B3%E5%81%9A%E4%B8%80%E6%AC%A1)
2020-04-30 20:10:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/34463436/>
{'cover': 'http://img.rr.tv/seasonCover/20200427/o_1587987230059.jpg',
 'data_type': 'movie',
 'id': 'rrmj_17582',
 'intro': '经历了创伤性的一年后，一个遭到无视的印度裔美国少女一心想要赢得大家的喜爱，但是她却面临朋友、家人和感情方面的重重问题。',
 'is_new': False,
 'name': '好想做一次',
 'platforms': '',
 'publishdate': '2020-04-27',
 'rate': 7.8,
 'sectionid': 'rrmj_1927',
 'tags': ['喜剧'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/34463436/'}
2020-04-30 20:10:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=EERIE%EF%BD%9E%E7%9C%8B%E4%B8%8D%E8%A7%81%E7%9A%84%E8%84%B8> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 20:10:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%BB%9D%E5%AF%B9%E9%9B%B6%E5%BA%A6%E7%AC%AC%E4%B8%89%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 20:10:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27594217/> (referer: https://www.douban.com/search?q=%E6%80%A7%E6%95%99%E8%82%B2%20%E7%AC%AC%E4%B8%80%E5%AD%A3)
2020-04-30 20:10:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/27594217/>
{'cover': 'http://img.rr.tv/album/20190112/o_1547258882205.jpg',
 'data_type': 'movie',
 'id': 'rrmj_13967',
 'intro': '欧帝斯固然缺乏性经验，他的母亲可是一名性治疗师。他决定将母亲的衣钵发扬光大，於是在就读的摩尔戴高中设立性爱治疗谘询服务，造福无可救药的同学。他们水乳交融，其乐无穷，一起渡过人生最灿烂的时光。',
 'is_new': False,
 'name': '性教育 第一季',
 'platforms': '',
 'publishdate': '2019-01-11',
 'rate': 9.1,
 'sectionid': 'rrmj_1927',
 'tags': ['剧情', '喜剧'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/27594217/'}
2020-04-30 20:10:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%BB%8A%E6%97%A5%E7%9A%84%E7%8C%AB%E6%9D%91%E5%B0%8F%E5%A7%90> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 20:10:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30232208/> (referer: https://www.douban.com/search?q=%E6%88%91%E7%9A%84ID%E6%98%AF%E6%B1%9F%E5%8D%97%E7%BE%8E%E4%BA%BA)
2020-04-30 20:10:18 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30232208/>
{'cover': 'http://img.rr.tv/album/20180711/o_1531281814912.jpg',
 'data_type': 'movie',
 'id': 'rrmj_12731',
 'intro': '该剧改编自同名网络漫画，讲述从小因为长相丑陋而受欺凌的女主角在整容后，以为能够过上新生活，却在进入大学后经历与梦想中完全不同的挫败，在过程中找到真爱的故事。',
 'is_new': False,
 'name': '我的ID是江南美人',
 'platforms': '',
 'publishdate': '2018-07-27',
 'rate': 7.5,
 'sectionid': 'rrmj_1244',
 'tags': ['剧情', '爱情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30232208/'}
2020-04-30 20:10:19 [scrapy.extensions.logstats] INFO: Crawled 1177 pages (at 46 pages/min), scraped 469 items (at 21 items/min)
2020-04-30 20:10:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%BF%83%E7%81%B5%E7%8C%8E%E4%BA%BA%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 20:10:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30438115/> (referer: https://www.douban.com/search?q=%E6%80%A7%E6%95%99%E8%82%B2%20%E7%AC%AC%E4%BA%8C%E5%AD%A3)
2020-04-30 20:10:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30438115/>
{'cover': 'http://img.rr.tv/cover/20200108/o_1578467050363.jpg',
 'data_type': 'movie',
 'id': 'rrmj_16981',
 'intro': '围绕不善社交的高中生奥蒂斯·米尔本展开，他和身为性治疗师的母亲珍住在一起。在第一季中，奥蒂斯和朋友梅芙·威利在学校里开办了一个性诊所，利用他的直觉天赋为同学们提供有关性的建议。在第二季中，晚熟的奥蒂斯必须控制他新发现的性冲动，以便在和女朋友欧拉的相处中取得进展，同时还要处理他与梅芙之间的紧张关系。与此同时，莫戴尔中学因衣原体感染爆发而陷入困境，这更是凸显了在学校开展更好的性教育的必要性，此外，新生入校也将挑战现状。',
 'is_new': False,
 'name': '性教育 第二季',
 'platforms': '',
 'publishdate': '2020-01-17',
 'rate': 9.6,
 'sectionid': 'rrmj_1926',
 'tags': ['剧情', '喜剧'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30438115/'}
2020-04-30 20:10:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%B6%85%E6%84%9F%E7%8C%8E%E6%9D%80%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 20:10:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30403333/> (referer: https://www.douban.com/search?q=%E8%AF%B7%E8%BE%93%E5%85%A5%E6%90%9C%E7%B4%A2%E8%AF%8D%EF%BC%9AWWW)
2020-04-30 20:10:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30403333/>
{'cover': 'http://img.rr.tv/album/20190514/o_1557823353267.jpg',
 'data_type': 'movie',
 'id': 'rrmj_14813',
 'intro': '该剧是一部奇幻电视剧，讲述没有选择成为妻子或母亲的当今女性的真实生活和成功故事，将描写门户网站业界激烈的竞争故事。                                                                    \u3000\u3000'
          '林秀晶饰演裴多美一角，她是在门户网站工作的30代后半段的上班族，非常好胜，为了成功失去了很多东西，渐渐对自己的人生产生了怀疑。                                                                    \u3000\u3000'
          '张基龙将在剧中饰演朴模建，他是制作游戏音乐的“密林Sound”公司代表，同时也是天才作曲家。                                                                    \u3000\u3000'
          '李多喜饰演车贤，她是一直停留在业界第2名的门户网站的公关本部长。                                                                    \u3000\u3000'
          '全慧珍饰演宋佳京，她是女主裴多美工作的门户网站的理事。',
 'is_new': False,
 'name': '请输入搜索词：WWW',
 'platforms': '',
 'publishdate': '2019-06-05',
 'rate': 8.4,
 'sectionid': 'rrmj_1244',
 'tags': ['剧情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30403333/'}
2020-04-30 20:10:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30441160/> (referer: https://www.douban.com/search?q=%E5%A4%A7%E5%8F%94%E4%B9%8B%E7%88%B12-in%20the%20sky-)
2020-04-30 20:10:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30441160/>
{'cover': 'http://img.rr.tv/album/20191023/o_1571797074745.jpg',
 'data_type': 'movie',
 'id': 'rrmj_16171',
 'intro': '而今年11月2日《大叔之爱~in the sky~》电视剧版第二季要回归啦！主演依然是田中圭、“女主角”依然由 '
          '吉田钢太郎（上司大叔）。故事舞台由不动产公司换成了航空公司，第二季中，田中饰演35岁被突然裁员、转行当空少的春田创一，依然延续废柴人设，吉田饰演为人、技术都得到同事信赖的机长黑泽武藏，基于这些背景人设，展开新的故事。千叶雄大饰演与黑泽搭档的副机师成濑龙、户次重幸饰演机修工四宫要、春田成濑四宫3人住在同一寝室。',
 'is_new': False,
 'name': '大叔之爱2-in the sky-',
 'platforms': '',
 'publishdate': '2019-11-02',
 'rate': 7.4,
 'sectionid': 'rrmj_989',
 'tags': ['喜剧', '爱情', '同性'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30441160/'}
2020-04-30 20:10:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%B5%AA%E5%AD%90%E7%A5%9E%E6%8E%A2%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 20:10:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/33383339/> (referer: https://www.douban.com/search?q=%E6%AD%A3%E5%B8%B8%E4%BA%BA%20%E7%AC%AC%E4%B8%80%E5%AD%A3)
2020-04-30 20:10:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/33383339/>
{'cover': 'http://img.rr.tv/cover/20200415/o_1586943795499.webp',
 'data_type': 'movie',
 'id': 'rrmj_17506',
 'intro': '一个获得超能力的普通人追求爱情的故事.',
 'is_new': False,
 'name': '正常人 第一季',
 'platforms': '',
 'publishdate': '2016-11-20',
 'rate': 7.5,
 'sectionid': 'rrmj_1926',
 'tags': ['喜剧', '动作', '短片'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/33383339/'}
2020-04-30 20:10:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%8E%AF%E5%BD%A2%E7%89%A9%E8%AF%AD%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 20:10:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30203507/> (referer: https://www.douban.com/search?q=EERIE%EF%BD%9E%E7%9C%8B%E4%B8%8D%E8%A7%81%E7%9A%84%E8%84%B8)
2020-04-30 20:10:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30203507/>
{'cover': 'http://img.rr.tv/album/20180831/o_1535702712090.jpg',
 'data_type': 'movie',
 'id': 'rrmj_12847',
 'intro': '大学教授广川诚司（小田切让）的妻子因病亡故，在葬礼的那天晚上，一位神秘女性拜访他，但完全看不到人。之后，广川所在大学的总长也突然去世，新总长的选举引发了一系列的猜忌矛盾，奇怪的事越来越多，甚至周围的垃圾堆裡还发现了尸体。而广川周遭的人也慢慢出现了违和感，暗自积极于总长选举的同僚， '
          '妻子生前同事水岛丽（仲里依纱），恐怖与不安的气氛逐渐蔓延……',
 'is_new': False,
 'name': 'EERIE～看不见的脸',
 'platforms': '',
 'publishdate': '2018-08-04',
 'rate': 8.4,
 'sectionid': 'rrmj_822',
 'tags': ['剧情', '悬疑'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30203507/'}
2020-04-30 20:10:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%89%B9%E6%AE%8A%E6%A1%88%E4%BB%B6%E4%B8%93%E6%A1%88%E7%BB%84TEN2> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 20:10:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/34867904/> (referer: https://www.douban.com/search?q=%E7%9C%8B%E5%88%B0%E4%BB%96%E4%BB%AC%E5%B0%B1%E4%BC%9A%E6%98%8E%E7%99%BD)
2020-04-30 20:10:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/34867904/>
{'cover': 'http://img.rr.tv/cover/20200113/o_1578887741312.jpg',
 'data_type': 'movie',
 'id': 'rrmj_17010',
 'intro': '人气淑女漫画家内田百百子（中山美穗饰）和再婚对象（生濑胜久饰）及大学生儿子共同居住在二子玉川公寓的最上层。与住在同一栋公寓的职业女性富泽瑞希（ '
          '木村多江饰）是同龄朋友。瑞希与丈夫（上地雄辅饰）则是一对相敬如宾的假面夫妇。有一天，20年前和百百子离婚的前夫（长野博饰）带着他的新妻子鸭居流美（大岛优子饰 '
          '）搬到公寓里。随着这对新婚夫妇的到来，百百子和瑞希所拥有的“秘密”被慢慢揭露出来。',
 'is_new': False,
 'name': '看到他们就会明白',
 'platforms': '',
 'publishdate': '2020-01-11',
 'rate': 7.5,
 'sectionid': 'rrmj_1244',
 'tags': ['剧情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/34867904/'}
2020-04-30 20:10:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%AC%B2%E7%BD%A2%E4%B8%8D%E8%83%BD%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 20:10:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/34971164/> (referer: https://www.douban.com/search?q=%E4%BB%8A%E6%97%A5%E7%9A%84%E7%8C%AB%E6%9D%91%E5%B0%8F%E5%A7%90)
2020-04-30 20:10:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/34971164/>
{'cover': 'http://img.rr.tv/cover/20200409/o_1586396107620.jpg',
 'data_type': 'movie',
 'id': 'rrmj_17454',
 'intro': '松重丰(《孤独的美食家》)颠覆形象，跨越性别、物种主演的漫改新剧《今日的猫村小姐》曝光造型照！剧集改编自星余里子的同名漫画，讲述一只猫咪想要打工赚钱学好英语，去国外见有救命之恩的小主人一面，因此来到一个问题家庭里当管家。该剧共24集，将于4月8日开播。',
 'is_new': False,
 'name': '今日的猫村小姐',
 'platforms': '',
 'publishdate': '2020-04-08',
 'rate': 7.0,
 'sectionid': 'rrmj_1926',
 'tags': ['喜剧', '短片', '奇幻'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/34971164/'}
2020-04-30 20:10:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%B8%8B%E8%BE%88%E5%AD%90%E6%88%91%E5%86%8D%E5%A5%BD%E5%A5%BD%E8%BF%87> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 20:10:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%80%81%E5%8F%B8%E6%9C%BA%E7%9A%84%E7%88%B1%E6%83%85%E6%95%85%E4%BA%8B> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 20:10:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26691486/> (referer: https://www.douban.com/search?q=%E5%BF%83%E7%81%B5%E7%8C%8E%E4%BA%BA%20%E7%AC%AC%E4%B8%80%E5%AD%A3)
2020-04-30 20:10:38 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26691486/>
{'cover': 'http://img.rr.tv/album/20180903/o_1535963829910.jpg',
 'data_type': 'movie',
 'id': 'rrmj_10624',
 'intro': '在 1970 '
          '年代晚期，两名联邦调查局探员深入探究谋杀的心理层面，并在危险距离内接触这些丧失人性的怪物，从而拓展犯罪科学。                                                                    \u3000\u3000'
          '《心灵猎人》由乔纳森·格罗夫 (《寻》)、霍特·麦克卡兰尼 (《萨利机长》)、安娜·托芙 (《危机边缘》) 和汉娜·格罗斯 '
          '(《除非》) 主演，由 大卫·芬奇 (《消失的爱人》、《社交网络》、《十二宫》)、阿斯弗·卡帕迪尔 '
          '(《艾米》、《永远的车神》)、托比亚斯·林道赫姆 (《战争》、《怒海劫运》) 和安德鲁·道格拉斯 '
          '(《鬼哭神嚎》、《你想我杀了他吗？》) 担任导演，芬奇、约书亚·多恩 (《消失的爱人》、《致命快感》)、查理兹·塞隆 '
          '(《妹子老板》、《血仇》) 和切安·查芬 (《消失的爱人》、《搏击俱乐部》) 担任监制。',
 'is_new': False,
 'name': '心灵猎人 第一季',
 'platforms': '',
 'publishdate': '2017-10-13',
 'rate': 8.9,
 'sectionid': 'rrmj_822',
 'tags': ['剧情', '惊悚', '犯罪'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26691486/'}
2020-04-30 20:10:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E8%8A%B1%E6%A0%B7%E5%B9%B4%E5%8D%8E-%E7%94%9F%E5%A6%82%E5%A4%8F%E8%8A%B1> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 20:10:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26588970/> (referer: https://www.douban.com/search?q=%E6%9C%9D5%E6%99%9A9%EF%BC%9A%E5%B8%85%E6%B0%94%E5%92%8C%E5%B0%9A%E7%88%B1%E4%B8%8A%E6%88%91)
2020-04-30 20:10:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26588970/>
{'cover': 'https://img.rr.tv/season/20170209/o_1486607542414.jpg',
 'data_type': 'movie',
 'id': 'rrmj_4684',
 'intro': '樱庭润子（石原里美 '
          '饰）在一家英语教学机构里担任讲师，勤勤恳恳的工作只为了攒够钱前往朝思暮想的纽约生活。一场法事中，腿麻的润子将骨灰撒在了和尚星川（山下智久 '
          '饰）的头上，没想到这场意外却让星川对润子一见钟情，之后，星川对润子展开了一连串与其说是热烈不如说是近乎于“骚扰” '
          '的攻势。                                                                    \u3000\u3000'
          '清宫真言（田中圭 饰）是润子曾经的老师如今的上司，两人之间有过一段朦朦胧胧尚未挑明的感情。三岛聪（古川雄辉 '
          '饰）和润子曾是同学，现在却成为了润子门下的学生，对润子有着难以启齿的爱慕。里中由希（高田彪我 '
          '饰）表面上是可爱的女孩子，实际上却是男儿身，这样的他苦苦单恋着润子。然而，一切的阻挠都无法消磨星川对于润子的深深爱意，包括他肩上所背负着的，继承寺庙成为下一任住持的沉重使命。                                                                    \u3000\u3000'
          '本剧根据相原实贵的同名漫画改编。',
 'is_new': False,
 'name': '朝5晚9：帅气和尚爱上我',
 'platforms': '',
 'publishdate': '2015-10-12',
 'rate': 7.5,
 'sectionid': 'rrmj_1244',
 'tags': ['喜剧', '爱情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/26588970/'}
2020-04-30 20:10:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%8E%BB%E4%BB%96%E5%A6%88%E7%9A%84%E4%B8%96%E7%95%8C%20%E7%AC%AC%E4%BA%8C%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 20:10:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/23011215/> (referer: https://www.douban.com/search?q=%E8%B6%85%E6%84%9F%E7%8C%8E%E6%9D%80%20%E7%AC%AC%E4%B8%80%E5%AD%A3)
2020-04-30 20:10:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/23011215/>
{'cover': 'https://img.rr.tv/video/20151013/o_1444730902224.jpg',
 'data_type': 'movie',
 'id': 'rrmj_505',
 'intro': '本剧由《黑客帝国》系列和《云图》导演沃卓斯基姐妹与《巴比伦5号》编剧、著名制作人J·迈克尔·斯特拉辛斯基共同监制此剧，讲述来自不同城市的八位陌生人，不同身份，不同取向，因为某个神秘事件实现通感，不仅共享情感和思想，还能共享语言和技能。一方面，有个神秘人想将这八个人聚集在 '
          '一起；另一方面，一个神秘组织又使尽一切手段猎杀他们。他们必须齐心协力，杀出一条生路，找寻超感真相。                                                                    \u3000\u3000'
          '影片八人组的成员包括《自由坠落》的德意志美男马克思·雷迈特，《男孩战争》的美利坚帅哥布莱恩·J·史密斯，《空乘情人》的西班牙型男米格尔·安格·希尔维斯特，《木星上行》和《星图》的韩国女演员裴斗娜等实力演员。                                                                    \u3000\u3000'
          '剧集已于当地时间6月5日在Netflix放出整季，并引发讨论热潮，成为现象级的热门科幻剧集。',
 'is_new': False,
 'name': '超感猎杀 第一季',
 'platforms': '',
 'publishdate': '2015-06-05',
 'rate': 8.8,
 'sectionid': 'rrmj_1927',
 'tags': ['剧情', '科幻'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/23011215/'}
2020-04-30 20:10:44 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/30197878/> (referer: https://www.douban.com/search?q=%E8%BF%9B%E5%8F%A3%E5%AA%B3%E5%A6%87%E4%B9%8B%E6%88%91%E7%9A%84%E9%9C%B8%E9%81%93%E6%96%B0%E5%A8%98)
2020-04-30 20:10:44 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/30197878/>: HTTP status code is not handled or not allowed
2020-04-30 20:10:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%8F%AF%E4%BB%A5%E4%B8%8D%E5%8F%AF%E4%BB%A5-%E5%88%AB%E6%89%AD%E6%88%90%E5%B9%B4%E4%BA%BA%E7%9A%84%E5%90%88%E7%A7%9F%E6%88%BF-> (referer: https://api.rr.tv/v3plus/index/channel)
2020-04-30 20:10:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/23023943/> (referer: https://www.douban.com/search?q=%E7%89%B9%E6%AE%8A%E6%A1%88%E4%BB%B6%E4%B8%93%E6%A1%88%E7%BB%84TEN2)
2020-04-30 20:10:47 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/23023943/>
{'cover': 'http://img.rr.tv/album/20190910/o_1568087717764.jpg',
 'data_type': 'movie',
 'id': 'rrmj_11207',
 'intro': '该剧是《特殊案件专案组TEN》的第二季。是由韩国OCN电视台放映的 '
          '由朱相昱、赵安、金尚浩、崔宇植领衔主演。该剧题材新颖，是描绘负责破案率不足10%的重大刑侦案件侦破组工作情形的正宗刑侦剧。第一季2011年11月18日每周五晚播出，第一季获得了韩国2012有线电视最佳节目首奖，也获得了很多的好评。于是有了第二季。第二季也是原班人马回归值得关注。',
 'is_new': False,
 'name': '特殊案件专案组TEN2',
 'platforms': '',
 'publishdate': '2013-04-14',
 'rate': 9.25,
 'sectionid': 'rrmj_822',
 'tags': ['剧情', '悬疑', '犯罪'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/23023943/'}
2020-04-30 20:10:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/35017030/> (referer: https://www.douban.com/search?q=%E6%AC%B2%E7%BD%A2%E4%B8%8D%E8%83%BD%20%E7%AC%AC%E4%B8%80%E5%AD%A3)
2020-04-30 20:10:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/35017030/>
{'cover': 'http://img.rr.tv/seasonCover/20200417/o_1587121848829.png',
 'data_type': 'movie',
 'id': 'rrmj_17527',
 'intro': '来自世界各地的十名热辣单身者齐聚在热带天堂，这群年轻人认为这将是他们生命中最具异国情调和最性感的夏天，但转折不约而至。如果想要赢得 '
          '10 '
          '万美元的大奖，这些喜欢随意约会的承诺恐惧症患者在整个过程中都不得有任何耍花招的行为。没有亲吻，没有爱抚，没有任何形式的自我满足。每僭越一次，奖金就会随之减少。在这个奢侈的禁欲区，热衷单身的人能够建立更深的情感联系吗？还是诱惑太过强烈，让人无法自持？',
 'is_new': False,
 'name': '欲罢不能 第一季',
 'platforms': '',
 'publishdate': '2020-04-17',
 'rate': 7.8,
 'sectionid': 'rrmj_1927',
 'tags': ['真人秀'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/35017030/'}
2020-04-30 20:10:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/34906701/> (referer: https://www.douban.com/search?q=%E4%B8%8B%E8%BE%88%E5%AD%90%E6%88%91%E5%86%8D%E5%A5%BD%E5%A5%BD%E8%BF%87)
2020-04-30 20:10:51 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/34906701/>
{'cover': 'http://img.rr.tv/cover/20200103/o_1578019347327.png',
 'data_type': 'movie',
 'id': 'rrmj_16958',
 'intro': '电视连续剧《来世会好好做的》（即《来世ではちゃんとします》）将于【2020年1月8日】在东京电视台，Drama '
          'Parai等播出。这部剧是根据《JUMP》上连载的同名漫画改编而成的。《来世会好好做的》以CG制作公司的「三角工作室」为舞台，描写了在不同男女身上发生的故事。其中 '
          '有对性非常开放并同时拥有多名性伴侣的女生【大森桃江】（内田理央饰），对于无法成为自己本命男性恋人这一事实，她一方面感到空虚，另一方面也表示「算了算了，下辈子我会好好做的」；有不负责任地玩弄女性的帅哥【松田健】（小关裕太饰）；有对恋爱不感兴趣喜欢BL的高杉梅喜欢BL、并标榜“没有男朋友的年数=年龄”的处女【高杉梅】（太田莉菜饰）；还有受过伤害之后只喜欢处女的男人【林胜】（后藤刚范饰）及将大部分收入都奉献给风俗店的男人等等。                                                                            \u3000\u3000'
          '该剧的编剧将由《恋之月》、《只想住在吉祥寺吗》的编剧沟口真...',
 'is_new': False,
 'name': '下辈子我再好好过',
 'platforms': '',
 'publishdate': '2020-01-08',
 'rate': 7.5,
 'sectionid': 'rrmj_1927',
 'tags': ['喜剧', '爱情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/34906701/'}
2020-04-30 20:10:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/30271241/> (referer: https://www.douban.com/search?q=%E8%80%81%E5%8F%B8%E6%9C%BA%E7%9A%84%E7%88%B1%E6%83%85%E6%95%85%E4%BA%8B)
2020-04-30 20:10:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/30271241/>
{'cover': 'http://img.rr.tv/album/20180803/o_1533261378886.png',
 'data_type': 'movie',
 'id': 'rrmj_12909',
 'intro': '故事围绕大学生久住春彦(猪塚健太饰)和官能小说家木岛理生(竹财辉之助饰)展开。因为一场意外，久住春彦骑车不小心导致了木岛理生骨折，而暂无他法的久住春彦只能提议让木岛理生口述写小说。两人之间你侬我侬的纠缠情感就此上演。',
 'is_new': False,
 'name': '老司机的爱情故事',
 'platforms': '',
 'publishdate': '2018-07-28',
 'rate': 8.6,
 'sectionid': 'rrmj_1927',
 'tags': ['剧情', '同性'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/30271241/'}
2020-04-30 20:10:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/34883159/> (referer: https://www.douban.com/search?q=%E8%8A%B1%E6%A0%B7%E5%B9%B4%E5%8D%8E-%E7%94%9F%E5%A6%82%E5%A4%8F%E8%8A%B1)
2020-04-30 20:10:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/34883159/>
{'cover': 'http://img.rr.tv/cover/20200403/o_1585885209074.jpg',
 'data_type': 'movie',
 'id': 'rrmj_17389',
 'intro': '该剧是讲述和初恋重逢的40代男女的故事，既不是中年人也不是青春年华的他们，激烈相爱、纠结，迎来人生的第二个“花样年华”。                                                                            \u3000\u3000'
          '刘智泰饰演企业家韩在贤，他是一个有着修长的身材和出众的外貌的“美中年”，但却是一个冷血汉子，现在变成一个精于理财的俗气的人物。                                                                            \u3000\u3000'
          '李宝英饰演尹智秀，她 '
          '是独自抚养着孩子的坚强的单亲妈妈。她曾经是受人追捧的检察长家的千金，但因为事故失去家人，辛苦过着每一天。韩在贤和尹智秀相爱着，迎来了第一个花样年华。在对人生感到疲劳的中年以完全不同的境遇重逢，延续着爱情故事。                                                                            \u3000\u3000'
          '朴珍荣剧中饰演1993年的韩在贤，他出身于首尔周边，全校第一进入延世大学法学系，修长的个子、英俊的五官，刚一进入大学就被评为法学院的"王牌"而受到关注，但本人却对男女之情毫不关心，没有谁的说服和强迫，只是像流水一样自然地参加了学生运动。                                                                            \u3000\u3000'
          '该剧是讲述和初恋重逢的40代男女的故事，...',
 'is_new': False,
 'name': '花样年华-生如夏花',
 'platforms': '',
 'publishdate': '2020-04-25',
 'rate': 8.0,
 'sectionid': 'rrmj_1926',
 'tags': ['爱情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/34883159/'}
2020-04-30 20:10:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/27625457/> (referer: https://www.douban.com/search?q=%E5%8E%BB%E4%BB%96%E5%A6%88%E7%9A%84%E4%B8%96%E7%95%8C%20%E7%AC%AC%E4%BA%8C%E5%AD%A3)
2020-04-30 20:10:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/27625457/>
{'cover': 'http://img.rr.tv/album/20191028/o_1572248821784.jpg',
 'data_type': 'movie',
 'id': 'rrmj_16398',
 'intro': '阿莉莎（杰西卡·巴登饰，《龙虾》）仍在应对第一季中各种事件带来的影响。第二季中添加了新人物邦妮，由荣获英国独立电影奖 (BIFA) '
          '的娜奥米·阿基（《麦克白夫人》和即将上映的《星球大战 '
          '9：天行者崛起》）饰演。邦妮是一个有着复杂过往的局外人，并与阿莉莎有着神秘的联系。                                                                            \u3000\u3000'
          '英国编剧查理·科维尔回归，为《这个破世界的末日》续写精彩。本剧改编自查尔斯·福斯曼荣获奖项的同名漫画书系列。原创歌曲和配乐将再次由格拉翰姆·考可森操刀。英国导演露西·福布斯（《In '
          'My '
          'Skin》）和德斯蒂尼·埃卡拉戛（《得寸进尺》）分别执导了第一部分和第二部分。                                                                            \u3000\u3000'
          '该剧集由 Clerkenwell Films 和 Dominic Buchanan Productions '
          '制作。由默里·弗格森、埃德·麦克唐纳、安迪·贝克、多米尼克·布坎南、乔纳森·恩特威斯尔和查理·科维尔担任监制，珍妮...',
 'is_new': False,
 'name': '去他妈的世界 第二季',
 'platforms': '',
 'publishdate': '2019-11-04',
 'rate': 9.2,
 'sectionid': 'rrmj_1926',
 'tags': ['剧情', '喜剧', '爱情', '冒险'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/27625457/'}
2020-04-30 20:11:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/33379429/> (referer: https://www.douban.com/search?q=%E5%8F%AF%E4%BB%A5%E4%B8%8D%E5%8F%AF%E4%BB%A5-%E5%88%AB%E6%89%AD%E6%88%90%E5%B9%B4%E4%BA%BA%E7%9A%84%E5%90%88%E7%A7%9F%E6%88%BF-)
2020-04-30 20:11:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/33379429/>
{'cover': 'http://img.rr.tv/album/20190423/o_1556001833783.jpg',
 'data_type': 'movie',
 'id': 'rrmj_14631',
 'intro': '求职受到挫折，现在自由职业者的寺田亚希（24岁）被同居的男朋友甩了，在朋友合租的房子里生活。在那里再会了的，是初中的同学，初次男朋友兼第一次「做了」对方·本行智也。近两年一直“不拍”的他，偶然与亚希接触后，不知为何反应很奇怪！！亚希答应绝对不...',
 'is_new': False,
 'name': '可以不可以-别扭成年人的合租房-',
 'platforms': '',
 'publishdate': '2019-04-25',
 'rate': 6.5,
 'sectionid': 'rrmj_1927',
 'tags': ['剧情', '喜剧', '爱情'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/33379429/'}
2020-04-30 20:11:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 29 pages/min), scraped 486 items (at 17 items/min)
2020-04-30 20:12:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 20:13:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 20:14:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 20:15:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 20:16:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 20:17:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 20:18:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 20:19:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 20:20:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 20:21:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 20:22:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 20:23:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 20:24:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 20:25:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 20:26:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 20:27:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 20:28:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 20:29:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 20:30:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 20:31:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 20:32:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 20:33:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 20:34:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 20:35:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 20:36:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 20:37:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 20:38:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 20:39:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 20:40:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 20:41:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 20:42:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 20:43:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 20:44:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 20:45:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 20:46:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 20:47:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 20:48:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 20:49:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 20:50:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 20:51:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 20:52:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 20:53:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 20:54:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 20:55:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 20:56:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 20:57:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 20:58:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 20:59:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 21:00:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 21:01:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 21:02:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 21:03:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 21:04:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 21:05:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 21:06:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 21:07:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 21:08:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 21:09:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 21:10:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 21:11:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 21:12:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 21:13:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 21:14:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 21:15:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 21:16:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 21:17:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 21:18:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 21:19:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 21:20:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 21:21:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 21:22:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 21:23:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 21:24:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 21:25:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 21:26:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 21:27:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 21:28:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 21:29:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 21:30:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 21:31:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 21:32:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 21:33:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 21:34:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 21:35:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 21:36:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 21:37:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 21:38:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 21:39:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 21:40:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 21:41:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 21:42:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 21:43:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 21:44:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 21:45:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 21:46:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 21:47:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 21:48:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 21:49:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 21:50:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 21:51:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 21:52:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 21:53:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 21:54:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 21:55:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 21:56:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 21:57:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 21:58:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 21:59:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 22:00:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 22:01:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 22:02:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 22:03:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 22:04:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 22:05:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 22:06:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 22:07:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 22:08:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 22:09:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 22:10:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 22:11:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 22:12:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 22:13:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 22:14:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 22:15:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 22:16:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 22:17:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 22:18:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 22:19:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 22:20:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 22:21:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 22:22:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 22:23:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 22:24:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 22:25:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 22:26:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 22:27:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 22:28:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 22:29:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 22:30:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 22:31:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 22:32:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 22:33:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 22:34:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 22:35:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 22:36:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 22:37:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 22:38:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 22:39:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 22:40:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 22:41:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 22:42:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 22:43:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 22:44:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 22:45:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 22:46:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 22:47:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 22:48:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 22:49:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 22:50:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 22:51:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 22:52:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 22:53:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 22:54:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 22:55:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 22:56:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 22:57:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 22:58:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 22:59:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 23:00:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 23:01:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 23:02:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 23:03:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 23:04:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 23:05:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 23:06:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 23:07:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 23:08:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 23:09:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 23:10:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 23:11:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 23:12:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 23:13:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 23:14:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 23:15:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 23:16:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 23:17:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 23:18:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 23:19:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 23:20:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 23:21:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 23:22:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 23:23:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 23:24:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 23:25:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 23:26:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 23:27:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 23:28:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 23:29:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 23:30:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 23:31:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 23:32:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 23:33:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 23:34:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 23:35:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 23:36:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 23:37:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 23:38:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 23:39:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 23:40:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 23:41:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 23:42:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 23:43:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 23:44:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 23:45:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 23:46:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 23:47:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 23:48:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 23:49:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 23:50:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 23:51:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 23:52:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 23:53:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 23:54:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 23:55:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 23:56:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 23:57:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 23:58:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-04-30 23:59:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 00:00:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 00:01:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 00:02:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 00:03:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 00:04:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 00:05:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 00:06:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 00:07:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 00:08:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 00:09:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 00:10:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 00:11:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 00:12:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 00:13:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 00:14:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 00:15:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 00:16:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 00:17:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 00:18:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 00:19:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 00:20:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 00:21:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 00:22:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 00:23:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 00:24:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 00:25:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 00:26:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 00:27:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 00:28:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 00:29:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 00:30:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 00:31:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 00:32:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 00:33:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 00:34:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 00:35:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 00:36:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 00:37:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 00:38:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 00:39:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 00:40:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 00:41:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 00:42:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 00:43:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 00:44:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 00:45:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 00:46:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 00:47:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 00:48:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 00:49:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 00:50:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 00:51:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 00:52:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 00:53:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 00:54:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 00:55:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 00:56:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 00:57:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 00:58:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 00:59:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 01:00:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 01:01:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 01:02:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 01:03:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 01:04:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 01:05:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 01:06:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 01:07:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 01:08:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 01:09:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 01:10:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 01:11:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 01:12:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 01:13:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 01:14:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 01:15:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 01:16:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 01:17:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 01:18:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 01:19:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 01:20:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 01:21:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 01:22:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 01:23:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 01:24:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 01:25:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 01:26:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 01:27:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 01:28:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 01:29:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 01:30:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 01:31:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 01:32:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 01:33:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 01:34:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 01:35:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 01:36:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 01:37:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 01:38:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 01:39:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 01:40:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 01:41:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 01:42:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 01:43:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 01:44:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 01:45:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 01:46:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 01:47:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 01:48:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 01:49:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 01:50:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 01:51:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 01:52:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 01:53:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 01:54:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 01:55:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 01:56:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 01:57:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 01:58:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 01:59:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 02:00:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 02:01:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 02:02:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 02:03:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 02:04:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 02:05:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 02:06:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 02:07:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 02:08:19 [scrapy.extensions.logstats] INFO: Crawled 1206 pages (at 0 pages/min), scraped 486 items (at 0 items/min)
2020-05-01 02:08:59 [rrmj] DEBUG: Read 1 requests from 'rrmj:spider:strat_urls'
2020-05-01 02:08:59 [scrapy.core.engine] DEBUG: Crawled (200) <POST https://api.rr.tv/v3plus/index/channel> (referer: None)
2020-05-01 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1912',
 'sectionImg': '',
 'sectionName': '看剧鉴渣男手撕不心软'}
2020-05-01 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1917',
 'sectionImg': '',
 'sectionName': '抖音爆火洗脑剧'}
2020-05-01 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1904',
 'sectionImg': '',
 'sectionName': '台剧新来袭！！'}
2020-05-01 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1244',
 'sectionImg': '',
 'sectionName': '致我们甜甜的恋爱时光'}
2020-05-01 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_822',
 'sectionImg': '',
 'sectionName': '细思极恐 谁是凶手？'}
2020-05-01 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1926',
 'sectionImg': '',
 'sectionName': '力推！豆瓣高分推荐'}
2020-05-01 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1927',
 'sectionImg': '',
 'sectionName': '深夜舔屏福利'}
2020-05-01 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1646',
 'sectionImg': '',
 'sectionName': '急诊室的人间冷暖'}
2020-05-01 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1903',
 'sectionImg': '',
 'sectionName': '恶魔在人间'}
2020-05-01 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1693',
 'sectionImg': '',
 'sectionName': '病毒藏在每个角落'}
2020-05-01 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_742',
 'sectionImg': '',
 'sectionName': '热剧回归！'}
2020-05-01 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_989',
 'sectionImg': '',
 'sectionName': '腐眼看人基'}
2020-05-01 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1883',
 'sectionImg': '',
 'sectionName': '吃货必备！这些纪录片很“下饭”'}
2020-05-01 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1399',
 'sectionImg': '',
 'sectionName': '他改变了世界'}
2020-05-01 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1729',
 'sectionImg': '',
 'sectionName': '【电影】获奖佳片集结'}
2020-05-01 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1405',
 'sectionImg': '',
 'sectionName': '幕后更精彩'}
2020-05-01 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_745',
 'sectionImg': '',
 'sectionName': '本周新剧'}
2020-05-01 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1431',
 'sectionImg': '',
 'sectionName': 'LGBT人生纪实 '}
2020-05-01 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1416',
 'sectionImg': '',
 'sectionName': '怪奇世界物语'}
2020-05-01 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1421',
 'sectionImg': '',
 'sectionName': '笑到飞起的脱口秀'}
2020-05-01 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1295',
 'sectionImg': '',
 'sectionName': '巨星的诞生'}
2020-05-01 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1425',
 'sectionImg': '',
 'sectionName': '大家都在看'}
2020-05-01 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1657',
 'sectionImg': '',
 'sectionName': '奥斯卡最佳纪录片'}
2020-05-01 02:09:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1005',
 'sectionImg': '',
 'sectionName': '德国之声特辑'}
2020-05-01 02:09:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_747',
 'sectionImg': '',
 'sectionName': '完结力推'}
2020-05-01 02:09:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 1 pages/min), scraped 511 items (at 25 items/min)
2020-05-01 02:10:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 02:11:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 02:12:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 02:13:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 02:14:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 02:15:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 02:16:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 02:17:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 02:18:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 02:19:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 02:20:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 02:21:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 02:22:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 02:23:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 02:24:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 02:25:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 02:26:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 02:27:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 02:28:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 02:29:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 02:30:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 02:31:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 02:32:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 02:33:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 02:34:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 02:35:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 02:36:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 02:37:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 02:38:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 02:39:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 02:40:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 02:41:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 02:42:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 02:43:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 02:44:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 02:45:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 02:46:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 02:47:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 02:48:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 02:49:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 02:50:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 02:51:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 02:52:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 02:53:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 02:54:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 02:55:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 02:56:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 02:57:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 02:58:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 02:59:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 03:00:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 03:01:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 03:02:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 03:03:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 03:04:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 03:05:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 03:06:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 03:07:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 03:08:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 03:09:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 03:10:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 03:11:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 03:12:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 03:13:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 03:14:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 03:15:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 03:16:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 03:17:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 03:18:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 03:19:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 03:20:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 03:21:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 03:22:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 03:23:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 03:24:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 03:25:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 03:26:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 03:27:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 03:28:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 03:29:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 03:30:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 03:31:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 03:32:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 03:33:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 03:34:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 03:35:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 03:36:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 03:37:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 03:38:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 03:39:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 03:40:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 03:41:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 03:42:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 03:43:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 03:44:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 03:45:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 03:46:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 03:47:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 03:48:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 03:49:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 03:50:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 03:51:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 03:52:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 03:53:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 03:54:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 03:55:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 03:56:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 03:57:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 03:58:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 03:59:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 04:00:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 04:01:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 04:02:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 04:03:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 04:04:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 04:05:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 04:06:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 04:07:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 04:08:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 04:09:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 04:10:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 04:11:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 04:12:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 04:13:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 04:14:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 04:15:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 04:16:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 04:17:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 04:18:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 04:19:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 04:20:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 04:21:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 04:22:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 04:23:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 04:24:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 04:25:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 04:26:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 04:27:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 04:28:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 04:29:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 04:30:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 04:31:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 04:32:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 04:33:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 04:34:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 04:35:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 04:36:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 04:37:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 04:38:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 04:39:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 04:40:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 04:41:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 04:42:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 04:43:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 04:44:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 04:45:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 04:46:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 04:47:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 04:48:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 04:49:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 04:50:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 04:51:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 04:52:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 04:53:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 04:54:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 04:55:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 04:56:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 04:57:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 04:58:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 04:59:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 05:00:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 05:01:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 05:02:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 05:03:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 05:04:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 05:05:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 05:06:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 05:07:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 05:08:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 05:09:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 05:10:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 05:11:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 05:12:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 05:13:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 05:14:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 05:15:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 05:16:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 05:17:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 05:18:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 05:19:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 05:20:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 05:21:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 05:22:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 05:23:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 05:24:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 05:25:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 05:26:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 05:27:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 05:28:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 05:29:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 05:30:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 05:31:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 05:32:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 05:33:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 05:34:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 05:35:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 05:36:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 05:37:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 05:38:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 05:39:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 05:40:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 05:41:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 05:42:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 05:43:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 05:44:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 05:45:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 05:46:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 05:47:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 05:48:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 05:49:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 05:50:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 05:51:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 05:52:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 05:53:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 05:54:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 05:55:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 05:56:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 05:57:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 05:58:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 05:59:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 06:00:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 06:01:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 06:02:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 06:03:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 06:04:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 06:05:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 06:06:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 06:07:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 06:08:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 06:09:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 06:10:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 06:11:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 06:12:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 06:13:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 06:14:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 06:15:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 06:16:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 06:17:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 06:18:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 06:19:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 06:20:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 06:21:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 06:22:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 06:23:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 06:24:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 06:25:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 06:26:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 06:27:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 06:28:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 06:29:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 06:30:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 06:31:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 06:32:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 06:33:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 06:34:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 06:35:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 06:36:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 06:37:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 06:38:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 06:39:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 06:40:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 06:41:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 06:42:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 06:43:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 06:44:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 06:45:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 06:46:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 06:47:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 06:48:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 06:49:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 06:50:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 06:51:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 06:52:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 06:53:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 06:54:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 06:55:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 06:56:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 06:57:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 06:58:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 06:59:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 07:00:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 07:01:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 07:02:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 07:03:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 07:04:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 07:05:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 07:06:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 07:07:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 07:08:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 07:09:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 07:10:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 07:11:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 07:12:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 07:13:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 07:14:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 07:15:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 07:16:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 07:17:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 07:18:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 07:19:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 07:20:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 07:21:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 07:22:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 07:23:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 07:24:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 07:25:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 07:26:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 07:27:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 07:28:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 07:29:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 07:30:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 07:31:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 07:32:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 07:33:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 07:34:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 07:35:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 07:36:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 07:37:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 07:38:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 07:39:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 07:40:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 07:41:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 07:42:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 07:43:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 07:44:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 07:45:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 07:46:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 07:47:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 07:48:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 07:49:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 07:50:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 07:51:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 07:52:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 07:53:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 07:54:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 07:55:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 07:56:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 07:57:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 07:58:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 07:59:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 08:00:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 08:01:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 08:02:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 08:03:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 08:04:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 08:05:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 08:06:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 08:07:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 08:08:19 [scrapy.extensions.logstats] INFO: Crawled 1207 pages (at 0 pages/min), scraped 511 items (at 0 items/min)
2020-05-01 08:08:59 [rrmj] DEBUG: Read 1 requests from 'rrmj:spider:strat_urls'
2020-05-01 08:08:59 [scrapy.core.engine] DEBUG: Crawled (200) <POST https://api.rr.tv/v3plus/index/channel> (referer: None)
2020-05-01 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1912',
 'sectionImg': '',
 'sectionName': '看剧鉴渣男手撕不心软'}
2020-05-01 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1917',
 'sectionImg': '',
 'sectionName': '抖音爆火洗脑剧'}
2020-05-01 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1904',
 'sectionImg': '',
 'sectionName': '台剧新来袭！！'}
2020-05-01 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1244',
 'sectionImg': '',
 'sectionName': '致我们甜甜的恋爱时光'}
2020-05-01 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_822',
 'sectionImg': '',
 'sectionName': '细思极恐 谁是凶手？'}
2020-05-01 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1926',
 'sectionImg': '',
 'sectionName': '力推！豆瓣高分推荐'}
2020-05-01 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1927',
 'sectionImg': '',
 'sectionName': '深夜舔屏福利'}
2020-05-01 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1646',
 'sectionImg': '',
 'sectionName': '急诊室的人间冷暖'}
2020-05-01 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1903',
 'sectionImg': '',
 'sectionName': '恶魔在人间'}
2020-05-01 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1693',
 'sectionImg': '',
 'sectionName': '病毒藏在每个角落'}
2020-05-01 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_742',
 'sectionImg': '',
 'sectionName': '热剧回归！'}
2020-05-01 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_989',
 'sectionImg': '',
 'sectionName': '腐眼看人基'}
2020-05-01 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1883',
 'sectionImg': '',
 'sectionName': '吃货必备！这些纪录片很“下饭”'}
2020-05-01 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1399',
 'sectionImg': '',
 'sectionName': '他改变了世界'}
2020-05-01 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1729',
 'sectionImg': '',
 'sectionName': '【电影】获奖佳片集结'}
2020-05-01 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1405',
 'sectionImg': '',
 'sectionName': '幕后更精彩'}
2020-05-01 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_745',
 'sectionImg': '',
 'sectionName': '本周新剧'}
2020-05-01 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1431',
 'sectionImg': '',
 'sectionName': 'LGBT人生纪实 '}
2020-05-01 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1416',
 'sectionImg': '',
 'sectionName': '怪奇世界物语'}
2020-05-01 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1421',
 'sectionImg': '',
 'sectionName': '笑到飞起的脱口秀'}
2020-05-01 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1295',
 'sectionImg': '',
 'sectionName': '巨星的诞生'}
2020-05-01 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1425',
 'sectionImg': '',
 'sectionName': '大家都在看'}
2020-05-01 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1657',
 'sectionImg': '',
 'sectionName': '奥斯卡最佳纪录片'}
2020-05-01 08:09:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1005',
 'sectionImg': '',
 'sectionName': '德国之声特辑'}
2020-05-01 08:09:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_747',
 'sectionImg': '',
 'sectionName': '完结力推'}
2020-05-01 08:09:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 1 pages/min), scraped 536 items (at 25 items/min)
2020-05-01 08:10:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 08:11:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 08:12:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 08:13:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 08:14:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 08:15:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 08:16:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 08:17:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 08:18:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 08:19:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 08:20:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 08:21:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 08:22:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 08:23:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 08:24:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 08:25:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 08:26:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 08:27:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 08:28:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 08:29:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 08:30:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 08:31:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 08:32:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 08:33:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 08:34:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 08:35:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 08:36:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 08:37:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 08:38:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 08:39:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 08:40:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 08:41:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 08:42:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 08:43:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 08:44:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 08:45:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 08:46:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 08:47:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 08:48:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 08:49:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 08:50:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 08:51:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 08:52:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 08:53:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 08:54:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 08:55:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 08:56:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 08:57:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 08:58:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 08:59:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 09:00:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 09:01:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 09:02:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 09:03:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 09:04:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 09:05:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 09:06:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 09:07:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 09:08:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 09:09:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 09:10:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 09:11:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 09:12:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 09:13:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 09:14:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 09:15:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 09:16:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 09:17:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 09:18:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 09:19:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 09:20:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 09:21:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 09:22:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 09:23:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 09:24:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 09:25:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 09:26:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 09:27:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 09:28:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 09:29:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 09:30:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 09:31:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 09:32:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 09:33:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 09:34:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 09:35:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 09:36:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 09:37:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 09:38:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 09:39:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 09:40:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 09:41:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 09:42:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 09:43:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 09:44:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 09:45:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 09:46:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 09:47:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 09:48:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 09:49:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 09:50:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 09:51:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 09:52:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 09:53:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 09:54:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 09:55:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 09:56:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 09:57:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 09:58:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 09:59:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 10:00:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 10:01:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 10:02:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 10:03:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 10:04:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 10:05:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 10:06:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 10:07:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 10:08:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 10:09:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 10:10:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 10:11:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 10:12:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 10:13:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 10:14:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 10:15:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 10:16:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 10:17:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 10:18:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 10:19:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 10:20:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 10:21:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 10:22:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 10:23:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 10:24:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 10:25:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 10:26:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 10:27:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 10:28:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 10:29:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 10:30:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 10:31:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 10:32:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 10:33:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 10:34:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 10:35:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 10:36:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 10:37:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 10:38:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 10:39:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 10:40:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 10:41:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 10:42:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 10:43:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 10:44:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 10:45:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 10:46:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 10:47:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 10:48:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 10:49:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 10:50:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 10:51:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 10:52:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 10:53:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 10:54:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 10:55:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 10:56:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 10:57:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 10:58:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 10:59:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 11:00:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 11:01:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 11:02:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 11:03:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 11:04:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 11:05:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 11:06:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 11:07:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 11:08:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 11:09:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 11:10:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 11:11:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 11:12:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 11:13:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 11:14:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 11:15:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 11:16:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 11:17:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 11:18:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 11:19:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 11:20:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 11:21:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 11:22:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 11:23:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 11:24:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 11:25:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 11:26:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 11:27:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 11:28:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 11:29:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 11:30:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 11:31:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 11:32:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 11:33:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 11:34:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 11:35:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 11:36:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 11:37:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 11:38:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 11:39:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 11:40:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 11:41:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 11:42:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 11:43:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 11:44:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 11:45:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 11:46:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 11:47:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 11:48:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 11:49:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 11:50:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 11:51:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 11:52:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 11:53:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 11:54:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 11:55:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 11:56:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 11:57:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 11:58:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 11:59:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 12:00:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 12:01:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 12:02:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 12:03:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 12:04:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 12:05:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 12:06:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 12:07:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 12:08:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 12:09:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 12:10:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 12:11:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 12:12:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 12:13:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 12:14:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 12:15:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 12:16:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 12:17:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 12:18:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 12:19:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 12:20:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 12:21:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 12:22:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 12:23:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 12:24:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 12:25:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 12:26:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 12:27:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 12:28:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 12:29:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 12:30:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 12:31:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 12:32:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 12:33:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 12:34:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 12:35:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 12:36:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 12:37:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 12:38:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 12:39:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 12:40:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 12:41:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 12:42:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 12:43:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 12:44:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 12:45:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 12:46:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 12:47:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 12:48:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 12:49:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 12:50:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 12:51:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 12:52:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 12:53:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 12:54:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 12:55:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 12:56:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 12:57:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 12:58:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 12:59:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 13:00:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 13:01:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 13:02:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 13:03:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 13:04:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 13:05:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 13:06:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 13:07:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 13:08:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 13:09:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 13:10:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 13:11:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 13:12:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 13:13:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 13:14:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 13:15:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 13:16:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 13:17:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 13:18:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 13:19:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 13:20:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 13:21:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 13:22:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 13:23:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 13:24:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 13:25:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 13:26:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 13:27:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 13:28:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 13:29:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 13:30:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 13:31:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 13:32:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 13:33:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 13:34:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 13:35:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 13:36:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 13:37:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 13:38:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 13:39:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 13:40:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 13:41:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 13:42:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 13:43:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 13:44:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 13:45:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 13:46:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 13:47:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 13:48:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 13:49:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 13:50:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 13:51:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 13:52:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 13:53:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 13:54:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 13:55:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 13:56:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 13:57:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 13:58:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 13:59:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 14:00:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 14:01:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 14:02:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 14:03:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 14:04:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 14:05:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 14:06:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 14:07:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 14:08:19 [scrapy.extensions.logstats] INFO: Crawled 1208 pages (at 0 pages/min), scraped 536 items (at 0 items/min)
2020-05-01 14:08:59 [rrmj] DEBUG: Read 1 requests from 'rrmj:spider:strat_urls'
2020-05-01 14:08:59 [scrapy.core.engine] DEBUG: Crawled (200) <POST https://api.rr.tv/v3plus/index/channel> (referer: None)
2020-05-01 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1912',
 'sectionImg': '',
 'sectionName': '看剧鉴渣男手撕不心软'}
2020-05-01 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1917',
 'sectionImg': '',
 'sectionName': '抖音爆火洗脑剧'}
2020-05-01 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1904',
 'sectionImg': '',
 'sectionName': '台剧新来袭！！'}
2020-05-01 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1244',
 'sectionImg': '',
 'sectionName': '致我们甜甜的恋爱时光'}
2020-05-01 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_822',
 'sectionImg': '',
 'sectionName': '细思极恐 谁是凶手？'}
2020-05-01 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1926',
 'sectionImg': '',
 'sectionName': '力推！豆瓣高分推荐'}
2020-05-01 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1927',
 'sectionImg': '',
 'sectionName': '深夜舔屏福利'}
2020-05-01 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1646',
 'sectionImg': '',
 'sectionName': '急诊室的人间冷暖'}
2020-05-01 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1903',
 'sectionImg': '',
 'sectionName': '恶魔在人间'}
2020-05-01 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1693',
 'sectionImg': '',
 'sectionName': '病毒藏在每个角落'}
2020-05-01 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_742',
 'sectionImg': '',
 'sectionName': '热剧回归！'}
2020-05-01 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_989',
 'sectionImg': '',
 'sectionName': '腐眼看人基'}
2020-05-01 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1883',
 'sectionImg': '',
 'sectionName': '吃货必备！这些纪录片很“下饭”'}
2020-05-01 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1399',
 'sectionImg': '',
 'sectionName': '他改变了世界'}
2020-05-01 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1729',
 'sectionImg': '',
 'sectionName': '【电影】获奖佳片集结'}
2020-05-01 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1405',
 'sectionImg': '',
 'sectionName': '幕后更精彩'}
2020-05-01 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_745',
 'sectionImg': '',
 'sectionName': '本周新剧'}
2020-05-01 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1431',
 'sectionImg': '',
 'sectionName': 'LGBT人生纪实 '}
2020-05-01 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1416',
 'sectionImg': '',
 'sectionName': '怪奇世界物语'}
2020-05-01 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1421',
 'sectionImg': '',
 'sectionName': '笑到飞起的脱口秀'}
2020-05-01 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1295',
 'sectionImg': '',
 'sectionName': '巨星的诞生'}
2020-05-01 14:09:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1425',
 'sectionImg': '',
 'sectionName': '大家都在看'}
2020-05-01 14:09:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1657',
 'sectionImg': '',
 'sectionName': '奥斯卡最佳纪录片'}
2020-05-01 14:09:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1005',
 'sectionImg': '',
 'sectionName': '德国之声特辑'}
2020-05-01 14:09:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_747',
 'sectionImg': '',
 'sectionName': '完结力推'}
2020-05-01 14:09:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 1 pages/min), scraped 561 items (at 25 items/min)
2020-05-01 14:10:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 14:11:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 14:12:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 14:13:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 14:14:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 14:15:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 14:16:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 14:17:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 14:18:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 14:19:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 14:20:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 14:21:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 14:22:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 14:23:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 14:24:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 14:25:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 14:26:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 14:27:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 14:28:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 14:29:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 14:30:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 14:31:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 14:32:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 14:33:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 14:34:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 14:35:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 14:36:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 14:37:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 14:38:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 14:39:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 14:40:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 14:41:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 14:42:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 14:43:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 14:44:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 14:45:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 14:46:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 14:47:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 14:48:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 14:49:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 14:50:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 14:51:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 14:52:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 14:53:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 14:54:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 14:55:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 14:56:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 14:57:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 14:58:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 14:59:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 15:00:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 15:01:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 15:02:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 15:03:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 15:04:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 15:05:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 15:06:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 15:07:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 15:08:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 15:09:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 15:10:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 15:11:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 15:12:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 15:13:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 15:14:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 15:15:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 15:16:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 15:17:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 15:18:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 15:19:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 15:20:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 15:21:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 15:22:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 15:23:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 15:24:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 15:25:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 15:26:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 15:27:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 15:28:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 15:29:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 15:30:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 15:31:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 15:32:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 15:33:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 15:34:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 15:35:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 15:36:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 15:37:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 15:38:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 15:39:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 15:40:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 15:41:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 15:42:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 15:43:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 15:44:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 15:45:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 15:46:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 15:47:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 15:48:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 15:49:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 15:50:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 15:51:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 15:52:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 15:53:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 15:54:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 15:55:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 15:56:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 15:57:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 15:58:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 15:59:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 16:00:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 16:01:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 16:02:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 16:03:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 16:04:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 16:05:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 16:06:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 16:07:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 16:08:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 16:09:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 16:10:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 16:11:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 16:12:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 16:13:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 16:14:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 16:15:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 16:16:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 16:17:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 16:18:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 16:19:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 16:20:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 16:21:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 16:22:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 16:23:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 16:24:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 16:25:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 16:26:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 16:27:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 16:28:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 16:29:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 16:30:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 16:31:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 16:32:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 16:33:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 16:34:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 16:35:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 16:36:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 16:37:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 16:38:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 16:39:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 16:40:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 16:41:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 16:42:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 16:43:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 16:44:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 16:45:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 16:46:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 16:47:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 16:48:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 16:49:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 16:50:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 16:51:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 16:52:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 16:53:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 16:54:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 16:55:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 16:56:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 16:57:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 16:58:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 16:59:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 17:00:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 17:01:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 17:02:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 17:03:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 17:04:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 17:05:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 17:06:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 17:07:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 17:08:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 17:09:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 17:10:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 17:11:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 17:12:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 17:13:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 17:14:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 17:15:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 17:16:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 17:17:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 17:18:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 17:19:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 17:20:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 17:21:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 17:22:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 17:23:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 17:24:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 17:25:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 17:26:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 17:27:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 17:28:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 17:29:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 17:30:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 17:31:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 17:32:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 17:33:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 17:34:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 17:35:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 17:36:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 17:37:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 17:38:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 17:39:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 17:40:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 17:41:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 17:42:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 17:43:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 17:44:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 17:45:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 17:46:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 17:47:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 17:48:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 17:49:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 17:50:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 17:51:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 17:52:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 17:53:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 17:54:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 17:55:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 17:56:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 17:57:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 17:58:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 17:59:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 18:00:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 18:01:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 18:02:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 18:03:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 18:04:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 18:05:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 18:06:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 18:07:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 18:08:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 18:09:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 18:10:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 18:11:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 18:12:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 18:13:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 18:14:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 18:15:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 18:16:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 18:17:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 18:18:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 18:19:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 18:20:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 18:21:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 18:22:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 18:23:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 18:24:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 18:25:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 18:26:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 18:27:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 18:28:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 18:29:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 18:30:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 18:31:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 18:32:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 18:33:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 18:34:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 18:35:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 18:36:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 18:37:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 18:38:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 18:39:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 18:40:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 18:41:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 18:42:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 18:43:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 18:44:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 18:45:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 18:46:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 18:47:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 18:48:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 18:49:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 18:50:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 18:51:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 18:52:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 18:53:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 18:54:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 18:55:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 18:56:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 18:57:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 18:58:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 18:59:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 19:00:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 19:01:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 19:02:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 19:03:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 19:04:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 19:05:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 19:06:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 19:07:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 19:08:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 19:09:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 19:10:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 19:11:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 19:12:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 19:13:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 19:14:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 19:15:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 19:16:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 19:17:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 19:18:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 19:19:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 19:20:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 19:21:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 19:22:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 19:23:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 19:24:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 19:25:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 19:26:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 19:27:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 19:28:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 19:29:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 19:30:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 19:31:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 19:32:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 19:33:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 19:34:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 19:35:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 19:36:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 19:37:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 19:38:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 19:39:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 19:40:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 19:41:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 19:42:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 19:43:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 19:44:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 19:45:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 19:46:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 19:47:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 19:48:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 19:49:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 19:50:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 19:51:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 19:52:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 19:53:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 19:54:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 19:55:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 19:56:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 19:57:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 19:58:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 19:59:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 20:00:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 20:01:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 20:02:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 20:03:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 20:04:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 20:05:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 20:06:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 20:07:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 20:08:19 [scrapy.extensions.logstats] INFO: Crawled 1209 pages (at 0 pages/min), scraped 561 items (at 0 items/min)
2020-05-01 20:08:59 [rrmj] DEBUG: Read 1 requests from 'rrmj:spider:strat_urls'
2020-05-01 20:08:59 [scrapy.core.engine] DEBUG: Crawled (200) <POST https://api.rr.tv/v3plus/index/channel> (referer: None)
2020-05-01 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1912',
 'sectionImg': '',
 'sectionName': '看剧鉴渣男手撕不心软'}
2020-05-01 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1917',
 'sectionImg': '',
 'sectionName': '抖音爆火洗脑剧'}
2020-05-01 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1904',
 'sectionImg': '',
 'sectionName': '台剧新来袭！！'}
2020-05-01 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1244',
 'sectionImg': '',
 'sectionName': '致我们甜甜的恋爱时光'}
2020-05-01 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_822',
 'sectionImg': '',
 'sectionName': '细思极恐 谁是凶手？'}
2020-05-01 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1926',
 'sectionImg': '',
 'sectionName': '力推！豆瓣高分推荐'}
2020-05-01 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1927',
 'sectionImg': '',
 'sectionName': '深夜舔屏福利'}
2020-05-01 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1646',
 'sectionImg': '',
 'sectionName': '急诊室的人间冷暖'}
2020-05-01 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1903',
 'sectionImg': '',
 'sectionName': '恶魔在人间'}
2020-05-01 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1693',
 'sectionImg': '',
 'sectionName': '病毒藏在每个角落'}
2020-05-01 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_742',
 'sectionImg': '',
 'sectionName': '热剧回归！'}
2020-05-01 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_989',
 'sectionImg': '',
 'sectionName': '腐眼看人基'}
2020-05-01 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1883',
 'sectionImg': '',
 'sectionName': '吃货必备！这些纪录片很“下饭”'}
2020-05-01 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1399',
 'sectionImg': '',
 'sectionName': '他改变了世界'}
2020-05-01 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1729',
 'sectionImg': '',
 'sectionName': '【电影】获奖佳片集结'}
2020-05-01 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1405',
 'sectionImg': '',
 'sectionName': '幕后更精彩'}
2020-05-01 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_745',
 'sectionImg': '',
 'sectionName': '本周新剧'}
2020-05-01 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1431',
 'sectionImg': '',
 'sectionName': 'LGBT人生纪实 '}
2020-05-01 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1416',
 'sectionImg': '',
 'sectionName': '怪奇世界物语'}
2020-05-01 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1421',
 'sectionImg': '',
 'sectionName': '笑到飞起的脱口秀'}
2020-05-01 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1295',
 'sectionImg': '',
 'sectionName': '巨星的诞生'}
2020-05-01 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1425',
 'sectionImg': '',
 'sectionName': '大家都在看'}
2020-05-01 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1657',
 'sectionImg': '',
 'sectionName': '奥斯卡最佳纪录片'}
2020-05-01 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1005',
 'sectionImg': '',
 'sectionName': '德国之声特辑'}
2020-05-01 20:09:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_747',
 'sectionImg': '',
 'sectionName': '完结力推'}
2020-05-01 20:09:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 1 pages/min), scraped 586 items (at 25 items/min)
2020-05-01 20:10:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 20:11:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 20:12:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 20:13:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 20:14:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 20:15:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 20:16:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 20:17:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 20:18:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 20:19:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 20:20:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 20:21:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 20:22:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 20:23:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 20:24:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 20:25:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 20:26:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 20:27:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 20:28:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 20:29:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 20:30:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 20:31:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 20:32:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 20:33:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 20:34:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 20:35:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 20:36:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 20:37:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 20:38:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 20:39:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 20:40:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 20:41:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 20:42:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 20:43:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 20:44:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 20:45:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 20:46:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 20:47:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 20:48:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 20:49:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 20:50:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 20:51:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 20:52:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 20:53:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 20:54:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 20:55:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 20:56:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 20:57:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 20:58:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 20:59:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 21:00:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 21:01:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 21:02:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 21:03:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 21:04:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 21:05:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 21:06:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 21:07:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 21:08:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 21:09:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 21:10:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 21:11:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 21:12:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 21:13:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 21:14:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 21:15:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 21:16:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 21:17:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 21:18:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 21:19:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 21:20:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 21:21:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 21:22:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 21:23:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 21:24:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 21:25:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 21:26:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 21:27:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 21:28:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 21:29:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 21:30:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 21:31:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 21:32:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 21:33:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 21:34:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 21:35:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 21:36:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 21:37:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 21:38:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 21:39:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 21:40:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 21:41:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 21:42:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 21:43:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 21:44:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 21:45:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 21:46:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 21:47:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 21:48:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 21:49:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 21:50:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 21:51:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 21:52:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 21:53:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 21:54:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 21:55:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 21:56:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 21:57:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 21:58:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 21:59:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 22:00:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 22:01:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 22:02:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 22:03:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 22:04:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 22:05:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 22:06:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 22:07:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 22:08:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 22:09:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 22:10:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 22:11:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 22:12:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 22:13:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 22:14:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 22:15:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 22:16:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 22:17:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 22:18:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 22:19:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 22:20:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 22:21:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 22:22:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 22:23:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 22:24:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 22:25:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 22:26:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 22:27:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 22:28:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 22:29:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 22:30:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 22:31:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 22:32:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 22:33:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 22:34:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 22:35:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 22:36:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 22:37:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 22:38:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 22:39:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 22:40:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 22:41:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 22:42:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 22:43:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 22:44:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 22:45:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 22:46:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 22:47:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 22:48:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 22:49:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 22:50:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 22:51:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 22:52:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 22:53:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 22:54:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 22:55:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 22:56:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 22:57:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 22:58:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 22:59:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 23:00:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 23:01:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 23:02:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 23:03:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 23:04:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 23:05:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 23:06:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 23:07:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 23:08:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 23:09:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 23:10:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 23:11:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 23:12:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 23:13:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 23:14:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 23:15:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 23:16:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 23:17:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 23:18:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 23:19:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 23:20:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 23:21:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 23:22:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 23:23:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 23:24:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 23:25:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 23:26:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 23:27:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 23:28:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 23:29:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 23:30:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 23:31:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 23:32:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 23:33:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 23:34:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 23:35:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 23:36:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 23:37:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 23:38:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 23:39:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 23:40:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 23:41:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 23:42:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 23:43:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 23:44:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 23:45:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 23:46:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 23:47:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 23:48:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 23:49:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 23:50:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 23:51:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 23:52:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 23:53:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 23:54:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 23:55:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 23:56:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 23:57:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 23:58:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-01 23:59:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 00:00:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 00:01:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 00:02:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 00:03:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 00:04:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 00:05:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 00:06:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 00:07:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 00:08:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 00:09:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 00:10:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 00:11:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 00:12:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 00:13:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 00:14:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 00:15:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 00:16:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 00:17:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 00:18:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 00:19:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 00:20:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 00:21:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 00:22:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 00:23:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 00:24:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 00:25:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 00:26:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 00:27:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 00:28:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 00:29:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 00:30:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 00:31:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 00:32:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 00:33:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 00:34:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 00:35:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 00:36:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 00:37:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 00:38:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 00:39:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 00:40:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 00:41:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 00:42:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 00:43:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 00:44:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 00:45:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 00:46:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 00:47:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 00:48:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 00:49:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 00:50:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 00:51:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 00:52:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 00:53:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 00:54:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 00:55:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 00:56:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 00:57:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 00:58:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 00:59:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 01:00:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 01:01:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 01:02:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 01:03:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 01:04:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 01:05:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 01:06:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 01:07:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 01:08:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 01:09:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 01:10:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 01:11:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 01:12:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 01:13:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 01:14:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 01:15:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 01:16:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 01:17:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 01:18:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 01:19:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 01:20:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 01:21:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 01:22:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 01:23:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 01:24:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 01:25:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 01:26:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 01:27:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 01:28:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 01:29:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 01:30:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 01:31:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 01:32:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 01:33:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 01:34:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 01:35:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 01:36:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 01:37:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 01:38:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 01:39:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 01:40:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 01:41:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 01:42:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 01:43:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 01:44:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 01:45:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 01:46:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 01:47:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 01:48:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 01:49:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 01:50:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 01:51:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 01:52:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 01:53:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 01:54:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 01:55:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 01:56:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 01:57:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 01:58:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 01:59:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 02:00:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 02:01:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 02:02:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 02:03:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 02:04:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 02:05:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 02:06:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 02:07:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 02:08:19 [scrapy.extensions.logstats] INFO: Crawled 1210 pages (at 0 pages/min), scraped 586 items (at 0 items/min)
2020-05-02 02:08:59 [rrmj] DEBUG: Read 1 requests from 'rrmj:spider:strat_urls'
2020-05-02 02:08:59 [scrapy.core.engine] DEBUG: Crawled (200) <POST https://api.rr.tv/v3plus/index/channel> (referer: None)
2020-05-02 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1912',
 'sectionImg': '',
 'sectionName': '看剧鉴渣男手撕不心软'}
2020-05-02 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1917',
 'sectionImg': '',
 'sectionName': '抖音爆火洗脑剧'}
2020-05-02 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1904',
 'sectionImg': '',
 'sectionName': '台剧新来袭！！'}
2020-05-02 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1244',
 'sectionImg': '',
 'sectionName': '致我们甜甜的恋爱时光'}
2020-05-02 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_822',
 'sectionImg': '',
 'sectionName': '细思极恐 谁是凶手？'}
2020-05-02 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1926',
 'sectionImg': '',
 'sectionName': '力推！豆瓣高分推荐'}
2020-05-02 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1927',
 'sectionImg': '',
 'sectionName': '深夜舔屏福利'}
2020-05-02 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1646',
 'sectionImg': '',
 'sectionName': '急诊室的人间冷暖'}
2020-05-02 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1903',
 'sectionImg': '',
 'sectionName': '恶魔在人间'}
2020-05-02 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1693',
 'sectionImg': '',
 'sectionName': '病毒藏在每个角落'}
2020-05-02 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_742',
 'sectionImg': '',
 'sectionName': '热剧回归！'}
2020-05-02 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_989',
 'sectionImg': '',
 'sectionName': '腐眼看人基'}
2020-05-02 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1883',
 'sectionImg': '',
 'sectionName': '吃货必备！这些纪录片很“下饭”'}
2020-05-02 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1399',
 'sectionImg': '',
 'sectionName': '他改变了世界'}
2020-05-02 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1729',
 'sectionImg': '',
 'sectionName': '【电影】获奖佳片集结'}
2020-05-02 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1405',
 'sectionImg': '',
 'sectionName': '幕后更精彩'}
2020-05-02 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_745',
 'sectionImg': '',
 'sectionName': '本周新剧'}
2020-05-02 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1431',
 'sectionImg': '',
 'sectionName': 'LGBT人生纪实 '}
2020-05-02 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1416',
 'sectionImg': '',
 'sectionName': '怪奇世界物语'}
2020-05-02 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1421',
 'sectionImg': '',
 'sectionName': '笑到飞起的脱口秀'}
2020-05-02 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1295',
 'sectionImg': '',
 'sectionName': '巨星的诞生'}
2020-05-02 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1425',
 'sectionImg': '',
 'sectionName': '大家都在看'}
2020-05-02 02:09:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1657',
 'sectionImg': '',
 'sectionName': '奥斯卡最佳纪录片'}
2020-05-02 02:09:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1005',
 'sectionImg': '',
 'sectionName': '德国之声特辑'}
2020-05-02 02:09:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_747',
 'sectionImg': '',
 'sectionName': '完结力推'}
2020-05-02 02:09:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E7%BE%8E%E5%9B%BD%E6%81%90%E6%80%96%E6%95%85%E4%BA%8B%20%E7%AC%AC%E4%B8%80%E5%AD%A3> (referer: https://api.rr.tv/v3plus/index/channel)
2020-05-02 02:09:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/6729183/> (referer: https://www.douban.com/search?q=%E7%BE%8E%E5%9B%BD%E6%81%90%E6%80%96%E6%95%85%E4%BA%8B%20%E7%AC%AC%E4%B8%80%E5%AD%A3)
2020-05-02 02:09:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/6729183/>
{'cover': 'http://img.rr.tv/album/20180831/o_1535710559352.jpg',
 'data_type': 'movie',
 'id': 'rrmj_191',
 'intro': '心理治疗师Ben（迪伦·麦克德莫特 Dylan McDermott 饰）因与女学生有染被妻子Vivien（康妮·布里登 Connie '
          'Britton '
          '饰）发现，经协调决定带着女儿Violet一家搬到洛杉矶开始新生活。                                                                            \u3000\u3000'
          '但各式奇怪的人接踵而来：亦老亦少的感女仆Moira（ 阿丽克丝·布莱肯瑞吉 Alexandra Breckenridge '
          '饰）；能预知的诡异女孩Adelaide；穿黑色紧身橡胶服的神秘人；满脑子古怪念头的病人Tate（伊万·彼得斯 Evan Peters '
          '饰），不请自来的邻居Constance（杰西卡·兰格 Jessica Lange 饰），令人不寒而栗的跟踪者Larry（丹尼斯·欧哈拉 '
          'Denis OHare '
          '饰）。而地下室里的怪物；萦绕不去的幽灵；坛坛罐罐里的秘密实验，这些离奇事件也似乎在证实这所房子隐藏着不可告人的神秘........',
 'is_new': False,
 'name': '美国恐怖故事 第一季',
 'platforms': '',
 'publishdate': '2011-10-05',
 'rate': 7.8,
 'sectionid': 'rrmj_1917',
 'tags': ['剧情', '悬疑', '恐怖'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/6729183/'}
2020-05-02 02:09:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 3 pages/min), scraped 612 items (at 26 items/min)
2020-05-02 02:10:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 02:11:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 02:12:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 02:13:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 02:14:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 02:15:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 02:16:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 02:17:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 02:18:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 02:19:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 02:20:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 02:21:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 02:22:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 02:23:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 02:24:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 02:25:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 02:26:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 02:27:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 02:28:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 02:29:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 02:30:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 02:31:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 02:32:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 02:33:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 02:34:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 02:35:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 02:36:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 02:37:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 02:38:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 02:39:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 02:40:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 02:41:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 02:42:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 02:43:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 02:44:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 02:45:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 02:46:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 02:47:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 02:48:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 02:49:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 02:50:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 02:51:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 02:52:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 02:53:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 02:54:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 02:55:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 02:56:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 02:57:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 02:58:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 02:59:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 03:00:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 03:01:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 03:02:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 03:03:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 03:04:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 03:05:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 03:06:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 03:07:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 03:08:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 03:09:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 03:10:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 03:11:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 03:12:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 03:13:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 03:14:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 03:15:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 03:16:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 03:17:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 03:18:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 03:19:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 03:20:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 03:21:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 03:22:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 03:23:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 03:24:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 03:25:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 03:26:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 03:27:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 03:28:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 03:29:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 03:30:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 03:31:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 03:32:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 03:33:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 03:34:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 03:35:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 03:36:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 03:37:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 03:38:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 03:39:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 03:40:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 03:41:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 03:42:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 03:43:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 03:44:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 03:45:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 03:46:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 03:47:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 03:48:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 03:49:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 03:50:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 03:51:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 03:52:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 03:53:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 03:54:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 03:55:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 03:56:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 03:57:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 03:58:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 03:59:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 04:00:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 04:01:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 04:02:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 04:03:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 04:04:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 04:05:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 04:06:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 04:07:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 04:08:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 04:09:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 04:10:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 04:11:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 04:12:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 04:13:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 04:14:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 04:15:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 04:16:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 04:17:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 04:18:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 04:19:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 04:20:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 04:21:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 04:22:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 04:23:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 04:24:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 04:25:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 04:26:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 04:27:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 04:28:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 04:29:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 04:30:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 04:31:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 04:32:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 04:33:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 04:34:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 04:35:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 04:36:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 04:37:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 04:38:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 04:39:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 04:40:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 04:41:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 04:42:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 04:43:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 04:44:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 04:45:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 04:46:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 04:47:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 04:48:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 04:49:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 04:50:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 04:51:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 04:52:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 04:53:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 04:54:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 04:55:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 04:56:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 04:57:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 04:58:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 04:59:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 05:00:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 05:01:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 05:02:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 05:03:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 05:04:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 05:05:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 05:06:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 05:07:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 05:08:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 05:09:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 05:10:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 05:11:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 05:12:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 05:13:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 05:14:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 05:15:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 05:16:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 05:17:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 05:18:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 05:19:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 05:20:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 05:21:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 05:22:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 05:23:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 05:24:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 05:25:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 05:26:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 05:27:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 05:28:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 05:29:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 05:30:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 05:31:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 05:32:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 05:33:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 05:34:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 05:35:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 05:36:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 05:37:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 05:38:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 05:39:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 05:40:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 05:41:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 05:42:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 05:43:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 05:44:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 05:45:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 05:46:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 05:47:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 05:48:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 05:49:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 05:50:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 05:51:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 05:52:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 05:53:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 05:54:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 05:55:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 05:56:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 05:57:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 05:58:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 05:59:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 06:00:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 06:01:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 06:02:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 06:03:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 06:04:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 06:05:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 06:06:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 06:07:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 06:08:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 06:09:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 06:10:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 06:11:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 06:12:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 06:13:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 06:14:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 06:15:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 06:16:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 06:17:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 06:18:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 06:19:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 06:20:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 06:21:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 06:22:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 06:23:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 06:24:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 06:25:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 06:26:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 06:27:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 06:28:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 06:29:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 06:30:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 06:31:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 06:32:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 06:33:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 06:34:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 06:35:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 06:36:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 06:37:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 06:38:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 06:39:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 06:40:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 06:41:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 06:42:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 06:43:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 06:44:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 06:45:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 06:46:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 06:47:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 06:48:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 06:49:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 06:50:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 06:51:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 06:52:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 06:53:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 06:54:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 06:55:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 06:56:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 06:57:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 06:58:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 06:59:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 07:00:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 07:01:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 07:02:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 07:03:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 07:04:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 07:05:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 07:06:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 07:07:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 07:08:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 07:09:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 07:10:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 07:11:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 07:12:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 07:13:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 07:14:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 07:15:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 07:16:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 07:17:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 07:18:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 07:19:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 07:20:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 07:21:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 07:22:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 07:23:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 07:24:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 07:25:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 07:26:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 07:27:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 07:28:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 07:29:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 07:30:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 07:31:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 07:32:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 07:33:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 07:34:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 07:35:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 07:36:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 07:37:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 07:38:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 07:39:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 07:40:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 07:41:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 07:42:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 07:43:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 07:44:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 07:45:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 07:46:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 07:47:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 07:48:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 07:49:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 07:50:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 07:51:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 07:52:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 07:53:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 07:54:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 07:55:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 07:56:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 07:57:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 07:58:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 07:59:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 08:00:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 08:01:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 08:02:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 08:03:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 08:04:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 08:05:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 08:06:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 08:07:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 08:08:19 [scrapy.extensions.logstats] INFO: Crawled 1213 pages (at 0 pages/min), scraped 612 items (at 0 items/min)
2020-05-02 08:08:59 [rrmj] DEBUG: Read 1 requests from 'rrmj:spider:strat_urls'
2020-05-02 08:08:59 [scrapy.core.engine] DEBUG: Crawled (200) <POST https://api.rr.tv/v3plus/index/channel> (referer: None)
2020-05-02 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1912',
 'sectionImg': '',
 'sectionName': '看剧鉴渣男手撕不心软'}
2020-05-02 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1917',
 'sectionImg': '',
 'sectionName': '抖音爆火洗脑剧'}
2020-05-02 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1904',
 'sectionImg': '',
 'sectionName': '台剧新来袭！！'}
2020-05-02 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1244',
 'sectionImg': '',
 'sectionName': '致我们甜甜的恋爱时光'}
2020-05-02 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_822',
 'sectionImg': '',
 'sectionName': '细思极恐 谁是凶手？'}
2020-05-02 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1926',
 'sectionImg': '',
 'sectionName': '力推！豆瓣高分推荐'}
2020-05-02 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1927',
 'sectionImg': '',
 'sectionName': '深夜舔屏福利'}
2020-05-02 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1646',
 'sectionImg': '',
 'sectionName': '急诊室的人间冷暖'}
2020-05-02 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1903',
 'sectionImg': '',
 'sectionName': '恶魔在人间'}
2020-05-02 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1693',
 'sectionImg': '',
 'sectionName': '病毒藏在每个角落'}
2020-05-02 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_742',
 'sectionImg': '',
 'sectionName': '热剧回归！'}
2020-05-02 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_989',
 'sectionImg': '',
 'sectionName': '腐眼看人基'}
2020-05-02 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1883',
 'sectionImg': '',
 'sectionName': '吃货必备！这些纪录片很“下饭”'}
2020-05-02 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1399',
 'sectionImg': '',
 'sectionName': '他改变了世界'}
2020-05-02 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1729',
 'sectionImg': '',
 'sectionName': '【电影】获奖佳片集结'}
2020-05-02 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1405',
 'sectionImg': '',
 'sectionName': '幕后更精彩'}
2020-05-02 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_745',
 'sectionImg': '',
 'sectionName': '本周新剧'}
2020-05-02 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1431',
 'sectionImg': '',
 'sectionName': 'LGBT人生纪实 '}
2020-05-02 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1416',
 'sectionImg': '',
 'sectionName': '怪奇世界物语'}
2020-05-02 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1421',
 'sectionImg': '',
 'sectionName': '笑到飞起的脱口秀'}
2020-05-02 08:09:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1295',
 'sectionImg': '',
 'sectionName': '巨星的诞生'}
2020-05-02 08:09:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1425',
 'sectionImg': '',
 'sectionName': '大家都在看'}
2020-05-02 08:09:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1657',
 'sectionImg': '',
 'sectionName': '奥斯卡最佳纪录片'}
2020-05-02 08:09:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1005',
 'sectionImg': '',
 'sectionName': '德国之声特辑'}
2020-05-02 08:09:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_747',
 'sectionImg': '',
 'sectionName': '完结力推'}
2020-05-02 08:09:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 1 pages/min), scraped 637 items (at 25 items/min)
2020-05-02 08:10:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 08:11:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 08:12:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 08:13:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 08:14:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 08:15:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 08:16:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 08:17:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 08:18:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 08:19:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 08:20:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 08:21:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 08:22:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 08:23:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 08:24:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 08:25:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 08:26:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 08:27:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 08:28:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 08:29:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 08:30:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 08:31:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 08:32:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 08:33:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 08:34:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 08:35:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 08:36:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 08:37:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 08:38:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 08:39:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 08:40:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 08:41:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 08:42:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 08:43:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 08:44:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 08:45:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 08:46:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 08:47:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 08:48:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 08:49:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 08:50:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 08:51:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 08:52:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 08:53:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 08:54:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 08:55:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 08:56:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 08:57:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 08:58:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 08:59:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 09:00:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 09:01:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 09:02:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 09:03:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 09:04:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 09:05:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 09:06:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 09:07:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 09:08:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 09:09:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 09:10:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 09:11:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 09:12:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 09:13:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 09:14:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 09:15:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 09:16:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 09:17:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 09:18:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 09:19:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 09:20:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 09:21:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 09:22:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 09:23:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 09:24:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 09:25:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 09:26:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 09:27:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 09:28:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 09:29:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 09:30:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 09:31:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 09:32:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 09:33:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 09:34:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 09:35:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 09:36:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 09:37:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 09:38:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 09:39:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 09:40:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 09:41:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 09:42:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 09:43:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 09:44:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 09:45:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 09:46:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 09:47:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 09:48:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 09:49:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 09:50:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 09:51:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 09:52:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 09:53:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 09:54:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 09:55:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 09:56:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 09:57:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 09:58:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 09:59:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 10:00:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 10:01:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 10:02:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 10:03:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 10:04:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 10:05:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 10:06:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 10:07:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 10:08:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 10:09:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 10:10:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 10:11:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 10:12:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 10:13:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 10:14:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 10:15:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 10:16:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 10:17:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 10:18:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 10:19:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 10:20:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 10:21:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 10:22:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 10:23:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 10:24:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 10:25:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 10:26:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 10:27:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 10:28:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 10:29:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 10:30:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 10:31:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 10:32:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 10:33:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 10:34:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 10:35:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 10:36:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 10:37:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 10:38:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 10:39:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 10:40:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 10:41:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 10:42:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 10:43:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 10:44:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 10:45:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 10:46:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 10:47:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 10:48:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 10:49:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 10:50:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 10:51:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 10:52:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 10:53:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 10:54:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 10:55:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 10:56:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 10:57:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 10:58:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 10:59:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 11:00:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 11:01:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 11:02:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 11:03:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 11:04:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 11:05:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 11:06:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 11:07:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 11:08:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 11:09:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 11:10:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 11:11:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 11:12:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 11:13:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 11:14:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 11:15:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 11:16:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 11:17:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 11:18:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 11:19:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 11:20:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 11:21:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 11:22:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 11:23:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 11:24:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 11:25:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 11:26:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 11:27:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 11:28:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 11:29:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 11:30:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 11:31:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 11:32:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 11:33:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 11:34:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 11:35:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 11:36:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 11:37:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 11:38:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 11:39:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 11:40:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 11:41:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 11:42:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 11:43:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 11:44:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 11:45:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 11:46:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 11:47:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 11:48:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 11:49:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 11:50:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 11:51:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 11:52:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 11:53:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 11:54:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 11:55:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 11:56:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 11:57:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 11:58:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 11:59:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 12:00:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 12:01:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 12:02:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 12:03:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 12:04:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 12:05:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 12:06:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 12:07:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 12:08:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 12:09:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 12:10:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 12:11:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 12:12:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 12:13:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 12:14:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 12:15:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 12:16:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 12:17:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 12:18:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 12:19:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 12:20:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 12:21:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 12:22:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 12:23:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 12:24:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 12:25:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 12:26:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 12:27:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 12:28:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 12:29:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 12:30:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 12:31:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 12:32:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 12:33:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 12:34:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 12:35:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 12:36:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 12:37:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 12:38:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 12:39:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 12:40:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 12:41:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 12:42:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 12:43:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 12:44:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 12:45:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 12:46:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 12:47:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 12:48:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 12:49:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 12:50:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 12:51:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 12:52:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 12:53:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 12:54:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 12:55:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 12:56:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 12:57:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 12:58:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 12:59:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 13:00:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 13:01:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 13:02:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 13:03:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 13:04:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 13:05:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 13:06:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 13:07:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 13:08:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 13:09:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 13:10:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 13:11:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 13:12:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 13:13:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 13:14:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 13:15:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 13:16:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 13:17:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 13:18:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 13:19:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 13:20:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 13:21:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 13:22:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 13:23:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 13:24:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 13:25:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 13:26:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 13:27:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 13:28:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 13:29:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 13:30:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 13:31:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 13:32:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 13:33:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 13:34:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 13:35:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 13:36:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 13:37:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 13:38:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 13:39:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 13:40:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 13:41:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 13:42:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 13:43:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 13:44:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 13:45:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 13:46:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 13:47:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 13:48:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 13:49:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 13:50:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 13:51:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 13:52:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 13:53:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 13:54:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 13:55:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 13:56:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 13:57:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 13:58:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 13:59:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 14:00:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 14:01:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 14:02:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 14:03:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 14:04:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 14:05:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 14:06:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 14:07:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 14:08:19 [scrapy.extensions.logstats] INFO: Crawled 1214 pages (at 0 pages/min), scraped 637 items (at 0 items/min)
2020-05-02 14:08:59 [rrmj] DEBUG: Read 1 requests from 'rrmj:spider:strat_urls'
2020-05-02 14:08:59 [scrapy.core.engine] DEBUG: Crawled (200) <POST https://api.rr.tv/v3plus/index/channel> (referer: None)
2020-05-02 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1912',
 'sectionImg': '',
 'sectionName': '看剧鉴渣男手撕不心软'}
2020-05-02 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1917',
 'sectionImg': '',
 'sectionName': '抖音爆火洗脑剧'}
2020-05-02 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1904',
 'sectionImg': '',
 'sectionName': '台剧新来袭！！'}
2020-05-02 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1244',
 'sectionImg': '',
 'sectionName': '致我们甜甜的恋爱时光'}
2020-05-02 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_822',
 'sectionImg': '',
 'sectionName': '细思极恐 谁是凶手？'}
2020-05-02 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1926',
 'sectionImg': '',
 'sectionName': '力推！豆瓣高分推荐'}
2020-05-02 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1927',
 'sectionImg': '',
 'sectionName': '深夜舔屏福利'}
2020-05-02 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1646',
 'sectionImg': '',
 'sectionName': '急诊室的人间冷暖'}
2020-05-02 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1903',
 'sectionImg': '',
 'sectionName': '恶魔在人间'}
2020-05-02 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1693',
 'sectionImg': '',
 'sectionName': '病毒藏在每个角落'}
2020-05-02 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_742',
 'sectionImg': '',
 'sectionName': '热剧回归！'}
2020-05-02 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_989',
 'sectionImg': '',
 'sectionName': '腐眼看人基'}
2020-05-02 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1883',
 'sectionImg': '',
 'sectionName': '吃货必备！这些纪录片很“下饭”'}
2020-05-02 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1399',
 'sectionImg': '',
 'sectionName': '他改变了世界'}
2020-05-02 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1729',
 'sectionImg': '',
 'sectionName': '【电影】获奖佳片集结'}
2020-05-02 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1405',
 'sectionImg': '',
 'sectionName': '幕后更精彩'}
2020-05-02 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_745',
 'sectionImg': '',
 'sectionName': '本周新剧'}
2020-05-02 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1431',
 'sectionImg': '',
 'sectionName': 'LGBT人生纪实 '}
2020-05-02 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1416',
 'sectionImg': '',
 'sectionName': '怪奇世界物语'}
2020-05-02 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1421',
 'sectionImg': '',
 'sectionName': '笑到飞起的脱口秀'}
2020-05-02 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1295',
 'sectionImg': '',
 'sectionName': '巨星的诞生'}
2020-05-02 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1425',
 'sectionImg': '',
 'sectionName': '大家都在看'}
2020-05-02 14:09:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1657',
 'sectionImg': '',
 'sectionName': '奥斯卡最佳纪录片'}
2020-05-02 14:09:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1005',
 'sectionImg': '',
 'sectionName': '德国之声特辑'}
2020-05-02 14:09:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_747',
 'sectionImg': '',
 'sectionName': '完结力推'}
2020-05-02 14:09:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 1 pages/min), scraped 662 items (at 25 items/min)
2020-05-02 14:10:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 14:11:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 14:12:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 14:13:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 14:14:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 14:15:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 14:16:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 14:17:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 14:18:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 14:19:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 14:20:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 14:21:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 14:22:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 14:23:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 14:24:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 14:25:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 14:26:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 14:27:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 14:28:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 14:29:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 14:30:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 14:31:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 14:32:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 14:33:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 14:34:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 14:35:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 14:36:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 14:37:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 14:38:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 14:39:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 14:40:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 14:41:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 14:42:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 14:43:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 14:44:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 14:45:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 14:46:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 14:47:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 14:48:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 14:49:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 14:50:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 14:51:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 14:52:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 14:53:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 14:54:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 14:55:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 14:56:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 14:57:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 14:58:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 14:59:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 15:00:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 15:01:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 15:02:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 15:03:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 15:04:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 15:05:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 15:06:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 15:07:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 15:08:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 15:09:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 15:10:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 15:11:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 15:12:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 15:13:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 15:14:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 15:15:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 15:16:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 15:17:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 15:18:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 15:19:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 15:20:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 15:21:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 15:22:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 15:23:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 15:24:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 15:25:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 15:26:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 15:27:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 15:28:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 15:29:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 15:30:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 15:31:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 15:32:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 15:33:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 15:34:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 15:35:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 15:36:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 15:37:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 15:38:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 15:39:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 15:40:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 15:41:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 15:42:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 15:43:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 15:44:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 15:45:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 15:46:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 15:47:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 15:48:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 15:49:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 15:50:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 15:51:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 15:52:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 15:53:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 15:54:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 15:55:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 15:56:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 15:57:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 15:58:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 15:59:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 16:00:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 16:01:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 16:02:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 16:03:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 16:04:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 16:05:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 16:06:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 16:07:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 16:08:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 16:09:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 16:10:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 16:11:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 16:12:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 16:13:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 16:14:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 16:15:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 16:16:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 16:17:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 16:18:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 16:19:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 16:20:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 16:21:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 16:22:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 16:23:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 16:24:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 16:25:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 16:26:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 16:27:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 16:28:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 16:29:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 16:30:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 16:31:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 16:32:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 16:33:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 16:34:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 16:35:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 16:36:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 16:37:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 16:38:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 16:39:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 16:40:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 16:41:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 16:42:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 16:43:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 16:44:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 16:45:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 16:46:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 16:47:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 16:48:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 16:49:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 16:50:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 16:51:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 16:52:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 16:53:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 16:54:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 16:55:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 16:56:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 16:57:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 16:58:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 16:59:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 17:00:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 17:01:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 17:02:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 17:03:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 17:04:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 17:05:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 17:06:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 17:07:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 17:08:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 17:09:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 17:10:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 17:11:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 17:12:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 17:13:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 17:14:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 17:15:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 17:16:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 17:17:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 17:18:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 17:19:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 17:20:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 17:21:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 17:22:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 17:23:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 17:24:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 17:25:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 17:26:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 17:27:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 17:28:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 17:29:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 17:30:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 17:31:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 17:32:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 17:33:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 17:34:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 17:35:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 17:36:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 17:37:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 17:38:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 17:39:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 17:40:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 17:41:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 17:42:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 17:43:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 17:44:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 17:45:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 17:46:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 17:47:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 17:48:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 17:49:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 17:50:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 17:51:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 17:52:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 17:53:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 17:54:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 17:55:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 17:56:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 17:57:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 17:58:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 17:59:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 18:00:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 18:01:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 18:02:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 18:03:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 18:04:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 18:05:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 18:06:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 18:07:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 18:08:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 18:09:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 18:10:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 18:11:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 18:12:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 18:13:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 18:14:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 18:15:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 18:16:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 18:17:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 18:18:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 18:19:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 18:20:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 18:21:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 18:22:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 18:23:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 18:24:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 18:25:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 18:26:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 18:27:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 18:28:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 18:29:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 18:30:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 18:31:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 18:32:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 18:33:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 18:34:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 18:35:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 18:36:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 18:37:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 18:38:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 18:39:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 18:40:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 18:41:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 18:42:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 18:43:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 18:44:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 18:45:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 18:46:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 18:47:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 18:48:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 18:49:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 18:50:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 18:51:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 18:52:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 18:53:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 18:54:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 18:55:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 18:56:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 18:57:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 18:58:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 18:59:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 19:00:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 19:01:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 19:02:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 19:03:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 19:04:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 19:05:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 19:06:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 19:07:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 19:08:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 19:09:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 19:10:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 19:11:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 19:12:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 19:13:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 19:14:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 19:15:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 19:16:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 19:17:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 19:18:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 19:19:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 19:20:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 19:21:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 19:22:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 19:23:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 19:24:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 19:25:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 19:26:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 19:27:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 19:28:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 19:29:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 19:30:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 19:31:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 19:32:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 19:33:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 19:34:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 19:35:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 19:36:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 19:37:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 19:38:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 19:39:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 19:40:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 19:41:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 19:42:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 19:43:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 19:44:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 19:45:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 19:46:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 19:47:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 19:48:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 19:49:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 19:50:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 19:51:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 19:52:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 19:53:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 19:54:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 19:55:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 19:56:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 19:57:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 19:58:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 19:59:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 20:00:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 20:01:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 20:02:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 20:03:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 20:04:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 20:05:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 20:06:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 20:07:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 20:08:19 [scrapy.extensions.logstats] INFO: Crawled 1215 pages (at 0 pages/min), scraped 662 items (at 0 items/min)
2020-05-02 20:08:59 [rrmj] DEBUG: Read 1 requests from 'rrmj:spider:strat_urls'
2020-05-02 20:08:59 [scrapy.core.engine] DEBUG: Crawled (200) <POST https://api.rr.tv/v3plus/index/channel> (referer: None)
2020-05-02 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1912',
 'sectionImg': '',
 'sectionName': '看剧鉴渣男手撕不心软'}
2020-05-02 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1917',
 'sectionImg': '',
 'sectionName': '抖音爆火洗脑剧'}
2020-05-02 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1904',
 'sectionImg': '',
 'sectionName': '台剧新来袭！！'}
2020-05-02 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1244',
 'sectionImg': '',
 'sectionName': '致我们甜甜的恋爱时光'}
2020-05-02 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_822',
 'sectionImg': '',
 'sectionName': '细思极恐 谁是凶手？'}
2020-05-02 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1926',
 'sectionImg': '',
 'sectionName': '力推！豆瓣高分推荐'}
2020-05-02 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1927',
 'sectionImg': '',
 'sectionName': '深夜舔屏福利'}
2020-05-02 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1646',
 'sectionImg': '',
 'sectionName': '急诊室的人间冷暖'}
2020-05-02 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1903',
 'sectionImg': '',
 'sectionName': '恶魔在人间'}
2020-05-02 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1693',
 'sectionImg': '',
 'sectionName': '病毒藏在每个角落'}
2020-05-02 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_742',
 'sectionImg': '',
 'sectionName': '热剧回归！'}
2020-05-02 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_989',
 'sectionImg': '',
 'sectionName': '腐眼看人基'}
2020-05-02 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1883',
 'sectionImg': '',
 'sectionName': '吃货必备！这些纪录片很“下饭”'}
2020-05-02 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1399',
 'sectionImg': '',
 'sectionName': '他改变了世界'}
2020-05-02 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1729',
 'sectionImg': '',
 'sectionName': '【电影】获奖佳片集结'}
2020-05-02 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1405',
 'sectionImg': '',
 'sectionName': '幕后更精彩'}
2020-05-02 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_745',
 'sectionImg': '',
 'sectionName': '本周新剧'}
2020-05-02 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1431',
 'sectionImg': '',
 'sectionName': 'LGBT人生纪实 '}
2020-05-02 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1416',
 'sectionImg': '',
 'sectionName': '怪奇世界物语'}
2020-05-02 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1421',
 'sectionImg': '',
 'sectionName': '笑到飞起的脱口秀'}
2020-05-02 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1295',
 'sectionImg': '',
 'sectionName': '巨星的诞生'}
2020-05-02 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1425',
 'sectionImg': '',
 'sectionName': '大家都在看'}
2020-05-02 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1657',
 'sectionImg': '',
 'sectionName': '奥斯卡最佳纪录片'}
2020-05-02 20:09:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1005',
 'sectionImg': '',
 'sectionName': '德国之声特辑'}
2020-05-02 20:09:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_747',
 'sectionImg': '',
 'sectionName': '完结力推'}
2020-05-02 20:09:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E6%91%A9%E7%99%BB%E8%90%BD%E5%B9%95%EF%BC%9A%E4%B8%8D%E6%83%B3%E8%AF%B4%E5%86%8D%E8%A7%81> (referer: https://api.rr.tv/v3plus/index/channel)
2020-05-02 20:09:03 [scrapy.core.engine] DEBUG: Crawled (404) <GET https://movie.douban.com/subject/3795062/> (referer: https://www.douban.com/search?q=%E6%91%A9%E7%99%BB%E8%90%BD%E5%B9%95%EF%BC%9A%E4%B8%8D%E6%83%B3%E8%AF%B4%E5%86%8D%E8%A7%81)
2020-05-02 20:09:03 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://movie.douban.com/subject/3795062/>: HTTP status code is not handled or not allowed
2020-05-02 20:09:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 3 pages/min), scraped 687 items (at 25 items/min)
2020-05-02 20:10:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 20:11:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 20:12:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 20:13:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 20:14:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 20:15:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 20:16:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 20:17:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 20:18:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 20:19:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 20:20:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 20:21:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 20:22:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 20:23:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 20:24:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 20:25:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 20:26:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 20:27:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 20:28:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 20:29:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 20:30:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 20:31:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 20:32:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 20:33:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 20:34:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 20:35:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 20:36:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 20:37:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 20:38:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 20:39:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 20:40:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 20:41:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 20:42:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 20:43:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 20:44:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 20:45:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 20:46:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 20:47:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 20:48:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 20:49:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 20:50:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 20:51:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 20:52:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 20:53:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 20:54:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 20:55:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 20:56:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 20:57:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 20:58:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 20:59:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 21:00:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 21:01:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 21:02:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 21:03:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 21:04:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 21:05:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 21:06:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 21:07:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 21:08:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 21:09:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 21:10:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 21:11:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 21:12:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 21:13:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 21:14:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 21:15:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 21:16:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 21:17:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 21:18:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 21:19:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 21:20:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 21:21:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 21:22:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 21:23:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 21:24:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 21:25:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 21:26:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 21:27:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 21:28:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 21:29:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 21:30:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 21:31:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 21:32:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 21:33:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 21:34:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 21:35:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 21:36:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 21:37:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 21:38:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 21:39:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 21:40:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 21:41:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 21:42:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 21:43:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 21:44:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 21:45:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 21:46:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 21:47:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 21:48:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 21:49:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 21:50:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 21:51:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 21:52:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 21:53:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 21:54:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 21:55:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 21:56:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 21:57:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 21:58:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 21:59:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 22:00:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 22:01:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 22:02:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 22:03:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 22:04:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 22:05:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 22:06:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 22:07:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 22:08:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 22:09:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 22:10:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 22:11:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 22:12:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 22:13:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 22:14:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 22:15:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 22:16:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 22:17:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 22:18:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 22:19:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 22:20:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 22:21:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 22:22:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 22:23:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 22:24:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 22:25:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 22:26:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 22:27:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 22:28:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 22:29:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 22:30:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 22:31:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 22:32:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 22:33:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 22:34:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 22:35:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 22:36:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 22:37:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 22:38:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 22:39:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 22:40:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 22:41:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 22:42:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 22:43:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 22:44:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 22:45:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 22:46:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 22:47:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 22:48:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 22:49:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 22:50:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 22:51:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 22:52:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 22:53:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 22:54:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 22:55:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 22:56:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 22:57:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 22:58:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 22:59:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 23:00:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 23:01:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 23:02:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 23:03:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 23:04:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 23:05:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 23:06:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 23:07:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 23:08:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 23:09:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 23:10:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 23:11:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 23:12:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 23:13:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 23:14:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 23:15:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 23:16:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 23:17:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 23:18:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 23:19:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 23:20:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 23:21:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 23:22:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 23:23:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 23:24:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 23:25:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 23:26:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 23:27:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 23:28:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 23:29:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 23:30:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 23:31:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 23:32:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 23:33:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 23:34:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 23:35:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 23:36:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 23:37:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 23:38:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 23:39:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 23:40:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 23:41:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 23:42:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 23:43:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 23:44:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 23:45:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 23:46:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 23:47:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 23:48:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 23:49:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 23:50:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 23:51:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 23:52:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 23:53:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 23:54:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 23:55:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 23:56:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 23:57:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 23:58:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-02 23:59:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 00:00:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 00:01:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 00:02:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 00:03:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 00:04:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 00:05:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 00:06:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 00:07:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 00:08:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 00:09:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 00:10:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 00:11:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 00:12:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 00:13:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 00:14:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 00:15:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 00:16:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 00:17:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 00:18:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 00:19:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 00:20:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 00:21:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 00:22:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 00:23:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 00:24:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 00:25:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 00:26:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 00:27:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 00:28:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 00:29:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 00:30:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 00:31:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 00:32:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 00:33:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 00:34:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 00:35:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 00:36:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 00:37:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 00:38:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 00:39:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 00:40:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 00:41:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 00:42:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 00:43:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 00:44:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 00:45:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 00:46:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 00:47:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 00:48:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 00:49:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 00:50:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 00:51:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 00:52:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 00:53:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 00:54:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 00:55:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 00:56:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 00:57:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 00:58:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 00:59:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 01:00:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 01:01:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 01:02:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 01:03:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 01:04:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 01:05:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 01:06:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 01:07:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 01:08:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 01:09:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 01:10:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 01:11:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 01:12:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 01:13:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 01:14:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 01:15:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 01:16:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 01:17:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 01:18:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 01:19:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 01:20:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 01:21:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 01:22:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 01:23:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 01:24:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 01:25:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 01:26:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 01:27:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 01:28:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 01:29:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 01:30:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 01:31:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 01:32:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 01:33:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 01:34:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 01:35:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 01:36:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 01:37:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 01:38:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 01:39:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 01:40:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 01:41:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 01:42:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 01:43:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 01:44:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 01:45:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 01:46:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 01:47:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 01:48:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 01:49:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 01:50:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 01:51:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 01:52:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 01:53:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 01:54:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 01:55:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 01:56:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 01:57:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 01:58:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 01:59:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 02:00:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 02:01:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 02:02:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 02:03:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 02:04:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 02:05:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 02:06:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 02:07:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 02:08:19 [scrapy.extensions.logstats] INFO: Crawled 1218 pages (at 0 pages/min), scraped 687 items (at 0 items/min)
2020-05-03 02:08:59 [rrmj] DEBUG: Read 1 requests from 'rrmj:spider:strat_urls'
2020-05-03 02:08:59 [scrapy.core.engine] DEBUG: Crawled (200) <POST https://api.rr.tv/v3plus/index/channel> (referer: None)
2020-05-03 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1912',
 'sectionImg': '',
 'sectionName': '看剧鉴渣男手撕不心软'}
2020-05-03 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1917',
 'sectionImg': '',
 'sectionName': '抖音爆火洗脑剧'}
2020-05-03 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1904',
 'sectionImg': '',
 'sectionName': '台剧新来袭！！'}
2020-05-03 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1244',
 'sectionImg': '',
 'sectionName': '致我们甜甜的恋爱时光'}
2020-05-03 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_822',
 'sectionImg': '',
 'sectionName': '细思极恐 谁是凶手？'}
2020-05-03 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1926',
 'sectionImg': '',
 'sectionName': '力推！豆瓣高分推荐'}
2020-05-03 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1927',
 'sectionImg': '',
 'sectionName': '深夜舔屏福利'}
2020-05-03 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1646',
 'sectionImg': '',
 'sectionName': '急诊室的人间冷暖'}
2020-05-03 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1903',
 'sectionImg': '',
 'sectionName': '恶魔在人间'}
2020-05-03 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1693',
 'sectionImg': '',
 'sectionName': '病毒藏在每个角落'}
2020-05-03 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_742',
 'sectionImg': '',
 'sectionName': '热剧回归！'}
2020-05-03 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_989',
 'sectionImg': '',
 'sectionName': '腐眼看人基'}
2020-05-03 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1883',
 'sectionImg': '',
 'sectionName': '吃货必备！这些纪录片很“下饭”'}
2020-05-03 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1399',
 'sectionImg': '',
 'sectionName': '他改变了世界'}
2020-05-03 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1729',
 'sectionImg': '',
 'sectionName': '【电影】获奖佳片集结'}
2020-05-03 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1405',
 'sectionImg': '',
 'sectionName': '幕后更精彩'}
2020-05-03 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_745',
 'sectionImg': '',
 'sectionName': '本周新剧'}
2020-05-03 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1431',
 'sectionImg': '',
 'sectionName': 'LGBT人生纪实 '}
2020-05-03 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1416',
 'sectionImg': '',
 'sectionName': '怪奇世界物语'}
2020-05-03 02:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1421',
 'sectionImg': '',
 'sectionName': '笑到飞起的脱口秀'}
2020-05-03 02:09:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1295',
 'sectionImg': '',
 'sectionName': '巨星的诞生'}
2020-05-03 02:09:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1425',
 'sectionImg': '',
 'sectionName': '大家都在看'}
2020-05-03 02:09:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1657',
 'sectionImg': '',
 'sectionName': '奥斯卡最佳纪录片'}
2020-05-03 02:09:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1005',
 'sectionImg': '',
 'sectionName': '德国之声特辑'}
2020-05-03 02:09:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_747',
 'sectionImg': '',
 'sectionName': '完结力推'}
2020-05-03 02:09:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 1 pages/min), scraped 712 items (at 25 items/min)
2020-05-03 02:10:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 02:11:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 02:12:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 02:13:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 02:14:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 02:15:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 02:16:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 02:17:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 02:18:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 02:19:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 02:20:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 02:21:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 02:22:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 02:23:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 02:24:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 02:25:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 02:26:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 02:27:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 02:28:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 02:29:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 02:30:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 02:31:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 02:32:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 02:33:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 02:34:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 02:35:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 02:36:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 02:37:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 02:38:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 02:39:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 02:40:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 02:41:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 02:42:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 02:43:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 02:44:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 02:45:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 02:46:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 02:47:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 02:48:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 02:49:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 02:50:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 02:51:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 02:52:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 02:53:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 02:54:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 02:55:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 02:56:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 02:57:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 02:58:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 02:59:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 03:00:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 03:01:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 03:02:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 03:03:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 03:04:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 03:05:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 03:06:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 03:07:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 03:08:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 03:09:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 03:10:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 03:11:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 03:12:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 03:13:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 03:14:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 03:15:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 03:16:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 03:17:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 03:18:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 03:19:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 03:20:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 03:21:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 03:22:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 03:23:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 03:24:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 03:25:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 03:26:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 03:27:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 03:28:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 03:29:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 03:30:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 03:31:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 03:32:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 03:33:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 03:34:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 03:35:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 03:36:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 03:37:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 03:38:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 03:39:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 03:40:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 03:41:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 03:42:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 03:43:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 03:44:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 03:45:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 03:46:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 03:47:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 03:48:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 03:49:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 03:50:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 03:51:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 03:52:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 03:53:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 03:54:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 03:55:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 03:56:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 03:57:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 03:58:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 03:59:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 04:00:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 04:01:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 04:02:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 04:03:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 04:04:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 04:05:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 04:06:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 04:07:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 04:08:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 04:09:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 04:10:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 04:11:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 04:12:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 04:13:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 04:14:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 04:15:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 04:16:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 04:17:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 04:18:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 04:19:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 04:20:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 04:21:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 04:22:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 04:23:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 04:24:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 04:25:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 04:26:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 04:27:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 04:28:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 04:29:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 04:30:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 04:31:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 04:32:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 04:33:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 04:34:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 04:35:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 04:36:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 04:37:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 04:38:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 04:39:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 04:40:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 04:41:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 04:42:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 04:43:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 04:44:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 04:45:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 04:46:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 04:47:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 04:48:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 04:49:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 04:50:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 04:51:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 04:52:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 04:53:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 04:54:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 04:55:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 04:56:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 04:57:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 04:58:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 04:59:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 05:00:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 05:01:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 05:02:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 05:03:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 05:04:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 05:05:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 05:06:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 05:07:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 05:08:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 05:09:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 05:10:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 05:11:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 05:12:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 05:13:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 05:14:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 05:15:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 05:16:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 05:17:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 05:18:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 05:19:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 05:20:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 05:21:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 05:22:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 05:23:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 05:24:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 05:25:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 05:26:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 05:27:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 05:28:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 05:29:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 05:30:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 05:31:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 05:32:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 05:33:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 05:34:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 05:35:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 05:36:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 05:37:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 05:38:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 05:39:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 05:40:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 05:41:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 05:42:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 05:43:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 05:44:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 05:45:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 05:46:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 05:47:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 05:48:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 05:49:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 05:50:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 05:51:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 05:52:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 05:53:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 05:54:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 05:55:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 05:56:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 05:57:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 05:58:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 05:59:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 06:00:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 06:01:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 06:02:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 06:03:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 06:04:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 06:05:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 06:06:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 06:07:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 06:08:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 06:09:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 06:10:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 06:11:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 06:12:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 06:13:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 06:14:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 06:15:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 06:16:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 06:17:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 06:18:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 06:19:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 06:20:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 06:21:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 06:22:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 06:23:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 06:24:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 06:25:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 06:26:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 06:27:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 06:28:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 06:29:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 06:30:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 06:31:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 06:32:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 06:33:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 06:34:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 06:35:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 06:36:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 06:37:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 06:38:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 06:39:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 06:40:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 06:41:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 06:42:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 06:43:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 06:44:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 06:45:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 06:46:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 06:47:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 06:48:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 06:49:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 06:50:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 06:51:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 06:52:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 06:53:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 06:54:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 06:55:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 06:56:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 06:57:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 06:58:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 06:59:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 07:00:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 07:01:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 07:02:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 07:03:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 07:04:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 07:05:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 07:06:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 07:07:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 07:08:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 07:09:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 07:10:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 07:11:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 07:12:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 07:13:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 07:14:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 07:15:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 07:16:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 07:17:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 07:18:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 07:19:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 07:20:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 07:21:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 07:22:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 07:23:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 07:24:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 07:25:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 07:26:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 07:27:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 07:28:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 07:29:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 07:30:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 07:31:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 07:32:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 07:33:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 07:34:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 07:35:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 07:36:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 07:37:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 07:38:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 07:39:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 07:40:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 07:41:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 07:42:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 07:43:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 07:44:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 07:45:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 07:46:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 07:47:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 07:48:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 07:49:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 07:50:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 07:51:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 07:52:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 07:53:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 07:54:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 07:55:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 07:56:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 07:57:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 07:58:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 07:59:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 08:00:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 08:01:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 08:02:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 08:03:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 08:04:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 08:05:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 08:06:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 08:07:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 08:08:19 [scrapy.extensions.logstats] INFO: Crawled 1219 pages (at 0 pages/min), scraped 712 items (at 0 items/min)
2020-05-03 08:08:59 [rrmj] DEBUG: Read 1 requests from 'rrmj:spider:strat_urls'
2020-05-03 08:08:59 [scrapy.core.engine] DEBUG: Crawled (200) <POST https://api.rr.tv/v3plus/index/channel> (referer: None)
2020-05-03 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1912',
 'sectionImg': '',
 'sectionName': '看剧鉴渣男手撕不心软'}
2020-05-03 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1917',
 'sectionImg': '',
 'sectionName': '抖音爆火洗脑剧'}
2020-05-03 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1904',
 'sectionImg': '',
 'sectionName': '台剧新来袭！！'}
2020-05-03 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1244',
 'sectionImg': '',
 'sectionName': '致我们甜甜的恋爱时光'}
2020-05-03 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_822',
 'sectionImg': '',
 'sectionName': '细思极恐 谁是凶手？'}
2020-05-03 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1926',
 'sectionImg': '',
 'sectionName': '力推！豆瓣高分推荐'}
2020-05-03 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1927',
 'sectionImg': '',
 'sectionName': '深夜舔屏福利'}
2020-05-03 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1646',
 'sectionImg': '',
 'sectionName': '急诊室的人间冷暖'}
2020-05-03 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1903',
 'sectionImg': '',
 'sectionName': '恶魔在人间'}
2020-05-03 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1693',
 'sectionImg': '',
 'sectionName': '病毒藏在每个角落'}
2020-05-03 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_742',
 'sectionImg': '',
 'sectionName': '热剧回归！'}
2020-05-03 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_989',
 'sectionImg': '',
 'sectionName': '腐眼看人基'}
2020-05-03 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1883',
 'sectionImg': '',
 'sectionName': '吃货必备！这些纪录片很“下饭”'}
2020-05-03 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1399',
 'sectionImg': '',
 'sectionName': '他改变了世界'}
2020-05-03 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1729',
 'sectionImg': '',
 'sectionName': '【电影】获奖佳片集结'}
2020-05-03 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1405',
 'sectionImg': '',
 'sectionName': '幕后更精彩'}
2020-05-03 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_745',
 'sectionImg': '',
 'sectionName': '本周新剧'}
2020-05-03 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1431',
 'sectionImg': '',
 'sectionName': 'LGBT人生纪实 '}
2020-05-03 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1416',
 'sectionImg': '',
 'sectionName': '怪奇世界物语'}
2020-05-03 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1421',
 'sectionImg': '',
 'sectionName': '笑到飞起的脱口秀'}
2020-05-03 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1295',
 'sectionImg': '',
 'sectionName': '巨星的诞生'}
2020-05-03 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1425',
 'sectionImg': '',
 'sectionName': '大家都在看'}
2020-05-03 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1657',
 'sectionImg': '',
 'sectionName': '奥斯卡最佳纪录片'}
2020-05-03 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1005',
 'sectionImg': '',
 'sectionName': '德国之声特辑'}
2020-05-03 08:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_747',
 'sectionImg': '',
 'sectionName': '完结力推'}
2020-05-03 08:09:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 1 pages/min), scraped 737 items (at 25 items/min)
2020-05-03 08:10:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 08:11:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 08:12:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 08:13:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 08:14:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 08:15:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 08:16:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 08:17:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 08:18:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 08:19:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 08:20:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 08:21:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 08:22:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 08:23:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 08:24:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 08:25:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 08:26:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 08:27:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 08:28:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 08:29:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 08:30:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 08:31:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 08:32:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 08:33:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 08:34:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 08:35:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 08:36:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 08:37:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 08:38:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 08:39:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 08:40:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 08:41:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 08:42:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 08:43:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 08:44:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 08:45:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 08:46:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 08:47:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 08:48:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 08:49:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 08:50:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 08:51:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 08:52:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 08:53:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 08:54:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 08:55:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 08:56:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 08:57:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 08:58:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 08:59:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 09:00:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 09:01:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 09:02:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 09:03:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 09:04:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 09:05:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 09:06:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 09:07:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 09:08:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 09:09:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 09:10:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 09:11:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 09:12:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 09:13:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 09:14:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 09:15:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 09:16:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 09:17:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 09:18:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 09:19:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 09:20:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 09:21:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 09:22:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 09:23:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 09:24:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 09:25:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 09:26:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 09:27:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 09:28:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 09:29:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 09:30:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 09:31:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 09:32:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 09:33:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 09:34:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 09:35:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 09:36:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 09:37:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 09:38:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 09:39:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 09:40:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 09:41:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 09:42:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 09:43:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 09:44:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 09:45:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 09:46:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 09:47:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 09:48:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 09:49:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 09:50:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 09:51:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 09:52:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 09:53:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 09:54:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 09:55:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 09:56:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 09:57:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 09:58:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 09:59:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 10:00:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 10:01:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 10:02:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 10:03:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 10:04:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 10:05:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 10:06:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 10:07:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 10:08:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 10:09:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 10:10:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 10:11:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 10:12:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 10:13:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 10:14:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 10:15:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 10:16:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 10:17:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 10:18:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 10:19:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 10:20:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 10:21:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 10:22:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 10:23:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 10:24:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 10:25:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 10:26:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 10:27:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 10:28:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 10:29:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 10:30:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 10:31:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 10:32:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 10:33:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 10:34:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 10:35:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 10:36:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 10:37:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 10:38:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 10:39:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 10:40:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 10:41:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 10:42:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 10:43:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 10:44:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 10:45:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 10:46:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 10:47:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 10:48:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 10:49:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 10:50:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 10:51:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 10:52:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 10:53:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 10:54:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 10:55:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 10:56:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 10:57:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 10:58:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 10:59:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 11:00:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 11:01:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 11:02:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 11:03:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 11:04:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 11:05:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 11:06:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 11:07:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 11:08:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 11:09:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 11:10:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 11:11:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 11:12:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 11:13:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 11:14:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 11:15:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 11:16:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 11:17:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 11:18:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 11:19:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 11:20:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 11:21:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 11:22:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 11:23:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 11:24:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 11:25:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 11:26:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 11:27:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 11:28:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 11:29:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 11:30:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 11:31:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 11:32:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 11:33:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 11:34:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 11:35:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 11:36:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 11:37:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 11:38:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 11:39:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 11:40:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 11:41:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 11:42:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 11:43:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 11:44:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 11:45:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 11:46:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 11:47:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 11:48:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 11:49:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 11:50:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 11:51:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 11:52:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 11:53:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 11:54:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 11:55:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 11:56:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 11:57:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 11:58:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 11:59:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 12:00:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 12:01:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 12:02:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 12:03:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 12:04:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 12:05:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 12:06:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 12:07:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 12:08:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 12:09:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 12:10:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 12:11:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 12:12:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 12:13:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 12:14:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 12:15:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 12:16:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 12:17:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 12:18:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 12:19:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 12:20:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 12:21:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 12:22:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 12:23:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 12:24:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 12:25:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 12:26:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 12:27:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 12:28:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 12:29:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 12:30:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 12:31:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 12:32:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 12:33:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 12:34:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 12:35:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 12:36:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 12:37:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 12:38:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 12:39:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 12:40:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 12:41:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 12:42:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 12:43:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 12:44:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 12:45:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 12:46:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 12:47:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 12:48:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 12:49:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 12:50:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 12:51:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 12:52:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 12:53:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 12:54:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 12:55:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 12:56:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 12:57:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 12:58:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 12:59:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 13:00:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 13:01:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 13:02:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 13:03:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 13:04:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 13:05:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 13:06:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 13:07:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 13:08:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 13:09:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 13:10:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 13:11:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 13:12:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 13:13:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 13:14:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 13:15:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 13:16:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 13:17:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 13:18:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 13:19:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 13:20:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 13:21:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 13:22:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 13:23:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 13:24:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 13:25:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 13:26:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 13:27:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 13:28:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 13:29:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 13:30:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 13:31:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 13:32:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 13:33:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 13:34:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 13:35:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 13:36:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 13:37:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 13:38:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 13:39:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 13:40:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 13:41:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 13:42:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 13:43:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 13:44:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 13:45:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 13:46:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 13:47:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 13:48:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 13:49:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 13:50:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 13:51:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 13:52:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 13:53:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 13:54:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 13:55:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 13:56:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 13:57:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 13:58:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 13:59:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 14:00:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 14:01:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 14:02:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 14:03:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 14:04:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 14:05:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 14:06:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 14:07:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 14:08:19 [scrapy.extensions.logstats] INFO: Crawled 1220 pages (at 0 pages/min), scraped 737 items (at 0 items/min)
2020-05-03 14:08:59 [rrmj] DEBUG: Read 1 requests from 'rrmj:spider:strat_urls'
2020-05-03 14:08:59 [scrapy.core.engine] DEBUG: Crawled (200) <POST https://api.rr.tv/v3plus/index/channel> (referer: None)
2020-05-03 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1912',
 'sectionImg': '',
 'sectionName': '看剧鉴渣男手撕不心软'}
2020-05-03 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1917',
 'sectionImg': '',
 'sectionName': '抖音爆火洗脑剧'}
2020-05-03 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1904',
 'sectionImg': '',
 'sectionName': '台剧新来袭！！'}
2020-05-03 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1244',
 'sectionImg': '',
 'sectionName': '致我们甜甜的恋爱时光'}
2020-05-03 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_822',
 'sectionImg': '',
 'sectionName': '细思极恐 谁是凶手？'}
2020-05-03 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1926',
 'sectionImg': '',
 'sectionName': '力推！豆瓣高分推荐'}
2020-05-03 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1927',
 'sectionImg': '',
 'sectionName': '深夜舔屏福利'}
2020-05-03 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1646',
 'sectionImg': '',
 'sectionName': '急诊室的人间冷暖'}
2020-05-03 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1903',
 'sectionImg': '',
 'sectionName': '恶魔在人间'}
2020-05-03 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1693',
 'sectionImg': '',
 'sectionName': '病毒藏在每个角落'}
2020-05-03 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_742',
 'sectionImg': '',
 'sectionName': '热剧回归！'}
2020-05-03 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_989',
 'sectionImg': '',
 'sectionName': '腐眼看人基'}
2020-05-03 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1883',
 'sectionImg': '',
 'sectionName': '吃货必备！这些纪录片很“下饭”'}
2020-05-03 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1399',
 'sectionImg': '',
 'sectionName': '他改变了世界'}
2020-05-03 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1729',
 'sectionImg': '',
 'sectionName': '【电影】获奖佳片集结'}
2020-05-03 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1405',
 'sectionImg': '',
 'sectionName': '幕后更精彩'}
2020-05-03 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_745',
 'sectionImg': '',
 'sectionName': '本周新剧'}
2020-05-03 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1431',
 'sectionImg': '',
 'sectionName': 'LGBT人生纪实 '}
2020-05-03 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1416',
 'sectionImg': '',
 'sectionName': '怪奇世界物语'}
2020-05-03 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1421',
 'sectionImg': '',
 'sectionName': '笑到飞起的脱口秀'}
2020-05-03 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1295',
 'sectionImg': '',
 'sectionName': '巨星的诞生'}
2020-05-03 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1425',
 'sectionImg': '',
 'sectionName': '大家都在看'}
2020-05-03 14:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1657',
 'sectionImg': '',
 'sectionName': '奥斯卡最佳纪录片'}
2020-05-03 14:09:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1005',
 'sectionImg': '',
 'sectionName': '德国之声特辑'}
2020-05-03 14:09:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_747',
 'sectionImg': '',
 'sectionName': '完结力推'}
2020-05-03 14:09:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 1 pages/min), scraped 762 items (at 25 items/min)
2020-05-03 14:10:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 14:11:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 14:12:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 14:13:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 14:14:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 14:15:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 14:16:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 14:17:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 14:18:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 14:19:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 14:20:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 14:21:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 14:22:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 14:23:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 14:24:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 14:25:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 14:26:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 14:27:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 14:28:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 14:29:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 14:30:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 14:31:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 14:32:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 14:33:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 14:34:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 14:35:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 14:36:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 14:37:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 14:38:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 14:39:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 14:40:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 14:41:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 14:42:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 14:43:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 14:44:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 14:45:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 14:46:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 14:47:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 14:48:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 14:49:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 14:50:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 14:51:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 14:52:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 14:53:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 14:54:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 14:55:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 14:56:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 14:57:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 14:58:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 14:59:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 15:00:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 15:01:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 15:02:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 15:03:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 15:04:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 15:05:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 15:06:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 15:07:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 15:08:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 15:09:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 15:10:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 15:11:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 15:12:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 15:13:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 15:14:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 15:15:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 15:16:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 15:17:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 15:18:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 15:19:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 15:20:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 15:21:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 15:22:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 15:23:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 15:24:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 15:25:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 15:26:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 15:27:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 15:28:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 15:29:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 15:30:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 15:31:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 15:32:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 15:33:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 15:34:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 15:35:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 15:36:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 15:37:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 15:38:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 15:39:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 15:40:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 15:41:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 15:42:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 15:43:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 15:44:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 15:45:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 15:46:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 15:47:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 15:48:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 15:49:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 15:50:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 15:51:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 15:52:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 15:53:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 15:54:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 15:55:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 15:56:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 15:57:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 15:58:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 15:59:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 16:00:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 16:01:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 16:02:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 16:03:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 16:04:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 16:05:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 16:06:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 16:07:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 16:08:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 16:09:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 16:10:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 16:11:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 16:12:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 16:13:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 16:14:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 16:15:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 16:16:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 16:17:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 16:18:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 16:19:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 16:20:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 16:21:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 16:22:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 16:23:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 16:24:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 16:25:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 16:26:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 16:27:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 16:28:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 16:29:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 16:30:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 16:31:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 16:32:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 16:33:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 16:34:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 16:35:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 16:36:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 16:37:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 16:38:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 16:39:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 16:40:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 16:41:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 16:42:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 16:43:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 16:44:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 16:45:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 16:46:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 16:47:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 16:48:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 16:49:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 16:50:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 16:51:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 16:52:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 16:53:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 16:54:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 16:55:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 16:56:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 16:57:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 16:58:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 16:59:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 17:00:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 17:01:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 17:02:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 17:03:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 17:04:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 17:05:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 17:06:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 17:07:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 17:08:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 17:09:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 17:10:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 17:11:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 17:12:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 17:13:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 17:14:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 17:15:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 17:16:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 17:17:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 17:18:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 17:19:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 17:20:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 17:21:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 17:22:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 17:23:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 17:24:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 17:25:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 17:26:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 17:27:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 17:28:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 17:29:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 17:30:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 17:31:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 17:32:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 17:33:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 17:34:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 17:35:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 17:36:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 17:37:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 17:38:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 17:39:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 17:40:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 17:41:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 17:42:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 17:43:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 17:44:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 17:45:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 17:46:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 17:47:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 17:48:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 17:49:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 17:50:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 17:51:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 17:52:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 17:53:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 17:54:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 17:55:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 17:56:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 17:57:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 17:58:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 17:59:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 18:00:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 18:01:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 18:02:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 18:03:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 18:04:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 18:05:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 18:06:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 18:07:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 18:08:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 18:09:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 18:10:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 18:11:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 18:12:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 18:13:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 18:14:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 18:15:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 18:16:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 18:17:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 18:18:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 18:19:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 18:20:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 18:21:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 18:22:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 18:23:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 18:24:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 18:25:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 18:26:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 18:27:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 18:28:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 18:29:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 18:30:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 18:31:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 18:32:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 18:33:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 18:34:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 18:35:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 18:36:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 18:37:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 18:38:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 18:39:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 18:40:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 18:41:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 18:42:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 18:43:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 18:44:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 18:45:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 18:46:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 18:47:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 18:48:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 18:49:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 18:50:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 18:51:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 18:52:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 18:53:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 18:54:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 18:55:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 18:56:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 18:57:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 18:58:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 18:59:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 19:00:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 19:01:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 19:02:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 19:03:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 19:04:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 19:05:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 19:06:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 19:07:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 19:08:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 19:09:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 19:10:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 19:11:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 19:12:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 19:13:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 19:14:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 19:15:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 19:16:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 19:17:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 19:18:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 19:19:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 19:20:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 19:21:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 19:22:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 19:23:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 19:24:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 19:25:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 19:26:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 19:27:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 19:28:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 19:29:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 19:30:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 19:31:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 19:32:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 19:33:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 19:34:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 19:35:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 19:36:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 19:37:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 19:38:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 19:39:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 19:40:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 19:41:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 19:42:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 19:43:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 19:44:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 19:45:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 19:46:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 19:47:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 19:48:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 19:49:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 19:50:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 19:51:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 19:52:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 19:53:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 19:54:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 19:55:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 19:56:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 19:57:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 19:58:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 19:59:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 20:00:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 20:01:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 20:02:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 20:03:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 20:04:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 20:05:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 20:06:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 20:07:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 20:08:19 [scrapy.extensions.logstats] INFO: Crawled 1221 pages (at 0 pages/min), scraped 762 items (at 0 items/min)
2020-05-03 20:08:59 [rrmj] DEBUG: Read 1 requests from 'rrmj:spider:strat_urls'
2020-05-03 20:08:59 [scrapy.core.engine] DEBUG: Crawled (200) <POST https://api.rr.tv/v3plus/index/channel> (referer: None)
2020-05-03 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1912',
 'sectionImg': '',
 'sectionName': '看剧鉴渣男手撕不心软'}
2020-05-03 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1917',
 'sectionImg': '',
 'sectionName': '抖音爆火洗脑剧'}
2020-05-03 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1904',
 'sectionImg': '',
 'sectionName': '台剧新来袭！！'}
2020-05-03 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1244',
 'sectionImg': '',
 'sectionName': '致我们甜甜的恋爱时光'}
2020-05-03 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_822',
 'sectionImg': '',
 'sectionName': '细思极恐 谁是凶手？'}
2020-05-03 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1926',
 'sectionImg': '',
 'sectionName': '力推！豆瓣高分推荐'}
2020-05-03 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1927',
 'sectionImg': '',
 'sectionName': '深夜舔屏福利'}
2020-05-03 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1646',
 'sectionImg': '',
 'sectionName': '急诊室的人间冷暖'}
2020-05-03 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1903',
 'sectionImg': '',
 'sectionName': '恶魔在人间'}
2020-05-03 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1693',
 'sectionImg': '',
 'sectionName': '病毒藏在每个角落'}
2020-05-03 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_742',
 'sectionImg': '',
 'sectionName': '热剧回归！'}
2020-05-03 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_989',
 'sectionImg': '',
 'sectionName': '腐眼看人基'}
2020-05-03 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1883',
 'sectionImg': '',
 'sectionName': '吃货必备！这些纪录片很“下饭”'}
2020-05-03 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1399',
 'sectionImg': '',
 'sectionName': '他改变了世界'}
2020-05-03 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1729',
 'sectionImg': '',
 'sectionName': '【电影】获奖佳片集结'}
2020-05-03 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1405',
 'sectionImg': '',
 'sectionName': '幕后更精彩'}
2020-05-03 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_745',
 'sectionImg': '',
 'sectionName': '本周新剧'}
2020-05-03 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1431',
 'sectionImg': '',
 'sectionName': 'LGBT人生纪实 '}
2020-05-03 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1416',
 'sectionImg': '',
 'sectionName': '怪奇世界物语'}
2020-05-03 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1421',
 'sectionImg': '',
 'sectionName': '笑到飞起的脱口秀'}
2020-05-03 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1295',
 'sectionImg': '',
 'sectionName': '巨星的诞生'}
2020-05-03 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1425',
 'sectionImg': '',
 'sectionName': '大家都在看'}
2020-05-03 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1657',
 'sectionImg': '',
 'sectionName': '奥斯卡最佳纪录片'}
2020-05-03 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1005',
 'sectionImg': '',
 'sectionName': '德国之声特辑'}
2020-05-03 20:08:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_747',
 'sectionImg': '',
 'sectionName': '完结力推'}
2020-05-03 20:09:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 1 pages/min), scraped 787 items (at 25 items/min)
2020-05-03 20:10:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 20:11:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 20:12:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 20:13:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 20:14:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 20:15:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 20:16:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 20:17:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 20:18:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 20:19:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 20:20:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 20:21:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 20:22:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 20:23:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 20:24:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 20:25:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 20:26:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 20:27:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 20:28:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 20:29:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 20:30:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 20:31:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 20:32:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 20:33:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 20:34:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 20:35:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 20:36:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 20:37:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 20:38:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 20:39:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 20:40:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 20:41:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 20:42:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 20:43:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 20:44:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 20:45:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 20:46:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 20:47:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 20:48:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 20:49:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 20:50:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 20:51:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 20:52:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 20:53:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 20:54:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 20:55:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 20:56:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 20:57:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 20:58:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 20:59:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 21:00:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 21:01:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 21:02:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 21:03:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 21:04:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 21:05:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 21:06:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 21:07:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 21:08:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 21:09:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 21:10:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 21:11:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 21:12:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 21:13:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 21:14:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 21:15:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 21:16:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 21:17:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 21:18:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 21:19:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 21:20:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 21:21:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 21:22:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 21:23:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 21:24:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 21:25:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 21:26:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 21:27:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 21:28:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 21:29:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 21:30:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 21:31:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 21:32:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 21:33:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 21:34:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 21:35:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 21:36:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 21:37:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 21:38:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 21:39:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 21:40:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 21:41:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 21:42:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 21:43:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 21:44:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 21:45:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 21:46:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 21:47:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 21:48:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 21:49:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 21:50:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 21:51:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 21:52:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 21:53:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 21:54:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 21:55:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 21:56:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 21:57:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 21:58:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 21:59:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 22:00:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 22:01:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 22:02:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 22:03:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 22:04:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 22:05:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 22:06:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 22:07:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 22:08:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 22:09:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 22:10:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 22:11:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 22:12:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 22:13:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 22:14:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 22:15:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 22:16:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 22:17:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 22:18:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 22:19:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 22:20:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 22:21:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 22:22:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 22:23:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 22:24:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 22:25:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 22:26:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 22:27:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 22:28:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 22:29:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 22:30:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 22:31:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 22:32:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 22:33:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 22:34:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 22:35:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 22:36:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 22:37:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 22:38:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 22:39:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 22:40:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 22:41:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 22:42:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 22:43:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 22:44:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 22:45:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 22:46:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 22:47:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 22:48:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 22:49:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 22:50:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 22:51:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 22:52:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 22:53:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 22:54:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 22:55:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 22:56:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 22:57:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 22:58:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 22:59:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 23:00:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 23:01:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 23:02:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 23:03:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 23:04:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 23:05:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 23:06:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 23:07:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 23:08:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 23:09:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 23:10:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 23:11:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 23:12:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 23:13:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 23:14:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 23:15:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 23:16:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 23:17:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 23:18:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 23:19:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 23:20:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 23:21:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 23:22:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 23:23:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 23:24:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 23:25:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 23:26:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 23:27:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 23:28:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 23:29:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 23:30:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 23:31:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 23:32:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 23:33:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 23:34:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 23:35:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 23:36:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 23:37:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 23:38:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 23:39:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 23:40:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 23:41:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 23:42:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 23:43:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 23:44:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 23:45:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 23:46:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 23:47:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 23:48:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 23:49:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 23:50:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 23:51:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 23:52:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 23:53:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 23:54:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 23:55:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 23:56:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 23:57:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 23:58:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-03 23:59:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 00:00:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 00:01:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 00:02:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 00:03:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 00:04:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 00:05:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 00:06:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 00:07:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 00:08:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 00:09:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 00:10:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 00:11:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 00:12:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 00:13:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 00:14:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 00:15:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 00:16:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 00:17:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 00:18:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 00:19:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 00:20:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 00:21:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 00:22:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 00:23:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 00:24:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 00:25:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 00:26:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 00:27:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 00:28:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 00:29:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 00:30:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 00:31:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 00:32:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 00:33:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 00:34:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 00:35:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 00:36:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 00:37:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 00:38:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 00:39:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 00:40:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 00:41:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 00:42:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 00:43:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 00:44:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 00:45:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 00:46:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 00:47:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 00:48:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 00:49:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 00:50:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 00:51:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 00:52:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 00:53:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 00:54:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 00:55:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 00:56:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 00:57:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 00:58:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 00:59:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 01:00:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 01:01:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 01:02:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 01:03:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 01:04:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 01:05:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 01:06:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 01:07:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 01:08:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 01:09:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 01:10:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 01:11:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 01:12:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 01:13:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 01:14:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 01:15:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 01:16:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 01:17:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 01:18:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 01:19:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 01:20:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 01:21:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 01:22:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 01:23:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 01:24:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 01:25:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 01:26:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 01:27:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 01:28:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 01:29:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 01:30:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 01:31:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 01:32:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 01:33:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 01:34:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 01:35:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 01:36:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 01:37:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 01:38:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 01:39:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 01:40:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 01:41:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 01:42:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 01:43:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 01:44:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 01:45:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 01:46:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 01:47:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 01:48:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 01:49:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 01:50:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 01:51:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 01:52:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 01:53:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 01:54:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 01:55:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 01:56:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 01:57:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 01:58:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 01:59:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 02:00:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 02:01:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 02:02:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 02:03:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 02:04:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 02:05:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 02:06:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 02:07:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 02:08:19 [scrapy.extensions.logstats] INFO: Crawled 1222 pages (at 0 pages/min), scraped 787 items (at 0 items/min)
2020-05-04 02:09:04 [rrmj] DEBUG: Read 1 requests from 'rrmj:spider:strat_urls'
2020-05-04 02:09:04 [scrapy.core.engine] DEBUG: Crawled (200) <POST https://api.rr.tv/v3plus/index/channel> (referer: None)
2020-05-04 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1912',
 'sectionImg': '',
 'sectionName': '看剧鉴渣男手撕不心软'}
2020-05-04 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1917',
 'sectionImg': '',
 'sectionName': '抖音爆火洗脑剧'}
2020-05-04 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1904',
 'sectionImg': '',
 'sectionName': '台剧新来袭！！'}
2020-05-04 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1244',
 'sectionImg': '',
 'sectionName': '致我们甜甜的恋爱时光'}
2020-05-04 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_822',
 'sectionImg': '',
 'sectionName': '细思极恐 谁是凶手？'}
2020-05-04 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1926',
 'sectionImg': '',
 'sectionName': '力推！豆瓣高分推荐'}
2020-05-04 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1927',
 'sectionImg': '',
 'sectionName': '深夜舔屏福利'}
2020-05-04 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1646',
 'sectionImg': '',
 'sectionName': '急诊室的人间冷暖'}
2020-05-04 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1903',
 'sectionImg': '',
 'sectionName': '恶魔在人间'}
2020-05-04 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1693',
 'sectionImg': '',
 'sectionName': '病毒藏在每个角落'}
2020-05-04 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_742',
 'sectionImg': '',
 'sectionName': '热剧回归！'}
2020-05-04 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_989',
 'sectionImg': '',
 'sectionName': '腐眼看人基'}
2020-05-04 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1883',
 'sectionImg': '',
 'sectionName': '吃货必备！这些纪录片很“下饭”'}
2020-05-04 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1399',
 'sectionImg': '',
 'sectionName': '他改变了世界'}
2020-05-04 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1729',
 'sectionImg': '',
 'sectionName': '【电影】获奖佳片集结'}
2020-05-04 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1405',
 'sectionImg': '',
 'sectionName': '幕后更精彩'}
2020-05-04 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_745',
 'sectionImg': '',
 'sectionName': '本周新剧'}
2020-05-04 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1431',
 'sectionImg': '',
 'sectionName': 'LGBT人生纪实 '}
2020-05-04 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1416',
 'sectionImg': '',
 'sectionName': '怪奇世界物语'}
2020-05-04 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1421',
 'sectionImg': '',
 'sectionName': '笑到飞起的脱口秀'}
2020-05-04 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1295',
 'sectionImg': '',
 'sectionName': '巨星的诞生'}
2020-05-04 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1425',
 'sectionImg': '',
 'sectionName': '大家都在看'}
2020-05-04 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1657',
 'sectionImg': '',
 'sectionName': '奥斯卡最佳纪录片'}
2020-05-04 02:09:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1005',
 'sectionImg': '',
 'sectionName': '德国之声特辑'}
2020-05-04 02:09:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_747',
 'sectionImg': '',
 'sectionName': '完结力推'}
2020-05-04 02:09:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 1 pages/min), scraped 812 items (at 25 items/min)
2020-05-04 02:10:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 02:11:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 02:12:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 02:13:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 02:14:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 02:15:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 02:16:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 02:17:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 02:18:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 02:19:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 02:20:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 02:21:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 02:22:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 02:23:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 02:24:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 02:25:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 02:26:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 02:27:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 02:28:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 02:29:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 02:30:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 02:31:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 02:32:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 02:33:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 02:34:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 02:35:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 02:36:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 02:37:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 02:38:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 02:39:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 02:40:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 02:41:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 02:42:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 02:43:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 02:44:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 02:45:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 02:46:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 02:47:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 02:48:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 02:49:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 02:50:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 02:51:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 02:52:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 02:53:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 02:54:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 02:55:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 02:56:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 02:57:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 02:58:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 02:59:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 03:00:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 03:01:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 03:02:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 03:03:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 03:04:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 03:05:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 03:06:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 03:07:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 03:08:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 03:09:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 03:10:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 03:11:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 03:12:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 03:13:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 03:14:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 03:15:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 03:16:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 03:17:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 03:18:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 03:19:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 03:20:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 03:21:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 03:22:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 03:23:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 03:24:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 03:25:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 03:26:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 03:27:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 03:28:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 03:29:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 03:30:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 03:31:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 03:32:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 03:33:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 03:34:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 03:35:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 03:36:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 03:37:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 03:38:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 03:39:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 03:40:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 03:41:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 03:42:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 03:43:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 03:44:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 03:45:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 03:46:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 03:47:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 03:48:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 03:49:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 03:50:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 03:51:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 03:52:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 03:53:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 03:54:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 03:55:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 03:56:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 03:57:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 03:58:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 03:59:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 04:00:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 04:01:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 04:02:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 04:03:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 04:04:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 04:05:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 04:06:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 04:07:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 04:08:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 04:09:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 04:10:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 04:11:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 04:12:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 04:13:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 04:14:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 04:15:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 04:16:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 04:17:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 04:18:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 04:19:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 04:20:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 04:21:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 04:22:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 04:23:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 04:24:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 04:25:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 04:26:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 04:27:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 04:28:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 04:29:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 04:30:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 04:31:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 04:32:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 04:33:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 04:34:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 04:35:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 04:36:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 04:37:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 04:38:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 04:39:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 04:40:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 04:41:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 04:42:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 04:43:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 04:44:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 04:45:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 04:46:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 04:47:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 04:48:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 04:49:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 04:50:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 04:51:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 04:52:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 04:53:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 04:54:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 04:55:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 04:56:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 04:57:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 04:58:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 04:59:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 05:00:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 05:01:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 05:02:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 05:03:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 05:04:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 05:05:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 05:06:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 05:07:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 05:08:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 05:09:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 05:10:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 05:11:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 05:12:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 05:13:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 05:14:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 05:15:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 05:16:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 05:17:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 05:18:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 05:19:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 05:20:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 05:21:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 05:22:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 05:23:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 05:24:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 05:25:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 05:26:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 05:27:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 05:28:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 05:29:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 05:30:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 05:31:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 05:32:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 05:33:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 05:34:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 05:35:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 05:36:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 05:37:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 05:38:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 05:39:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 05:40:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 05:41:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 05:42:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 05:43:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 05:44:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 05:45:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 05:46:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 05:47:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 05:48:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 05:49:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 05:50:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 05:51:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 05:52:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 05:53:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 05:54:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 05:55:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 05:56:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 05:57:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 05:58:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 05:59:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 06:00:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 06:01:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 06:02:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 06:03:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 06:04:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 06:05:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 06:06:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 06:07:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 06:08:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 06:09:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 06:10:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 06:11:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 06:12:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 06:13:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 06:14:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 06:15:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 06:16:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 06:17:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 06:18:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 06:19:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 06:20:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 06:21:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 06:22:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 06:23:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 06:24:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 06:25:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 06:26:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 06:27:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 06:28:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 06:29:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 06:30:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 06:31:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 06:32:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 06:33:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 06:34:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 06:35:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 06:36:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 06:37:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 06:38:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 06:39:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 06:40:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 06:41:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 06:42:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 06:43:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 06:44:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 06:45:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 06:46:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 06:47:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 06:48:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 06:49:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 06:50:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 06:51:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 06:52:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 06:53:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 06:54:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 06:55:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 06:56:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 06:57:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 06:58:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 06:59:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 07:00:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 07:01:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 07:02:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 07:03:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 07:04:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 07:05:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 07:06:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 07:07:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 07:08:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 07:09:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 07:10:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 07:11:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 07:12:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 07:13:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 07:14:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 07:15:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 07:16:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 07:17:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 07:18:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 07:19:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 07:20:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 07:21:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 07:22:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 07:23:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 07:24:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 07:25:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 07:26:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 07:27:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 07:28:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 07:29:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 07:30:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 07:31:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 07:32:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 07:33:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 07:34:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 07:35:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 07:36:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 07:37:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 07:38:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 07:39:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 07:40:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 07:41:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 07:42:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 07:43:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 07:44:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 07:45:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 07:46:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 07:47:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 07:48:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 07:49:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 07:50:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 07:51:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 07:52:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 07:53:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 07:54:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 07:55:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 07:56:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 07:57:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 07:58:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 07:59:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 08:00:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 08:01:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 08:02:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 08:03:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 08:04:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 08:05:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 08:06:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 08:07:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 08:08:19 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 0 pages/min), scraped 812 items (at 0 items/min)
2020-05-04 08:09:04 [rrmj] DEBUG: Read 1 requests from 'rrmj:spider:strat_urls'
2020-05-04 08:09:04 [scrapy.core.engine] DEBUG: Crawled (200) <POST https://api.rr.tv/v3plus/index/channel> (referer: None)
2020-05-04 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1912',
 'sectionImg': '',
 'sectionName': '看剧鉴渣男手撕不心软'}
2020-05-04 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1917',
 'sectionImg': '',
 'sectionName': '抖音爆火洗脑剧'}
2020-05-04 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1904',
 'sectionImg': '',
 'sectionName': '台剧新来袭！！'}
2020-05-04 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1244',
 'sectionImg': '',
 'sectionName': '致我们甜甜的恋爱时光'}
2020-05-04 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_822',
 'sectionImg': '',
 'sectionName': '细思极恐 谁是凶手？'}
2020-05-04 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1926',
 'sectionImg': '',
 'sectionName': '力推！豆瓣高分推荐'}
2020-05-04 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1927',
 'sectionImg': '',
 'sectionName': '深夜舔屏福利'}
2020-05-04 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1646',
 'sectionImg': '',
 'sectionName': '急诊室的人间冷暖'}
2020-05-04 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1903',
 'sectionImg': '',
 'sectionName': '恶魔在人间'}
2020-05-04 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1693',
 'sectionImg': '',
 'sectionName': '病毒藏在每个角落'}
2020-05-04 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_742',
 'sectionImg': '',
 'sectionName': '热剧回归！'}
2020-05-04 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_989',
 'sectionImg': '',
 'sectionName': '腐眼看人基'}
2020-05-04 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1883',
 'sectionImg': '',
 'sectionName': '吃货必备！这些纪录片很“下饭”'}
2020-05-04 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1399',
 'sectionImg': '',
 'sectionName': '他改变了世界'}
2020-05-04 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1729',
 'sectionImg': '',
 'sectionName': '【电影】获奖佳片集结'}
2020-05-04 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1405',
 'sectionImg': '',
 'sectionName': '幕后更精彩'}
2020-05-04 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_745',
 'sectionImg': '',
 'sectionName': '本周新剧'}
2020-05-04 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1431',
 'sectionImg': '',
 'sectionName': 'LGBT人生纪实 '}
2020-05-04 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1416',
 'sectionImg': '',
 'sectionName': '怪奇世界物语'}
2020-05-04 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1421',
 'sectionImg': '',
 'sectionName': '笑到飞起的脱口秀'}
2020-05-04 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1295',
 'sectionImg': '',
 'sectionName': '巨星的诞生'}
2020-05-04 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1425',
 'sectionImg': '',
 'sectionName': '大家都在看'}
2020-05-04 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1657',
 'sectionImg': '',
 'sectionName': '奥斯卡最佳纪录片'}
2020-05-04 08:09:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1005',
 'sectionImg': '',
 'sectionName': '德国之声特辑'}
2020-05-04 08:09:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_747',
 'sectionImg': '',
 'sectionName': '完结力推'}
2020-05-04 08:09:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 1 pages/min), scraped 837 items (at 25 items/min)
2020-05-04 08:10:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 08:11:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 08:12:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 08:13:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 08:14:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 08:15:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 08:16:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 08:17:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 08:18:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 08:19:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 08:20:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 08:21:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 08:22:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 08:23:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 08:24:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 08:25:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 08:26:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 08:27:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 08:28:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 08:29:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 08:30:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 08:31:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 08:32:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 08:33:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 08:34:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 08:35:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 08:36:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 08:37:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 08:38:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 08:39:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 08:40:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 08:41:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 08:42:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 08:43:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 08:44:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 08:45:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 08:46:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 08:47:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 08:48:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 08:49:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 08:50:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 08:51:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 08:52:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 08:53:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 08:54:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 08:55:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 08:56:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 08:57:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 08:58:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 08:59:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 09:00:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 09:01:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 09:02:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 09:03:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 09:04:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 09:05:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 09:06:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 09:07:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 09:08:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 09:09:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 09:10:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 09:11:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 09:12:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 09:13:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 09:14:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 09:15:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 09:16:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 09:17:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 09:18:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 09:19:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 09:20:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 09:21:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 09:22:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 09:23:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 09:24:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 09:25:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 09:26:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 09:27:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 09:28:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 09:29:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 09:30:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 09:31:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 09:32:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 09:33:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 09:34:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 09:35:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 09:36:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 09:37:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 09:38:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 09:39:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 09:40:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 09:41:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 09:42:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 09:43:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 09:44:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 09:45:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 09:46:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 09:47:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 09:48:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 09:49:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 09:50:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 09:51:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 09:52:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 09:53:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 09:54:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 09:55:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 09:56:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 09:57:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 09:58:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 09:59:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 10:00:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 10:01:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 10:02:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 10:03:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 10:04:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 10:05:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 10:06:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 10:07:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 10:08:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 10:09:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 10:10:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 10:11:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 10:12:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 10:13:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 10:14:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 10:15:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 10:16:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 10:17:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 10:18:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 10:19:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 10:20:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 10:21:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 10:22:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 10:23:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 10:24:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 10:25:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 10:26:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 10:27:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 10:28:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 10:29:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 10:30:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 10:31:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 10:32:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 10:33:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 10:34:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 10:35:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 10:36:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 10:37:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 10:38:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 10:39:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 10:40:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 10:41:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 10:42:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 10:43:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 10:44:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 10:45:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 10:46:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 10:47:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 10:48:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 10:49:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 10:50:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 10:51:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 10:52:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 10:53:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 10:54:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 10:55:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 10:56:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 10:57:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 10:58:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 10:59:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 11:00:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 11:01:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 11:02:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 11:03:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 11:04:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 11:05:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 11:06:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 11:07:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 11:08:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 11:09:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 11:10:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 11:11:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 11:12:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 11:13:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 11:14:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 11:15:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 11:16:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 11:17:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 11:18:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 11:19:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 11:20:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 11:21:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 11:22:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 11:23:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 11:24:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 11:25:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 11:26:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 11:27:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 11:28:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 11:29:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 11:30:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 11:31:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 11:32:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 11:33:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 11:34:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 11:35:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 11:36:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 11:37:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 11:38:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 11:39:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 11:40:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 11:41:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 11:42:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 11:43:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 11:44:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 11:45:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 11:46:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 11:47:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 11:48:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 11:49:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 11:50:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 11:51:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 11:52:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 11:53:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 11:54:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 11:55:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 11:56:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 11:57:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 11:58:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 11:59:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 12:00:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 12:01:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 12:02:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 12:03:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 12:04:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 12:05:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 12:06:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 12:07:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 12:08:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 12:09:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 12:10:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 12:11:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 12:12:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 12:13:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 12:14:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 12:15:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 12:16:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 12:17:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 12:18:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 12:19:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 12:20:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 12:21:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 12:22:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 12:23:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 12:24:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 12:25:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 12:26:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 12:27:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 12:28:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 12:29:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 12:30:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 12:31:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 12:32:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 12:33:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 12:34:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 12:35:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 12:36:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 12:37:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 12:38:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 12:39:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 12:40:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 12:41:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 12:42:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 12:43:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 12:44:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 12:45:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 12:46:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 12:47:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 12:48:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 12:49:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 12:50:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 12:51:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 12:52:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 12:53:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 12:54:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 12:55:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 12:56:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 12:57:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 12:58:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 12:59:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 13:00:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 13:01:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 13:02:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 13:03:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 13:04:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 13:05:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 13:06:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 13:07:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 13:08:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 13:09:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 13:10:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 13:11:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 13:12:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 13:13:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 13:14:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 13:15:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 13:16:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 13:17:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 13:18:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 13:19:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 13:20:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 13:21:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 13:22:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 13:23:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 13:24:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 13:25:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 13:26:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 13:27:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 13:28:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 13:29:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 13:30:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 13:31:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 13:32:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 13:33:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 13:34:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 13:35:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 13:36:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 13:37:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 13:38:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 13:39:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 13:40:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 13:41:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 13:42:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 13:43:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 13:44:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 13:45:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 13:46:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 13:47:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 13:48:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 13:49:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 13:50:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 13:51:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 13:52:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 13:53:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 13:54:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 13:55:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 13:56:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 13:57:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 13:58:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 13:59:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 14:00:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 14:01:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 14:02:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 14:03:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 14:04:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 14:05:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 14:06:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 14:07:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 14:08:19 [scrapy.extensions.logstats] INFO: Crawled 1224 pages (at 0 pages/min), scraped 837 items (at 0 items/min)
2020-05-04 14:09:04 [rrmj] DEBUG: Read 1 requests from 'rrmj:spider:strat_urls'
2020-05-04 14:09:04 [scrapy.core.engine] DEBUG: Crawled (200) <POST https://api.rr.tv/v3plus/index/channel> (referer: None)
2020-05-04 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1912',
 'sectionImg': '',
 'sectionName': '看剧鉴渣男手撕不心软'}
2020-05-04 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1917',
 'sectionImg': '',
 'sectionName': '抖音爆火洗脑剧'}
2020-05-04 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1904',
 'sectionImg': '',
 'sectionName': '台剧新来袭！！'}
2020-05-04 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1244',
 'sectionImg': '',
 'sectionName': '致我们甜甜的恋爱时光'}
2020-05-04 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_822',
 'sectionImg': '',
 'sectionName': '细思极恐 谁是凶手？'}
2020-05-04 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1926',
 'sectionImg': '',
 'sectionName': '力推！豆瓣高分推荐'}
2020-05-04 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1927',
 'sectionImg': '',
 'sectionName': '深夜舔屏福利'}
2020-05-04 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1646',
 'sectionImg': '',
 'sectionName': '急诊室的人间冷暖'}
2020-05-04 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1903',
 'sectionImg': '',
 'sectionName': '恶魔在人间'}
2020-05-04 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1693',
 'sectionImg': '',
 'sectionName': '病毒藏在每个角落'}
2020-05-04 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_742',
 'sectionImg': '',
 'sectionName': '热剧回归！'}
2020-05-04 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_989',
 'sectionImg': '',
 'sectionName': '腐眼看人基'}
2020-05-04 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1883',
 'sectionImg': '',
 'sectionName': '吃货必备！这些纪录片很“下饭”'}
2020-05-04 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1399',
 'sectionImg': '',
 'sectionName': '他改变了世界'}
2020-05-04 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1729',
 'sectionImg': '',
 'sectionName': '【电影】获奖佳片集结'}
2020-05-04 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1405',
 'sectionImg': '',
 'sectionName': '幕后更精彩'}
2020-05-04 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_745',
 'sectionImg': '',
 'sectionName': '本周新剧'}
2020-05-04 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1431',
 'sectionImg': '',
 'sectionName': 'LGBT人生纪实 '}
2020-05-04 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1416',
 'sectionImg': '',
 'sectionName': '怪奇世界物语'}
2020-05-04 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1421',
 'sectionImg': '',
 'sectionName': '笑到飞起的脱口秀'}
2020-05-04 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1295',
 'sectionImg': '',
 'sectionName': '巨星的诞生'}
2020-05-04 14:09:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1425',
 'sectionImg': '',
 'sectionName': '大家都在看'}
2020-05-04 14:09:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1657',
 'sectionImg': '',
 'sectionName': '奥斯卡最佳纪录片'}
2020-05-04 14:09:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1005',
 'sectionImg': '',
 'sectionName': '德国之声特辑'}
2020-05-04 14:09:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_747',
 'sectionImg': '',
 'sectionName': '完结力推'}
2020-05-04 14:09:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 1 pages/min), scraped 862 items (at 25 items/min)
2020-05-04 14:10:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 14:11:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 14:12:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 14:13:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 14:14:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 14:15:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 14:16:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 14:17:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 14:18:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 14:19:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 14:20:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 14:21:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 14:22:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 14:23:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 14:24:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 14:25:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 14:26:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 14:27:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 14:28:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 14:29:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 14:30:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 14:31:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 14:32:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 14:33:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 14:34:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 14:35:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 14:36:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 14:37:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 14:38:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 14:39:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 14:40:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 14:41:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 14:42:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 14:43:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 14:44:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 14:45:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 14:46:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 14:47:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 14:48:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 14:49:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 14:50:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 14:51:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 14:52:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 14:53:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 14:54:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 14:55:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 14:56:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 14:57:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 14:58:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 14:59:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 15:00:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 15:01:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 15:02:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 15:03:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 15:04:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 15:05:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 15:06:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 15:07:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 15:08:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 15:09:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 15:10:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 15:11:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 15:12:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 15:13:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 15:14:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 15:15:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 15:16:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 15:17:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 15:18:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 15:19:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 15:20:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 15:21:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 15:22:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 15:23:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 15:24:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 15:25:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 15:26:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 15:27:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 15:28:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 15:29:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 15:30:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 15:31:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 15:32:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 15:33:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 15:34:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 15:35:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 15:36:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 15:37:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 15:38:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 15:39:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 15:40:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 15:41:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 15:42:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 15:43:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 15:44:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 15:45:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 15:46:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 15:47:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 15:48:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 15:49:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 15:50:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 15:51:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 15:52:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 15:53:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 15:54:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 15:55:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 15:56:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 15:57:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 15:58:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 15:59:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 16:00:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 16:01:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 16:02:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 16:03:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 16:04:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 16:05:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 16:06:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 16:07:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 16:08:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 16:09:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 16:10:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 16:11:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 16:12:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 16:13:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 16:14:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 16:15:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 16:16:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 16:17:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 16:18:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 16:19:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 16:20:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 16:21:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 16:22:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 16:23:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 16:24:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 16:25:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 16:26:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 16:27:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 16:28:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 16:29:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 16:30:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 16:31:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 16:32:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 16:33:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 16:34:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 16:35:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 16:36:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 16:37:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 16:38:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 16:39:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 16:40:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 16:41:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 16:42:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 16:43:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 16:44:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 16:45:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 16:46:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 16:47:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 16:48:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 16:49:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 16:50:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 16:51:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 16:52:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 16:53:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 16:54:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 16:55:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 16:56:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 16:57:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 16:58:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 16:59:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 17:00:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 17:01:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 17:02:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 17:03:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 17:04:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 17:05:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 17:06:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 17:07:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 17:08:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 17:09:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 17:10:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 17:11:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 17:12:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 17:13:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 17:14:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 17:15:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 17:16:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 17:17:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 17:18:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 17:19:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 17:20:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 17:21:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 17:22:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 17:23:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 17:24:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 17:25:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 17:26:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 17:27:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 17:28:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 17:29:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 17:30:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 17:31:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 17:32:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 17:33:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 17:34:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 17:35:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 17:36:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 17:37:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 17:38:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 17:39:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 17:40:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 17:41:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 17:42:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 17:43:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 17:44:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 17:45:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 17:46:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 17:47:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 17:48:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 17:49:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 17:50:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 17:51:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 17:52:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 17:53:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 17:54:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 17:55:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 17:56:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 17:57:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 17:58:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 17:59:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 18:00:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 18:01:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 18:02:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 18:03:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 18:04:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 18:05:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 18:06:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 18:07:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 18:08:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 18:09:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 18:10:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 18:11:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 18:12:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 18:13:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 18:14:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 18:15:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 18:16:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 18:17:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 18:18:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 18:19:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 18:20:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 18:21:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 18:22:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 18:23:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 18:24:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 18:25:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 18:26:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 18:27:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 18:28:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 18:29:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 18:30:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 18:31:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 18:32:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 18:33:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 18:34:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 18:35:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 18:36:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 18:37:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 18:38:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 18:39:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 18:40:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 18:41:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 18:42:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 18:43:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 18:44:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 18:45:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 18:46:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 18:47:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 18:48:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 18:49:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 18:50:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 18:51:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 18:52:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 18:53:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 18:54:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 18:55:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 18:56:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 18:57:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 18:58:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 18:59:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 19:00:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 19:01:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 19:02:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 19:03:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 19:04:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 19:05:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 19:06:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 19:07:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 19:08:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 19:09:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 19:10:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 19:11:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 19:12:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 19:13:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 19:14:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 19:15:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 19:16:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 19:17:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 19:18:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 19:19:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 19:20:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 19:21:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 19:22:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 19:23:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 19:24:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 19:25:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 19:26:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 19:27:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 19:28:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 19:29:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 19:30:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 19:31:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 19:32:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 19:33:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 19:34:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 19:35:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 19:36:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 19:37:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 19:38:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 19:39:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 19:40:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 19:41:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 19:42:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 19:43:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 19:44:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 19:45:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 19:46:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 19:47:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 19:48:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 19:49:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 19:50:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 19:51:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 19:52:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 19:53:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 19:54:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 19:55:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 19:56:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 19:57:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 19:58:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 19:59:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 20:00:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 20:01:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 20:02:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 20:03:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 20:04:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 20:05:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 20:06:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 20:07:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 20:08:19 [scrapy.extensions.logstats] INFO: Crawled 1225 pages (at 0 pages/min), scraped 862 items (at 0 items/min)
2020-05-04 20:09:04 [rrmj] DEBUG: Read 1 requests from 'rrmj:spider:strat_urls'
2020-05-04 20:09:04 [scrapy.core.engine] DEBUG: Crawled (200) <POST https://api.rr.tv/v3plus/index/channel> (referer: None)
2020-05-04 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1912',
 'sectionImg': '',
 'sectionName': '看剧鉴渣男手撕不心软'}
2020-05-04 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1917',
 'sectionImg': '',
 'sectionName': '抖音爆火洗脑剧'}
2020-05-04 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1904',
 'sectionImg': '',
 'sectionName': '台剧新来袭！！'}
2020-05-04 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1244',
 'sectionImg': '',
 'sectionName': '致我们甜甜的恋爱时光'}
2020-05-04 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_822',
 'sectionImg': '',
 'sectionName': '细思极恐 谁是凶手？'}
2020-05-04 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1926',
 'sectionImg': '',
 'sectionName': '力推！豆瓣高分推荐'}
2020-05-04 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1927',
 'sectionImg': '',
 'sectionName': '深夜舔屏福利'}
2020-05-04 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1646',
 'sectionImg': '',
 'sectionName': '急诊室的人间冷暖'}
2020-05-04 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1903',
 'sectionImg': '',
 'sectionName': '恶魔在人间'}
2020-05-04 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1693',
 'sectionImg': '',
 'sectionName': '病毒藏在每个角落'}
2020-05-04 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_742',
 'sectionImg': '',
 'sectionName': '热剧回归！'}
2020-05-04 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_989',
 'sectionImg': '',
 'sectionName': '腐眼看人基'}
2020-05-04 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1883',
 'sectionImg': '',
 'sectionName': '吃货必备！这些纪录片很“下饭”'}
2020-05-04 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1399',
 'sectionImg': '',
 'sectionName': '他改变了世界'}
2020-05-04 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1729',
 'sectionImg': '',
 'sectionName': '【电影】获奖佳片集结'}
2020-05-04 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1405',
 'sectionImg': '',
 'sectionName': '幕后更精彩'}
2020-05-04 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_745',
 'sectionImg': '',
 'sectionName': '本周新剧'}
2020-05-04 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1431',
 'sectionImg': '',
 'sectionName': 'LGBT人生纪实 '}
2020-05-04 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1416',
 'sectionImg': '',
 'sectionName': '怪奇世界物语'}
2020-05-04 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1421',
 'sectionImg': '',
 'sectionName': '笑到飞起的脱口秀'}
2020-05-04 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1295',
 'sectionImg': '',
 'sectionName': '巨星的诞生'}
2020-05-04 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1425',
 'sectionImg': '',
 'sectionName': '大家都在看'}
2020-05-04 20:09:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1657',
 'sectionImg': '',
 'sectionName': '奥斯卡最佳纪录片'}
2020-05-04 20:09:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1005',
 'sectionImg': '',
 'sectionName': '德国之声特辑'}
2020-05-04 20:09:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_747',
 'sectionImg': '',
 'sectionName': '完结力推'}
2020-05-04 20:09:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E4%BA%BF%E4%B8%87%20%E7%AC%AC%E4%BA%94%E5%AD%A3%20> (referer: https://api.rr.tv/v3plus/index/channel)
2020-05-04 20:09:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/33440173/> (referer: https://www.douban.com/search?q=%E4%BA%BF%E4%B8%87%20%E7%AC%AC%E4%BA%94%E5%AD%A3%20)
2020-05-04 20:09:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/33440173/>
{'cover': 'http://img.rr.tv/seasonCover/20200422/o_1587537241855.webp',
 'data_type': 'movie',
 'id': 'rrmj_17543',
 'intro': '就在新敌崛起准备大动干戈之际，鲍比·艾克斯罗德和查克·罗兹又双叒叕相互看不顺眼了……                                                                    \u3000\u3000'
          '社会影响力先锋迈克·普林斯（Mike '
          'Prince）对艾克斯优势地位构成实质威胁，查克则与一名难对付的地方检察官结下梁子。泰勒·梅森被迫重回艾斧资本（Axe '
          'Capital），他们必须为自身雇员和资产而战。温迪·罗兹重审自我忠心所向，并建立令人惊讶的新联盟，致使其与查克和艾克斯两人关系各生变数。',
 'is_new': False,
 'name': '亿万 第五季 ',
 'platforms': '',
 'publishdate': '2020-05-03',
 'rate': 9.2,
 'sectionid': 'rrmj_742',
 'tags': ['剧情', '犯罪'],
 'type': 'tv',
 'url': 'https://movie.douban.com/subject/33440173/'}
2020-05-04 20:09:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 3 pages/min), scraped 888 items (at 26 items/min)
2020-05-04 20:10:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 20:11:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 20:12:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 20:13:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 20:14:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 20:15:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 20:16:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 20:17:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 20:18:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 20:19:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 20:20:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 20:21:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 20:22:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 20:23:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 20:24:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 20:25:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 20:26:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 20:27:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 20:28:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 20:29:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 20:30:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 20:31:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 20:32:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 20:33:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 20:34:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 20:35:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 20:36:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 20:37:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 20:38:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 20:39:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 20:40:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 20:41:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 20:42:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 20:43:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 20:44:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 20:45:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 20:46:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 20:47:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 20:48:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 20:49:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 20:50:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 20:51:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 20:52:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 20:53:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 20:54:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 20:55:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 20:56:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 20:57:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 20:58:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 20:59:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 21:00:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 21:01:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 21:02:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 21:03:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 21:04:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 21:05:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 21:06:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 21:07:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 21:08:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 21:09:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 21:10:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 21:11:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 21:12:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 21:13:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 21:14:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 21:15:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 21:16:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 21:17:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 21:18:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 21:19:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 21:20:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 21:21:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 21:22:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 21:23:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 21:24:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 21:25:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 21:26:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 21:27:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 21:28:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 21:29:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 21:30:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 21:31:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 21:32:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 21:33:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 21:34:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 21:35:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 21:36:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 21:37:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 21:38:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 21:39:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 21:40:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 21:41:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 21:42:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 21:43:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 21:44:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 21:45:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 21:46:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 21:47:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 21:48:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 21:49:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 21:50:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 21:51:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 21:52:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 21:53:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 21:54:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 21:55:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 21:56:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 21:57:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 21:58:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 21:59:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 22:00:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 22:01:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 22:02:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 22:03:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 22:04:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 22:05:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 22:06:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 22:07:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 22:08:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 22:09:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 22:10:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 22:11:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 22:12:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 22:13:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 22:14:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 22:15:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 22:16:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 22:17:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 22:18:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 22:19:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 22:20:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 22:21:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 22:22:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 22:23:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 22:24:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 22:25:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 22:26:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 22:27:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 22:28:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 22:29:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 22:30:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 22:31:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 22:32:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 22:33:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 22:34:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 22:35:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 22:36:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 22:37:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 22:38:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 22:39:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 22:40:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 22:41:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 22:42:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 22:43:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 22:44:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 22:45:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 22:46:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 22:47:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 22:48:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 22:49:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 22:50:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 22:51:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 22:52:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 22:53:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 22:54:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 22:55:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 22:56:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 22:57:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 22:58:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 22:59:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 23:00:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 23:01:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 23:02:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 23:03:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 23:04:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 23:05:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 23:06:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 23:07:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 23:08:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 23:09:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 23:10:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 23:11:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 23:12:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 23:13:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 23:14:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 23:15:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 23:16:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 23:17:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 23:18:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 23:19:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 23:20:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 23:21:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 23:22:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 23:23:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 23:24:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 23:25:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 23:26:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 23:27:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 23:28:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 23:29:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 23:30:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 23:31:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 23:32:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 23:33:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 23:34:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 23:35:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 23:36:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 23:37:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 23:38:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 23:39:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 23:40:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 23:41:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 23:42:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 23:43:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 23:44:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 23:45:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 23:46:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 23:47:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 23:48:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 23:49:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 23:50:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 23:51:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 23:52:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 23:53:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 23:54:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 23:55:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 23:56:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 23:57:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 23:58:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-04 23:59:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 00:00:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 00:01:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 00:02:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 00:03:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 00:04:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 00:05:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 00:06:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 00:07:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 00:08:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 00:09:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 00:10:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 00:11:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 00:12:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 00:13:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 00:14:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 00:15:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 00:16:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 00:17:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 00:18:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 00:19:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 00:20:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 00:21:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 00:22:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 00:23:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 00:24:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 00:25:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 00:26:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 00:27:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 00:28:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 00:29:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 00:30:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 00:31:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 00:32:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 00:33:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 00:34:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 00:35:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 00:36:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 00:37:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 00:38:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 00:39:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 00:40:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 00:41:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 00:42:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 00:43:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 00:44:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 00:45:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 00:46:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 00:47:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 00:48:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 00:49:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 00:50:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 00:51:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 00:52:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 00:53:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 00:54:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 00:55:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 00:56:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 00:57:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 00:58:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 00:59:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 01:00:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 01:01:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 01:02:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 01:03:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 01:04:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 01:05:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 01:06:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 01:07:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 01:08:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 01:09:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 01:10:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 01:11:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 01:12:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 01:13:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 01:14:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 01:15:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 01:16:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 01:17:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 01:18:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 01:19:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 01:20:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 01:21:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 01:22:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 01:23:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 01:24:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 01:25:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 01:26:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 01:27:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 01:28:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 01:29:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 01:30:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 01:31:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 01:32:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 01:33:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 01:34:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 01:35:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 01:36:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 01:37:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 01:38:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 01:39:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 01:40:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 01:41:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 01:42:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 01:43:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 01:44:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 01:45:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 01:46:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 01:47:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 01:48:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 01:49:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 01:50:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 01:51:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 01:52:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 01:53:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 01:54:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 01:55:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 01:56:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 01:57:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 01:58:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 01:59:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 02:00:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 02:01:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 02:02:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 02:03:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 02:04:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 02:05:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 02:06:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 02:07:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 02:08:19 [scrapy.extensions.logstats] INFO: Crawled 1228 pages (at 0 pages/min), scraped 888 items (at 0 items/min)
2020-05-05 02:09:04 [rrmj] DEBUG: Read 1 requests from 'rrmj:spider:strat_urls'
2020-05-05 02:09:04 [scrapy.core.engine] DEBUG: Crawled (200) <POST https://api.rr.tv/v3plus/index/channel> (referer: None)
2020-05-05 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1912',
 'sectionImg': '',
 'sectionName': '看剧鉴渣男手撕不心软'}
2020-05-05 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1917',
 'sectionImg': '',
 'sectionName': '抖音爆火洗脑剧'}
2020-05-05 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1904',
 'sectionImg': '',
 'sectionName': '台剧新来袭！！'}
2020-05-05 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1244',
 'sectionImg': '',
 'sectionName': '致我们甜甜的恋爱时光'}
2020-05-05 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_822',
 'sectionImg': '',
 'sectionName': '细思极恐 谁是凶手？'}
2020-05-05 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1926',
 'sectionImg': '',
 'sectionName': '力推！豆瓣高分推荐'}
2020-05-05 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1927',
 'sectionImg': '',
 'sectionName': '深夜舔屏福利'}
2020-05-05 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1646',
 'sectionImg': '',
 'sectionName': '急诊室的人间冷暖'}
2020-05-05 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1903',
 'sectionImg': '',
 'sectionName': '恶魔在人间'}
2020-05-05 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1693',
 'sectionImg': '',
 'sectionName': '病毒藏在每个角落'}
2020-05-05 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_742',
 'sectionImg': '',
 'sectionName': '热剧回归！'}
2020-05-05 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_989',
 'sectionImg': '',
 'sectionName': '腐眼看人基'}
2020-05-05 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1883',
 'sectionImg': '',
 'sectionName': '吃货必备！这些纪录片很“下饭”'}
2020-05-05 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1399',
 'sectionImg': '',
 'sectionName': '他改变了世界'}
2020-05-05 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1729',
 'sectionImg': '',
 'sectionName': '【电影】获奖佳片集结'}
2020-05-05 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1405',
 'sectionImg': '',
 'sectionName': '幕后更精彩'}
2020-05-05 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_745',
 'sectionImg': '',
 'sectionName': '本周新剧'}
2020-05-05 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1431',
 'sectionImg': '',
 'sectionName': 'LGBT人生纪实 '}
2020-05-05 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1416',
 'sectionImg': '',
 'sectionName': '怪奇世界物语'}
2020-05-05 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1421',
 'sectionImg': '',
 'sectionName': '笑到飞起的脱口秀'}
2020-05-05 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1295',
 'sectionImg': '',
 'sectionName': '巨星的诞生'}
2020-05-05 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1425',
 'sectionImg': '',
 'sectionName': '大家都在看'}
2020-05-05 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1657',
 'sectionImg': '',
 'sectionName': '奥斯卡最佳纪录片'}
2020-05-05 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1005',
 'sectionImg': '',
 'sectionName': '德国之声特辑'}
2020-05-05 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_747',
 'sectionImg': '',
 'sectionName': '完结力推'}
2020-05-05 02:09:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 1 pages/min), scraped 913 items (at 25 items/min)
2020-05-05 02:10:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 02:11:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 02:12:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 02:13:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 02:14:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 02:15:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 02:16:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 02:17:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 02:18:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 02:19:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 02:20:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 02:21:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 02:22:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 02:23:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 02:24:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 02:25:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 02:26:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 02:27:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 02:28:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 02:29:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 02:30:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 02:31:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 02:32:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 02:33:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 02:34:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 02:35:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 02:36:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 02:37:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 02:38:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 02:39:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 02:40:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 02:41:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 02:42:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 02:43:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 02:44:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 02:45:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 02:46:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 02:47:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 02:48:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 02:49:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 02:50:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 02:51:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 02:52:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 02:53:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 02:54:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 02:55:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 02:56:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 02:57:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 02:58:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 02:59:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 03:00:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 03:01:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 03:02:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 03:03:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 03:04:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 03:05:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 03:06:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 03:07:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 03:08:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 03:09:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 03:10:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 03:11:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 03:12:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 03:13:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 03:14:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 03:15:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 03:16:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 03:17:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 03:18:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 03:19:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 03:20:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 03:21:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 03:22:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 03:23:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 03:24:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 03:25:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 03:26:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 03:27:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 03:28:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 03:29:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 03:30:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 03:31:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 03:32:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 03:33:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 03:34:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 03:35:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 03:36:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 03:37:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 03:38:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 03:39:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 03:40:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 03:41:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 03:42:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 03:43:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 03:44:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 03:45:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 03:46:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 03:47:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 03:48:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 03:49:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 03:50:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 03:51:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 03:52:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 03:53:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 03:54:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 03:55:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 03:56:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 03:57:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 03:58:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 03:59:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 04:00:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 04:01:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 04:02:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 04:03:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 04:04:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 04:05:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 04:06:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 04:07:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 04:08:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 04:09:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 04:10:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 04:11:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 04:12:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 04:13:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 04:14:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 04:15:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 04:16:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 04:17:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 04:18:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 04:19:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 04:20:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 04:21:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 04:22:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 04:23:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 04:24:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 04:25:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 04:26:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 04:27:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 04:28:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 04:29:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 04:30:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 04:31:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 04:32:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 04:33:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 04:34:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 04:35:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 04:36:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 04:37:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 04:38:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 04:39:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 04:40:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 04:41:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 04:42:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 04:43:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 04:44:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 04:45:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 04:46:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 04:47:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 04:48:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 04:49:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 04:50:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 04:51:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 04:52:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 04:53:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 04:54:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 04:55:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 04:56:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 04:57:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 04:58:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 04:59:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 05:00:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 05:01:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 05:02:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 05:03:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 05:04:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 05:05:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 05:06:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 05:07:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 05:08:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 05:09:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 05:10:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 05:11:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 05:12:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 05:13:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 05:14:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 05:15:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 05:16:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 05:17:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 05:18:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 05:19:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 05:20:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 05:21:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 05:22:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 05:23:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 05:24:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 05:25:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 05:26:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 05:27:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 05:28:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 05:29:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 05:30:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 05:31:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 05:32:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 05:33:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 05:34:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 05:35:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 05:36:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 05:37:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 05:38:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 05:39:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 05:40:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 05:41:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 05:42:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 05:43:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 05:44:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 05:45:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 05:46:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 05:47:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 05:48:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 05:49:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 05:50:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 05:51:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 05:52:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 05:53:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 05:54:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 05:55:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 05:56:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 05:57:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 05:58:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 05:59:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 06:00:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 06:01:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 06:02:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 06:03:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 06:04:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 06:05:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 06:06:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 06:07:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 06:08:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 06:09:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 06:10:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 06:11:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 06:12:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 06:13:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 06:14:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 06:15:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 06:16:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 06:17:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 06:18:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 06:19:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 06:20:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 06:21:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 06:22:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 06:23:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 06:24:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 06:25:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 06:26:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 06:27:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 06:28:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 06:29:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 06:30:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 06:31:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 06:32:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 06:33:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 06:34:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 06:35:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 06:36:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 06:37:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 06:38:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 06:39:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 06:40:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 06:41:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 06:42:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 06:43:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 06:44:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 06:45:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 06:46:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 06:47:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 06:48:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 06:49:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 06:50:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 06:51:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 06:52:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 06:53:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 06:54:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 06:55:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 06:56:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 06:57:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 06:58:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 06:59:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 07:00:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 07:01:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 07:02:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 07:03:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 07:04:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 07:05:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 07:06:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 07:07:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 07:08:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 07:09:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 07:10:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 07:11:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 07:12:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 07:13:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 07:14:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 07:15:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 07:16:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 07:17:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 07:18:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 07:19:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 07:20:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 07:21:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 07:22:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 07:23:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 07:24:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 07:25:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 07:26:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 07:27:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 07:28:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 07:29:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 07:30:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 07:31:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 07:32:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 07:33:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 07:34:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 07:35:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 07:36:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 07:37:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 07:38:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 07:39:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 07:40:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 07:41:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 07:42:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 07:43:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 07:44:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 07:45:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 07:46:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 07:47:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 07:48:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 07:49:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 07:50:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 07:51:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 07:52:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 07:53:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 07:54:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 07:55:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 07:56:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 07:57:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 07:58:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 07:59:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 08:00:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 08:01:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 08:02:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 08:03:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 08:04:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 08:05:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 08:06:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 08:07:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 08:08:19 [scrapy.extensions.logstats] INFO: Crawled 1229 pages (at 0 pages/min), scraped 913 items (at 0 items/min)
2020-05-05 08:09:04 [rrmj] DEBUG: Read 1 requests from 'rrmj:spider:strat_urls'
2020-05-05 08:09:04 [scrapy.core.engine] DEBUG: Crawled (200) <POST https://api.rr.tv/v3plus/index/channel> (referer: None)
2020-05-05 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1912',
 'sectionImg': '',
 'sectionName': '看剧鉴渣男手撕不心软'}
2020-05-05 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1917',
 'sectionImg': '',
 'sectionName': '抖音爆火洗脑剧'}
2020-05-05 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1904',
 'sectionImg': '',
 'sectionName': '台剧新来袭！！'}
2020-05-05 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1244',
 'sectionImg': '',
 'sectionName': '致我们甜甜的恋爱时光'}
2020-05-05 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_822',
 'sectionImg': '',
 'sectionName': '细思极恐 谁是凶手？'}
2020-05-05 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1926',
 'sectionImg': '',
 'sectionName': '力推！豆瓣高分推荐'}
2020-05-05 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1927',
 'sectionImg': '',
 'sectionName': '深夜舔屏福利'}
2020-05-05 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1646',
 'sectionImg': '',
 'sectionName': '急诊室的人间冷暖'}
2020-05-05 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1903',
 'sectionImg': '',
 'sectionName': '恶魔在人间'}
2020-05-05 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1693',
 'sectionImg': '',
 'sectionName': '病毒藏在每个角落'}
2020-05-05 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_742',
 'sectionImg': '',
 'sectionName': '热剧回归！'}
2020-05-05 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_989',
 'sectionImg': '',
 'sectionName': '腐眼看人基'}
2020-05-05 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1883',
 'sectionImg': '',
 'sectionName': '吃货必备！这些纪录片很“下饭”'}
2020-05-05 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1399',
 'sectionImg': '',
 'sectionName': '他改变了世界'}
2020-05-05 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1729',
 'sectionImg': '',
 'sectionName': '【电影】获奖佳片集结'}
2020-05-05 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1405',
 'sectionImg': '',
 'sectionName': '幕后更精彩'}
2020-05-05 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_745',
 'sectionImg': '',
 'sectionName': '本周新剧'}
2020-05-05 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1431',
 'sectionImg': '',
 'sectionName': 'LGBT人生纪实 '}
2020-05-05 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1416',
 'sectionImg': '',
 'sectionName': '怪奇世界物语'}
2020-05-05 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1421',
 'sectionImg': '',
 'sectionName': '笑到飞起的脱口秀'}
2020-05-05 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1295',
 'sectionImg': '',
 'sectionName': '巨星的诞生'}
2020-05-05 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1425',
 'sectionImg': '',
 'sectionName': '大家都在看'}
2020-05-05 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1657',
 'sectionImg': '',
 'sectionName': '奥斯卡最佳纪录片'}
2020-05-05 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1005',
 'sectionImg': '',
 'sectionName': '德国之声特辑'}
2020-05-05 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_747',
 'sectionImg': '',
 'sectionName': '完结力推'}
2020-05-05 08:09:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 1 pages/min), scraped 938 items (at 25 items/min)
2020-05-05 08:10:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 08:11:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 08:12:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 08:13:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 08:14:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 08:15:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 08:16:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 08:17:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 08:18:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 08:19:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 08:20:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 08:21:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 08:22:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 08:23:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 08:24:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 08:25:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 08:26:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 08:27:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 08:28:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 08:29:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 08:30:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 08:31:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 08:32:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 08:33:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 08:34:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 08:35:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 08:36:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 08:37:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 08:38:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 08:39:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 08:40:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 08:41:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 08:42:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 08:43:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 08:44:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 08:45:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 08:46:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 08:47:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 08:48:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 08:49:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 08:50:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 08:51:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 08:52:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 08:53:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 08:54:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 08:55:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 08:56:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 08:57:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 08:58:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 08:59:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 09:00:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 09:01:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 09:02:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 09:03:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 09:04:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 09:05:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 09:06:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 09:07:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 09:08:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 09:09:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 09:10:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 09:11:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 09:12:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 09:13:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 09:14:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 09:15:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 09:16:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 09:17:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 09:18:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 09:19:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 09:20:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 09:21:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 09:22:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 09:23:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 09:24:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 09:25:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 09:26:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 09:27:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 09:28:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 09:29:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 09:30:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 09:31:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 09:32:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 09:33:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 09:34:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 09:35:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 09:36:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 09:37:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 09:38:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 09:39:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 09:40:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 09:41:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 09:42:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 09:43:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 09:44:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 09:45:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 09:46:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 09:47:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 09:48:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 09:49:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 09:50:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 09:51:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 09:52:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 09:53:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 09:54:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 09:55:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 09:56:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 09:57:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 09:58:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 09:59:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 10:00:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 10:01:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 10:02:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 10:03:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 10:04:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 10:05:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 10:06:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 10:07:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 10:08:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 10:09:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 10:10:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 10:11:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 10:12:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 10:13:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 10:14:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 10:15:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 10:16:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 10:17:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 10:18:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 10:19:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 10:20:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 10:21:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 10:22:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 10:23:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 10:24:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 10:25:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 10:26:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 10:27:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 10:28:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 10:29:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 10:30:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 10:31:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 10:32:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 10:33:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 10:34:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 10:35:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 10:36:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 10:37:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 10:38:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 10:39:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 10:40:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 10:41:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 10:42:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 10:43:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 10:44:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 10:45:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 10:46:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 10:47:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 10:48:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 10:49:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 10:50:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 10:51:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 10:52:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 10:53:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 10:54:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 10:55:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 10:56:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 10:57:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 10:58:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 10:59:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 11:00:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 11:01:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 11:02:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 11:03:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 11:04:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 11:05:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 11:06:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 11:07:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 11:08:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 11:09:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 11:10:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 11:11:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 11:12:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 11:13:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 11:14:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 11:15:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 11:16:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 11:17:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 11:18:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 11:19:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 11:20:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 11:21:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 11:22:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 11:23:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 11:24:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 11:25:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 11:26:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 11:27:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 11:28:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 11:29:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 11:30:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 11:31:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 11:32:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 11:33:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 11:34:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 11:35:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 11:36:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 11:37:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 11:38:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 11:39:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 11:40:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 11:41:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 11:42:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 11:43:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 11:44:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 11:45:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 11:46:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 11:47:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 11:48:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 11:49:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 11:50:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 11:51:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 11:52:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 11:53:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 11:54:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 11:55:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 11:56:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 11:57:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 11:58:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 11:59:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 12:00:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 12:01:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 12:02:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 12:03:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 12:04:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 12:05:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 12:06:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 12:07:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 12:08:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 12:09:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 12:10:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 12:11:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 12:12:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 12:13:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 12:14:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 12:15:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 12:16:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 12:17:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 12:18:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 12:19:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 12:20:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 12:21:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 12:22:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 12:23:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 12:24:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 12:25:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 12:26:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 12:27:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 12:28:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 12:29:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 12:30:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 12:31:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 12:32:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 12:33:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 12:34:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 12:35:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 12:36:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 12:37:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 12:38:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 12:39:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 12:40:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 12:41:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 12:42:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 12:43:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 12:44:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 12:45:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 12:46:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 12:47:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 12:48:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 12:49:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 12:50:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 12:51:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 12:52:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 12:53:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 12:54:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 12:55:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 12:56:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 12:57:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 12:58:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 12:59:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 13:00:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 13:01:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 13:02:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 13:03:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 13:04:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 13:05:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 13:06:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 13:07:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 13:08:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 13:09:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 13:10:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 13:11:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 13:12:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 13:13:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 13:14:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 13:15:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 13:16:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 13:17:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 13:18:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 13:19:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 13:20:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 13:21:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 13:22:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 13:23:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 13:24:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 13:25:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 13:26:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 13:27:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 13:28:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 13:29:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 13:30:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 13:31:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 13:32:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 13:33:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 13:34:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 13:35:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 13:36:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 13:37:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 13:38:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 13:39:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 13:40:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 13:41:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 13:42:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 13:43:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 13:44:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 13:45:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 13:46:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 13:47:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 13:48:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 13:49:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 13:50:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 13:51:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 13:52:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 13:53:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 13:54:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 13:55:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 13:56:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 13:57:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 13:58:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 13:59:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 14:00:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 14:01:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 14:02:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 14:03:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 14:04:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 14:05:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 14:06:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 14:07:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 14:08:19 [scrapy.extensions.logstats] INFO: Crawled 1230 pages (at 0 pages/min), scraped 938 items (at 0 items/min)
2020-05-05 14:09:04 [rrmj] DEBUG: Read 1 requests from 'rrmj:spider:strat_urls'
2020-05-05 14:09:04 [scrapy.core.engine] DEBUG: Crawled (200) <POST https://api.rr.tv/v3plus/index/channel> (referer: None)
2020-05-05 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1912',
 'sectionImg': '',
 'sectionName': '看剧鉴渣男手撕不心软'}
2020-05-05 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1917',
 'sectionImg': '',
 'sectionName': '抖音爆火洗脑剧'}
2020-05-05 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1904',
 'sectionImg': '',
 'sectionName': '台剧新来袭！！'}
2020-05-05 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1244',
 'sectionImg': '',
 'sectionName': '致我们甜甜的恋爱时光'}
2020-05-05 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_822',
 'sectionImg': '',
 'sectionName': '细思极恐 谁是凶手？'}
2020-05-05 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1926',
 'sectionImg': '',
 'sectionName': '力推！豆瓣高分推荐'}
2020-05-05 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1927',
 'sectionImg': '',
 'sectionName': '深夜舔屏福利'}
2020-05-05 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1646',
 'sectionImg': '',
 'sectionName': '急诊室的人间冷暖'}
2020-05-05 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1903',
 'sectionImg': '',
 'sectionName': '恶魔在人间'}
2020-05-05 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1693',
 'sectionImg': '',
 'sectionName': '病毒藏在每个角落'}
2020-05-05 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_742',
 'sectionImg': '',
 'sectionName': '热剧回归！'}
2020-05-05 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_989',
 'sectionImg': '',
 'sectionName': '腐眼看人基'}
2020-05-05 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1883',
 'sectionImg': '',
 'sectionName': '吃货必备！这些纪录片很“下饭”'}
2020-05-05 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1399',
 'sectionImg': '',
 'sectionName': '他改变了世界'}
2020-05-05 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1729',
 'sectionImg': '',
 'sectionName': '【电影】获奖佳片集结'}
2020-05-05 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1405',
 'sectionImg': '',
 'sectionName': '幕后更精彩'}
2020-05-05 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_745',
 'sectionImg': '',
 'sectionName': '本周新剧'}
2020-05-05 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1431',
 'sectionImg': '',
 'sectionName': 'LGBT人生纪实 '}
2020-05-05 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1416',
 'sectionImg': '',
 'sectionName': '怪奇世界物语'}
2020-05-05 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1421',
 'sectionImg': '',
 'sectionName': '笑到飞起的脱口秀'}
2020-05-05 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1295',
 'sectionImg': '',
 'sectionName': '巨星的诞生'}
2020-05-05 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1425',
 'sectionImg': '',
 'sectionName': '大家都在看'}
2020-05-05 14:09:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1657',
 'sectionImg': '',
 'sectionName': '奥斯卡最佳纪录片'}
2020-05-05 14:09:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1005',
 'sectionImg': '',
 'sectionName': '德国之声特辑'}
2020-05-05 14:09:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_747',
 'sectionImg': '',
 'sectionName': '完结力推'}
2020-05-05 14:09:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 1 pages/min), scraped 963 items (at 25 items/min)
2020-05-05 14:10:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 14:11:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 14:12:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 14:13:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 14:14:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 14:15:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 14:16:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 14:17:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 14:18:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 14:19:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 14:20:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 14:21:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 14:22:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 14:23:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 14:24:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 14:25:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 14:26:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 14:27:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 14:28:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 14:29:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 14:30:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 14:31:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 14:32:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 14:33:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 14:34:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 14:35:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 14:36:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 14:37:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 14:38:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 14:39:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 14:40:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 14:41:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 14:42:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 14:43:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 14:44:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 14:45:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 14:46:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 14:47:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 14:48:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 14:49:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 14:50:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 14:51:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 14:52:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 14:53:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 14:54:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 14:55:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 14:56:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 14:57:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 14:58:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 14:59:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 15:00:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 15:01:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 15:02:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 15:03:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 15:04:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 15:05:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 15:06:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 15:07:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 15:08:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 15:09:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 15:10:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 15:11:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 15:12:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 15:13:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 15:14:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 15:15:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 15:16:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 15:17:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 15:18:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 15:19:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 15:20:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 15:21:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 15:22:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 15:23:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 15:24:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 15:25:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 15:26:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 15:27:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 15:28:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 15:29:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 15:30:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 15:31:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 15:32:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 15:33:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 15:34:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 15:35:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 15:36:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 15:37:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 15:38:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 15:39:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 15:40:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 15:41:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 15:42:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 15:43:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 15:44:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 15:45:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 15:46:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 15:47:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 15:48:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 15:49:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 15:50:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 15:51:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 15:52:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 15:53:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 15:54:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 15:55:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 15:56:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 15:57:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 15:58:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 15:59:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 16:00:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 16:01:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 16:02:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 16:03:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 16:04:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 16:05:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 16:06:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 16:07:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 16:08:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 16:09:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 16:10:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 16:11:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 16:12:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 16:13:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 16:14:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 16:15:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 16:16:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 16:17:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 16:18:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 16:19:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 16:20:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 16:21:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 16:22:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 16:23:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 16:24:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 16:25:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 16:26:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 16:27:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 16:28:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 16:29:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 16:30:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 16:31:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 16:32:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 16:33:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 16:34:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 16:35:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 16:36:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 16:37:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 16:38:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 16:39:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 16:40:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 16:41:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 16:42:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 16:43:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 16:44:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 16:45:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 16:46:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 16:47:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 16:48:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 16:49:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 16:50:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 16:51:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 16:52:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 16:53:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 16:54:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 16:55:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 16:56:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 16:57:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 16:58:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 16:59:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 17:00:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 17:01:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 17:02:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 17:03:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 17:04:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 17:05:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 17:06:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 17:07:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 17:08:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 17:09:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 17:10:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 17:11:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 17:12:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 17:13:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 17:14:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 17:15:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 17:16:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 17:17:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 17:18:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 17:19:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 17:20:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 17:21:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 17:22:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 17:23:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 17:24:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 17:25:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 17:26:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 17:27:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 17:28:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 17:29:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 17:30:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 17:31:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 17:32:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 17:33:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 17:34:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 17:35:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 17:36:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 17:37:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 17:38:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 17:39:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 17:40:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 17:41:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 17:42:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 17:43:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 17:44:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 17:45:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 17:46:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 17:47:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 17:48:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 17:49:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 17:50:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 17:51:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 17:52:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 17:53:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 17:54:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 17:55:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 17:56:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 17:57:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 17:58:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 17:59:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 18:00:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 18:01:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 18:02:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 18:03:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 18:04:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 18:05:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 18:06:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 18:07:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 18:08:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 18:09:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 18:10:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 18:11:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 18:12:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 18:13:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 18:14:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 18:15:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 18:16:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 18:17:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 18:18:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 18:19:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 18:20:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 18:21:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 18:22:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 18:23:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 18:24:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 18:25:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 18:26:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 18:27:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 18:28:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 18:29:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 18:30:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 18:31:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 18:32:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 18:33:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 18:34:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 18:35:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 18:36:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 18:37:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 18:38:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 18:39:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 18:40:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 18:41:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 18:42:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 18:43:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 18:44:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 18:45:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 18:46:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 18:47:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 18:48:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 18:49:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 18:50:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 18:51:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 18:52:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 18:53:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 18:54:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 18:55:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 18:56:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 18:57:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 18:58:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 18:59:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 19:00:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 19:01:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 19:02:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 19:03:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 19:04:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 19:05:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 19:06:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 19:07:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 19:08:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 19:09:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 19:10:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 19:11:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 19:12:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 19:13:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 19:14:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 19:15:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 19:16:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 19:17:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 19:18:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 19:19:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 19:20:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 19:21:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 19:22:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 19:23:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 19:24:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 19:25:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 19:26:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 19:27:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 19:28:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 19:29:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 19:30:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 19:31:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 19:32:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 19:33:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 19:34:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 19:35:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 19:36:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 19:37:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 19:38:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 19:39:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 19:40:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 19:41:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 19:42:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 19:43:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 19:44:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 19:45:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 19:46:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 19:47:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 19:48:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 19:49:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 19:50:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 19:51:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 19:52:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 19:53:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 19:54:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 19:55:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 19:56:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 19:57:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 19:58:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 19:59:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 20:00:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 20:01:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 20:02:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 20:03:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 20:04:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 20:05:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 20:06:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 20:07:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 20:08:19 [scrapy.extensions.logstats] INFO: Crawled 1231 pages (at 0 pages/min), scraped 963 items (at 0 items/min)
2020-05-05 20:09:04 [rrmj] DEBUG: Read 1 requests from 'rrmj:spider:strat_urls'
2020-05-05 20:09:04 [scrapy.core.engine] DEBUG: Crawled (200) <POST https://api.rr.tv/v3plus/index/channel> (referer: None)
2020-05-05 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1912',
 'sectionImg': '',
 'sectionName': '看剧鉴渣男手撕不心软'}
2020-05-05 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1917',
 'sectionImg': '',
 'sectionName': '抖音爆火洗脑剧'}
2020-05-05 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1904',
 'sectionImg': '',
 'sectionName': '台剧新来袭！！'}
2020-05-05 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1244',
 'sectionImg': '',
 'sectionName': '致我们甜甜的恋爱时光'}
2020-05-05 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_822',
 'sectionImg': '',
 'sectionName': '细思极恐 谁是凶手？'}
2020-05-05 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1926',
 'sectionImg': '',
 'sectionName': '力推！豆瓣高分推荐'}
2020-05-05 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1927',
 'sectionImg': '',
 'sectionName': '深夜舔屏福利'}
2020-05-05 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1646',
 'sectionImg': '',
 'sectionName': '急诊室的人间冷暖'}
2020-05-05 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1903',
 'sectionImg': '',
 'sectionName': '恶魔在人间'}
2020-05-05 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1693',
 'sectionImg': '',
 'sectionName': '病毒藏在每个角落'}
2020-05-05 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_742',
 'sectionImg': '',
 'sectionName': '热剧回归！'}
2020-05-05 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_989',
 'sectionImg': '',
 'sectionName': '腐眼看人基'}
2020-05-05 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1883',
 'sectionImg': '',
 'sectionName': '吃货必备！这些纪录片很“下饭”'}
2020-05-05 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1399',
 'sectionImg': '',
 'sectionName': '他改变了世界'}
2020-05-05 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1729',
 'sectionImg': '',
 'sectionName': '【电影】获奖佳片集结'}
2020-05-05 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1405',
 'sectionImg': '',
 'sectionName': '幕后更精彩'}
2020-05-05 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_745',
 'sectionImg': '',
 'sectionName': '本周新剧'}
2020-05-05 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1431',
 'sectionImg': '',
 'sectionName': 'LGBT人生纪实 '}
2020-05-05 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1416',
 'sectionImg': '',
 'sectionName': '怪奇世界物语'}
2020-05-05 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1421',
 'sectionImg': '',
 'sectionName': '笑到飞起的脱口秀'}
2020-05-05 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1295',
 'sectionImg': '',
 'sectionName': '巨星的诞生'}
2020-05-05 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1425',
 'sectionImg': '',
 'sectionName': '大家都在看'}
2020-05-05 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1657',
 'sectionImg': '',
 'sectionName': '奥斯卡最佳纪录片'}
2020-05-05 20:09:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1005',
 'sectionImg': '',
 'sectionName': '德国之声特辑'}
2020-05-05 20:09:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_747',
 'sectionImg': '',
 'sectionName': '完结力推'}
2020-05-05 20:09:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 1 pages/min), scraped 988 items (at 25 items/min)
2020-05-05 20:10:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 20:11:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 20:12:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 20:13:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 20:14:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 20:15:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 20:16:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 20:17:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 20:18:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 20:19:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 20:20:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 20:21:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 20:22:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 20:23:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 20:24:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 20:25:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 20:26:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 20:27:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 20:28:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 20:29:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 20:30:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 20:31:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 20:32:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 20:33:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 20:34:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 20:35:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 20:36:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 20:37:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 20:38:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 20:39:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 20:40:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 20:41:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 20:42:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 20:43:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 20:44:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 20:45:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 20:46:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 20:47:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 20:48:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 20:49:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 20:50:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 20:51:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 20:52:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 20:53:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 20:54:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 20:55:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 20:56:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 20:57:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 20:58:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 20:59:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 21:00:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 21:01:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 21:02:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 21:03:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 21:04:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 21:05:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 21:06:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 21:07:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 21:08:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 21:09:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 21:10:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 21:11:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 21:12:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 21:13:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 21:14:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 21:15:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 21:16:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 21:17:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 21:18:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 21:19:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 21:20:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 21:21:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 21:22:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 21:23:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 21:24:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 21:25:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 21:26:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 21:27:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 21:28:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 21:29:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 21:30:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 21:31:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 21:32:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 21:33:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 21:34:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 21:35:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 21:36:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 21:37:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 21:38:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 21:39:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 21:40:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 21:41:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 21:42:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 21:43:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 21:44:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 21:45:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 21:46:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 21:47:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 21:48:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 21:49:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 21:50:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 21:51:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 21:52:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 21:53:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 21:54:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 21:55:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 21:56:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 21:57:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 21:58:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 21:59:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 22:00:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 22:01:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 22:02:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 22:03:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 22:04:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 22:05:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 22:06:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 22:07:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 22:08:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 22:09:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 22:10:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 22:11:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 22:12:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 22:13:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 22:14:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 22:15:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 22:16:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 22:17:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 22:18:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 22:19:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 22:20:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 22:21:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 22:22:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 22:23:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 22:24:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 22:25:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 22:26:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 22:27:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 22:28:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 22:29:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 22:30:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 22:31:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 22:32:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 22:33:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 22:34:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 22:35:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 22:36:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 22:37:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 22:38:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 22:39:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 22:40:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 22:41:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 22:42:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 22:43:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 22:44:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 22:45:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 22:46:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 22:47:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 22:48:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 22:49:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 22:50:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 22:51:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 22:52:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 22:53:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 22:54:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 22:55:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 22:56:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 22:57:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 22:58:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 22:59:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 23:00:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 23:01:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 23:02:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 23:03:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 23:04:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 23:05:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 23:06:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 23:07:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 23:08:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 23:09:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 23:10:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 23:11:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 23:12:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 23:13:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 23:14:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 23:15:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 23:16:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 23:17:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 23:18:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 23:19:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 23:20:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 23:21:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 23:22:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 23:23:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 23:24:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 23:25:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 23:26:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 23:27:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 23:28:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 23:29:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 23:30:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 23:31:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 23:32:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 23:33:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 23:34:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 23:35:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 23:36:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 23:37:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 23:38:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 23:39:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 23:40:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 23:41:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 23:42:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 23:43:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 23:44:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 23:45:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 23:46:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 23:47:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 23:48:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 23:49:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 23:50:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 23:51:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 23:52:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 23:53:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 23:54:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 23:55:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 23:56:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 23:57:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 23:58:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-05 23:59:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 00:00:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 00:01:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 00:02:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 00:03:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 00:04:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 00:05:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 00:06:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 00:07:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 00:08:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 00:09:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 00:10:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 00:11:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 00:12:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 00:13:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 00:14:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 00:15:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 00:16:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 00:17:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 00:18:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 00:19:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 00:20:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 00:21:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 00:22:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 00:23:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 00:24:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 00:25:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 00:26:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 00:27:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 00:28:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 00:29:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 00:30:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 00:31:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 00:32:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 00:33:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 00:34:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 00:35:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 00:36:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 00:37:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 00:38:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 00:39:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 00:40:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 00:41:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 00:42:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 00:43:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 00:44:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 00:45:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 00:46:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 00:47:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 00:48:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 00:49:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 00:50:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 00:51:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 00:52:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 00:53:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 00:54:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 00:55:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 00:56:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 00:57:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 00:58:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 00:59:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 01:00:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 01:01:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 01:02:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 01:03:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 01:04:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 01:05:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 01:06:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 01:07:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 01:08:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 01:09:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 01:10:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 01:11:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 01:12:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 01:13:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 01:14:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 01:15:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 01:16:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 01:17:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 01:18:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 01:19:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 01:20:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 01:21:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 01:22:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 01:23:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 01:24:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 01:25:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 01:26:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 01:27:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 01:28:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 01:29:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 01:30:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 01:31:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 01:32:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 01:33:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 01:34:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 01:35:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 01:36:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 01:37:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 01:38:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 01:39:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 01:40:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 01:41:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 01:42:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 01:43:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 01:44:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 01:45:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 01:46:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 01:47:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 01:48:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 01:49:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 01:50:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 01:51:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 01:52:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 01:53:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 01:54:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 01:55:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 01:56:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 01:57:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 01:58:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 01:59:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 02:00:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 02:01:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 02:02:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 02:03:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 02:04:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 02:05:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 02:06:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 02:07:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 02:08:19 [scrapy.extensions.logstats] INFO: Crawled 1232 pages (at 0 pages/min), scraped 988 items (at 0 items/min)
2020-05-06 02:09:04 [rrmj] DEBUG: Read 1 requests from 'rrmj:spider:strat_urls'
2020-05-06 02:09:04 [scrapy.core.engine] DEBUG: Crawled (200) <POST https://api.rr.tv/v3plus/index/channel> (referer: None)
2020-05-06 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1912',
 'sectionImg': '',
 'sectionName': '看剧鉴渣男手撕不心软'}
2020-05-06 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1917',
 'sectionImg': '',
 'sectionName': '抖音爆火洗脑剧'}
2020-05-06 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1904',
 'sectionImg': '',
 'sectionName': '台剧新来袭！！'}
2020-05-06 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1244',
 'sectionImg': '',
 'sectionName': '致我们甜甜的恋爱时光'}
2020-05-06 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_822',
 'sectionImg': '',
 'sectionName': '细思极恐 谁是凶手？'}
2020-05-06 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1926',
 'sectionImg': '',
 'sectionName': '力推！豆瓣高分推荐'}
2020-05-06 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1927',
 'sectionImg': '',
 'sectionName': '深夜舔屏福利'}
2020-05-06 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1646',
 'sectionImg': '',
 'sectionName': '急诊室的人间冷暖'}
2020-05-06 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1903',
 'sectionImg': '',
 'sectionName': '恶魔在人间'}
2020-05-06 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1693',
 'sectionImg': '',
 'sectionName': '病毒藏在每个角落'}
2020-05-06 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_742',
 'sectionImg': '',
 'sectionName': '热剧回归！'}
2020-05-06 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_989',
 'sectionImg': '',
 'sectionName': '腐眼看人基'}
2020-05-06 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1883',
 'sectionImg': '',
 'sectionName': '吃货必备！这些纪录片很“下饭”'}
2020-05-06 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1399',
 'sectionImg': '',
 'sectionName': '他改变了世界'}
2020-05-06 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1729',
 'sectionImg': '',
 'sectionName': '【电影】获奖佳片集结'}
2020-05-06 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1405',
 'sectionImg': '',
 'sectionName': '幕后更精彩'}
2020-05-06 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_745',
 'sectionImg': '',
 'sectionName': '本周新剧'}
2020-05-06 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1431',
 'sectionImg': '',
 'sectionName': 'LGBT人生纪实 '}
2020-05-06 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1416',
 'sectionImg': '',
 'sectionName': '怪奇世界物语'}
2020-05-06 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1421',
 'sectionImg': '',
 'sectionName': '笑到飞起的脱口秀'}
2020-05-06 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1295',
 'sectionImg': '',
 'sectionName': '巨星的诞生'}
2020-05-06 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1425',
 'sectionImg': '',
 'sectionName': '大家都在看'}
2020-05-06 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1657',
 'sectionImg': '',
 'sectionName': '奥斯卡最佳纪录片'}
2020-05-06 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1005',
 'sectionImg': '',
 'sectionName': '德国之声特辑'}
2020-05-06 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_747',
 'sectionImg': '',
 'sectionName': '完结力推'}
2020-05-06 02:09:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 1 pages/min), scraped 1013 items (at 25 items/min)
2020-05-06 02:10:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 02:11:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 02:12:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 02:13:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 02:14:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 02:15:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 02:16:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 02:17:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 02:18:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 02:19:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 02:20:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 02:21:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 02:22:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 02:23:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 02:24:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 02:25:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 02:26:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 02:27:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 02:28:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 02:29:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 02:30:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 02:31:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 02:32:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 02:33:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 02:34:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 02:35:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 02:36:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 02:37:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 02:38:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 02:39:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 02:40:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 02:41:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 02:42:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 02:43:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 02:44:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 02:45:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 02:46:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 02:47:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 02:48:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 02:49:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 02:50:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 02:51:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 02:52:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 02:53:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 02:54:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 02:55:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 02:56:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 02:57:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 02:58:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 02:59:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 03:00:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 03:01:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 03:02:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 03:03:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 03:04:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 03:05:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 03:06:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 03:07:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 03:08:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 03:09:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 03:10:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 03:11:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 03:12:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 03:13:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 03:14:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 03:15:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 03:16:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 03:17:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 03:18:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 03:19:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 03:20:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 03:21:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 03:22:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 03:23:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 03:24:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 03:25:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 03:26:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 03:27:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 03:28:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 03:29:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 03:30:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 03:31:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 03:32:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 03:33:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 03:34:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 03:35:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 03:36:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 03:37:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 03:38:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 03:39:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 03:40:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 03:41:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 03:42:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 03:43:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 03:44:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 03:45:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 03:46:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 03:47:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 03:48:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 03:49:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 03:50:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 03:51:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 03:52:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 03:53:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 03:54:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 03:55:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 03:56:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 03:57:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 03:58:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 03:59:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 04:00:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 04:01:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 04:02:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 04:03:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 04:04:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 04:05:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 04:06:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 04:07:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 04:08:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 04:09:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 04:10:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 04:11:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 04:12:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 04:13:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 04:14:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 04:15:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 04:16:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 04:17:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 04:18:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 04:19:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 04:20:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 04:21:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 04:22:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 04:23:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 04:24:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 04:25:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 04:26:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 04:27:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 04:28:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 04:29:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 04:30:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 04:31:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 04:32:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 04:33:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 04:34:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 04:35:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 04:36:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 04:37:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 04:38:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 04:39:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 04:40:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 04:41:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 04:42:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 04:43:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 04:44:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 04:45:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 04:46:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 04:47:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 04:48:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 04:49:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 04:50:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 04:51:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 04:52:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 04:53:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 04:54:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 04:55:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 04:56:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 04:57:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 04:58:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 04:59:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 05:00:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 05:01:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 05:02:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 05:03:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 05:04:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 05:05:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 05:06:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 05:07:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 05:08:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 05:09:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 05:10:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 05:11:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 05:12:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 05:13:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 05:14:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 05:15:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 05:16:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 05:17:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 05:18:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 05:19:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 05:20:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 05:21:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 05:22:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 05:23:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 05:24:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 05:25:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 05:26:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 05:27:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 05:28:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 05:29:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 05:30:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 05:31:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 05:32:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 05:33:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 05:34:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 05:35:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 05:36:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 05:37:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 05:38:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 05:39:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 05:40:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 05:41:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 05:42:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 05:43:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 05:44:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 05:45:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 05:46:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 05:47:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 05:48:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 05:49:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 05:50:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 05:51:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 05:52:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 05:53:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 05:54:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 05:55:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 05:56:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 05:57:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 05:58:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 05:59:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 06:00:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 06:01:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 06:02:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 06:03:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 06:04:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 06:05:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 06:06:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 06:07:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 06:08:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 06:09:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 06:10:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 06:11:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 06:12:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 06:13:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 06:14:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 06:15:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 06:16:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 06:17:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 06:18:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 06:19:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 06:20:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 06:21:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 06:22:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 06:23:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 06:24:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 06:25:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 06:26:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 06:27:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 06:28:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 06:29:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 06:30:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 06:31:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 06:32:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 06:33:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 06:34:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 06:35:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 06:36:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 06:37:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 06:38:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 06:39:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 06:40:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 06:41:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 06:42:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 06:43:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 06:44:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 06:45:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 06:46:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 06:47:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 06:48:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 06:49:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 06:50:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 06:51:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 06:52:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 06:53:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 06:54:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 06:55:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 06:56:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 06:57:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 06:58:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 06:59:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 07:00:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 07:01:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 07:02:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 07:03:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 07:04:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 07:05:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 07:06:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 07:07:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 07:08:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 07:09:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 07:10:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 07:11:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 07:12:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 07:13:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 07:14:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 07:15:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 07:16:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 07:17:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 07:18:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 07:19:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 07:20:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 07:21:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 07:22:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 07:23:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 07:24:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 07:25:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 07:26:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 07:27:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 07:28:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 07:29:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 07:30:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 07:31:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 07:32:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 07:33:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 07:34:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 07:35:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 07:36:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 07:37:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 07:38:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 07:39:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 07:40:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 07:41:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 07:42:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 07:43:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 07:44:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 07:45:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 07:46:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 07:47:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 07:48:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 07:49:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 07:50:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 07:51:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 07:52:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 07:53:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 07:54:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 07:55:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 07:56:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 07:57:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 07:58:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 07:59:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 08:00:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 08:01:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 08:02:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 08:03:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 08:04:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 08:05:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 08:06:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 08:07:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 08:08:19 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 0 pages/min), scraped 1013 items (at 0 items/min)
2020-05-06 08:09:04 [rrmj] DEBUG: Read 1 requests from 'rrmj:spider:strat_urls'
2020-05-06 08:09:04 [scrapy.core.engine] DEBUG: Crawled (200) <POST https://api.rr.tv/v3plus/index/channel> (referer: None)
2020-05-06 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1912',
 'sectionImg': '',
 'sectionName': '看剧鉴渣男手撕不心软'}
2020-05-06 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1917',
 'sectionImg': '',
 'sectionName': '抖音爆火洗脑剧'}
2020-05-06 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1904',
 'sectionImg': '',
 'sectionName': '台剧新来袭！！'}
2020-05-06 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1244',
 'sectionImg': '',
 'sectionName': '致我们甜甜的恋爱时光'}
2020-05-06 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_822',
 'sectionImg': '',
 'sectionName': '细思极恐 谁是凶手？'}
2020-05-06 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1926',
 'sectionImg': '',
 'sectionName': '力推！豆瓣高分推荐'}
2020-05-06 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1927',
 'sectionImg': '',
 'sectionName': '深夜舔屏福利'}
2020-05-06 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1646',
 'sectionImg': '',
 'sectionName': '急诊室的人间冷暖'}
2020-05-06 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1903',
 'sectionImg': '',
 'sectionName': '恶魔在人间'}
2020-05-06 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1693',
 'sectionImg': '',
 'sectionName': '病毒藏在每个角落'}
2020-05-06 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_742',
 'sectionImg': '',
 'sectionName': '热剧回归！'}
2020-05-06 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_989',
 'sectionImg': '',
 'sectionName': '腐眼看人基'}
2020-05-06 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1883',
 'sectionImg': '',
 'sectionName': '吃货必备！这些纪录片很“下饭”'}
2020-05-06 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1399',
 'sectionImg': '',
 'sectionName': '他改变了世界'}
2020-05-06 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1729',
 'sectionImg': '',
 'sectionName': '【电影】获奖佳片集结'}
2020-05-06 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1405',
 'sectionImg': '',
 'sectionName': '幕后更精彩'}
2020-05-06 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_745',
 'sectionImg': '',
 'sectionName': '本周新剧'}
2020-05-06 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1431',
 'sectionImg': '',
 'sectionName': 'LGBT人生纪实 '}
2020-05-06 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1416',
 'sectionImg': '',
 'sectionName': '怪奇世界物语'}
2020-05-06 08:09:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1421',
 'sectionImg': '',
 'sectionName': '笑到飞起的脱口秀'}
2020-05-06 08:09:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1295',
 'sectionImg': '',
 'sectionName': '巨星的诞生'}
2020-05-06 08:09:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1425',
 'sectionImg': '',
 'sectionName': '大家都在看'}
2020-05-06 08:09:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1657',
 'sectionImg': '',
 'sectionName': '奥斯卡最佳纪录片'}
2020-05-06 08:09:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1005',
 'sectionImg': '',
 'sectionName': '德国之声特辑'}
2020-05-06 08:09:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_747',
 'sectionImg': '',
 'sectionName': '完结力推'}
2020-05-06 08:09:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 1 pages/min), scraped 1038 items (at 25 items/min)
2020-05-06 08:10:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 08:11:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 08:12:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 08:13:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 08:14:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 08:15:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 08:16:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 08:17:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 08:18:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 08:19:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 08:20:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 08:21:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 08:22:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 08:23:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 08:24:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 08:25:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 08:26:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 08:27:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 08:28:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 08:29:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 08:30:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 08:31:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 08:32:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 08:33:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 08:34:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 08:35:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 08:36:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 08:37:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 08:38:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 08:39:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 08:40:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 08:41:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 08:42:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 08:43:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 08:44:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 08:45:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 08:46:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 08:47:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 08:48:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 08:49:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 08:50:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 08:51:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 08:52:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 08:53:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 08:54:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 08:55:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 08:56:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 08:57:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 08:58:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 08:59:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 09:00:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 09:01:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 09:02:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 09:03:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 09:04:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 09:05:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 09:06:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 09:07:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 09:08:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 09:09:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 09:10:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 09:11:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 09:12:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 09:13:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 09:14:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 09:15:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 09:16:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 09:17:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 09:18:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 09:19:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 09:20:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 09:21:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 09:22:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 09:23:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 09:24:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 09:25:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 09:26:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 09:27:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 09:28:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 09:29:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 09:30:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 09:31:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 09:32:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 09:33:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 09:34:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 09:35:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 09:36:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 09:37:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 09:38:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 09:39:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 09:40:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 09:41:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 09:42:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 09:43:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 09:44:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 09:45:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 09:46:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 09:47:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 09:48:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 09:49:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 09:50:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 09:51:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 09:52:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 09:53:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 09:54:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 09:55:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 09:56:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 09:57:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 09:58:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 09:59:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 10:00:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 10:01:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 10:02:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 10:03:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 10:04:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 10:05:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 10:06:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 10:07:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 10:08:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 10:09:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 10:10:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 10:11:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 10:12:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 10:13:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 10:14:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 10:15:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 10:16:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 10:17:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 10:18:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 10:19:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 10:20:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 10:21:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 10:22:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 10:23:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 10:24:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 10:25:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 10:26:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 10:27:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 10:28:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 10:29:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 10:30:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 10:31:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 10:32:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 10:33:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 10:34:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 10:35:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 10:36:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 10:37:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 10:38:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 10:39:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 10:40:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 10:41:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 10:42:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 10:43:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 10:44:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 10:45:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 10:46:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 10:47:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 10:48:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 10:49:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 10:50:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 10:51:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 10:52:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 10:53:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 10:54:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 10:55:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 10:56:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 10:57:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 10:58:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 10:59:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 11:00:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 11:01:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 11:02:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 11:03:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 11:04:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 11:05:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 11:06:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 11:07:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 11:08:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 11:09:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 11:10:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 11:11:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 11:12:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 11:13:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 11:14:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 11:15:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 11:16:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 11:17:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 11:18:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 11:19:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 11:20:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 11:21:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 11:22:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 11:23:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 11:24:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 11:25:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 11:26:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 11:27:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 11:28:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 11:29:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 11:30:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 11:31:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 11:32:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 11:33:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 11:34:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 11:35:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 11:36:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 11:37:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 11:38:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 11:39:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 11:40:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 11:41:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 11:42:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 11:43:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 11:44:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 11:45:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 11:46:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 11:47:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 11:48:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 11:49:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 11:50:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 11:51:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 11:52:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 11:53:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 11:54:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 11:55:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 11:56:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 11:57:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 11:58:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 11:59:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 12:00:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 12:01:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 12:02:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 12:03:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 12:04:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 12:05:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 12:06:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 12:07:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 12:08:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 12:09:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 12:10:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 12:11:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 12:12:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 12:13:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 12:14:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 12:15:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 12:16:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 12:17:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 12:18:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 12:19:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 12:20:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 12:21:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 12:22:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 12:23:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 12:24:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 12:25:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 12:26:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 12:27:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 12:28:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 12:29:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 12:30:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 12:31:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 12:32:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 12:33:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 12:34:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 12:35:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 12:36:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 12:37:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 12:38:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 12:39:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 12:40:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 12:41:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 12:42:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 12:43:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 12:44:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 12:45:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 12:46:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 12:47:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 12:48:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 12:49:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 12:50:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 12:51:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 12:52:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 12:53:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 12:54:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 12:55:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 12:56:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 12:57:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 12:58:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 12:59:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 13:00:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 13:01:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 13:02:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 13:03:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 13:04:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 13:05:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 13:06:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 13:07:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 13:08:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 13:09:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 13:10:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 13:11:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 13:12:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 13:13:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 13:14:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 13:15:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 13:16:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 13:17:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 13:18:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 13:19:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 13:20:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 13:21:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 13:22:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 13:23:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 13:24:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 13:25:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 13:26:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 13:27:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 13:28:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 13:29:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 13:30:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 13:31:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 13:32:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 13:33:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 13:34:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 13:35:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 13:36:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 13:37:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 13:38:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 13:39:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 13:40:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 13:41:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 13:42:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 13:43:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 13:44:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 13:45:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 13:46:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 13:47:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 13:48:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 13:49:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 13:50:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 13:51:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 13:52:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 13:53:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 13:54:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 13:55:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 13:56:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 13:57:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 13:58:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 13:59:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 14:00:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 14:01:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 14:02:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 14:03:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 14:04:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 14:05:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 14:06:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 14:07:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 14:08:19 [scrapy.extensions.logstats] INFO: Crawled 1234 pages (at 0 pages/min), scraped 1038 items (at 0 items/min)
2020-05-06 14:09:04 [rrmj] DEBUG: Read 1 requests from 'rrmj:spider:strat_urls'
2020-05-06 14:09:04 [scrapy.core.engine] DEBUG: Crawled (200) <POST https://api.rr.tv/v3plus/index/channel> (referer: None)
2020-05-06 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1912',
 'sectionImg': '',
 'sectionName': '看剧鉴渣男手撕不心软'}
2020-05-06 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1917',
 'sectionImg': '',
 'sectionName': '抖音爆火洗脑剧'}
2020-05-06 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1904',
 'sectionImg': '',
 'sectionName': '台剧新来袭！！'}
2020-05-06 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1244',
 'sectionImg': '',
 'sectionName': '致我们甜甜的恋爱时光'}
2020-05-06 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_822',
 'sectionImg': '',
 'sectionName': '细思极恐 谁是凶手？'}
2020-05-06 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1926',
 'sectionImg': '',
 'sectionName': '力推！豆瓣高分推荐'}
2020-05-06 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1927',
 'sectionImg': '',
 'sectionName': '深夜舔屏福利'}
2020-05-06 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1646',
 'sectionImg': '',
 'sectionName': '急诊室的人间冷暖'}
2020-05-06 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1903',
 'sectionImg': '',
 'sectionName': '恶魔在人间'}
2020-05-06 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1693',
 'sectionImg': '',
 'sectionName': '病毒藏在每个角落'}
2020-05-06 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_742',
 'sectionImg': '',
 'sectionName': '热剧回归！'}
2020-05-06 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_989',
 'sectionImg': '',
 'sectionName': '腐眼看人基'}
2020-05-06 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1883',
 'sectionImg': '',
 'sectionName': '吃货必备！这些纪录片很“下饭”'}
2020-05-06 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1399',
 'sectionImg': '',
 'sectionName': '他改变了世界'}
2020-05-06 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1729',
 'sectionImg': '',
 'sectionName': '【电影】获奖佳片集结'}
2020-05-06 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1405',
 'sectionImg': '',
 'sectionName': '幕后更精彩'}
2020-05-06 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_745',
 'sectionImg': '',
 'sectionName': '本周新剧'}
2020-05-06 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1431',
 'sectionImg': '',
 'sectionName': 'LGBT人生纪实 '}
2020-05-06 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1416',
 'sectionImg': '',
 'sectionName': '怪奇世界物语'}
2020-05-06 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1421',
 'sectionImg': '',
 'sectionName': '笑到飞起的脱口秀'}
2020-05-06 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1295',
 'sectionImg': '',
 'sectionName': '巨星的诞生'}
2020-05-06 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1425',
 'sectionImg': '',
 'sectionName': '大家都在看'}
2020-05-06 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1657',
 'sectionImg': '',
 'sectionName': '奥斯卡最佳纪录片'}
2020-05-06 14:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1005',
 'sectionImg': '',
 'sectionName': '德国之声特辑'}
2020-05-06 14:09:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_747',
 'sectionImg': '',
 'sectionName': '完结力推'}
2020-05-06 14:09:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 1 pages/min), scraped 1063 items (at 25 items/min)
2020-05-06 14:10:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 14:11:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 14:12:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 14:13:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 14:14:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 14:15:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 14:16:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 14:17:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 14:18:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 14:19:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 14:20:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 14:21:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 14:22:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 14:23:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 14:24:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 14:25:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 14:26:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 14:27:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 14:28:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 14:29:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 14:30:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 14:31:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 14:32:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 14:33:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 14:34:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 14:35:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 14:36:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 14:37:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 14:38:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 14:39:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 14:40:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 14:41:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 14:42:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 14:43:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 14:44:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 14:45:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 14:46:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 14:47:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 14:48:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 14:49:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 14:50:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 14:51:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 14:52:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 14:53:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 14:54:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 14:55:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 14:56:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 14:57:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 14:58:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 14:59:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 15:00:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 15:01:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 15:02:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 15:03:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 15:04:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 15:05:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 15:06:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 15:07:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 15:08:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 15:09:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 15:10:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 15:11:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 15:12:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 15:13:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 15:14:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 15:15:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 15:16:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 15:17:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 15:18:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 15:19:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 15:20:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 15:21:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 15:22:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 15:23:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 15:24:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 15:25:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 15:26:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 15:27:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 15:28:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 15:29:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 15:30:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 15:31:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 15:32:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 15:33:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 15:34:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 15:35:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 15:36:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 15:37:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 15:38:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 15:39:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 15:40:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 15:41:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 15:42:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 15:43:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 15:44:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 15:45:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 15:46:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 15:47:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 15:48:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 15:49:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 15:50:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 15:51:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 15:52:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 15:53:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 15:54:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 15:55:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 15:56:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 15:57:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 15:58:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 15:59:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 16:00:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 16:01:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 16:02:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 16:03:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 16:04:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 16:05:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 16:06:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 16:07:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 16:08:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 16:09:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 16:10:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 16:11:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 16:12:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 16:13:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 16:14:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 16:15:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 16:16:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 16:17:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 16:18:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 16:19:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 16:20:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 16:21:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 16:22:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 16:23:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 16:24:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 16:25:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 16:26:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 16:27:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 16:28:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 16:29:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 16:30:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 16:31:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 16:32:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 16:33:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 16:34:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 16:35:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 16:36:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 16:37:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 16:38:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 16:39:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 16:40:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 16:41:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 16:42:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 16:43:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 16:44:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 16:45:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 16:46:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 16:47:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 16:48:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 16:49:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 16:50:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 16:51:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 16:52:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 16:53:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 16:54:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 16:55:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 16:56:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 16:57:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 16:58:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 16:59:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 17:00:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 17:01:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 17:02:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 17:03:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 17:04:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 17:05:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 17:06:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 17:07:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 17:08:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 17:09:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 17:10:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 17:11:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 17:12:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 17:13:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 17:14:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 17:15:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 17:16:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 17:17:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 17:18:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 17:19:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 17:20:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 17:21:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 17:22:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 17:23:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 17:24:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 17:25:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 17:26:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 17:27:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 17:28:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 17:29:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 17:30:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 17:31:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 17:32:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 17:33:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 17:34:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 17:35:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 17:36:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 17:37:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 17:38:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 17:39:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 17:40:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 17:41:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 17:42:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 17:43:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 17:44:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 17:45:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 17:46:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 17:47:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 17:48:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 17:49:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 17:50:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 17:51:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 17:52:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 17:53:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 17:54:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 17:55:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 17:56:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 17:57:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 17:58:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 17:59:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 18:00:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 18:01:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 18:02:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 18:03:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 18:04:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 18:05:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 18:06:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 18:07:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 18:08:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 18:09:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 18:10:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 18:11:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 18:12:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 18:13:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 18:14:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 18:15:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 18:16:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 18:17:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 18:18:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 18:19:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 18:20:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 18:21:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 18:22:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 18:23:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 18:24:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 18:25:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 18:26:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 18:27:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 18:28:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 18:29:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 18:30:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 18:31:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 18:32:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 18:33:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 18:34:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 18:35:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 18:36:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 18:37:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 18:38:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 18:39:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 18:40:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 18:41:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 18:42:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 18:43:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 18:44:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 18:45:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 18:46:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 18:47:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 18:48:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 18:49:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 18:50:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 18:51:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 18:52:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 18:53:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 18:54:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 18:55:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 18:56:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 18:57:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 18:58:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 18:59:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 19:00:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 19:01:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 19:02:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 19:03:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 19:04:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 19:05:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 19:06:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 19:07:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 19:08:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 19:09:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 19:10:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 19:11:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 19:12:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 19:13:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 19:14:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 19:15:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 19:16:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 19:17:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 19:18:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 19:19:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 19:20:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 19:21:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 19:22:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 19:23:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 19:24:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 19:25:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 19:26:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 19:27:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 19:28:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 19:29:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 19:30:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 19:31:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 19:32:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 19:33:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 19:34:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 19:35:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 19:36:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 19:37:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 19:38:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 19:39:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 19:40:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 19:41:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 19:42:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 19:43:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 19:44:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 19:45:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 19:46:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 19:47:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 19:48:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 19:49:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 19:50:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 19:51:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 19:52:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 19:53:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 19:54:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 19:55:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 19:56:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 19:57:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 19:58:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 19:59:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 20:00:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 20:01:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 20:02:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 20:03:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 20:04:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 20:05:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 20:06:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 20:07:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 20:08:19 [scrapy.extensions.logstats] INFO: Crawled 1235 pages (at 0 pages/min), scraped 1063 items (at 0 items/min)
2020-05-06 20:09:04 [rrmj] DEBUG: Read 1 requests from 'rrmj:spider:strat_urls'
2020-05-06 20:09:04 [scrapy.core.engine] DEBUG: Crawled (200) <POST https://api.rr.tv/v3plus/index/channel> (referer: None)
2020-05-06 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1912',
 'sectionImg': '',
 'sectionName': '看剧鉴渣男手撕不心软'}
2020-05-06 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1917',
 'sectionImg': '',
 'sectionName': '抖音爆火洗脑剧'}
2020-05-06 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1904',
 'sectionImg': '',
 'sectionName': '台剧新来袭！！'}
2020-05-06 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1244',
 'sectionImg': '',
 'sectionName': '致我们甜甜的恋爱时光'}
2020-05-06 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_822',
 'sectionImg': '',
 'sectionName': '细思极恐 谁是凶手？'}
2020-05-06 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1926',
 'sectionImg': '',
 'sectionName': '力推！豆瓣高分推荐'}
2020-05-06 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1927',
 'sectionImg': '',
 'sectionName': '深夜舔屏福利'}
2020-05-06 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1646',
 'sectionImg': '',
 'sectionName': '急诊室的人间冷暖'}
2020-05-06 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1903',
 'sectionImg': '',
 'sectionName': '恶魔在人间'}
2020-05-06 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1693',
 'sectionImg': '',
 'sectionName': '病毒藏在每个角落'}
2020-05-06 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_742',
 'sectionImg': '',
 'sectionName': '热剧回归！'}
2020-05-06 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_989',
 'sectionImg': '',
 'sectionName': '腐眼看人基'}
2020-05-06 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1883',
 'sectionImg': '',
 'sectionName': '吃货必备！这些纪录片很“下饭”'}
2020-05-06 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1399',
 'sectionImg': '',
 'sectionName': '他改变了世界'}
2020-05-06 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1729',
 'sectionImg': '',
 'sectionName': '【电影】获奖佳片集结'}
2020-05-06 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1405',
 'sectionImg': '',
 'sectionName': '幕后更精彩'}
2020-05-06 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_745',
 'sectionImg': '',
 'sectionName': '本周新剧'}
2020-05-06 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1431',
 'sectionImg': '',
 'sectionName': 'LGBT人生纪实 '}
2020-05-06 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1416',
 'sectionImg': '',
 'sectionName': '怪奇世界物语'}
2020-05-06 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1421',
 'sectionImg': '',
 'sectionName': '笑到飞起的脱口秀'}
2020-05-06 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1295',
 'sectionImg': '',
 'sectionName': '巨星的诞生'}
2020-05-06 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1425',
 'sectionImg': '',
 'sectionName': '大家都在看'}
2020-05-06 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1657',
 'sectionImg': '',
 'sectionName': '奥斯卡最佳纪录片'}
2020-05-06 20:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1005',
 'sectionImg': '',
 'sectionName': '德国之声特辑'}
2020-05-06 20:09:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_747',
 'sectionImg': '',
 'sectionName': '完结力推'}
2020-05-06 20:09:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.douban.com/search?q=%E5%A5%B3%E5%AD%A9%E8%88%9E%E6%AD%A5> (referer: https://api.rr.tv/v3plus/index/channel)
2020-05-06 20:09:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://movie.douban.com/subject/26259641/> (referer: https://www.douban.com/search?q=%E5%A5%B3%E5%AD%A9%E8%88%9E%E6%AD%A5)
2020-05-06 20:09:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://movie.douban.com/subject/26259641/>
{'cover': 'http://img.rr.tv/seasonCover/20200506/o_1588754952788.jpg',
 'data_type': 'movie',
 'id': 'rrmj_16532',
 'intro': '一座普通高中内，生活这一群平凡的女孩。貌不惊人的西原梓（石井杏奈 '
          '饰）小心翼翼和隶属拉拉队的同班同学搞好关系，只是因为不想重蹈当年被孤立的覆辙。这一日，她被体育老师叫到办公室，由于之前的缺勤导致学分不够，所以必须去参加某个舞蹈比赛补修学分。和她一起的还有性格阴郁的片濑爱海（小芝风花 '
          '饰）、家境平平的小泽叶月（小野花梨 饰）、只知道念书的岸本环（秋月三佳 饰）以及相貌凶恶的不良少女贵岛美香（上原实矩 '
          '饰）。偏偏担任教练的Kenny（冢本高史 '
          '饰）看起来又是一个不太靠谱的男人，因此这支街舞团成立之初可谓历经磨难。好不容易修够学分，不过女孩们似乎找到人生的方向，她们决定再努力拼搏一次……                                                                    \u3000\u3000'
          '本片根据宇山佳佑的同名原作改编。',
 'is_new': False,
 'name': '女孩舞步',
 'platforms': '',
 'publishdate': '2015-09-12',
 'rate': 7.6,
 'sectionid': 'rrmj_1729',
 'tags': ['剧情'],
 'type': 'movie',
 'url': 'https://movie.douban.com/subject/26259641/'}
2020-05-06 20:09:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 3 pages/min), scraped 1089 items (at 26 items/min)
2020-05-06 20:10:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 20:11:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 20:12:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 20:13:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 20:14:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 20:15:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 20:16:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 20:17:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 20:18:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 20:19:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 20:20:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 20:21:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 20:22:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 20:23:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 20:24:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 20:25:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 20:26:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 20:27:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 20:28:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 20:29:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 20:30:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 20:31:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 20:32:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 20:33:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 20:34:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 20:35:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 20:36:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 20:37:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 20:38:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 20:39:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 20:40:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 20:41:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 20:42:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 20:43:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 20:44:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 20:45:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 20:46:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 20:47:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 20:48:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 20:49:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 20:50:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 20:51:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 20:52:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 20:53:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 20:54:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 20:55:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 20:56:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 20:57:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 20:58:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 20:59:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 21:00:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 21:01:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 21:02:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 21:03:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 21:04:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 21:05:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 21:06:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 21:07:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 21:08:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 21:09:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 21:10:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 21:11:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 21:12:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 21:13:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 21:14:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 21:15:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 21:16:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 21:17:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 21:18:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 21:19:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 21:20:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 21:21:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 21:22:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 21:23:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 21:24:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 21:25:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 21:26:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 21:27:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 21:28:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 21:29:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 21:30:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 21:31:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 21:32:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 21:33:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 21:34:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 21:35:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 21:36:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 21:37:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 21:38:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 21:39:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 21:40:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 21:41:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 21:42:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 21:43:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 21:44:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 21:45:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 21:46:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 21:47:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 21:48:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 21:49:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 21:50:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 21:51:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 21:52:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 21:53:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 21:54:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 21:55:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 21:56:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 21:57:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 21:58:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 21:59:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 22:00:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 22:01:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 22:02:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 22:03:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 22:04:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 22:05:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 22:06:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 22:07:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 22:08:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 22:09:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 22:10:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 22:11:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 22:12:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 22:13:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 22:14:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 22:15:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 22:16:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 22:17:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 22:18:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 22:19:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 22:20:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 22:21:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 22:22:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 22:23:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 22:24:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 22:25:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 22:26:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 22:27:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 22:28:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 22:29:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 22:30:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 22:31:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 22:32:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 22:33:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 22:34:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 22:35:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 22:36:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 22:37:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 22:38:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 22:39:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 22:40:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 22:41:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 22:42:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 22:43:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 22:44:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 22:45:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 22:46:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 22:47:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 22:48:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 22:49:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 22:50:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 22:51:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 22:52:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 22:53:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 22:54:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 22:55:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 22:56:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 22:57:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 22:58:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 22:59:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 23:00:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 23:01:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 23:02:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 23:03:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 23:04:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 23:05:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 23:06:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 23:07:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 23:08:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 23:09:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 23:10:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 23:11:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 23:12:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 23:13:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 23:14:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 23:15:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 23:16:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 23:17:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 23:18:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 23:19:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 23:20:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 23:21:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 23:22:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 23:23:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 23:24:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 23:25:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 23:26:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 23:27:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 23:28:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 23:29:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 23:30:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 23:31:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 23:32:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 23:33:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 23:34:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 23:35:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 23:36:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 23:37:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 23:38:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 23:39:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 23:40:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 23:41:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 23:42:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 23:43:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 23:44:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 23:45:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 23:46:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 23:47:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 23:48:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 23:49:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 23:50:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 23:51:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 23:52:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 23:53:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 23:54:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 23:55:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 23:56:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 23:57:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 23:58:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-06 23:59:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 00:00:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 00:01:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 00:02:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 00:03:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 00:04:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 00:05:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 00:06:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 00:07:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 00:08:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 00:09:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 00:10:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 00:11:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 00:12:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 00:13:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 00:14:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 00:15:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 00:16:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 00:17:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 00:18:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 00:19:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 00:20:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 00:21:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 00:22:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 00:23:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 00:24:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 00:25:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 00:26:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 00:27:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 00:28:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 00:29:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 00:30:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 00:31:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 00:32:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 00:33:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 00:34:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 00:35:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 00:36:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 00:37:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 00:38:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 00:39:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 00:40:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 00:41:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 00:42:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 00:43:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 00:44:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 00:45:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 00:46:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 00:47:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 00:48:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 00:49:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 00:50:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 00:51:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 00:52:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 00:53:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 00:54:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 00:55:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 00:56:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 00:57:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 00:58:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 00:59:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 01:00:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 01:01:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 01:02:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 01:03:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 01:04:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 01:05:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 01:06:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 01:07:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 01:08:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 01:09:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 01:10:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 01:11:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 01:12:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 01:13:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 01:14:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 01:15:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 01:16:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 01:17:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 01:18:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 01:19:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 01:20:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 01:21:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 01:22:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 01:23:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 01:24:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 01:25:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 01:26:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 01:27:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 01:28:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 01:29:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 01:30:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 01:31:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 01:32:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 01:33:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 01:34:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 01:35:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 01:36:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 01:37:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 01:38:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 01:39:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 01:40:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 01:41:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 01:42:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 01:43:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 01:44:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 01:45:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 01:46:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 01:47:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 01:48:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 01:49:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 01:50:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 01:51:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 01:52:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 01:53:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 01:54:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 01:55:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 01:56:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 01:57:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 01:58:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 01:59:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 02:00:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 02:01:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 02:02:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 02:03:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 02:04:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 02:05:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 02:06:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 02:07:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 02:08:19 [scrapy.extensions.logstats] INFO: Crawled 1238 pages (at 0 pages/min), scraped 1089 items (at 0 items/min)
2020-05-07 02:09:04 [rrmj] DEBUG: Read 1 requests from 'rrmj:spider:strat_urls'
2020-05-07 02:09:04 [scrapy.core.engine] DEBUG: Crawled (200) <POST https://api.rr.tv/v3plus/index/channel> (referer: None)
2020-05-07 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1912',
 'sectionImg': '',
 'sectionName': '看剧鉴渣男手撕不心软'}
2020-05-07 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1917',
 'sectionImg': '',
 'sectionName': '抖音爆火洗脑剧'}
2020-05-07 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1904',
 'sectionImg': '',
 'sectionName': '台剧新来袭！！'}
2020-05-07 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1244',
 'sectionImg': '',
 'sectionName': '致我们甜甜的恋爱时光'}
2020-05-07 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_822',
 'sectionImg': '',
 'sectionName': '细思极恐 谁是凶手？'}
2020-05-07 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1926',
 'sectionImg': '',
 'sectionName': '力推！豆瓣高分推荐'}
2020-05-07 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1927',
 'sectionImg': '',
 'sectionName': '深夜舔屏福利'}
2020-05-07 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1646',
 'sectionImg': '',
 'sectionName': '急诊室的人间冷暖'}
2020-05-07 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1903',
 'sectionImg': '',
 'sectionName': '恶魔在人间'}
2020-05-07 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1693',
 'sectionImg': '',
 'sectionName': '病毒藏在每个角落'}
2020-05-07 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_742',
 'sectionImg': '',
 'sectionName': '热剧回归！'}
2020-05-07 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_989',
 'sectionImg': '',
 'sectionName': '腐眼看人基'}
2020-05-07 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1883',
 'sectionImg': '',
 'sectionName': '吃货必备！这些纪录片很“下饭”'}
2020-05-07 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1399',
 'sectionImg': '',
 'sectionName': '他改变了世界'}
2020-05-07 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1729',
 'sectionImg': '',
 'sectionName': '【电影】获奖佳片集结'}
2020-05-07 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1405',
 'sectionImg': '',
 'sectionName': '幕后更精彩'}
2020-05-07 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_745',
 'sectionImg': '',
 'sectionName': '本周新剧'}
2020-05-07 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1431',
 'sectionImg': '',
 'sectionName': 'LGBT人生纪实 '}
2020-05-07 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1416',
 'sectionImg': '',
 'sectionName': '怪奇世界物语'}
2020-05-07 02:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1421',
 'sectionImg': '',
 'sectionName': '笑到飞起的脱口秀'}
2020-05-07 02:09:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1295',
 'sectionImg': '',
 'sectionName': '巨星的诞生'}
2020-05-07 02:09:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1425',
 'sectionImg': '',
 'sectionName': '大家都在看'}
2020-05-07 02:09:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1657',
 'sectionImg': '',
 'sectionName': '奥斯卡最佳纪录片'}
2020-05-07 02:09:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1005',
 'sectionImg': '',
 'sectionName': '德国之声特辑'}
2020-05-07 02:09:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_747',
 'sectionImg': '',
 'sectionName': '完结力推'}
2020-05-07 02:09:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 1 pages/min), scraped 1114 items (at 25 items/min)
2020-05-07 02:10:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 02:11:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 02:12:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 02:13:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 02:14:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 02:15:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 02:16:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 02:17:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 02:18:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 02:19:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 02:20:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 02:21:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 02:22:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 02:23:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 02:24:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 02:25:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 02:26:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 02:27:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 02:28:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 02:29:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 02:30:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 02:31:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 02:32:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 02:33:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 02:34:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 02:35:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 02:36:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 02:37:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 02:38:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 02:39:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 02:40:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 02:41:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 02:42:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 02:43:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 02:44:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 02:45:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 02:46:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 02:47:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 02:48:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 02:49:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 02:50:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 02:51:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 02:52:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 02:53:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 02:54:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 02:55:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 02:56:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 02:57:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 02:58:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 02:59:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 03:00:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 03:01:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 03:02:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 03:03:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 03:04:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 03:05:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 03:06:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 03:07:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 03:08:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 03:09:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 03:10:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 03:11:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 03:12:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 03:13:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 03:14:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 03:15:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 03:16:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 03:17:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 03:18:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 03:19:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 03:20:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 03:21:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 03:22:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 03:23:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 03:24:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 03:25:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 03:26:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 03:27:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 03:28:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 03:29:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 03:30:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 03:31:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 03:32:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 03:33:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 03:34:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 03:35:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 03:36:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 03:37:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 03:38:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 03:39:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 03:40:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 03:41:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 03:42:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 03:43:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 03:44:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 03:45:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 03:46:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 03:47:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 03:48:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 03:49:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 03:50:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 03:51:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 03:52:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 03:53:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 03:54:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 03:55:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 03:56:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 03:57:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 03:58:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 03:59:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 04:00:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 04:01:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 04:02:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 04:03:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 04:04:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 04:05:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 04:06:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 04:07:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 04:08:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 04:09:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 04:10:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 04:11:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 04:12:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 04:13:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 04:14:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 04:15:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 04:16:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 04:17:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 04:18:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 04:19:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 04:20:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 04:21:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 04:22:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 04:23:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 04:24:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 04:25:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 04:26:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 04:27:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 04:28:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 04:29:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 04:30:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 04:31:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 04:32:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 04:33:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 04:34:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 04:35:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 04:36:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 04:37:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 04:38:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 04:39:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 04:40:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 04:41:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 04:42:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 04:43:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 04:44:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 04:45:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 04:46:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 04:47:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 04:48:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 04:49:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 04:50:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 04:51:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 04:52:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 04:53:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 04:54:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 04:55:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 04:56:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 04:57:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 04:58:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 04:59:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 05:00:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 05:01:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 05:02:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 05:03:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 05:04:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 05:05:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 05:06:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 05:07:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 05:08:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 05:09:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 05:10:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 05:11:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 05:12:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 05:13:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 05:14:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 05:15:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 05:16:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 05:17:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 05:18:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 05:19:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 05:20:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 05:21:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 05:22:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 05:23:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 05:24:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 05:25:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 05:26:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 05:27:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 05:28:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 05:29:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 05:30:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 05:31:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 05:32:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 05:33:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 05:34:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 05:35:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 05:36:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 05:37:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 05:38:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 05:39:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 05:40:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 05:41:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 05:42:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 05:43:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 05:44:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 05:45:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 05:46:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 05:47:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 05:48:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 05:49:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 05:50:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 05:51:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 05:52:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 05:53:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 05:54:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 05:55:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 05:56:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 05:57:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 05:58:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 05:59:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 06:00:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 06:01:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 06:02:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 06:03:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 06:04:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 06:05:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 06:06:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 06:07:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 06:08:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 06:09:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 06:10:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 06:11:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 06:12:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 06:13:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 06:14:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 06:15:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 06:16:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 06:17:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 06:18:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 06:19:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 06:20:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 06:21:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 06:22:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 06:23:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 06:24:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 06:25:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 06:26:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 06:27:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 06:28:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 06:29:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 06:30:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 06:31:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 06:32:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 06:33:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 06:34:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 06:35:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 06:36:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 06:37:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 06:38:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 06:39:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 06:40:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 06:41:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 06:42:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 06:43:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 06:44:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 06:45:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 06:46:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 06:47:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 06:48:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 06:49:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 06:50:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 06:51:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 06:52:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 06:53:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 06:54:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 06:55:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 06:56:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 06:57:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 06:58:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 06:59:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 07:00:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 07:01:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 07:02:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 07:03:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 07:04:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 07:05:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 07:06:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 07:07:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 07:08:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 07:09:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 07:10:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 07:11:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 07:12:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 07:13:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 07:14:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 07:15:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 07:16:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 07:17:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 07:18:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 07:19:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 07:20:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 07:21:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 07:22:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 07:23:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 07:24:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 07:25:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 07:26:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 07:27:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 07:28:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 07:29:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 07:30:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 07:31:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 07:32:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 07:33:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 07:34:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 07:35:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 07:36:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 07:37:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 07:38:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 07:39:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 07:40:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 07:41:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 07:42:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 07:43:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 07:44:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 07:45:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 07:46:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 07:47:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 07:48:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 07:49:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 07:50:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 07:51:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 07:52:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 07:53:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 07:54:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 07:55:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 07:56:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 07:57:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 07:58:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 07:59:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 08:00:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 08:01:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 08:02:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 08:03:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 08:04:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 08:05:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 08:06:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 08:07:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 08:08:19 [scrapy.extensions.logstats] INFO: Crawled 1239 pages (at 0 pages/min), scraped 1114 items (at 0 items/min)
2020-05-07 08:09:04 [rrmj] DEBUG: Read 1 requests from 'rrmj:spider:strat_urls'
2020-05-07 08:09:04 [scrapy.core.engine] DEBUG: Crawled (200) <POST https://api.rr.tv/v3plus/index/channel> (referer: None)
2020-05-07 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1912',
 'sectionImg': '',
 'sectionName': '看剧鉴渣男手撕不心软'}
2020-05-07 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1917',
 'sectionImg': '',
 'sectionName': '抖音爆火洗脑剧'}
2020-05-07 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1904',
 'sectionImg': '',
 'sectionName': '台剧新来袭！！'}
2020-05-07 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1244',
 'sectionImg': '',
 'sectionName': '致我们甜甜的恋爱时光'}
2020-05-07 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_822',
 'sectionImg': '',
 'sectionName': '细思极恐 谁是凶手？'}
2020-05-07 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1926',
 'sectionImg': '',
 'sectionName': '力推！豆瓣高分推荐'}
2020-05-07 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1927',
 'sectionImg': '',
 'sectionName': '深夜舔屏福利'}
2020-05-07 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1646',
 'sectionImg': '',
 'sectionName': '急诊室的人间冷暖'}
2020-05-07 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1903',
 'sectionImg': '',
 'sectionName': '恶魔在人间'}
2020-05-07 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1693',
 'sectionImg': '',
 'sectionName': '病毒藏在每个角落'}
2020-05-07 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_742',
 'sectionImg': '',
 'sectionName': '热剧回归！'}
2020-05-07 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_989',
 'sectionImg': '',
 'sectionName': '腐眼看人基'}
2020-05-07 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1883',
 'sectionImg': '',
 'sectionName': '吃货必备！这些纪录片很“下饭”'}
2020-05-07 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1399',
 'sectionImg': '',
 'sectionName': '他改变了世界'}
2020-05-07 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1729',
 'sectionImg': '',
 'sectionName': '【电影】获奖佳片集结'}
2020-05-07 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1405',
 'sectionImg': '',
 'sectionName': '幕后更精彩'}
2020-05-07 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_745',
 'sectionImg': '',
 'sectionName': '本周新剧'}
2020-05-07 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1431',
 'sectionImg': '',
 'sectionName': 'LGBT人生纪实 '}
2020-05-07 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1416',
 'sectionImg': '',
 'sectionName': '怪奇世界物语'}
2020-05-07 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1421',
 'sectionImg': '',
 'sectionName': '笑到飞起的脱口秀'}
2020-05-07 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1295',
 'sectionImg': '',
 'sectionName': '巨星的诞生'}
2020-05-07 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1425',
 'sectionImg': '',
 'sectionName': '大家都在看'}
2020-05-07 08:09:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1657',
 'sectionImg': '',
 'sectionName': '奥斯卡最佳纪录片'}
2020-05-07 08:09:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_1005',
 'sectionImg': '',
 'sectionName': '德国之声特辑'}
2020-05-07 08:09:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://api.rr.tv/v3plus/index/channel>
{'data_type': 'section',
 'sectionId': 'rrmj_747',
 'sectionImg': '',
 'sectionName': '完结力推'}
2020-05-07 08:09:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 1 pages/min), scraped 1139 items (at 25 items/min)
2020-05-07 08:10:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 08:11:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 08:12:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 08:13:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 08:14:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 08:15:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 08:16:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 08:17:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 08:18:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 08:19:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 08:20:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 08:21:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 08:22:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 08:23:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 08:24:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 08:25:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 08:26:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 08:27:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 08:28:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 08:29:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 08:30:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 08:31:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 08:32:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 08:33:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 08:34:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 08:35:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 08:36:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 08:37:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 08:38:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 08:39:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 08:40:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 08:41:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 08:42:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 08:43:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 08:44:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 08:45:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 08:46:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 08:47:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 08:48:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 08:49:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 08:50:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 08:51:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 08:52:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 08:53:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 08:54:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 08:55:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 08:56:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 08:57:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 08:58:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 08:59:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 09:00:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 09:01:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 09:02:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 09:03:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 09:04:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 09:05:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 09:06:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 09:07:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 09:08:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 09:09:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 09:10:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 09:11:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 09:12:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 09:13:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 09:14:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 09:15:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 09:16:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 09:17:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 09:18:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 09:19:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 09:20:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 09:21:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 09:22:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 09:23:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 09:24:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 09:25:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 09:26:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 09:27:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 09:28:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 09:29:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 09:30:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 09:31:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 09:32:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 09:33:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 09:34:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 09:35:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 09:36:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 09:37:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 09:38:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 09:39:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 09:40:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 09:41:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 09:42:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 09:43:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 09:44:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 09:45:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 09:46:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 09:47:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 09:48:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 09:49:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 09:50:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 09:51:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 09:52:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 09:53:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 09:54:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 09:55:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 09:56:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 09:57:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 09:58:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 09:59:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 10:00:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 10:01:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 10:02:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 10:03:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 10:04:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 10:05:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 10:06:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 10:07:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 10:08:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 10:09:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 10:10:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 10:11:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 10:12:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 10:13:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 10:14:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 10:15:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 10:16:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 10:17:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 10:18:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 10:19:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 10:20:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 10:21:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 10:22:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 10:23:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 10:24:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 10:25:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 10:26:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 10:27:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 10:28:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 10:29:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 10:30:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 10:31:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 10:32:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 10:33:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 10:34:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 10:35:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 10:36:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 10:37:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 10:38:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 10:39:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 10:40:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 10:41:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 10:42:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 10:43:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 10:44:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 10:45:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 10:46:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 10:47:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 10:48:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 10:49:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 10:50:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 10:51:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 10:52:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 10:53:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 10:54:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 10:55:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 10:56:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 10:57:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 10:58:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 10:59:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 11:00:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 11:01:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 11:02:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 11:03:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 11:04:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 11:05:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 11:06:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 11:07:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 11:08:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 11:09:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 11:10:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 11:11:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 11:12:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 11:13:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 11:14:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 11:15:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 11:16:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 11:17:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 11:18:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 11:19:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 11:20:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 11:21:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 11:22:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 11:23:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 11:24:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 11:25:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 11:26:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 11:27:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 11:28:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 11:29:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 11:30:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 11:31:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 11:32:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 11:33:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 11:34:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 11:35:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 11:36:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 11:37:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 11:38:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 11:39:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 11:40:19 [scrapy.extensions.logstats] INFO: Crawled 1240 pages (at 0 pages/min), scraped 1139 items (at 0 items/min)
2020-05-07 11:40:53 [scrapy.crawler] INFO: Received SIGTERM, shutting down gracefully. Send again to force 
2020-05-07 11:40:53 [scrapy.core.engine] INFO: Closing spider (shutdown)
2020-05-07 11:40:53 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 669210,
 'downloader/request_count': 1332,
 'downloader/request_method_count/GET': 1304,
 'downloader/request_method_count/POST': 28,
 'downloader/response_bytes': 21946533,
 'downloader/response_count': 1332,
 'downloader/response_status_count/200': 1067,
 'downloader/response_status_count/302': 92,
 'downloader/response_status_count/403': 92,
 'downloader/response_status_count/404': 81,
 'elapsed_time_seconds': 595894.607471,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2020, 5, 7, 3, 40, 53, 903614),
 'httperror/response_ignored_count': 173,
 'httperror/response_ignored_status_count/403': 92,
 'httperror/response_ignored_status_count/404': 81,
 'item_scraped_count': 1139,
 'log_count/DEBUG': 2501,
 'log_count/ERROR': 13,
 'log_count/INFO': 10117,
 'log_count/WARNING': 1,
 'memusage/max': 100884480,
 'memusage/startup': 69902336,
 'request_depth_max': 2,
 'response_received_count': 1240,
 'scheduler/dequeued/redis': 1332,
 'scheduler/enqueued/redis': 1014,
 'start_time': datetime.datetime(2020, 4, 30, 6, 9, 19, 296143)}
2020-05-07 11:40:53 [scrapy.core.engine] INFO: Spider closed (shutdown)
